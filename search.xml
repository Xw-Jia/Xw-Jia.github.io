<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>9.2_Recommender_Systems</title>
      <link href="/2020/02/07/9-2-recommender-systems/"/>
      <url>/2020/02/07/9-2-recommender-systems/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-b1a09f95c4c0e4ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-Predicting-Movie-Ratings"><a href="#ä¸€-Predicting-Movie-Ratings" class="headerlink" title="ä¸€. Predicting Movie Ratings"></a>ä¸€. Predicting Movie Ratings</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/80_1.png" alt=""></p><p>ä»¥é¢„æµ‹ç¬¬3éƒ¨ç”µå½±ç¬¬1ä¸ªç”¨æˆ·å¯èƒ½è¯„çš„åˆ†æ•°ä¸ºä¾‹å­ã€‚</p><p>é¦–å…ˆæˆ‘ä»¬ç”¨ $x_1$ è¡¨ç¤ºçˆ±æƒ…æµªæ¼«ç”µå½±ç±»å‹ï¼Œ $x_2$ è¡¨ç¤ºåŠ¨ä½œç‰‡ç±»å‹ã€‚ä¸Šå›¾å·¦è¡¨å³ä¾§åˆ™ä¸ºæ¯éƒ¨ç”µå½±å¯¹äºè¿™ä¸¤ä¸ªåˆ†ç±»çš„ç›¸å…³ç¨‹åº¦ã€‚æˆ‘ä»¬é»˜è®¤ $x_0=1$ ã€‚åˆ™ç¬¬ä¸€éƒ¨ç”µå½±ä¸ä¸¤ä¸ªç±»å‹çš„ç›¸å…³ç¨‹åº¦å¯ä»¥è¿™æ ·è¡¨ç¤ºï¼š </p>$x^{(3)}=\left[ \begin{array}{ccc}1 \\0.99 \\0 \end{array} \right]$ ã€‚ç„¶åç”¨ $\theta^{(j)}$ è¡¨ç¤ºç¬¬ j ä¸ªç”¨æˆ·å¯¹äºè¯¥ç§ç±»ç”µå½±çš„è¯„åˆ†ã€‚è¿™é‡Œæˆ‘ä»¬å‡è®¾å·²ç»çŸ¥é“ï¼ˆè¯¦æƒ…ä¸‹é¢å†è®²ï¼‰ $\theta^{(1)}=\left[ \begin{array}{ccc}0 \\5 \\0 \end{array} \right]$ ï¼Œé‚£ä¹ˆæˆ‘ä»¬ç”¨ $(\theta^{(j)})^Tx^{(i)}$ å³å¯è®¡ç®—å‡ºæµ‹ç¬¬3éƒ¨ç”µå½±ç¬¬1ä¸ªç”¨æˆ·å¯èƒ½è¯„çš„åˆ†æ•°ã€‚è¿™é‡Œè®¡ç®—å‡ºæ˜¯4.95ã€‚<h3 id="1-ç›®æ ‡ä¼˜åŒ–"><a href="#1-ç›®æ ‡ä¼˜åŒ–" class="headerlink" title="1. ç›®æ ‡ä¼˜åŒ–"></a>1. ç›®æ ‡ä¼˜åŒ–</h3><p>ä¸ºäº†å¯¹ç”¨æˆ· j æ‰“åˆ†çŠ¶å†µä½œå‡ºæœ€ç²¾ç¡®çš„é¢„æµ‹ï¼Œæˆ‘ä»¬éœ€è¦ï¼š</p><p>$$\min_{(\theta^{(j)})}=\frac{1}{2}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$</p><p>è®¡ç®—å‡ºæ‰€æœ‰çš„ $\theta$ ä¸ºï¼š </p><p>$$J(\theta^{(1)},\cdots,\theta^{(n_u)})=\min_{(\theta^{(1)},\cdots,\theta^{(n_u)})}=\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$</p><p>ä¸å‰é¢æ‰€å­¦çº¿æ€§å›å½’å†…å®¹çš„æ€è·¯ä¸€è‡´ï¼Œä¸ºäº†è®¡ç®—å‡º $J(\theta^{(1)},\cdots,\theta^{(n_u)})$ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥æ›´æ–°å‚æ•°ï¼š</p><p>æ›´æ–°åç½®ï¼ˆæ’å€¼ï¼‰ï¼š</p>$$\theta^{(j)}_0=\theta^{(j)}_0-\alpha \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_0$$<p>æ›´æ–°æƒé‡ï¼š</p>$$\theta^{(j)}_k=\theta^{(j)}_k-\alpha \left( \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_k+\lambda \theta^{(j)}_k \right),\;\;\; k \neq 0$$<hr><h2 id="äºŒ-Collaborative-Filtering-ååŒè¿‡æ»¤"><a href="#äºŒ-Collaborative-Filtering-ååŒè¿‡æ»¤" class="headerlink" title="äºŒ. Collaborative Filtering ååŒè¿‡æ»¤"></a>äºŒ. Collaborative Filtering ååŒè¿‡æ»¤</h2><p>å‰ææ˜¯æˆ‘ä»¬çŸ¥é“äº† $\theta^{(j)}$ ä¹Ÿå°±æ˜¯æ¯ä¸ªç”¨æˆ·å¯¹äºå„ä¸ªç”µå½±ç±»å‹çš„å–œçˆ±ç¨‹åº¦ã€‚é‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æ ¹æ®å„ä¸ªç”¨æˆ·å¯¹å„éƒ¨ç”µå½±çš„è¯„åˆ†= $(\theta^{(j)})^Tx^{(i)}$ åæ¨å‡º $x^{(i)}$ ã€‚</p><h3 id="1-ç›®æ ‡ä¼˜åŒ–-1"><a href="#1-ç›®æ ‡ä¼˜åŒ–-1" class="headerlink" title="1. ç›®æ ‡ä¼˜åŒ–"></a>1. ç›®æ ‡ä¼˜åŒ–</h3><p>å½“ç”¨æˆ·ç»™å‡ºä»–ä»¬å–œæ¬¢çš„ç±»å‹ï¼Œå³ $\theta^{(1)},\cdots,\theta^{(n_u)}$ ï¼Œæˆ‘ä»¬å¯ä»¥ç”±ä¸‹åˆ—å¼å­å¾—å‡º $x^{(i)}$ ï¼š </p><p>$$\min_{(x^{(i)})}=\frac{1}{2}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{k=1}^{n}{(x_k^{(i)})^2}$$</p><p>å¯å‡ºæ‰€æœ‰çš„ x åˆ™ä¸ºï¼š</p><p>$$\min_{(x^{(1)},\cdots,x^{(n_m)})}=\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}$$</p><p>åªè¦æˆ‘ä»¬å¾—åˆ° $\theta$ æˆ–è€… x ï¼Œéƒ½èƒ½äº’ç›¸æ¨å¯¼å‡ºæ¥ã€‚</p><p>ååŒè¿‡æ»¤ç®—æ³•åŸºæœ¬æ€æƒ³å°±æ˜¯å½“æˆ‘ä»¬å¾—åˆ°å…¶ä¸­ä¸€ä¸ªæ•°æ®çš„æ—¶å€™ï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºå¦ä¸€ä¸ªï¼Œç„¶åæ ¹æ®æ¨å¯¼å‡ºæ¥çš„å†æ¨å¯¼å›å»è¿›è¡Œä¼˜åŒ–ï¼Œä¼˜åŒ–åå†ç»§ç»­æ¨å¯¼ç»§ç»­ä¼˜åŒ–ï¼Œå¦‚æ­¤å¾ªç¯ååŒæ¨å¯¼ã€‚</p><h3 id="2-ååŒè¿‡æ»¤çš„ç›®æ ‡ä¼˜åŒ–"><a href="#2-ååŒè¿‡æ»¤çš„ç›®æ ‡ä¼˜åŒ–" class="headerlink" title="2. ååŒè¿‡æ»¤çš„ç›®æ ‡ä¼˜åŒ–"></a>2. ååŒè¿‡æ»¤çš„ç›®æ ‡ä¼˜åŒ–</h3><ol><li>æ¨æµ‹ç”¨æˆ·å–œå¥½ï¼šç»™å®š$x^{(1)},\cdots,x^{(n_m)}$ ï¼Œä¼°è®¡$\theta^{(1)},\cdots,\theta^{(n_\mu)}$ ï¼š<br>$$\min_{(\theta^{(1)},\cdots,\theta^{(n_\mu)})}=\frac{1}{2}\sum_{j=1}^{n_\mu}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_\mu}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$</li><li>æ¨æµ‹å•†å“å†…å®¹ï¼šç»™å®š$\theta^{(1)},\cdots,\theta^{(n_\mu)}$ ï¼Œä¼°è®¡$x^{(1)},\cdots,x^{(n_m)}$ ï¼š<br>$$\min_{(x^{(1)},\cdots,x^{(n_m)})}=\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}$$</li><li>ååŒè¿‡æ»¤ï¼šåŒæ—¶ä¼˜åŒ–$x^{(1)},\cdots,x^{(n_m)}$ ï¼Œä¼°è®¡$\theta^{(1)},\cdots,\theta^{(n_\mu)}$ï¼š<br>$$\min ; J(x^{(1)},\cdots,x^{(n_m)};\theta^{(1)},\cdots,\theta^{(n_\mu)})$$</li></ol><p>å³ï¼š</p><p>$$\min_{(x^{(1)},\cdots,x^{(n_m)};\theta^{(1)},\cdots,\theta^{(n_\mu)})}=\frac{1}{2}\sum_{(i,j):r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}$$</p><p>å› ä¸ºæ­£åˆ™åŒ–çš„åŸå› åœ¨è¿™é‡Œé¢ä¸å†æœ‰ä¹‹å‰çš„ $x_0=1$,$\theta_0=0$ ã€‚</p><h3 id="3-ååŒè¿‡æ»¤ç®—æ³•çš„æ­¥éª¤ä¸ºï¼š"><a href="#3-ååŒè¿‡æ»¤ç®—æ³•çš„æ­¥éª¤ä¸ºï¼š" class="headerlink" title="3. ååŒè¿‡æ»¤ç®—æ³•çš„æ­¥éª¤ä¸ºï¼š"></a>3. ååŒè¿‡æ»¤ç®—æ³•çš„æ­¥éª¤ä¸ºï¼š</h3><ol><li>éšæœºåˆå§‹åŒ–$x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_\mu)} $ä¸ºä¸€äº›è¾ƒå°å€¼ï¼Œä¸ç¥ç»ç½‘ç»œçš„å‚æ•°åˆå§‹åŒ–ç±»ä¼¼ï¼Œä¸ºé¿å…ç³»ç»Ÿé™·å…¥åƒµæ­»çŠ¶æ€ï¼Œä¸ä½¿ç”¨ 0 å€¼åˆå§‹åŒ–ã€‚</li><li>é€šè¿‡æ¢¯åº¦ä¸‹é™çš„ç®—æ³•è®¡ç®—å‡º$J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_\mu)})$,å‚æ•°æ›´æ–°å¼ä¸ºï¼š   $$x^{(i)}_k=x^{(i)}_k-\alpha \left( \sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta^{(j)}_k+\lambda x^{(i)}_k \right)$$   $$\theta^{(j)}_k=\theta^{(j)}_k-\alpha \left( \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_k+\lambda \theta^{(j)}_k \right)$$   </li><li>å¦‚æœç”¨æˆ·çš„åå¥½å‘é‡ä¸º$\theta$ï¼Œè€Œå•†å“çš„ç‰¹å¾å‘é‡ä¸º x ï¼Œåˆ™å¯ä»¥é¢„æµ‹ç”¨æˆ·è¯„ä»·ä¸º $\theta^Tx$ ã€‚</li></ol><p>å› ä¸ºååŒè¿‡æ»¤ç®—æ³• $\theta$ å’Œ x ç›¸äº’å½±å“ï¼Œå› æ­¤ï¼ŒäºŒè€…éƒ½æ²¡å¿…è¦ä½¿ç”¨åç½® $\theta_0$ å’Œ $x_0$ï¼Œå³ï¼Œ$x \in \mathbb{R}^n$ã€ $\theta \in \mathbb{R}^n$ ã€‚</p><hr><h2 id="ä¸‰-Low-Rank-Matrix-Factorization-ä½ç§©çŸ©é˜µåˆ†è§£"><a href="#ä¸‰-Low-Rank-Matrix-Factorization-ä½ç§©çŸ©é˜µåˆ†è§£" class="headerlink" title="ä¸‰. Low Rank Matrix Factorization ä½ç§©çŸ©é˜µåˆ†è§£"></a>ä¸‰. Low Rank Matrix Factorization ä½ç§©çŸ©é˜µåˆ†è§£</h2><h3 id="1-å‘é‡åŒ–"><a href="#1-å‘é‡åŒ–" class="headerlink" title="1. å‘é‡åŒ–"></a>1. å‘é‡åŒ–</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/80_2.png" alt=""></p><p>è¿˜æ˜¯ä»¥ç”µå½±è¯„åˆ†ä¸ºä¾‹å­ã€‚é¦–å…ˆæˆ‘ä»¬å°†ç”¨æˆ·çš„è¯„åˆ†å†™æˆä¸€ä¸ªçŸ©é˜µ Y ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/80_3.png" alt=""></p><p>æ›´ä¸ºè¯¦ç»†çš„è¡¨è¾¾å¦‚ä¸Šå›¾æ‰€ç¤ºã€‚çŸ©é˜µ Y å¯è¡¨ç¤ºä¸º $\Theta^TX$ ã€‚è¿™ä¸ªç®—æ³•ä¹Ÿå«ä½ç§©çŸ©é˜µåˆ†è§£ï¼ˆLow Rank Matric Factorizationï¼‰ã€‚</p><h3 id="2-å‡å€¼æ ‡å‡†åŒ–-Mean-Normalization"><a href="#2-å‡å€¼æ ‡å‡†åŒ–-Mean-Normalization" class="headerlink" title="2. å‡å€¼æ ‡å‡†åŒ– Mean Normalization"></a>2. å‡å€¼æ ‡å‡†åŒ– Mean Normalization</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/80_4.png" alt=""></p><p>å½“æœ‰ä¸€ä¸ªç”¨æˆ·ä»€ä¹ˆç”µå½±éƒ½æ²¡æœ‰çœ‹è¿‡çš„è¯ï¼Œæˆ‘ä»¬ç”¨ $\Theta^TX$ è®¡ç®—æœ€åå¾—åˆ°çš„ç»“æœå…¨éƒ¨éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå¹¶ä¸èƒ½å¾ˆå¥½åœ°æ¨èå“ªä¸€éƒ¨ç”µå½±ç»™ä»–ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/80_5.png" alt=""></p><p>å‡å€¼å½’ä¸€åŒ–è¦åšçš„å°±æ˜¯å…ˆè®¡ç®—æ¯ä¸€è¡Œçš„å¹³å‡å€¼ï¼Œå†å°†æ¯ä¸€ä¸ªæ•°æ®å‡å»è¯¥è¡Œçš„å¹³å‡å€¼ï¼Œå¾—å‡ºä¸€ä¸ªæ–°çš„è¯„åˆ†çŸ©é˜µã€‚ç„¶åæ ¹æ®è¿™ä¸ªçŸ©é˜µæ‹Ÿåˆå‡º $\Theta^TX$ ï¼Œæœ€åçš„è¡¡é‡ç»“æœåŠ ä¸Šå¹³å‡å€¼ï¼Œå³ï¼š $\Theta^TX+\mu_i$ ã€‚è€Œè¯¥ $\mu_i$ å°±ä½œä¸ºä¹‹å‰ä»€ä¹ˆéƒ½æ²¡æœ‰çš„ä¸€ä¸ªæƒå€¼è¿›è¡Œæ¨èã€‚</p><hr><h2 id="å››-Recommender-Systems-æµ‹è¯•"><a href="#å››-Recommender-Systems-æµ‹è¯•" class="headerlink" title="å››. Recommender Systems æµ‹è¯•"></a>å››. Recommender Systems æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose you run a bookstore, and have ratings (1 to 5 stars) of books. Your collaborative filtering algorithm has learned a parameter vector Î¸(j) for user j, and a feature vector x(i) for each book. You would like to compute the â€œtraining errorâ€, meaning the average squared error of your systemâ€™s predictions on all the ratings that you have gotten from your users. Which of these are correct ways of doing so (check all that apply)? For this problem, let m be the total number of ratings you have gotten from your users. (Another way of saying this is that $m=\sum^{n_m}_{i=1}\sum^{n_\mu}_{j=1}r(i,j))$. [Hint: Two of the four options below are correct.]</p><p>A. $$\frac{1}{m}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^{T}x_{i}^{(i)}-y^{(i,j)})^2$$</p><p>B. $$\frac{1}{m}\sum^{n_\mu}_{i=1}\sum_{j:r(i,j)=1}(\sum_{k=1}^{n}(\theta^{(j)})_{k}x_{k}^{(i)}-y^{(i,j)})^2$$</p><p>C. $$\frac{1}{m}\sum^{n_\mu}_{j=1}\sum_{i:r(i,j)=1}(\sum_{k=1}^{n}(\theta^{(k)})_{j}x_{i}^{(k)}-y^{(i,j)})^2$$</p><p>D. $$\frac{1}{m}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^{T}x_{i}^{(i)}-r(i,j))^2$$</p><p>è§£ç­”ï¼šAã€B</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>In which of the following situations will a collaborative filtering system be the most appropriate learning algorithm (compared to linear or logistic regression)?</p><p>A. You run an online bookstore and collect the ratings of many users. You want to use this to identify what books are â€œsimilarâ€ to each other (i.e., if one user likes a certain book, what are other books that she might also like?)</p><p>B. You own a clothing store that sells many styles and brands of jeans. You have collected reviews of the different styles and brands from frequent shoppers, and you want to use these reviews to offer those shoppers discounts on the jeans you think they are most likely to purchase</p><p>C. You manage an online bookstore and you have the book ratings from many users. You want to learn to predict the expected sales volume (number of books sold) as a function of the average rating of a book.</p><p>D. Youâ€™re an artist and hand-paint portraits for your clients. Each client gets a different portrait (of themselves) and gives you 1-5 star rating feedback, and each client purchases at most 1 portrait. Youâ€™d like to predict what rating your next customer will give you.</p><p>è§£ç­”ï¼šAã€B</p><p>ååŒè¿‡æ»¤ç®—æ³•çš„è¦æ±‚æ˜¯ç‰¹å¾é‡å’Œæ•°æ®æ¯”è¾ƒå¤šã€‚</p><p>A. æ‚¨è¿è¡Œåœ¨çº¿ä¹¦åº—å¹¶æ”¶é›†è®¸å¤šç”¨æˆ·çš„è¯„åˆ†ã€‚ä½ æƒ³ç”¨è¿™ä¸ªæ¥ç¡®å®šå“ªäº›ä¹¦æ˜¯å½¼æ­¤â€œç›¸ä¼¼â€çš„ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªç”¨æˆ·å–œæ¬¢æŸæœ¬ä¹¦ï¼Œå¥¹å¯èƒ½è¿˜å–œæ¬¢å…¶ä»–ä¹¦ï¼Ÿï¼‰ç‰¹å¾é‡å¾ˆå¤šï¼ŒååŒè¿‡æ»¤ã€‚</p><p>B. ä½ æ‹¥æœ‰ä¸€å®¶é”€å”®å¤šç§é£æ ¼å’Œå“ç‰Œç‰›ä»”è£¤çš„æœè£…åº—ã€‚æ‚¨å·²ç»æ”¶é›†äº†æ¥è‡ªç»å¸¸è´­ç‰©è€…çš„ä¸åŒæ¬¾å¼å’Œå“ç‰Œçš„è¯„è®ºï¼Œå¹¶ä¸”æ‚¨å¸Œæœ›ä½¿ç”¨è¿™äº›è¯„è®ºä¸ºæ‚¨è®¤ä¸ºä»–ä»¬æœ€æœ‰å¯èƒ½è´­ä¹°çš„ç‰›ä»”è£¤æä¾›è¿™äº›è´­ç‰©è€…æŠ˜æ‰£ã€‚ç‰¹å¾é‡å¾ˆå¤šï¼ŒååŒè¿‡æ»¤ã€‚</p><p>C. æ‚¨å¯ä»¥ç®¡ç†åœ¨çº¿ä¹¦åº—ï¼Œå¹¶æ‹¥æœ‰æ¥è‡ªè®¸å¤šç”¨æˆ·çš„å›¾ä¹¦è¯„åˆ†ã€‚ä½ æƒ³è¦å­¦ä¹ é¢„æµ‹é¢„æœŸé”€å”®é‡ï¼ˆå‡ºå”®ä¹¦ç±çš„æ•°é‡ï¼‰ä½œä¸ºä¹¦ç±å¹³å‡è¯„åˆ†çš„å‡½æ•°ã€‚ç”¨çº¿æ€§å›å½’æ›´å¥½ã€‚</p><p>D. ä½ æ˜¯ä¸€ä½è‰ºæœ¯å®¶ï¼Œä¸ºä½ çš„å®¢æˆ·æä¾›æ‰‹ç»˜è‚–åƒç”»ã€‚æ¯ä¸ªå®¢æˆ·éƒ½ä¼šè·å¾—ä¸åŒçš„è‚–åƒï¼ˆä»–ä»¬è‡ªå·±ï¼‰ï¼Œå¹¶ä¸ºæ‚¨æä¾›1-5æ˜Ÿè¯„çº§åé¦ˆï¼Œæ¯ä½å®¢æˆ·è‡³å¤šè´­ä¹°1å¼ è‚–åƒã€‚æ‚¨æƒ³é¢„æµ‹ä¸‹ä¸€ä½å®¢æˆ·ç»™æ‚¨çš„è¯„åˆ†ã€‚ç”¨é€»è¾‘å›å½’æ›´å¥½ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>You run a movie empire, and want to build a movie recommendation system based on collaborative filtering. There were three popular review websites (which weâ€™ll call A, B and C) which users to go to rate movies, and you have just acquired all three companies that run these websites. Youâ€™d like to merge the three companiesâ€™ datasets together to build a single/unified system. On website A, users rank a movie as having 1 through 5 stars. On website B, users rank on a scale of 1 - 10, and decimal values (e.g., 7.5) are allowed. On website C, the ratings are from 1 to 100. You also have enough information to identify users/movies on one website with users/movies on a different website. Which of the following statements is true?</p><p>A. It is not possible to combine these websitesâ€™ data. You must build three separate recommendation systems.</p><p>B. You can merge the three datasets into one, but you should first normalize each dataset separately by subtracting the mean and then dividing by (max - min) where the max and min (5-1) or (10-1) or (100-1) for the three websites respectively.</p><p>C. You can combine all three training sets into one as long as your perform mean normalization and feature scaling after you merge the data.</p><p>D. You can combine all three training sets into one without any modification and expect high performance from a recommendation system.</p><p>è§£ç­”ï¼š B</p><p>åšç‰¹å¾ç¼©æ”¾ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following are true of collaborative filtering systems? Check all that apply.</p><p>A. Even if each user has rated only a small fraction of all of your products (so r(i,j)=0 for the vast majority of (i,j) pairs), you can still build a recommender system by using collaborative filtering.</p><p>B. For collaborative filtering, it is possible to use one of the advanced optimization algoirthms (L-BFGS/conjugate gradient/etc.) to solve for both the $x^{(i)}$â€™s and $\theta^{(j)}$â€™s simultaneously.</p><p>C. For collaborative filtering, the optimization algorithm you should use is gradient descent. In particular, you cannot use more advanced optimization algorithms (L-BFGS/conjugate gradient/etc.) for collaborative filtering, since you have to solve for both the $x^{(i)}$â€™s and $\theta^{(j)}$â€™s simultaneously.</p><p>D. Suppose you are writing a recommender system to predict a userâ€™s book preferences. In order to build such a system, you need that user to rate all the other books in your training set.</p><p>è§£ç­”ï¼šAã€B</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Suppose you have two matrices A and B, where A is 5x3 and B is 3x5. Their product is C=AB, a 5x5 matrix. Furthermore, you have a 5x5 matrix R where every entry is 0 or 1. You want to find the sum of all elements C(i,j) for which the corresponding R(i,j) is 1, and ignore all elements C(i,j) where R(i,j)=0. One way to do so is the following code:</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/7X_5_0.png" alt=""></p><p>Which of the following pieces of Octave code will also correctly compute this total? Check all that apply. Assume all options are in code.</p><p>A. $total = sum(sum((A * B) .* R))$</p><p>B. $C = A * B; total = sum(sum(C(R == 1)))$;</p><p>C. $C = (A * B) * R; total = sum(C(:))$;</p><p>D. $total = sum(sum(A(R == 1) * B(R == 1))$;</p><p>è§£ç­”ï¼šAã€B</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Recommender_Systems.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Recommender_Systems.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.1_Anomaly_Detection</title>
      <link href="/2020/02/07/9-1-anomaly-detection/"/>
      <url>/2020/02/07/9-1-anomaly-detection/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/79_0.png" alt=""></p><h2 id="ä¸€-Density-Estimation-å¯†åº¦ä¼°è®¡"><a href="#ä¸€-Density-Estimation-å¯†åº¦ä¼°è®¡" class="headerlink" title="ä¸€. Density Estimation å¯†åº¦ä¼°è®¡"></a>ä¸€. Density Estimation å¯†åº¦ä¼°è®¡</h2><p>å‡å¦‚è¦æ›´ä¸ºæ­£å¼å®šä¹‰å¼‚å¸¸æ£€æµ‹é—®é¢˜ï¼Œé¦–å…ˆæˆ‘ä»¬æœ‰ä¸€ç»„ä» $x^{(1)}$ åˆ° $x^{(m)}$ mä¸ªæ ·æœ¬ï¼Œä¸”è¿™äº›æ ·æœ¬å‡ä¸ºæ­£å¸¸çš„ã€‚æˆ‘ä»¬å°†è¿™äº›æ ·æœ¬æ•°æ®å»ºç«‹ä¸€ä¸ªæ¨¡å‹ p(x) ï¼Œ p(x) è¡¨ç¤ºä¸º x çš„åˆ†å¸ƒæ¦‚ç‡ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_1.png" alt=""></p><p>é‚£ä¹ˆå‡å¦‚æˆ‘ä»¬çš„æµ‹è¯•é›† $x_{test}$ æ¦‚ç‡ p ä½äºé˜ˆå€¼ $\varepsilon$ ï¼Œé‚£ä¹ˆåˆ™å°†å…¶æ ‡è®°ä¸ºå¼‚å¸¸ã€‚</p><p>å¼‚å¸¸æ£€æµ‹çš„æ ¸å¿ƒå°±åœ¨äºæ‰¾åˆ°ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œå¸®åŠ©æˆ‘ä»¬çŸ¥é“ä¸€ä¸ªæ ·æœ¬è½å…¥æ­£å¸¸æ ·æœ¬ä¸­çš„æ¦‚ç‡ï¼Œä»è€Œå¸®åŠ©æˆ‘ä»¬åŒºåˆ†æ­£å¸¸å’Œå¼‚å¸¸æ ·æœ¬ã€‚é«˜æ–¯åˆ†å¸ƒï¼ˆGaussian Distributionï¼‰æ¨¡å‹å°±æ˜¯å¼‚å¸¸æ£€æµ‹ç®—æ³•æœ€å¸¸ä½¿ç”¨çš„æ¦‚ç‡åˆ†å¸ƒæ¨¡å‹ã€‚</p><h3 id="1-é«˜æ–¯åˆ†å¸ƒ"><a href="#1-é«˜æ–¯åˆ†å¸ƒ" class="headerlink" title="1. é«˜æ–¯åˆ†å¸ƒ"></a>1. é«˜æ–¯åˆ†å¸ƒ</h3><p>å‡å¦‚ x æœä»é«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†è¡¨ç¤ºä¸ºï¼š $x\sim N(\mu,\sigma^2)$ ã€‚å…¶åˆ†å¸ƒæ¦‚ç‡ä¸ºï¼š </p><p>$$p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})$$ </p><p>å…¶ä¸­ $\mu$ ä¸ºæœŸæœ›å€¼ï¼ˆå‡å€¼ï¼‰ï¼Œ $\sigma^2$ ä¸ºæ–¹å·®ã€‚</p><p>å…¶ä¸­ï¼ŒæœŸæœ›å€¼ $\mu$ å†³å®šäº†å…¶è½´çš„ä½ç½®ï¼Œæ ‡å‡†å·® $\sigma$ å†³å®šäº†åˆ†å¸ƒçš„å¹…åº¦å®½çª„ã€‚å½“ $\mu=0,\sigma=1$ æ—¶çš„æ­£æ€åˆ†å¸ƒæ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_2.png" alt=""></p><p><strong>ç”±æ¦‚ç‡åˆ†å¸ƒçš„æ€§è´¨ï¼Œæ›²çº¿ä¸‹æ–¹çš„é¢ç§¯ç­‰äº1ï¼Œå³ç§¯åˆ†ä¸º1ï¼Œæ‰€ä»¥å›¾å½¢è¶Šå®½ï¼Œé«˜åº¦è¶ŠçŸ®ï¼›å›¾åƒè¶Šé«˜ï¼Œå®½åº¦è¶Šçª„ã€‚</strong></p><p>æœŸæœ›å€¼ï¼š$$\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$</p><p>æ–¹å·®ï¼š $$\sigma^2=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)}^2$$</p><p><strong>ä¸Šé¢è®¡ç®—æœŸæœ›å€¼å’Œæ–¹å·®ï¼Œå°±æ˜¯ç»Ÿè®¡å­¦é‡Œé¢çš„æå¤§ä¼¼ç„¶ä¼°è®¡</strong>ã€‚</p><p>å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ç»„ m ä¸ªæ— æ ‡ç­¾è®­ç»ƒé›†ï¼Œå…¶ä¸­æ¯ä¸ªè®­ç»ƒæ•°æ®åˆæœ‰ n ä¸ªç‰¹å¾ï¼Œé‚£ä¹ˆè¿™ä¸ªè®­ç»ƒé›†åº”è¯¥æ˜¯ m ä¸ª n ç»´å‘é‡æ„æˆçš„æ ·æœ¬çŸ©é˜µã€‚</p><p>åœ¨æ¦‚ç‡è®ºä¸­ï¼Œå¯¹æœ‰é™ä¸ªæ ·æœ¬è¿›è¡Œå‚æ•°ä¼°è®¡</p><p>$$\mu_j = \frac{1}{m} \sum_{i=1}^{m}x_j^{(i)};;;,;;; \delta^2_j = \frac{1}{m} \sum_{i=1}^{m}(x_j^{(i)}-\mu_j)^2$$</p><p>è¿™é‡Œå¯¹å‚æ•° $\mu$ å’Œå‚æ•° $\delta^2$ çš„ä¼°è®¡å°±æ˜¯äºŒè€…çš„æå¤§ä¼¼ç„¶ä¼°è®¡ã€‚</p><p>å‡å®šæ¯ä¸€ä¸ªç‰¹å¾ $x_{1}$ åˆ° $x_{n}$ å‡æœä»æ­£æ€åˆ†å¸ƒï¼Œåˆ™å…¶æ¨¡å‹çš„æ¦‚ç‡ä¸ºï¼š</p>$$\begin{align*}p(x)&amp;=p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma_2^2) \cdots p(x_n;\mu_n,\sigma_n^2)\\&amp;=\prod_{j=1}^{n}p(x_j;\mu_j,\sigma_j^2)\\&amp;=\prod_{j=1}^{n} \frac{1}{\sqrt{2\pi}\sigma_{j}}exp(-\frac{(x_{j}-\mu_{j})^2}{2\sigma_{j}^2})\end{align*}$$<p>å½“ $p(x)&lt;\varepsilon$æ—¶ï¼Œ$x$ ä¸ºå¼‚å¸¸æ ·æœ¬ã€‚</p><h3 id="2-ä¸¾ä¾‹"><a href="#2-ä¸¾ä¾‹" class="headerlink" title="2. ä¸¾ä¾‹"></a>2. ä¸¾ä¾‹</h3><p>å‡å®šæˆ‘ä»¬æœ‰ä¸¤ä¸ªç‰¹å¾ $x_1$ ã€ $x_2$ ï¼Œå®ƒä»¬éƒ½æœä»äºé«˜æ–¯åˆ†å¸ƒï¼Œå¹¶ä¸”é€šè¿‡å‚æ•°ä¼°è®¡ï¼Œæˆ‘ä»¬çŸ¥é“äº†åˆ†å¸ƒå‚æ•°ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_3.png" alt=""></p><p>åˆ™æ¨¡å‹ $p(x)$  èƒ½ç”±å¦‚ä¸‹çš„çƒ­åŠ›å›¾åæ˜ ï¼Œçƒ­åŠ›å›¾è¶Šçƒ­çš„åœ°æ–¹ï¼Œæ˜¯æ­£å¸¸æ ·æœ¬çš„æ¦‚ç‡è¶Šé«˜ï¼Œå‚æ•° $\varepsilon$ æè¿°äº†ä¸€ä¸ªæˆªæ–­é«˜åº¦ï¼Œå½“æ¦‚ç‡è½åˆ°äº†æˆªæ–­é«˜åº¦ä»¥ä¸‹ï¼ˆä¸‹å›¾ç´«è‰²åŒºåŸŸæ‰€ç¤ºï¼‰ï¼Œåˆ™ä¸ºå¼‚å¸¸æ ·æœ¬ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_4.png" alt=""></p><p>å°† $p(x)$ æŠ•å½±åˆ°ç‰¹å¾ $x_1$ ã€$x_2$ æ‰€åœ¨å¹³é¢ï¼Œä¸‹å›¾ç´«è‰²æ›²çº¿å°±åæ˜ äº† $\varepsilon$ çš„æŠ•å½±ï¼Œå®ƒæ˜¯ä¸€æ¡æˆªæ–­æ›²çº¿ï¼Œè½åœ¨æˆªæ–­æ›²çº¿ä»¥å¤–çš„æ ·æœ¬ï¼Œéƒ½ä¼šè¢«è®¤ä¸ºæ˜¯å¼‚å¸¸æ ·æœ¬ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_5.png" alt=""></p><h3 id="3-ç®—æ³•è¯„ä¼°"><a href="#3-ç®—æ³•è¯„ä¼°" class="headerlink" title="3. ç®—æ³•è¯„ä¼°"></a>3. ç®—æ³•è¯„ä¼°</h3><p>ç”±äºå¼‚å¸¸æ ·æœ¬æ˜¯éå¸¸å°‘çš„ï¼Œæ‰€ä»¥æ•´ä¸ªæ•°æ®é›†æ˜¯éå¸¸åæ–œçš„ï¼Œæˆ‘ä»¬ä¸èƒ½å•çº¯çš„ç”¨é¢„æµ‹å‡†ç¡®ç‡æ¥è¯„ä¼°ç®—æ³•ä¼˜åŠ£ï¼Œæ‰€ä»¥ç”¨æˆ‘ä»¬ä¹‹å‰çš„æŸ¥å‡†ç‡ï¼ˆPrecisionï¼‰å’Œå¬å›ç‡ï¼ˆRecallï¼‰è®¡ç®—å‡º F å€¼è¿›è¡Œè¡¡é‡å¼‚å¸¸æ£€æµ‹ç®—æ³•äº†ã€‚</p><ul><li>çœŸé˜³æ€§ã€å‡é˜³æ€§ã€çœŸé˜´æ€§ã€å‡é˜´æ€§    </li><li>æŸ¥å‡†ç‡ï¼ˆPrecisionï¼‰ä¸ å¬å›ç‡ï¼ˆRecallï¼‰   </li><li>F1 Score  </li></ul><p>æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªå‚æ•° $\varepsilon$ ï¼Œè¿™ä¸ª $\varepsilon$ æ˜¯æˆ‘ä»¬ç”¨æ¥å†³å®šä»€ä¹ˆæ—¶å€™æŠŠä¸€ä¸ªæ ·æœ¬å½“åšæ˜¯å¼‚å¸¸æ ·æœ¬çš„é˜ˆå€¼ã€‚æˆ‘ä»¬åº”è¯¥è¯•ç”¨å¤šä¸ªä¸åŒçš„ $\varepsilon$ å€¼ï¼Œé€‰å–ä¸€ä¸ªä½¿å¾— F å€¼æœ€å¤§çš„é‚£ä¸ª $\varepsilon$ ã€‚</p><hr><h2 id="äºŒ-Building-an-Anomaly-Detection-System"><a href="#äºŒ-Building-an-Anomaly-Detection-System" class="headerlink" title="äºŒ. Building an Anomaly Detection System"></a>äºŒ. Building an Anomaly Detection System</h2><h3 id="1-æœ‰ç›‘ç£å­¦ä¹ ä¸å¼‚å¸¸æ£€æµ‹"><a href="#1-æœ‰ç›‘ç£å­¦ä¹ ä¸å¼‚å¸¸æ£€æµ‹" class="headerlink" title="1. æœ‰ç›‘ç£å­¦ä¹ ä¸å¼‚å¸¸æ£€æµ‹"></a>1. æœ‰ç›‘ç£å­¦ä¹ ä¸å¼‚å¸¸æ£€æµ‹</h3><table><thead><tr><th align="center">æœ‰ç›‘ç£å­¦ä¹ </th><th align="center">å¼‚å¸¸æ£€æµ‹</th></tr></thead><tbody><tr><td align="center">æ•°æ®åˆ†å¸ƒå‡åŒ€</td><td align="center">æ•°æ®éå¸¸åæ–œï¼Œå¼‚å¸¸æ ·æœ¬æ•°ç›®è¿œå°äºæ­£å¸¸æ ·æœ¬æ•°ç›®</td></tr><tr><td align="center">å¯ä»¥æ ¹æ®å¯¹æ­£æ ·æœ¬çš„æ‹Ÿåˆæ¥çŸ¥é“æ­£æ ·æœ¬çš„å½¢æ€ï¼Œä»è€Œé¢„æµ‹æ–°æ¥çš„æ ·æœ¬æ˜¯å¦æ˜¯æ­£æ ·æœ¬</td><td align="center">å¼‚å¸¸çš„ç±»å‹ä¸ä¸€ï¼Œå¾ˆéš¾æ ¹æ®å¯¹ç°æœ‰çš„å¼‚å¸¸æ ·æœ¬ï¼ˆå³æ­£æ ·æœ¬ï¼‰çš„æ‹Ÿåˆæ¥åˆ¤æ–­å‡ºå¼‚å¸¸æ ·æœ¬çš„å½¢æ€</td></tr></tbody></table><p>ä¸‹é¢çš„è¡¨æ ¼åˆ™å±•ç¤ºäº†äºŒè€…çš„ä¸€äº›åº”ç”¨åœºæ™¯ï¼š</p><table><thead><tr><th align="center">æœ‰ç›‘ç£å­¦ä¹ </th><th align="center">å¼‚å¸¸æ£€æµ‹</th></tr></thead><tbody><tr><td align="center">åƒåœ¾é‚®ä»¶æ£€æµ‹</td><td align="center">æ•…éšœæ£€æµ‹</td></tr><tr><td align="center">å¤©æ°”é¢„æµ‹ï¼ˆé¢„æµ‹é›¨å¤©ã€æ™´å¤©ã€æˆ–æ˜¯å¤šäº‘å¤©æ°”ï¼‰</td><td align="center">æŸæ•°æ®ä¸­å¿ƒå¯¹äºæœºå™¨è®¾å¤‡çš„ç›‘æ§</td></tr><tr><td align="center">ç™Œç—‡çš„åˆ†ç±»</td><td align="center">åˆ¶é€ ä¸šåˆ¤æ–­ä¸€ä¸ªé›¶éƒ¨ä»¶æ˜¯å¦å¼‚å¸¸</td></tr></tbody></table><p>å¦‚æœå¼‚å¸¸æ ·æœ¬éå¸¸å°‘ï¼Œç‰¹å¾ä¹Ÿä¸ä¸€æ ·å®Œå…¨ä¸€æ ·ï¼ˆæ¯”å¦‚ä»Šå¤©é£æœºå¼•æ“å¼‚å¸¸æ˜¯å› ä¸ºåŸå› ä¸€ï¼Œæ˜å¤©é£æœºå¼•æ“å¼‚å¸¸æ˜¯å› ä¸ºåŸå› äºŒï¼Œè°ä¹Ÿä¸çŸ¥é“å“ªå¤©å‡ºç°å¼‚å¸¸æ˜¯ä»€ä¹ˆåŸå› ï¼‰ï¼Œè¿™ç§æƒ…å†µä¸‹å°±åº”è¯¥é‡‡ç”¨å¼‚å¸¸æ£€æµ‹ã€‚</p><p>å¦‚æœå¼‚å¸¸æ ·æœ¬å¤šï¼Œç‰¹å¾æ¯”è¾ƒç¨³å½“ï¼Œè¿™ç§æƒ…å†µå°±åº”è¯¥é‡‡ç”¨ç›‘ç£å­¦ä¹ ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_6.png" alt=""></p><p>å‡å¦‚æˆ‘ä»¬çš„æ•°æ®çœ‹èµ·æ¥ä¸æ˜¯å¾ˆæœä»é«˜æ–¯åˆ†å¸ƒï¼Œå¯ä»¥é€šè¿‡å¯¹æ•°ã€æŒ‡æ•°ã€å¹‚ç­‰æ•°å­¦å˜æ¢è®©å…¶æ¥è¿‘äºé«˜æ–¯åˆ†å¸ƒã€‚</p><hr><h2 id="ä¸‰-Multivariate-Gaussian-Distribution-Optional"><a href="#ä¸‰-Multivariate-Gaussian-Distribution-Optional" class="headerlink" title="ä¸‰. Multivariate Gaussian Distribution (Optional)"></a>ä¸‰. Multivariate Gaussian Distribution (Optional)</h2><h3 id="1-å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹"><a href="#1-å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹" class="headerlink" title="1. å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹"></a>1. å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_7.png" alt=""></p><p>æˆ‘ä»¬ä»¥æ•°æ®ä¸­å¿ƒçš„ç›‘æ§è®¡ç®—æœºä¸ºä¾‹å­ã€‚ $x_1$ æ˜¯CPUçš„è´Ÿè½½ï¼Œ$x_2$ æ˜¯å†…å­˜çš„ä½¿ç”¨é‡ã€‚å…¶æ­£å¸¸æ ·æœ¬å¦‚å·¦å›¾çº¢è‰²ç‚¹æ‰€ç¤ºã€‚å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªå¼‚å¸¸çš„æ ·æœ¬ï¼ˆå›¾ä¸­å·¦ä¸Šè§’ç»¿è‰²ç‚¹ï¼‰ï¼Œåœ¨å›¾ä¸­çœ‹å¾ˆæ˜æ˜¾å®ƒå¹¶ä¸æ˜¯æ­£å¸¸æ ·æœ¬æ‰€åœ¨çš„èŒƒå›´ã€‚ä½†æ˜¯åœ¨è®¡ç®—æ¦‚ç‡ $p(x)$ çš„æ—¶å€™ï¼Œå› ä¸ºå®ƒåœ¨ $x_1$ å’Œ $x_2$ çš„é«˜æ–¯åˆ†å¸ƒéƒ½å±äºæ­£å¸¸èŒƒå›´ï¼Œæ‰€ä»¥è¯¥ç‚¹å¹¶ä¸ä¼šè¢«åˆ¤æ–­ä¸ºå¼‚å¸¸ç‚¹ã€‚</p><p>è¿™æ˜¯å› ä¸ºåœ¨é«˜æ–¯åˆ†å¸ƒä¸­ï¼Œå®ƒå¹¶ä¸èƒ½å¯Ÿè§‰åœ¨è“è‰²æ¤­åœ†å¤„æ‰æ˜¯æ­£å¸¸æ ·æœ¬æ¦‚ç‡é«˜çš„èŒƒå›´ï¼Œå…¶æ¦‚ç‡æ˜¯é€šè¿‡åœ†åœˆé€æ¸å‘å¤–å‡å°ã€‚æ‰€ä»¥åœ¨åŒä¸€ä¸ªåœ†åœˆå†…ï¼Œè™½ç„¶åœ¨è®¡ç®—ä¸­æ¦‚ç‡æ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯åœ¨å®é™…ä¸Šå´å¾€å¾€æœ‰å¾ˆå¤§åå·®ã€‚</p><p>æ‰€ä»¥æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ”¹è‰¯ç‰ˆçš„å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼šå¤šå…ƒé«˜æ–¯åˆ†å¸ƒã€‚</p><p>æˆ‘ä»¬ä¸å°†æ¯ä¸€ä¸ªç‰¹å¾å€¼éƒ½åˆ†å¼€è¿›è¡Œé«˜æ–¯åˆ†å¸ƒçš„è®¡ç®—ï¼Œè€Œæ˜¯ä½œä¸ºæ•´ä¸ªæ¨¡å‹è¿›è¡Œé«˜æ–¯åˆ†å¸ƒçš„æ‹Ÿåˆã€‚</p><p>å…¶æ¦‚ç‡æ¨¡å‹ä¸ºï¼š $$p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))$$ ï¼ˆå…¶ä¸­ $|\Sigma|$ æ˜¯ $\Sigma$ çš„è¡Œåˆ—å¼ï¼Œ$\mu$ è¡¨ç¤ºæ ·æœ¬å‡å€¼ï¼Œ$\Sigma$ è¡¨ç¤ºæ ·æœ¬åæ–¹å·®çŸ©é˜µã€‚ï¼‰ã€‚</p><p>å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„çƒ­åŠ›å›¾å¦‚ä¸‹ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_8.png" alt=""></p><p>$\Sigma$ æ˜¯ä¸€ä¸ªåæ–¹å·®çŸ©é˜µï¼Œæ‰€ä»¥å®ƒè¡¡é‡çš„æ˜¯æ–¹å·®ã€‚å‡å° $\Sigma$ å…¶å®½åº¦ä¹Ÿéšä¹‹å‡å°‘ï¼Œå¢å¤§åä¹‹ã€‚</p><p><strong>åŒç†ï¼Œå¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¹ŸåŒæ ·éµå¾ªæ¦‚ç‡åˆ†å¸ƒï¼Œæ›²çº¿ä¸‹æ–¹çš„ç§¯åˆ†ç­‰äº1</strong>ã€‚å¦‚ä¸Šå›¾ï¼Œå¤šå…ƒé«˜æ–¯åˆ†å¸ƒç›¸å½“äºä½“ç§¯ä¸º1 ã€‚è¿™æ ·å°±å¯ä»¥é€šè¿‡ $\mu$ å’Œ $\Sigma$ (è¿™é‡Œæ˜¯åæ–¹å·®çŸ©é˜µï¼ŒåŸæ¥æ˜¯ $\sigma$ )çš„å…³ç³»æ¥åˆ¤æ–­å›¾å½¢çš„å¤§è‡´å½¢çŠ¶ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_9.png" alt=""></p><p>$\Sigma$ ä¸­ç¬¬ä¸€ä¸ªæ•°å­—æ˜¯è¡¡é‡ $x_1$ çš„ï¼Œå‡å¦‚å‡å°‘ç¬¬ä¸€ä¸ªæ•°å­—ï¼Œåˆ™å¯ä»å›¾ä¸­è§‚å¯Ÿåˆ° $x_1$ çš„èŒƒå›´ä¹Ÿéšä¹‹è¢«å‹ç¼©ï¼Œå˜æˆäº†ä¸€ä¸ªæ¤­åœ†ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_10.png" alt=""></p><p>å¤šå…ƒé«˜æ–¯åˆ†å¸ƒè¿˜å¯ä»¥ç»™æ•°æ®çš„ç›¸å…³æ€§å»ºç«‹æ¨¡å‹ã€‚å‡å¦‚æˆ‘ä»¬åœ¨éä¸»å¯¹è§’çº¿ä¸Šæ”¹å˜æ•°æ®ï¼ˆå¦‚å›¾ä¸­é—´é‚£å‰¯ï¼‰ï¼Œåˆ™å…¶å›¾åƒä¼šæ ¹æ® $y=x$ è¿™æ¡ç›´çº¿ä¸Šè¿›è¡Œé«˜æ–¯åˆ†å¸ƒã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_11.png" alt=""></p><p>åä¹‹äº¦ç„¶ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_12.png" alt=""></p><p>æ”¹å˜ $\mu$ çš„å€¼åˆ™æ˜¯æ”¹å˜å…¶ä¸­å¿ƒç‚¹çš„ä½ç½®ã€‚</p><h3 id="2-å‚æ•°ä¼°è®¡"><a href="#2-å‚æ•°ä¼°è®¡" class="headerlink" title="2. å‚æ•°ä¼°è®¡"></a>2. å‚æ•°ä¼°è®¡</h3><p>å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å‚æ•°ä¼°è®¡å¦‚ä¸‹ï¼š</p><p>$$\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$</p><p>$$\Sigma=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)(x^{(i)}-\mu)^T}$$</p><h3 id="3-ç®—æ³•æµç¨‹"><a href="#3-ç®—æ³•æµç¨‹" class="headerlink" title="3. ç®—æ³•æµç¨‹"></a>3. ç®—æ³•æµç¨‹</h3><p>é‡‡ç”¨äº†å¤šå…ƒé«˜æ–¯åˆ†å¸ƒçš„å¼‚å¸¸æ£€æµ‹ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š</p><ol><li>é€‰æ‹©ä¸€äº›è¶³å¤Ÿåæ˜ å¼‚å¸¸æ ·æœ¬çš„ç‰¹å¾ $x_j$ ã€‚</li><li>å¯¹å„ä¸ªæ ·æœ¬è¿›è¡Œå‚æ•°ä¼°è®¡ï¼š<br>$$\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$<br>$$\Sigma=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)(x^{(i)}-\mu)^T}$$</li><li>å½“æ–°çš„æ ·æœ¬ x åˆ°æ¥æ—¶ï¼Œè®¡ç®— $p(x)$ ï¼š</li></ol><p>$$p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))$$</p><p>å¦‚æœ $p(x)&lt;\varepsilon $ ï¼Œåˆ™è®¤ä¸ºæ ·æœ¬ x æ˜¯å¼‚å¸¸æ ·æœ¬ã€‚</p><h3 id="4-å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¸ä¸€èˆ¬é«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å·®å¼‚"><a href="#4-å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¸ä¸€èˆ¬é«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å·®å¼‚" class="headerlink" title="4. å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¸ä¸€èˆ¬é«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å·®å¼‚"></a>4. å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¸ä¸€èˆ¬é«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å·®å¼‚</h3><p>ä¸€èˆ¬çš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹åªæ˜¯å¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„ä¸€ä¸ªçº¦æŸï¼Œå®ƒå°†å¤šå…ƒé«˜æ–¯åˆ†å¸ƒçš„ç­‰é«˜çº¿çº¦æŸåˆ°äº†å¦‚ä¸‹æ‰€ç¤ºåŒè½´åˆ†å¸ƒï¼ˆæ¦‚ç‡å¯†åº¦çš„ç­‰é«˜çº¿æ˜¯æ²¿ç€è½´å‘çš„ï¼‰ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/79_13.png" alt=""></p><p><strong>ä¸€èˆ¬çš„å¤šå…ƒé«˜æ–¯æ¨¡å‹çš„è½®å»“ï¼ˆç­‰é«˜çº¿ï¼‰æ€»æ˜¯è½´å¯¹é½çš„ï¼ˆaxis-alignedï¼‰ï¼Œä¹Ÿå°±æ˜¯ $\Sigma $ é™¤å¯¹è§’çº¿ä»¥å¤–çš„éƒ¨åˆ†éƒ½æ˜¯ 0ï¼Œå½“å¯¹è§’çº¿ä»¥å¤–çš„éƒ¨åˆ†ä¸ä¸º 0 çš„æ—¶å€™ï¼Œç­‰é«˜çº¿ä¼šå‡ºç°æ–œç€çš„ï¼Œä¸ä¸¤ä¸ªè½´äº§ç”Ÿä¸€å®šçš„æ–œç‡</strong>ã€‚</p><p>å½“ï¼š $\Sigma=\left[ \begin{array}{ccc}\sigma_1^2 \ &amp; \sigma_2^2 \ &amp;&amp;â€¦\&amp;&amp;&amp;\sigma_n^2\end{array} \right]$ çš„æ—¶å€™ï¼Œæ­¤æ—¶çš„å¤šå…ƒé«˜æ–¯åˆ†å¸ƒå³æ˜¯åŸæ¥çš„å¤šå…ƒé«˜æ–¯åˆ†å¸ƒã€‚ï¼ˆå› ä¸ºåªæœ‰ä¸»å¯¹è§’çº¿æ–¹å·®ï¼Œå¹¶æ²¡æœ‰å…¶å®ƒæ–œç‡çš„å˜åŒ–ï¼‰</p><p>å¯¹æ¯”</p><h3 id="æ¨¡å‹å®šä¹‰"><a href="#æ¨¡å‹å®šä¹‰" class="headerlink" title="æ¨¡å‹å®šä¹‰"></a>æ¨¡å‹å®šä¹‰</h3><p>ä¸€èˆ¬é«˜æ–¯æ¨¡å‹ï¼š</p>$$\begin{align*}p(x)&amp;=p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma_2^2) \cdots p(x_n;\mu_n,\sigma_n^2)\\&amp;=\prod_{j=1}^{n}p(x_j;\mu_j,\sigma_j^2)\\&amp;=\prod_{j=1}^{n} \frac{1}{\sqrt{2\pi}\sigma_{j}}exp(-\frac{(x_{j}-\mu_{j})^2}{2\sigma_{j}^2})\end{align*}$$<p>å¤šå…ƒé«˜æ–¯æ¨¡å‹ï¼š</p><p>$$p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))$$</p><h3 id="ç›¸å…³æ€§"><a href="#ç›¸å…³æ€§" class="headerlink" title="ç›¸å…³æ€§"></a>ç›¸å…³æ€§</h3><p>ä¸€èˆ¬é«˜æ–¯æ¨¡å‹ï¼š</p><p>éœ€è¦æ‰‹åŠ¨åˆ›å»ºä¸€äº›ç‰¹å¾æ¥æè¿°æŸäº›ç‰¹å¾çš„ç›¸å…³æ€§</p><p>å¤šå…ƒé«˜æ–¯æ¨¡å‹ï¼š</p><p>åˆ©ç”¨åæ–¹å·®çŸ©é˜µ$\Sigma$è·å¾—äº†å„ä¸ªç‰¹å¾ç›¸å…³æ€§</p><h3 id="å¤æ‚åº¦"><a href="#å¤æ‚åº¦" class="headerlink" title="å¤æ‚åº¦"></a>å¤æ‚åº¦</h3><p>ä¸€èˆ¬é«˜æ–¯æ¨¡å‹ï¼š</p><p>è®¡ç®—å¤æ‚åº¦ä½ï¼Œé€‚ç”¨äºé«˜ç»´ç‰¹å¾    </p><p>å¤šå…ƒé«˜æ–¯æ¨¡å‹ï¼š</p><p>è®¡ç®—å¤æ‚</p><h3 id="æ•ˆæœ"><a href="#æ•ˆæœ" class="headerlink" title="æ•ˆæœ"></a>æ•ˆæœ</h3><p>ä¸€èˆ¬é«˜æ–¯æ¨¡å‹ï¼š</p><p>åœ¨æ ·æœ¬æ•°ç›® m è¾ƒå°æ—¶ä¹Ÿå·¥ä½œè‰¯å¥½    </p><p>å¤šå…ƒé«˜æ–¯æ¨¡å‹ï¼š</p><p>éœ€è¦ $\Sigma$ å¯é€†ï¼Œäº¦å³éœ€è¦ $m&gt;n$ ï¼Œï¼ˆé€šå¸¸ä¼šè€ƒè™‘ $ m \geqslant 10*n $ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿå¤šçš„æ•°æ®å»æ‹Ÿåˆè¿™äº›å˜é‡ï¼Œæ›´å¥½çš„å»è¯„ä¼°åæ–¹å·®çŸ©é˜µ $\Sigma$ )ä¸”å„ä¸ªç‰¹å¾ä¸èƒ½çº¿æ€§ç›¸å…³ï¼Œå¦‚ä¸èƒ½å­˜åœ¨ $x_2=3x_1$  æˆ–è€… $x_3=x_1+2x_2$</p><p>ç»“è®ºï¼š<strong>åŸºäºå¤šå…ƒé«˜æ–¯åˆ†å¸ƒæ¨¡å‹çš„å¼‚å¸¸æ£€æµ‹åº”ç”¨ååˆ†æœ‰é™</strong>ã€‚</p><hr><h2 id="å››-Anomaly-Detection-æµ‹è¯•"><a href="#å››-Anomaly-Detection-æµ‹è¯•" class="headerlink" title="å››. Anomaly Detection æµ‹è¯•"></a>å››. Anomaly Detection æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>For which of the following problems would anomaly detection be a suitable algorithm?</p><p>A. Given a dataset of credit card transactions, identify unusual transactions to flag them as possibly fraudulent.</p><p>B. Given data from credit card transactions, classify each transaction according to type of purchase (for example: food, transportation, clothing).</p><p>C. Given an image of a face, determine whether or not it is the face of a particular famous individual.</p><p>D. From a large set of primary care patient records, identify individuals who might have unusual health conditions.</p><p>è§£ç­”ï¼šAã€D</p><p>Aã€D æ‰é€‚åˆå¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you have trained an anomaly detection system for fraud detection, and your system that flags anomalies when $p(x)$ is less than Îµ, and you find on the cross-validation set that it is missing many fradulent transactions (i.e., failing to flag them as anomalies). What should you do?</p><p>A. Decrease $\varepsilon$</p><p>B. Increase $\varepsilon$</p><p>è§£ç­”ï¼šB</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you are developing an anomaly detection system to catch manufacturing defects in airplane engines. You model uses</p><p>$$p(x) = \prod_{j=1}^{n}p(x_{j};\mu_{j},\sigma_{j}^{2})$$</p><p>You have two features $x_1$ = vibration intensity, and $x_2$ = heat generated. Both $x_1$ and $x_2$ take on values between 0 and 1 (and are strictly greater than 0), and for most â€œnormalâ€ engines you expect that $x_1 \approx  x_2$. One of the suspected anomalies is that a flawed engine may vibrate very intensely even without generating much heat (large $x_1$, small $x_2$), even though the particular values of $x_1$ and $x_2$ may not fall outside their typical ranges of values. What additional feature $x_3$ should you create to capture these types of anomalies:</p><p>A. $x_3 = \frac{x_1}{x_2}$</p><p>B. $x_3 = x_1^2\times x_2^2$</p><p>C. $x_3 = (x_1 +  x_2)^2$</p><p>D. $x_3 = x_1 \times x_2^2$</p><p>è§£ç­”ï¼šA</p><p>å‡å¦‚ç‰¹å¾é‡ $x_1$ å’Œ $x_2$ ï¼Œå¯å»ºç«‹ç‰¹å¾é‡ $x_3=\frac{x_1}{x_2}$ ç»“åˆä¸¤è€…ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following are true? Check all that apply.</p><p>A. When evaluating an anomaly detection algorithm on the cross validation set (containing some positive and some negative examples), classification accuracy is usually a good evaluation metric to use.</p><p>B. When developing an anomaly detection system, it is often useful to select an appropriate numerical performance metric to evaluate the effectiveness of the learning algorithm.</p><p>C. In a typical anomaly detection setting, we have a large number of anomalous examples, and a relatively small number of normal/non-anomalous examples.</p><p>D. In anomaly detection, we fit a model p(x) to a set of negative (y=0) examples, without using any positive examples we may have collected of previously observed anomalies.</p><p>è§£ç­”ï¼šBã€D</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>You have a 1-D dataset $\begin{Bmatrix}<br>x^{(i)},\cdots,x^{(m)}<br>\end{Bmatrix}$ and you want to detect outliers in the dataset. You first plot the dataset and it looks like this:</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/7X_5.png" alt=""></p><p>Suppose you fit the gaussian distribution parameters $\mu_1$ and $\sigma_1^2$ to this dataset. Which of the following values for $\mu_1$ and $\sigma_1^2$ might you get?</p><p>A. $\mu = -3$,$\sigma_1^2 = 4$</p><p>B. $\mu = -6$,$\sigma_1^2 = 4$</p><p>C. $\mu = -3$,$\sigma_1^2 = 2$</p><p>D. $\mu = -6$,$\sigma_1^2 = 2$</p><p>è§£ç­”ï¼šA</p><p>ä¸­å¿ƒç‚¹åœ¨-3ï¼Œåœ¨-3å‘¨å›´å³ï¼ˆ-4ï¼Œ-2ï¼‰å‘¨å›´ä»æ¯”è¾ƒå¯†é›†ï¼Œæ‰€ä»¥ $\sigma_1=2$ ã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Anomaly_Detection.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Anomaly_Detection.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.2_Dimensionality_Reduction</title>
      <link href="/2020/02/07/8-2-dimensionality-reduction/"/>
      <url>/2020/02/07/8-2-dimensionality-reduction/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/78_0.png" alt=""></p><h2 id="ä¸€-Motivation"><a href="#ä¸€-Motivation" class="headerlink" title="ä¸€. Motivation"></a>ä¸€. Motivation</h2><p>æˆ‘ä»¬å¾ˆå¸Œæœ›æœ‰è¶³å¤Ÿå¤šçš„ç‰¹å¾ï¼ˆçŸ¥è¯†ï¼‰æ¥ä¿å‡†å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ•ˆæœï¼Œå°¤å…¶åœ¨å›¾åƒå¤„ç†è¿™ç±»çš„ä»»åŠ¡ä¸­ï¼Œé«˜ç»´ç‰¹å¾æ˜¯åœ¨æ‰€éš¾å…çš„ï¼Œä½†æ˜¯ï¼Œé«˜ç»´çš„ç‰¹å¾ä¹Ÿæœ‰å‡ ä¸ªå¦‚ä¸‹ä¸å¥½çš„åœ°æ–¹ï¼š</p><ol><li>å­¦ä¹ æ€§èƒ½ä¸‹é™ï¼ŒçŸ¥è¯†è¶Šå¤šï¼Œå¸æ”¶çŸ¥è¯†ï¼ˆè¾“å…¥ï¼‰ï¼Œå¹¶ä¸”ç²¾é€šçŸ¥è¯†ï¼ˆå­¦ä¹ ï¼‰çš„é€Ÿåº¦å°±è¶Šæ…¢ã€‚</li><li>è¿‡å¤šçš„ç‰¹å¾éš¾äºåˆ†è¾¨ï¼Œä½ å¾ˆéš¾ç¬¬ä¸€æ—¶é—´è®¤è¯†æŸä¸ªç‰¹å¾ä»£è¡¨çš„æ„ä¹‰ã€‚</li><li>ç‰¹å¾å†—ä½™ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå˜ç±³å’Œè‹±å°ºå°±æ˜¯ä¸€å¯¹å†—ä½™ç‰¹å¾ï¼Œä»–ä»¬æœ¬èº«ä»£è¡¨çš„æ„ä¹‰æ˜¯ä¸€æ ·çš„ï¼Œå¹¶ä¸”èƒ½å¤Ÿç›¸äº’è½¬æ¢ã€‚</li></ol><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_1.png" alt=""></p><p>æˆ‘ä»¬ä½¿ç”¨ç°åœ¨ä½¿ç”¨äº†ä¸€æ¡ç»¿è‰²ç›´çº¿ï¼Œå°†å„ä¸ªæ ·æœ¬æŠ•å½±åˆ°è¯¥ç›´çº¿ï¼Œé‚£ä¹ˆï¼ŒåŸæ¥äºŒç»´çš„ç‰¹å¾  x=(å˜ç±³ï¼Œè‹±å°º)  å°±è¢«é™ä½ä¸ºäº†ä¸€ç»´  x=(ç›´çº¿ä¸Šçš„ç›¸å¯¹ä½ç½®)</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_2.png" alt=""></p><p>è€Œåœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆå°†ä¸‰ç»´ç‰¹å¾æŠ•å½±åˆ°äºŒä½å¹³é¢ï¼Œä»è€Œå°†ä¸‰ç»´ç‰¹å¾é™åˆ°äº†äºŒç»´ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_3.png" alt=""></p><p>ç‰¹å¾é™ç»´çš„ä¸€èˆ¬æ‰‹æ®µå°±æ˜¯å°†é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°ä½ç»´ç©ºé—´ã€‚</p><p>é™ç»´çš„åŠ¨æœºæœ‰ä¸¤ä¸ªï¼š</p><ol><li>å‹ç¼©æ•°æ®</li><li>æ•°æ®å¯è§†åŒ–</li></ol><hr><h2 id="äºŒ-Principal-Component-Analysis-ä¸»æˆåˆ†åˆ†æ"><a href="#äºŒ-Principal-Component-Analysis-ä¸»æˆåˆ†åˆ†æ" class="headerlink" title="äºŒ. Principal Component Analysis ä¸»æˆåˆ†åˆ†æ"></a>äºŒ. Principal Component Analysis ä¸»æˆåˆ†åˆ†æ</h2><p>PCAï¼ŒPrinciple Component Analysisï¼Œå³ä¸»æˆåˆ†åˆ†ææ³•ï¼Œæ˜¯ç‰¹å¾é™ç»´çš„æœ€å¸¸ç”¨æ‰‹æ®µã€‚é¡¾åæ€ä¹‰ï¼ŒPCA èƒ½ä»å†—ä½™ç‰¹å¾ä¸­æå–ä¸»è¦æˆåˆ†ï¼Œåœ¨ä¸å¤ªæŸå¤±æ¨¡å‹è´¨é‡çš„æƒ…å†µä¸‹ï¼Œæå‡äº†æ¨¡å‹è®­ç»ƒé€Ÿåº¦ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_4.png" alt=""></p><p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å°†æ ·æœ¬åˆ°çº¢è‰²å‘é‡çš„è·ç¦»ç§°ä½œæ˜¯æŠ•å½±è¯¯å·®ï¼ˆProjection Errorï¼‰ã€‚ä»¥äºŒç»´æŠ•å½±åˆ°ä¸€ç»´ä¸ºä¾‹ï¼ŒPCA å°±æ˜¯è¦æ‰¾å¯»ä¸€æ¡ç›´çº¿ï¼Œä½¿å¾—å„ä¸ªç‰¹å¾çš„æŠ•å½±è¯¯å·®è¶³å¤Ÿå°ï¼Œè¿™æ ·æ‰èƒ½å°½å¯èƒ½çš„ä¿ç•™åŸç‰¹å¾å…·æœ‰çš„ä¿¡æ¯ã€‚</p><p>å‡è®¾æˆ‘ä»¬è¦å°†ç‰¹å¾ä»  n  ç»´åº¦é™åˆ°  k  ç»´ï¼šPCA é¦–å…ˆæ‰¾å¯»  k  ä¸ª  n  ç»´å‘é‡ï¼Œç„¶åå°†ç‰¹å¾æŠ•å½±åˆ°è¿™äº›å‘é‡æ„æˆçš„  k ç»´ç©ºé—´ï¼Œå¹¶ä¿è¯æŠ•å½±è¯¯å·®è¶³å¤Ÿå°ã€‚ä¸‹å›¾ä¸­ä¸­ï¼Œä¸ºäº†å°†ç‰¹å¾ç»´åº¦ä»ä¸‰ç»´é™ä½åˆ°äºŒä½ï¼ŒPCA å°±ä¼šå…ˆæ‰¾å¯»ä¸¤ä¸ªä¸‰ç»´å‘é‡  $\mu^{(1)},\mu^{(2)}$ ï¼ŒäºŒè€…æ„æˆäº†ä¸€ä¸ªäºŒç»´å¹³é¢ï¼Œç„¶åå°†åŸæ¥çš„ä¸‰ç»´ç‰¹å¾æŠ•å½±åˆ°è¯¥äºŒç»´å¹³é¢ä¸Šï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_5.png" alt=""></p><h3 id="1-åŒºåˆ«"><a href="#1-åŒºåˆ«" class="headerlink" title="1. åŒºåˆ«"></a>1. åŒºåˆ«</h3><p>PCA å’Œ çº¿æ€§å›å½’çš„åŒºåˆ«æ˜¯ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_3_.png" alt=""></p><p>çº¿æ€§å›å½’æ‰¾çš„æ˜¯å‚ç›´äº X è½´è·ç¦»æœ€å°å€¼ï¼ŒPCA æ‰¾çš„æ˜¯æŠ•å½±å‚ç›´è·ç¦»æœ€å°å€¼ã€‚</p><p>çº¿æ€§å›å½’ç›®çš„æ˜¯æƒ³é€šè¿‡ x é¢„æµ‹ yï¼Œä½†æ˜¯ PCA çš„ç›®çš„æ˜¯ä¸ºäº†æ‰¾ä¸€ä¸ªé™ç»´çš„é¢ï¼Œæ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šçš„ yï¼Œä»£è¡¨é™ç»´çš„é¢çš„å‘é‡ $x_1$ã€$x_2$ã€$x_3$ã€$x_n$ éƒ½æ˜¯åŒç­‰åœ°ä½çš„ã€‚</p><h3 id="2-ç®—æ³•æµç¨‹"><a href="#2-ç®—æ³•æµç¨‹" class="headerlink" title="2. ç®—æ³•æµç¨‹"></a>2. ç®—æ³•æµç¨‹</h3><p>å‡å®šæˆ‘ä»¬éœ€è¦å°†ç‰¹å¾ç»´åº¦ä» n ç»´é™åˆ° k ç»´ã€‚åˆ™ PCA çš„æ‰§è¡Œæµç¨‹å¦‚ä¸‹ï¼š</p><p>ç‰¹å¾æ ‡å‡†åŒ–ï¼Œå¹³è¡¡å„ä¸ªç‰¹å¾å°ºåº¦ï¼š</p><p>$$x^{(i)}_j=\frac{x^{(i)}_j-\mu_j}{s_j}$$</p><p>$\mu_j$ ä¸ºç‰¹å¾ j çš„å‡å€¼ï¼Œsj ä¸ºç‰¹å¾ j çš„æ ‡å‡†å·®ã€‚</p><p>è®¡ç®—åæ–¹å·®çŸ©é˜µ $\Sigma $ ï¼š</p><p>$$\Sigma =\frac{1}{m}\sum_{i=1}{m}(x^{(i)})(x^{(i)})^T=\frac{1}{m} \cdot  X^TX$$</p><p>é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰ï¼Œæ±‚å– $\Sigma $  çš„ç‰¹å¾å‘é‡ï¼ˆeigenvectorsï¼‰ï¼š</p><p>$$(U,S,V^T)=SVD(\Sigma )$$</p><p>ä» U ä¸­å–å‡ºå‰ k ä¸ªå·¦å¥‡å¼‚å‘é‡ï¼Œæ„æˆä¸€ä¸ªçº¦å‡çŸ©é˜µ  Ureduce :</p><p>$$U_{reduce}=(\mu^{(1)},\mu^{(2)},\cdots,\mu^{(k)})$$</p><p>è®¡ç®—æ–°çš„ç‰¹å¾å‘é‡ï¼š $z^{(i)}$ </p><p>$$z^{(i)}=U^{T}_{reduce} \cdot  x^{(i)}$$</p><h3 id="3-ç‰¹å¾è¿˜åŸ"><a href="#3-ç‰¹å¾è¿˜åŸ" class="headerlink" title="3. ç‰¹å¾è¿˜åŸ"></a>3. ç‰¹å¾è¿˜åŸ</h3><p>å› ä¸º PCA ä»…ä¿ç•™äº†ç‰¹å¾çš„ä¸»æˆåˆ†ï¼Œæ‰€ä»¥ PCA æ˜¯ä¸€ç§æœ‰æŸçš„å‹ç¼©æ–¹å¼ï¼Œå‡å®šæˆ‘ä»¬è·å¾—æ–°ç‰¹å¾å‘é‡ä¸ºï¼š</p><p>$$z=U^T_{reduce}x$$</p><p>é‚£ä¹ˆï¼Œè¿˜åŸåçš„ç‰¹å¾ $x_{approx}$ ä¸ºï¼š</p><p>$$x_{approx}=U_{reduce}z$$</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/78_6.png" alt=""></p><h3 id="4-é™ç»´å¤šå°‘æ‰åˆé€‚ï¼Ÿ"><a href="#4-é™ç»´å¤šå°‘æ‰åˆé€‚ï¼Ÿ" class="headerlink" title="4. é™ç»´å¤šå°‘æ‰åˆé€‚ï¼Ÿ"></a>4. é™ç»´å¤šå°‘æ‰åˆé€‚ï¼Ÿ</h3><p>ä» PCA çš„æ‰§è¡Œæµç¨‹ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œéœ€è¦ä¸º PCA æŒ‡å®šç›®çš„ç»´åº¦ k ã€‚å¦‚æœé™ç»´ä¸å¤šï¼Œåˆ™æ€§èƒ½æå‡ä¸å¤§ï¼›å¦‚æœç›®æ ‡ç»´åº¦å¤ªå°ï¼Œåˆ™åˆä¸¢å¤±äº†è®¸å¤šä¿¡æ¯ã€‚é€šå¸¸ï¼Œä½¿ç”¨å¦‚ä¸‹çš„æµç¨‹çš„æ¥è¯„ä¼° k å€¼é€‰å–ä¼˜å¼‚ï¼š</p><p>æ±‚å„æ ·æœ¬çš„æŠ•å½±å‡æ–¹è¯¯å·®:</p><p>$$\min \frac{1}{m}\sum_{j=1}^{m}\left | x^{(i)}-x^{(i)}_{approx} \right |^2$$</p><p>æ±‚æ•°æ®çš„æ€»å˜å·®ï¼š</p><p>$$\frac{1}{m}\sum_{j=1}^{m}\left | x^{(i)} \right |^2$$</p><p>è¯„ä¼°ä¸‹å¼æ˜¯å¦æˆç«‹:</p>$$\frac{\min \frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)}-x^{(i)}_{approx} \right \|^2}{\frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)} \right \|^2} \leqslant \epsilon $$<p>å…¶ä¸­ï¼Œ $\epsilon $  çš„å–å€¼å¯ä»¥ä¸º  0.01,0.05,0.10,â‹¯ï¼Œå‡è®¾  $\epsilon = 0.01 $ ï¼Œæˆ‘ä»¬å°±è¯´â€œç‰¹å¾é—´ 99% çš„å·®å¼‚æ€§å¾—åˆ°ä¿ç•™â€ã€‚</p><h3 id="5-ä¸è¦æå‰ä¼˜åŒ–"><a href="#5-ä¸è¦æå‰ä¼˜åŒ–" class="headerlink" title="5. ä¸è¦æå‰ä¼˜åŒ–"></a>5. ä¸è¦æå‰ä¼˜åŒ–</h3><p>ç”±äº PCA å‡å°äº†ç‰¹å¾ç»´åº¦ï¼Œå› è€Œä¹Ÿæœ‰å¯èƒ½å¸¦æ¥è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚PCA ä¸æ˜¯å¿…é¡»çš„ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€å®šè°¨è®°ä¸è¦æå‰ä¼˜åŒ–ï¼Œåªæœ‰å½“ç®—æ³•è¿è¡Œæ•ˆç‡ä¸å°½å¦‚å¦‚äººæ„æ—¶ï¼Œå†è€ƒè™‘ä½¿ç”¨ PCA æˆ–è€…å…¶ä»–ç‰¹å¾é™ç»´æ‰‹æ®µæ¥æå‡è®­ç»ƒé€Ÿåº¦ã€‚</p><p>å½“ä½ åœ¨ä¿ç•™ 99% æˆ–è€… 95% æˆ–è€…å…¶å®ƒç™¾åˆ†æ¯”çš„æ–¹å·®æ—¶ï¼Œç»“æœè¡¨æ˜ï¼Œå°±åªä½¿ç”¨æ­£åˆ™åŒ–å°†ä¼šç»™ä½ ä¸€ç§é¿å…è¿‡æ‹Ÿåˆç»å¯¹å¥½çš„æ–¹æ³•ï¼ŒåŒæ—¶æ­£åˆ™åŒ–æ•ˆæœä¹Ÿä¼šæ¯” PCA æ›´å¥½ å› ä¸ºå½“ä½ ä½¿ç”¨çº¿æ€§å›å½’æˆ–è€…é€»è¾‘å›å½’æˆ–å…¶ä»–çš„æ–¹æ³•ï¼Œé…åˆæ­£åˆ™åŒ–æ—¶ï¼Œè¿™ä¸ªæœ€å°åŒ–é—®é¢˜å®é™…å°±å˜æˆäº† y å€¼æ˜¯ä»€ä¹ˆï¼Œæ‰ä¸è‡³äºå°†æœ‰ç”¨çš„ä¿¡æ¯èˆå¼ƒæ‰ã€‚ç„¶è€Œ PCA ä¸éœ€è¦ä½¿ç”¨åˆ°è¿™äº›æ ‡ç­¾æ›´å®¹æ˜“å°†æœ‰ä»·å€¼ä¿¡æ¯èˆå¼ƒæ€»ä¹‹ï¼Œä½¿ç”¨ PCA çš„ç›®çš„æ˜¯åŠ é€Ÿå­¦ä¹ ç®—æ³•çš„æ—¶å€™æ˜¯å¥½çš„ï¼Œä½†æ˜¯ç”¨å®ƒæ¥é¿å…è¿‡æ‹Ÿåˆï¼Œå´å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½çš„ PCA åº”ç”¨ã€‚æˆ‘ä»¬ä½¿ç”¨æ­£åˆ™åŒ–çš„æ–¹æ³•æ¥ä»£æ›¿ PCA æ–¹æ³•æ˜¯å¾ˆå¤šäººå»ºè®®çš„ ã€‚</p><p><strong>PCA ç”¨æ¥è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜æ˜¯é”™è¯¯çš„é€‰æ‹©ï¼Œè¯·è€ƒè™‘æ­£åˆ™åŒ–çš„æ–¹å¼è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜</strong>ã€‚</p><p>ä½ çš„å­¦ä¹ ç®—æ³•æ”¶æ•›åœ°éå¸¸ç¼“æ…¢ï¼Œå ç”¨å†…å­˜æˆ–è€…ç¡¬ç›˜ç©ºé—´éå¸¸å¤§ æ‰€ä»¥ä½ æƒ³æ¥å‹ç¼©æ•°æ®ã€‚åªæœ‰å½“ä½ çš„ $x^{(i)}$ æ•ˆæœä¸å¥½ï¼Œåªæœ‰å½“ä½ æœ‰è¯æ®æˆ–è€…ï¼Œå……è¶³çš„ç†ç”±æ¥ç¡®å®š $x^{(i)}$ æ•ˆæœä¸å¥½çš„æ—¶å€™ï¼Œé‚£ä¹ˆå°±è€ƒè™‘ç”¨ PCA æ¥è¿›è¡Œå‹ç¼©æ•°æ®ã€‚</p><p>PCA é€šå¸¸éƒ½æ˜¯è¢«ç”¨æ¥å‹ç¼©æ•°æ®çš„ï¼Œä»¥å‡å°‘å†…å­˜ä½¿ç”¨æˆ–ç¡¬ç›˜ç©ºé—´å ç”¨ï¼Œæˆ–è€…ç”¨æ¥å¯è§†åŒ–æ•°æ®ã€‚</p><hr><h2 id="ä¸‰-Principal-Component-Analysis-æµ‹è¯•"><a href="#ä¸‰-Principal-Component-Analysis-æµ‹è¯•" class="headerlink" title="ä¸‰. Principal Component Analysis æµ‹è¯•"></a>ä¸‰. Principal Component Analysis æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Consider the following 2D dataset:</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/7X_1.png" alt=""></p><p>Which of the following figures correspond to possible values that PCA may return for u(1) (the first eigenvector / first principal component)? Check all that apply (you may have to check more than one figure).</p><p>A. <img src="https://img.halfrost.com/Blog/ArticleImage/7X_1A.png" alt=""></p><p>B. <img src="https://img.halfrost.com/Blog/ArticleImage/7X_1B.png" alt=""></p><p>C. <img src="https://img.halfrost.com/Blog/ArticleImage/7X_1C.png" alt=""></p><p>D. <img src="https://img.halfrost.com/Blog/ArticleImage/7X_1D.png" alt=""></p><p>è§£ç­”ï¼šAã€B</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Which of the following is a reasonable way to select the number of principal components k?</p><p>(Recall that n is the dimensionality of the input data and m is the number of input examples.)</p><p>A. Choose k to be the smallest value so that at least 1% of the variance is retained.</p><p>B. Choose k to be the smallest value so that at least 99% of the variance is retained.</p><p>C. Choose the value of k that minimizes the approximation error $\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} - x</em>{approx}^{(i)} \right |^{2}$.</p><p>D. Choose k to be 99% of n (i.e., k=0.99âˆ—n, rounded to the nearest integer).</p><p>è§£ç­”ï¼š B</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose someone tells you that they ran PCA in such a way that â€œ95% of the variance was retained.â€ What is an equivalent statement to this?</p><p>A. $\frac{\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} \right |^{2}}{\frac{1}{m}\sum^{m}</em>{i=1}\left | x^{(i)} - x_{approx}^{(i)} \right |^{2}} \geqslant 0.05$</p><p>B. $\frac{\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} \right |^{2}}{\frac{1}{m}\sum^{m}</em>{i=1}\left | x^{(i)} - x_{approx}^{(i)} \right |^{2}}  \leqslant  0.95$</p><p>C. $\frac{\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} - x</em>{approx}^{(i)} \right |^{2}}{\frac{1}{m}\sum^{m}_{i=1}\left | x^{(i)} \right |^{2}} \leqslant 0.05$</p><p>D. $\frac{\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} \right |^{2}}{\frac{1}{m}\sum^{m}</em>{i=1}\left | x^{(i)} - x_{approx}^{(i)} \right |^{2}} \leqslant 0.05$</p><p>è§£ç­”ï¼š C</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. If the input features are on very different scales, it is a good idea to perform feature scaling before applying PCA.</p><p>B. Feature scaling is not useful for PCA, since the eigenvector calculation (such as using Octaveâ€™s ğšœğšŸğš(ğš‚ğš’ğšğš–ğšŠ) routine) takes care of this automatically.</p><p>C. Given an input $x \in \mathbb{R}^{n}$, PCA compresses it to a lower-dimensional vector $z \in \mathbb{R}^{k}$.</p><p>D. PCA can be used only to reduce the dimensionality of data by 1 (such as 3D to 2D, or 2D to 1D).</p><p>è§£ç­”ï¼šAã€C</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following are recommended applications of PCA? Select all that apply.</p><p>A. To get more features to feed into a learning algorithm.</p><p>B. Data compression: Reduce the dimension of your data, so that it takes up less memory / disk space.</p><p>C. Data visualization: Reduce data to 2D (or 3D) so that it can be plotted.</p><p>D. Data compression: Reduce the dimension of your input data $x^{(i)}$, which will be used in a supervised learning algorithm (i.e., use PCA so that your supervised learning algorithm runs faster).</p><p>è§£ç­”ï¼šBã€C</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Dimensionality_Reduction.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Dimensionality_Reduction.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.1_Unsupervised_Learning</title>
      <link href="/2020/02/07/8-1-unsupervised-learning/"/>
      <url>/2020/02/07/8-1-unsupervised-learning/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-7c48451bfdd10339.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-Clustering"><a href="#ä¸€-Clustering" class="headerlink" title="ä¸€. Clustering"></a>ä¸€. Clustering</h2><h3 id="1-å®šä¹‰"><a href="#1-å®šä¹‰" class="headerlink" title="1. å®šä¹‰"></a>1. å®šä¹‰</h3><p>ä»æœ¬èŠ‚å¼€å§‹ï¼Œå°†æ­£å¼è¿›å…¥åˆ°æ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervised Learningï¼‰éƒ¨åˆ†ã€‚æ— ç›‘ç£å­¦ä¹ ï¼Œé¡¾åæ€ä¹‰ï¼Œå°±æ˜¯ä¸å—ç›‘ç£çš„å­¦ä¹ ï¼Œä¸€ç§è‡ªç”±çš„å­¦ä¹ æ–¹å¼ã€‚è¯¥å­¦ä¹ æ–¹å¼ä¸éœ€è¦å…ˆéªŒçŸ¥è¯†è¿›è¡ŒæŒ‡å¯¼ï¼Œè€Œæ˜¯ä¸æ–­åœ°è‡ªæˆ‘è®¤çŸ¥ï¼Œè‡ªæˆ‘å·©å›ºï¼Œæœ€åè¿›è¡Œè‡ªæˆ‘å½’çº³ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ— ç›‘ç£å­¦ä¹ å¯ä»¥è¢«ç®€å•ç†è§£ä¸ºä¸ä¸ºè®­ç»ƒé›†æä¾›å¯¹åº”çš„ç±»åˆ«æ ‡è¯†ï¼ˆlabelï¼‰ï¼Œå…¶ä¸æœ‰ç›‘ç£å­¦ä¹ çš„å¯¹æ¯”å¦‚ä¸‹ï¼š</p><p>æœ‰ç›‘ç£å­¦ä¹ ï¼ˆSupervised Learningï¼‰ä¸‹çš„è®­ç»ƒé›†ï¼š</p>$$\left\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\cdots,(x^{(m)},y^{(m)}) \right\}$$<p>æ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervised Learningï¼‰ä¸‹çš„è®­ç»ƒé›†ï¼š</p>$$\left\{ (x^{(1)}),(x^{(2)}),(x^{(3)}),\cdots,(x^{(m)}) \right\}$$<p><img src="https://img.halfrost.com/Blog/ArticleImage/77_1.png" alt=""></p><p>åœ¨æœ‰ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬æŠŠå¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»çš„è¿‡ç¨‹ç§°ä¹‹ä¸ºåˆ†ç±»ï¼ˆClassificationï¼‰ï¼Œè€Œåœ¨æ— ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ç‰©ä½“è¢«åˆ’åˆ†åˆ°ä¸åŒé›†åˆçš„è¿‡ç¨‹ç§°ä¹‹ä¸ºèšç±»ï¼ˆClusteringï¼‰ã€‚èšè¿™ä¸ªåŠ¨è¯ååˆ†ç²¾ç¡®ï¼Œä»–ä¼ ç¥åœ°æç»˜äº†å„ä¸ªç‰©ä½“è‡ªä¸»åœ°æƒ³å±äºè‡ªå·±çš„é›†åˆé æ‹¢çš„è¿‡ç¨‹ã€‚</p><p>åœ¨èšç±»ä¸­ï¼Œæˆ‘ä»¬æŠŠç‰©ä½“æ‰€åœ¨çš„é›†åˆç§°ä¹‹ä¸ºç°‡ï¼ˆclusterï¼‰ã€‚</p><h3 id="2-K-Means"><a href="#2-K-Means" class="headerlink" title="2. K-Means"></a>2. K-Means</h3><p>åœ¨èšç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å°†æœªåŠ æ ‡ç­¾çš„æ•°æ®é€šè¿‡ç®—æ³•è‡ªåŠ¨åˆ†æˆæœ‰ç´§å¯†å…³ç³»çš„å­é›†ã€‚é‚£ä¹ˆKå‡å€¼èšç±»ç®—æ³•ï¼ˆK-meanï¼‰æ˜¯ç°åœ¨æœ€ä¸ºå¹¿æ³›ä½¿ç”¨çš„èšç±»æ–¹æ³•ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_2.png" alt=""></p><p>æˆ‘ä»¬æ‰§è¡ŒKå‡å€¼èšç±»ç®—æ³•æ˜¯è¿™æ ·çš„ã€‚é¦–å…ˆéšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹ï¼Œè¿™ä¸¤ä¸ªç‚¹å«åšèšç±»ä¸­å¿ƒï¼ˆcluster centroidsï¼‰ï¼Œä¹Ÿå°±æ˜¯å›¾ä¸­çº¢è‰²å’Œè“è‰²çš„äº¤å‰ã€‚Kå‡å€¼èšç±» ä¸€ä¸ªè¿­ä»£çš„æ–¹æ³•ï¼Œå®ƒè¦åšä¸¤ä»¶äº‹ï¼Œä¸€ä»¶æ˜¯ç°‡åˆ†é…ï¼Œå¦ä¸€ä»¶æ˜¯ç§»åŠ¨èšç±»ä¸­å¿ƒã€‚</p><p>åœ¨Kå‡å€¼èšç±»ç®—æ³•çš„æ¯æ¬¡å¾ªç¯é‡Œé¢ï¼Œç¬¬ä¸€æ­¥è¦è¿›è¡Œçš„æ˜¯ç°‡åˆ†é…ã€‚é¦–å…ˆè¦å†éæ‰€æœ‰çš„æ ·æœ¬ï¼Œä¹Ÿå°±æ˜¯ä¸Šå›¾ä¸­æ¯ä¸€ä¸ªç»¿è‰²çš„ç‚¹ï¼Œç„¶åæ ¹æ®æ¯ä¸€ä¸ªç‚¹æ˜¯æ›´æ¥è¿‘çº¢è‰²çš„è¿™ä¸ªä¸­å¿ƒè¿˜æ˜¯è“è‰²çš„è¿™ä¸ªä¸­å¿ƒï¼Œå°†æ¯ä¸€ä¸ªæ•°æ®ç‚¹åˆ†é…åˆ°ä¸¤ä¸ªä¸åŒçš„èšç±»ä¸­å¿ƒã€‚</p><p>ä¾‹å¦‚ç¬¬ä¸€æ¬¡æˆ‘ä»¬éšæœºå®šçš„ä¸¤ä¸ªä¸­å¿ƒç‚¹å’Œå…¶ç°‡åˆ†é…å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_3.png" alt=""></p><p>ç¬¬äºŒæ­¥è¦åšçš„è‡ªç„¶æ˜¯è¦ç§»åŠ¨èšç±»ä¸­å¿ƒã€‚æˆ‘ä»¬éœ€è¦å°†ä¸¤ä¸ªä¸­å¿ƒç‚¹ç§»åŠ¨åˆ°åˆšæ‰æˆ‘ä»¬åˆ†æˆä¸¤ç±»çš„æ•°æ®å„è‡ªçš„å‡å€¼å¤„ã€‚é‚£ä¹ˆæ‰€è¦åšçš„å°±æ˜¯æ‰¾å‡ºæ‰€æœ‰çº¢è‰²çš„ç‚¹è®¡ç®—å‡ºä»–ä»¬çš„å‡å€¼ï¼Œç„¶åæŠŠçº¢è‰²å‰å‰ç§»åŠ¨åˆ°è¯¥å‡å€¼å¤„ï¼Œè“è‰²å‰å‰äº¦ç„¶ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_4.png" alt=""></p><p>ç„¶åé€šè¿‡ä¸æ–­é‡å¤ä¸Šè¿°ä¸¤ä¸ªæ­¥éª¤ï¼Œé€šè¿‡ä¸æ–­è¿­ä»£ç›´åˆ°å…¶èšç±»ä¸­å¿ƒä¸å˜ï¼Œé‚£ä¹ˆä¹Ÿå°±æ˜¯è¯´Kå‡å€¼èšç±»å·²ç»æ”¶æ•›äº†ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä»è¯¥æ•°æ®ä¸­æ‰¾åˆ°ä¸¤ä¸ªæœ€æœ‰å…³è”çš„ç°‡äº†ã€‚å…¶è¿‡ç¨‹å¤§æ¦‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_5.png" alt=""></p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_6.png" alt=""></p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_7.png" alt=""></p><p>Kå‡å€¼èšç±»ç®—æ³•æœ‰ä¸¤ä¸ªè¾“å…¥ï¼šä¸€ä¸ªæ˜¯å‚æ•°Kï¼Œä¹Ÿå°±æ˜¯ä½ æƒ³ä»æ•°æ®ä¸­èšç±»å‡ºç°‡çš„ä¸ªæ•°ã€‚å¦ä¸€ä¸ªå°±æ˜¯åªæœ‰xæ²¡æœ‰yçš„è®­ç»ƒé›†ã€‚</p><p>ä»¥ä¸‹æ˜¯ K å‡å€¼èšç±»ç®—æ³•çš„è¿‡ç¨‹ã€‚</p><p>ç¬¬ä¸€æ­¥æ˜¯éšæœºåˆå§‹åŒ–Kä¸ªèšç±»ä¸­å¿ƒï¼Œè®°åšï¼š  $\mu_1, \mu_2,\cdots,\mu_k$ ã€‚</p><p>ç¬¬äºŒä¸ªå¤§éƒ¨åˆ†å°±æ˜¯è¿›è¡Œè¿­ä»£ã€‚å…¶ä¸­ç¬¬ä¸€ä¸ªå¾ªç¯æ˜¯ï¼šå¯¹äºæ¯ä¸ªè®­ç»ƒæ ·æœ¬ ï¼Œæˆ‘ä»¬ç”¨å˜é‡ $c^{(i)}$ è¡¨ç¤ºåœ¨ K ä¸ªèšç±»ä¸­å¿ƒé‡Œé¢æœ€æ¥è¿‘ $x^{(i)}$ é‚£ä¸ªä¸­å¿ƒçš„ä¸‹æ ‡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ $min_k||x^{(i)}-\mu_k||$ è¿›è¡Œè®¡ç®—ã€‚ç¬¬äºŒä¸ªå¾ªç¯æ˜¯ï¼šç§»åŠ¨èšç±»ä¸­å¿ƒã€‚å°†  $\mu_k$ ä¹Ÿå°±æ˜¯ä¸­å¿ƒç‚¹çš„å€¼ = åˆšæ‰æˆ‘ä»¬åˆ†å¥½çš„ç°‡çš„å‡å€¼ã€‚</p><p>ä¾‹å¦‚ï¼š  $\mu_2$ è¢«åˆ†é…åˆ°ä¸€äº›æ ·æœ¬å€¼ï¼š $x^{(1)},x^{(5)},x^{(6)},x^{(10)}$ ã€‚è¿™ä¹Ÿå°±æ„å‘³ç€ï¼š $c^{(1)}=2,c^{(5)}=2,c^{(6)}=2,c^{(10)}=2$ ã€‚é‚£ä¹ˆ  $\mu_2$ çš„æ–°å€¼åº”è¯¥ä¸ºï¼š $\frac{1}{4}[ x^{(1)}+x^{(5)}+x^{(6)}+x^{(10)}]$ ã€‚</p><h3 id="3-ä¼˜åŒ–"><a href="#3-ä¼˜åŒ–" class="headerlink" title="3. ä¼˜åŒ–"></a>3. ä¼˜åŒ–</h3><p>å’Œå…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•ä¸€æ ·ï¼ŒK-Means ä¹Ÿè¦è¯„ä¼°å¹¶ä¸”æœ€å°åŒ–èšç±»ä»£ä»·ï¼Œåœ¨å¼•å…¥ K-Means çš„ä»£ä»·å‡½æ•°ä¹‹å‰ï¼Œå…ˆå¼•å…¥å¦‚ä¸‹å®šä¹‰ï¼š</p><p>$\mu^{(i)}_c$=æ ·æœ¬ $x^{(i)}$ è¢«åˆ†é…åˆ°çš„èšç±»ä¸­å¿ƒ</p><p>å¼•å…¥ä»£ä»·å‡½æ•°ï¼š</p><p>$$J(c^{(1)},c^{(2)},\cdots,c^{(m)};\mu_1,\mu_2,\cdots,\mu_k)=\frac{1}{m}\sum_{i=1}^m\left | x^{(i)}-\mu_c(i) \right |^2$$</p><p>J ä¹Ÿè¢«ç§°ä¸ºå¤±çœŸä»£ä»·å‡½æ•°(Distortion Cost Function),å¯ä»¥åœ¨è°ƒè¯•Kå‡å€¼èšç±»è®¡ç®—çš„æ—¶å€™å¯ä»¥çœ‹å…¶æ˜¯å¦æ”¶æ•›æ¥åˆ¤æ–­ç®—æ³•æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚</p><p>å®é™…ä¸Šï¼ŒK-Means çš„ä¸¤æ­¥å·²ç»å®Œæˆäº†æœ€å°åŒ–ä»£ä»·å‡½æ•°çš„è¿‡ç¨‹ï¼š</p><ol><li>æ ·æœ¬åˆ†é…æ—¶(ç°‡åˆ†é…)ï¼š<br>æˆ‘ä»¬å›ºå®šä½äº†  $(\mu_1,\mu_2,\cdots,\mu_k)$ ï¼Œè€Œå…³äº  $(c^{(1)},c^{(2)},\cdots,c^{(m)})$  æœ€å°åŒ–äº† J ã€‚</li><li>ä¸­å¿ƒç§»åŠ¨æ—¶(ç§»åŠ¨ç±»èšä¸­å¿ƒ)ï¼š<br>æˆ‘ä»¬å†å…³äº $(\mu_1,\mu_2,\cdots,\mu_k)$ æœ€å°åŒ–äº† J ã€‚</li></ol><p>ç”±äº K-Means æ¯æ¬¡è¿­ä»£è¿‡ç¨‹éƒ½åœ¨æœ€å°åŒ– J ï¼Œæ‰€ä»¥ä¸‹é¢çš„ä»£ä»·å‡½æ•°å˜åŒ–æ›²çº¿ä¸ä¼šå‡ºç°ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_8.png" alt=""></p><h3 id="4-å¦‚ä½•åˆå§‹åŒ–èšç±»ä¸­å¿ƒ"><a href="#4-å¦‚ä½•åˆå§‹åŒ–èšç±»ä¸­å¿ƒ" class="headerlink" title="4. å¦‚ä½•åˆå§‹åŒ–èšç±»ä¸­å¿ƒ"></a>4. å¦‚ä½•åˆå§‹åŒ–èšç±»ä¸­å¿ƒ</h3><p>å½“æˆ‘ä»¬è¿è¡ŒKå‡å€¼ç®—æ³•çš„æ—¶å€™ï¼Œå…¶èšç±»ä¸­å¿ƒKçš„å€¼è¦å°‘äºæ ·æœ¬æ€»æ•°mã€‚</p><p>ç„¶åæˆ‘ä»¬éšä¾¿é€‰Kä¸ªè®­ç»ƒæ ·æœ¬ä½œä¸ºèšç±»ä¸­å¿ƒã€‚ä¾‹å¦‚K=2çš„æ—¶å€™ï¼Œå¦‚å³å›¾ï¼Œéšä¾¿é€‰å–é‚£ä¸¤ä¸ªè®­ç»ƒæ ·æœ¬ä½œä¸ºä¸¤ä¸ªä¸åŒçš„èšç±»ä¸­å¿ƒã€‚</p><p>ä½†æ˜¯è¿™æ ·éšä¾¿é€‰çš„è¯ï¼Œä¼šé€ æˆKå‡å€¼è½åœ¨å±€éƒ¨æœ€ä¼˜ä¸å¥½çš„ç»“æœã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_9.png" alt=""></p><p>ä¾‹å¦‚ï¼Œæˆ‘ä»¬ç»™å‡ºå·¦å›¾çš„æ•°æ®ï¼Œå¾ˆå®¹æ˜“çœ‹å‡ºå¯ä»¥åˆ†æˆ3ä¸ªèšç±»ï¼Œä½†æ˜¯å› ä¸ºéšæœºåˆå§‹åŒ–ä¸å¥½çš„æ—¶å€™ï¼Œä¼šè½å…¥åˆ°å±€éƒ¨æœ€ä¼˜è€Œä¸æ˜¯å…¨å±€æœ€ä¼˜ã€‚ä¹Ÿå°±æ˜¯å³ä¸‹å›¾çš„ä¸¤ç§æƒ…å†µã€‚</p><p>æ‰€ä»¥æˆ‘ä»¬éšæœºåˆå§‹åŒ–çš„æ“ä½œå¦‚ä¸‹ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_10.png" alt=""></p><p>é€šå¸¸ï¼Œæˆ‘ä»¬ä¼šéšæœºé€‰  K ä¸ªæ ·æœ¬ä½œä¸º K ä¸ªèšç±»ä¸­å¿ƒ ( K&lt;m )ã€‚ä½†æ˜¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸åŒçš„åˆå§‹åŒ–æœ‰å¯èƒ½å¼•èµ·ä¸åŒçš„èšç±»ç»“æœï¼Œèƒ½è¾¾åˆ°å…¨å±€æœ€ä¼˜ï¼ˆglobal optimalï¼‰å›ºç„¶æ˜¯å¥½çš„ï¼Œä½†æ˜¯ï¼Œå¾€å¾€å¾—åˆ°çš„æ˜¯å±€éƒ¨æœ€ä¼˜ï¼ˆlocal optimalï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_12.png" alt=""></p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_13.png" alt=""></p><p>ç°åœ¨ï¼Œæƒ³è¦æå‰é¿å…ä¸å¥½çš„èšç±»ç»“æœä»æ˜¯å›°éš¾çš„ï¼Œæˆ‘ä»¬åªèƒ½å°è¯•ä¸åŒçš„åˆå§‹åŒ–ï¼š</p><p>for  i=1  to  100 (ä¸€èˆ¬å¾ªç¯é€‰æ‹©åœ¨ 50 - 1000 ä¹‹é—´)ï¼š</p><ol><li>éšæœºåˆå§‹åŒ–ï¼Œæ‰§è¡Œ K-Meansï¼Œå¾—åˆ°æ¯ä¸ªæ‰€å±çš„ç°‡ $c^{(i)}$ ï¼Œä»¥åŠå„èšç±»çš„ä¸­å¿ƒä½ç½® $\mu$ :<br>$$c^{(1)},c^{(2)},\cdots,c^{(m)};\mu_1,\mu_2,\cdots,\mu_k$$</li><li>è®¡ç®—å¤±çœŸå‡½æ•°  J </li></ol><p>é€‰æ‹©è¿™ 100 æ¬¡ä¸­ï¼Œ J  æœ€å°çš„ä½œä¸ºæœ€ç»ˆçš„èšç±»ç»“æœã€‚</p><p>éšæœºé€‰å– K å€¼ï¼Œä½†æ˜¯è¦å¾ªç¯ä¸é‡å¤å–100æ¬¡ï¼Œå–å…¶ $J(c^{(1)},c^{(2)},\cdots,c^{(m)};\mu_1,\mu_2,\cdots,\mu_k)$ æœ€ä½çš„é‚£ä¸ªç»“æœã€‚</p><p>ä¸€èˆ¬ K çš„ç»éªŒå€¼åœ¨ 2 - 10 ä¹‹é—´ã€‚</p><h3 id="5-å¦‚ä½•ç¡®å®šèšç±»æ•°"><a href="#5-å¦‚ä½•ç¡®å®šèšç±»æ•°" class="headerlink" title="5. å¦‚ä½•ç¡®å®šèšç±»æ•°"></a>5. å¦‚ä½•ç¡®å®šèšç±»æ•°</h3><p>è‚˜éƒ¨æ³•åˆ™ï¼ˆElbow Methodï¼‰:</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/77_11.png" alt=""></p><p>æˆ‘ä»¬é€šè¿‡è§‚å¯Ÿå¢åŠ èšç±»ä¸­å¿ƒçš„ä¸ªæ•°ï¼Œå…¶ä»£ä»·å‡½æ•°æ˜¯å¦‚ä½•å˜åŒ–çš„ã€‚æœ‰æ—¶å€™æˆ‘ä»¬å¯ä»¥å¾—åˆ°å¦‚å·¦è¾¹çš„å›¾åƒï¼Œå¯ä»¥çœ‹åˆ°åœ¨K=3çš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªè‚˜ç‚¹ï¼ˆElbowï¼‰ã€‚å› ä¸ºä»1-3ï¼Œä»£ä»·å‡½æ•°è¿…é€Ÿä¸‹é™ï¼Œä½†æ˜¯éšåä¸‹é™æ¯”è¾ƒç¼“æ…¢ï¼Œæ‰€ä»¥K=3ï¼Œä¹Ÿå°±æ˜¯åˆ†ä¸º3ä¸ªç±»æ˜¯ä¸€ä¸ªå¥½çš„é€‰æ‹©ã€‚</p><p>ç„¶è€Œï¼Œç°å®å¾€å¾€æ˜¯æ®‹é…·çš„ï¼Œæˆ‘ä»¬ä¹Ÿä¼šå¾—åˆ°å³è¾¹çš„ä»£ä»·å‡½æ•°ï¼Œæ ¹æœ¬æ²¡æœ‰è‚˜ç‚¹ï¼Œè¿™å°±è®©æˆ‘ä»¬éš¾ä»¥é€‰åˆ™äº†ã€‚</p><hr><h2 id="äºŒ-Unsupervised-Learning-æµ‹è¯•"><a href="#äºŒ-Unsupervised-Learning-æµ‹è¯•" class="headerlink" title="äºŒ. Unsupervised Learning æµ‹è¯•"></a>äºŒ. Unsupervised Learning æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>For which of the following tasks might K-means clustering be a suitable algorithm? Select all that apply.</p><p>A. Given a database of information about your users, automatically group them into different market segments.</p><p>B. Given sales data from a large number of products in a supermarket, figure out which products tend to form coherent groups (say are frequently purchased together) and thus should be put on the same shelf.</p><p>C. Given historical weather records, predict the amount of rainfall tomorrow (this would be a real-valued output)</p><p>D. Given sales data from a large number of products in a supermarket, estimate future sales for each of these products.</p><p>è§£ç­”ï¼šAã€B</p><p>A.å‰é¢çš„ç»†åˆ†å¸‚åœºä¾‹å­ã€‚<br>B.ç»†åˆ†å¸‚åœºçš„å®ä¾‹ã€‚<br>C.ç»™å‡ºå†å²çš„å¤©æ°”è®°å½•ï¼Œé‚£ä¹Ÿå°±æ˜¯è¯´æ˜ç¡®çŸ¥é“äº†çœŸå®å€¼ã€‚å±äºç›‘ç£å­¦ä¹ ã€‚<br>D.åŒCã€‚  </p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose we have three cluster centroids $\mu_{1}  = \begin{bmatrix}<br>1\<br>2<br>\end{bmatrix}$, $\mu_{2}  = \begin{bmatrix}<br>-3\<br>0<br>\end{bmatrix}$ and $\mu_{3}  = \begin{bmatrix}<br>4\<br>2<br>\end{bmatrix}$. Furthermore, we have a training example $x^{(i)}  = \begin{bmatrix}<br>3\<br>1<br>\end{bmatrix}$. After a cluster assignment step, what will $c^{(i)}$ be?</p><p>A. $c^{(i)} = 1$  </p><p>B. $c^{(i)} = 3$  </p><p>C. $c^{(i)} = 2$  </p><p>D. $c^{(i)} $ is not assigned  </p><p>è§£ç­”ï¼šB</p><p>è®¡ç®— $\frac{1}{m}\sum^{m}_{i=1}\left \| x^{(i)} - \mu_{c}^{(i)} \right \|^{2}$ æœ€å°å€¼ï¼Œä»£å…¥è®¡ç®—å³å¯ï¼ŒB é€‰é¡¹æ˜¯æœ€å°çš„ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>K-means is an iterative algorithm, and two of the following steps are repeatedly carried out in its inner-loop. Which two?</p><p>A. Using the elbow method to choose K.</p><p>B. The cluster assignment step, where the parameters $c^{(i)} $ are updated.</p><p>C. Feature scaling, to ensure each feature is on a comparable scale to the others.</p><p>D. Move the cluster centroids, where the centroids $\mu_{k}$ are updated.</p><p>è§£ç­”ï¼šBã€D</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Suppose you have an unlabeled dataset $\begin{Bmatrix}<br>x^{(1)},\cdots,x^{(m)}<br>\end{Bmatrix}$. You run K-means with 50 different random initializations, and obtain 50 different clusterings of the data. What is the recommended way for choosing which one of these 50 clusterings to use?</p><p>A. The only way to do so is if we also have labels y(i) for our data.</p><p>B. For each of the clusterings, compute $\frac{1}{m}\sum^{m}<em>{i=1}\left | x^{(i)} - \mu</em>{c}^{(i)} \right |^{2}$, and pick the one that minimizes this.</p><p>C. Always pick the final (50th) clustering found, since by that time it is more likely to have converged to a good solution.</p><p>D. The answer is ambiguous, and there is no good way of choosing.</p><p>è§£ç­”ï¼š C</p><p>åˆå§‹åŒ–é€‰ä»£ä»·å‡½æ•°æœ€å°çš„ã€‚</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Select all that apply.</p><p>A. If we are worried about K-means getting stuck in bad local optima, one way to ameliorate (reduce) this problem is if we try using multiple random initializations.</p><p>B. Since K-Means is an unsupervised learning algorithm, it cannot overfit the data, and thus it is always better to have as large a number of clusters as is computationally feasible.</p><p>C. The standard way of initializing K-means is setting $\mu_{1},\cdots,\mu_{k}$ to be equal to a vector of zeros.</p><p>D. For some datasets, the â€œrightâ€ or â€œcorrectâ€ value of K (the number of clusters) can be ambiguous, and hard even for a human expert looking carefully at the data to decide.</p><p>è§£ç­”ï¼šAã€D</p><p>A. ä¸ºäº†å‡å°‘é™·å…¥å±€éƒ¨æœ€ä¼˜çš„ç»“æœï¼Œå¯ä»¥å¤šæ¬¡é€‰å–éšæœºåˆå§‹å‚æ•°ã€‚<br>B. å› ä¸ºéç›‘ç£å­¦ä¹ æ²¡æœ‰è¿‡æ‹Ÿåˆæ‰€ä»¥å¯ä»¥é€‰å–æ›´å¤šçš„ç°‡ï¼Œé‚£æ˜¾ç„¶æ˜¯ä¸å¯¹çš„ï¼Œä¸æ˜¯è¶Šå¤šçš„ç°‡è¶Šå¥½ï¼Œè€Œæ˜¯çœ‹æˆ‘ä»¬çš„è¦æ±‚çš„ã€‚<br>C. åˆå§‹åŒ–èšç±»ä¸­å¿ƒåº”è¯¥æ˜¯è®©å…¶éšæœºç­‰äºè®­ç»ƒæ ·æœ¬çš„å€¼ã€‚<br>D. Kå€¼å¾ˆéš¾ç¡®å®šï¼Œæ­£ç¡®ã€‚  </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Unsupervised_Learning.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Unsupervised_Learning.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.1_Support_Vector_Machines</title>
      <link href="/2020/02/07/7-1-support-vector-machines/"/>
      <url>/2020/02/07/7-1-support-vector-machines/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-db5ca3ef83a4cc2e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-å¼•å­"><a href="#ä¸€-å¼•å­" class="headerlink" title="ä¸€. å¼•å­"></a>ä¸€. å¼•å­</h2><p>åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæˆ‘ä»¬çš„é¢„æµ‹å‡½æ•°ä¸ºï¼š</p><p>$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$</p><p>å¯¹äºæ¯ä¸€ä¸ªæ ·æœ¬ (x,y) è€Œè¨€ï¼ˆæ³¨æ„æ˜¯æ¯ä¸€ä¸ªï¼‰ï¼Œå…¶ä»£ä»·å‡½æ•°ä¸ºï¼š</p> $$\begin{align*}J(\theta)&amp;=-(ylogh_\theta(x)+(1-y)log(1-h_\theta((x)))\\&amp;=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}})\end{align*}\\$$<p>é‚£ä¹ˆå½“ y=1 çš„æ—¶å€™ï¼Œ $J(\theta)=-ylog\frac{1}{1+e^{-\theta^Tx}}$ ï¼Œå…¶ä»£ä»·å‡½æ•°çš„å›¾åƒå…¥å·¦ä¸‹å›¾æ‰€ç¤ºã€‚</p><p>å½“ y=0 çš„æ—¶å€™ï¼Œ $J(\theta)=-(1-y)log(1-\frac{1}{1+e^{-\theta^Tx}})$ ï¼Œå…¶ä»£ä»·å‡½æ•°çš„å›¾åƒå…¥å³ä¸‹å›¾æ‰€ç¤ºã€‚</p><p>å¯¹äºæ”¯æŒå‘é‡æœºè€Œè¨€ï¼Œ</p><p>$y=1$ çš„æ—¶å€™ï¼š</p><p>$$cost_1(\theta^Tx^{(i)})=(-logh_\theta(x^{(i)}))$$</p><p>$y=0$ çš„æ—¶å€™ï¼š</p><p>$$cost_0((\theta^Tx^{(i)})=((-log(1-h_\theta(x^{(i)})))$$ </p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_1.png" alt=""></p><p>å½“ y=1 æ—¶ï¼Œéšç€ z å–å€¼å˜å¤§ï¼Œé¢„æµ‹ä»£ä»·å˜å°ï¼Œå› æ­¤ï¼Œé€»è¾‘å›å½’æƒ³è¦åœ¨é¢å¯¹æ­£æ ·æœ¬  y=1  æ—¶ï¼Œè·å¾—è¶³å¤Ÿé«˜çš„é¢„æµ‹ç²¾åº¦ï¼Œå°±å¸Œæœ›  $z= \theta^Tx\gg 0 $ ã€‚è€Œ SVM åˆ™å°†ä¸Šå›¾çš„æ›²çº¿æ‹‰ç›´ä¸ºä¸‹å›¾ä¸­çš„æŠ˜çº¿ï¼Œæ„æˆäº† y=1 æ—¶çš„ä»£ä»·å‡½æ•°æ›²çº¿  $cost_1(z)$ ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_2.png" alt=""></p><p>å½“ y=1 æ—¶ï¼Œä¸ºäº†é¢„æµ‹ç²¾åº¦è¶³å¤Ÿé«˜ï¼ŒSVM å¸Œæœ› $\theta^Tx\geqslant 1$ ã€‚</p><p>åŒæ ·ï¼Œåœ¨ y=0 æ—¶ï¼ŒSVM å®šä¹‰äº†ä»£ä»·å‡½æ•° $cost_0(z)$ ï¼Œä¸ºäº†é¢„æµ‹ç²¾åº¦è¶³å¤Ÿé«˜ï¼ŒSVM å¸Œæœ›  $\theta^Tx \leqslant -1$ ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_3.png" alt=""></p><p>åœ¨é€»è¾‘å›å½’ä¸­ï¼Œå…¶ä»£ä»·å‡½æ•°æ˜¯ï¼š </p>$$J(\theta)=min_{\theta} \frac{1}{m}[\sum_{i=1}^{m}{y^{(i)}}(-logh_\theta(x^{(i)}))+(1-y^{(i)})((-log(1-h_\theta(x^{(i)})))]+\frac{\lambda}{2m}\sum_{j=1}^{n}{\theta_j^2}$$<p>å¯¹äºé€»è¾‘å›å½’è€Œè¨€ï¼Œå…¶ä»£ä»·å‡½æ•°æ˜¯æœ‰ä¸¤é¡¹å†³å®šçš„ï¼Œç¬¬ä¸€é¡¹æ˜¯æ¥è‡ªè®­ç»ƒæ ·æœ¬çš„ä»£ä»·å‡½æ•°ï¼Œç¬¬äºŒé¡¹æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œè¿™å°±ç›¸å½“äºæˆ‘ä»¬ç”¨æœ€å°åŒ– A åŠ ä¸Šæ­£åˆ™åŒ–å‚æ•° $\lambda$ ä¹˜ä»¥å‚æ•°å¹³æ–¹é¡¹ Bï¼Œå…¶å½¢å¼å¤§æ¦‚æ˜¯ï¼š $A+\lambda B$ ã€‚è¿™é‡Œæˆ‘ä»¬æ˜¯é€šè¿‡è®¾ç½®ä¸åŒçš„æ­£åˆ™å‚æ•° $\lambda$ æ¥è¾¾åˆ°ä¼˜åŒ–çš„ç›®çš„ã€‚ä½†æ˜¯åœ¨æ”¯æŒå‘é‡æœºè¿™é‡Œï¼ŒæŠŠå‚æ•°æåˆ°å‰é¢ï¼Œç”¨å‚æ•° C ä½œä¸º A çš„å‚æ•°ï¼Œä»¥ A ä½œä¸ºæƒé‡ã€‚æ‰€ä»¥å…¶å½¢å¼æ˜¯è¿™æ ·çš„ï¼š $CA+B$ ã€‚</p><p>åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ­£è§„åŒ–å‚æ•° $\lambda$ è°ƒèŠ‚ Aã€B æ‰€å çš„æƒé‡ï¼Œä¸” A çš„æƒé‡ä¸$\lambda$ å–å€¼æˆåæ¯”ã€‚è€Œåœ¨ SVM ä¸­ï¼Œåˆ™é€šè¿‡å‚æ•° C è°ƒèŠ‚ Aã€B æ‰€å çš„æƒé‡ï¼Œä¸” A çš„æƒé‡ä¸  C çš„å–å€¼æˆåæ¯”ã€‚äº¦å³ï¼Œå‚æ•° C å¯ä»¥è¢«è®¤ä¸ºæ˜¯æ‰®æ¼”äº† $\frac{1}{\lambda}$ çš„è§’è‰²ã€‚</p><p>æ‰€ä»¥ $\frac{1}{ m}$ è¿™ä¸€é¡¹ä»…ä»…æ˜¯ç›¸å½“äºä¸€ä¸ªå¸¸é‡ï¼Œå¯¹äºæœ€å°åŒ–å‚æ•° $\theta$ æ˜¯æ²¡æœ‰å®Œå…¨ä»»ä½•å½±å“çš„ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å°†å…¶å»æ‰ã€‚</p><p>æ”¯æŒå‘é‡æœºçš„ä»£ä»·å‡½æ•°ä¸ºï¼š</p>$$min_{\theta} C[\sum_{i=1}^{m}{y^{(i)}}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{j=1}^{n}{\theta_j^2}$$<p>æœ‰åˆ«äºé€»è¾‘å›å½’å‡è®¾å‡½æ•°è¾“å‡ºçš„æ˜¯æ¦‚ç‡ï¼Œæ”¯æŒå‘é‡æœºå®ƒæ˜¯ç›´æ¥é¢„æµ‹ y çš„å€¼æ˜¯0è¿˜æ˜¯1ã€‚ä¹Ÿå°±æ˜¯è¯´å…¶å‡è®¾å‡½æ•°æ˜¯è¿™æ ·å­çš„ï¼š</p>$$h_{\theta}(x)=\left\{\begin{matrix}1,\;\;if\; \theta^{T}x\geqslant 0\\ 0,\;\;otherwise\end{matrix}\right.$$<h2 id="äºŒ-Large-Margin-Classification-å¤§é—´è·åˆ†ç±»å™¨"><a href="#äºŒ-Large-Margin-Classification-å¤§é—´è·åˆ†ç±»å™¨" class="headerlink" title="äºŒ. Large Margin Classification å¤§é—´è·åˆ†ç±»å™¨"></a>äºŒ. Large Margin Classification å¤§é—´è·åˆ†ç±»å™¨</h2><p>æ”¯æŒå‘é‡æœºæ˜¯æœ€åä¸€ä¸ªç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œä¸å‰é¢æˆ‘ä»¬æ‰€å­¦çš„é€»è¾‘å›å½’å’Œç¥ç»ç½‘ç»œç›¸æ¯”ï¼Œæ”¯æŒå‘é‡æœºåœ¨å­¦ä¹ å¤æ‚çš„éçº¿æ€§æ–¹ç¨‹æ—¶ï¼Œæä¾›äº†ä¸€ç§æ›´ä¸ºæ¸…æ™°ã€æ›´åŠ å¼ºå¤§çš„æ–¹å¼ã€‚</p><p>æ”¯æŒå‘é‡æœºä¹Ÿå«åšå¤§é—´è·åˆ†ç±»å™¨(large margin classifiers)ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_4.png" alt=""></p><p>å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®é›†æ˜¯è¿™æ ·çš„ï¼Œå¯ä»¥çœ‹å‡ºï¼Œè¿™æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚ä½†æ˜¯æœ‰æ—¶å€™æˆ‘ä»¬çš„å†³ç­–è¾¹ç•Œå°±å¥½åƒå›¾ä¸­ç»¿è‰²çº¿æˆ–è€…ç²‰çº¢è‰²çº¿ä¸€æ ·ï¼Œè¿™æ ·çš„å†³ç­–è¾¹ç•Œçœ‹èµ·æ¥éƒ½ä¸æ˜¯ç‰¹åˆ«å¥½çš„é€‰æ‹©ã€‚æ”¯æŒå‘é‡æœºå°±ä¼šé€‰æ‹©é»‘è‰²è¿™ä¸€æ¡å†³ç­–è¾¹ç•Œã€‚é»‘è‰²è¿™æ¡è¾¹ç•Œç›¸æ¯”ä¹‹å‰è·Ÿæ­£è´Ÿæ ·æœ¬æœ‰æ›´å¤§çš„è·ç¦»ï¼Œè€Œè¿™ä¸ªè·ç¦»å°±å«åšé—´è·ï¼ˆmarginï¼‰ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†æ”¯æŒå‘é‡æœºå«åšå¤§é—´è·åˆ†ç±»å™¨çš„åŸå› ã€‚</p><p>æ”¯æŒå‘é‡æœºæ¨¡å‹çš„åšæ³•æ˜¯ï¼Œå³åŠªåŠ›å°†æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ç”¨æœ€å¤§çš„é—´è·åˆ†å¼€ã€‚</p><p>$$min_{\theta} C[\sum_{i=1}^{m}{y^{(i)}}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{j=1}^{n}{\theta_j^2}$$</p><p>å½“ y=1 æ—¶ï¼ŒSVM å¸Œæœ› $\theta^Tx\geqslant 1$ ã€‚åœ¨ y=0 æ—¶ï¼ŒSVM å¸Œæœ›  $\theta^Tx \leqslant -1$ï¼Œå¯¹äºå‰é¢çš„é‚£ä¸€é¡¹ A æœ€å°åŒ–ä»£ä»·å‡½æ•°ï¼Œé‚£ä¹ˆæœ€ç†æƒ³å½“ç„¶æ˜¯ä¸º0ã€‚æ‰€ä»¥è¿™å°±å˜æˆäº†ï¼š</p>$$min_{\theta}\frac{1}{2}\sum_{i=1}^{n}{\theta_j^2}\;\;\;\;\;\; \left\{\begin{matrix}\theta^Tx\geqslant 1,if \;y^{(i)}=1 \\\theta^Tx\leqslant 1 ,if \;y^{(i)}=0\end{matrix}\right.$$<p><img src="https://img.halfrost.com/Blog/ArticleImage/76_12.png" alt=""></p><p><strong>å‚æ•° C å…¶å®æ˜¯æ”¯æŒå‘é‡æœºå¯¹å¼‚å¸¸ç‚¹çš„æ•æ„Ÿç¨‹åº¦ï¼ŒC è¶Šå¤§å°±è¶Šæ•æ„Ÿï¼Œä»»ä½•å¼‚å¸¸ç‚¹éƒ½ä¼šå½±å“æœ€ç»ˆç»“æœã€‚ C è¶Šå°ï¼Œå¯¹å¼‚å¸¸ç‚¹å°±è¶Šä¸æ•æ„Ÿï¼Œæ™®é€šçš„ä¸€ä¸¤ä¸ªå¼‚å¸¸ç‚¹éƒ½ä¼šè¢«å¿½ç•¥ã€‚</strong></p><hr><h3 id="æ¨å¯¼"><a href="#æ¨å¯¼" class="headerlink" title="æ¨å¯¼"></a>æ¨å¯¼</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_5.png" alt=""></p><p>ä»¥ä¸¤ä¸ªäºŒç»´å‘é‡ä¸ºä¾‹ï¼Œæˆ‘ä»¬æŠŠå‘é‡ v æŠ•å½±åˆ°å‘é‡ u ä¸Šï¼Œå…¶æŠ•å½±çš„é•¿åº¦ä¸º pï¼Œ$\left | u \right |$ ä¸ºå‘é‡ u çš„æ¨¡ï¼Œé‚£ä¹ˆå‘é‡çš„å†…ç§¯å°±ç­‰äº$p*\left | u \right |$ã€‚åœ¨ä»£æ•°å®šä¹‰å‘é‡å†…ç§¯å¯è¡¨ç¤ºä¸ºï¼š $u_1v_1+u_2v_2$ ï¼Œæ ¹æ®æ­¤å®šä¹‰å¯ä»¥å¾—å‡ºï¼š $u^Tv=u_1v_1+u_2v_2$ ã€‚</p><p>$\left | u \right |$ä¸º $\overrightarrow{u}$ çš„èŒƒæ•°ï¼Œä¹Ÿå°±æ˜¯å‘é‡ $\overrightarrow{u}$ çš„æ¬§å‡ é‡Œå¾—é•¿åº¦ã€‚</p><p>æœ€å°åŒ–å‡½æ•°ä¸ºï¼š $$min_{\theta}\frac{1}{2}\sum_{i=1}^{n}{\theta_j^2}$$ </p><p>è¿™é‡Œä»¥ç®€å•çš„äºŒç»´ä¸ºä¾‹ï¼š</p>$$min_{\theta}\frac{1}{2}\sum_{i=1}^{n}{\theta_j^2}=\frac{1}{2}(\theta_1^2+\theta_2^2)=\frac{1}{2}(\sqrt{\theta_1^2+\theta_2^2})^2=\frac{1}{2}\left \| \theta \right \|^2$$<p>æ¯•è¾¾å“¥æ‹‰æ–¯å®šç†ï¼š</p><p>$$ \left | u \right | = \sqrt{u_{1}^{2} + u_{2}^{2}}$$</p><p><strong>åªè¦ $\theta$ èƒ½æœ€å°ï¼Œæœ€å°åŒ–å‡½æ•°å°±èƒ½å–åˆ°æœ€å°</strong>ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_11.png" alt=""></p><p>å½“å‚ç›´çš„æ—¶å€™ $\theta$ å–æœ€å°å€¼(å‚ç›´çš„æ—¶å€™ï¼Œä¸¤ä¸ªå‘é‡çš„å¤¹è§’ cos $\theta$ æœ€å°)ã€‚è¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆæ”¯æŒå‘é‡æœºçš„å†³ç­–è¾¹ç•Œä¸ä¼šé€‰æ‹©å·¦å›¾ç»¿è‰²é‚£æ¡ã€‚å› ä¸ºæ–¹ä¾¿ç†è§£æ‰€ä»¥ $\theta_0=0$ ï¼Œè¿™å°±æ„å‘³ç€å†³ç­–è¾¹ç•Œè¦ç»è¿‡åŸç‚¹ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨å‚ç›´äºå†³ç­–è¾¹ç•Œçš„ $\theta $å’Œ $x^{(i)}$ çš„å…³ç³»ï¼ˆçº¢è‰²æŠ•å½±å’Œç²‰çº¢è‰²æŠ•å½±ï¼‰ï¼Œå¯ä»¥çœ‹åˆ°å…¶æŠ•å½± $p^{(i)}$ çš„å€¼éƒ½æ¯”è¾ƒå°ï¼Œè¿™ä¹Ÿå°±æ„å‘³ç€è¦ $||\theta||^2$ çš„å€¼å¾ˆå¤§ã€‚è¿™æ˜¾ç„¶æ˜¯ä¸æœ€å°åŒ–å…¬å¼ $\frac{1}{2}||\theta||^2$ çŸ›ç›¾çš„ã€‚æ‰€ä»¥æ”¯æŒå‘é‡æœºçš„å†³ç­–è¾¹ç•Œä¼šä½¿ $p^{(i)}$ åœ¨ $\theta$ çš„æŠ•å½±å°½é‡å¤§ã€‚</p><p>è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå†³ç­–è¾¹ç•Œä¼šæ˜¯å³å›¾çš„åŸå› ï¼Œä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆæ”¯æŒå‘é‡æœºèƒ½æœ‰æ•ˆåœ°äº§ç”Ÿæœ€å¤§é—´è·åˆ†ç±»çš„åŸå› ã€‚</p><p>(<strong>å› ä¸ºåªæœ‰æœ€å¤§é—´è·æ‰èƒ½ä½¿ $p^{(i)}$ å¤§ï¼Œä»è€Œ $||\theta||^2$ å€¼å°</strong>)</p><hr><h2 id="ä¸‰-Kernels"><a href="#ä¸‰-Kernels" class="headerlink" title="ä¸‰. Kernels"></a>ä¸‰. Kernels</h2><h3 id="1-å®šä¹‰"><a href="#1-å®šä¹‰" class="headerlink" title="1. å®šä¹‰"></a>1. å®šä¹‰</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_6.png" alt=""></p><p>åœ¨æˆ‘ä»¬ä¹‹å‰æ‹Ÿåˆä¸€ä¸ªéçº¿æ€§çš„åˆ¤æ–­è¾¹ç•Œæ¥åŒºåˆ«æ­£è´Ÿæ ·æœ¬ï¼Œæ˜¯æ„é€ å¤šé¡¹å¼ç‰¹å¾å˜é‡ã€‚</p><p>æˆ‘ä»¬å…ˆç”¨ä¸€ç§æ–°çš„å†™æ³•æ¥è¡¨ç¤ºå†³ç­–è¾¹ç•Œï¼š $\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+\cdots $ã€‚æˆ‘ä»¬è¿™é‡Œç”¨ $f_i$ è¡¨è¾¾æ–°çš„ç‰¹å¾å˜é‡ã€‚</p><p>å‡å¦‚æ˜¯ä¹‹å‰æˆ‘ä»¬æ‰€å­¦çš„å†³ç­–è¾¹ç•Œï¼Œé‚£ä¹ˆå°±æ˜¯ï¼š $f_1=x_1 , f_2=x_2 , f_3=x_1x_2 , f_4=x_1^2 ï¼Œ f_5=x_2^2$ ï¼Œç­‰ç­‰ã€‚ä½†æ˜¯è¿™æ ·çš„é«˜é˜¶é¡¹ä½œä¸ºç‰¹å¾å˜é‡å¹¶ä¸æ˜¯æˆ‘ä»¬ç¡®å®šæ‰€éœ€è¦çš„ï¼Œè€Œä¸”è¿ç®—é‡éå¸¸å·¨å¤§ï¼Œé‚£ä¹ˆæœ‰æ²¡æœ‰å…¶ä»–æ›´é«˜çš„ç‰¹å¾å˜é‡å‘¢ï¼Ÿ</p><p>ä¸‹é¢æ˜¯æ„é€ æ–°ç‰¹å¾é‡çš„ä¸€ç§æƒ³æ³•ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_7.png" alt=""></p><p>ä¸ºäº†ç®€å•ç†è§£ï¼Œæˆ‘ä»¬è¿™é‡Œåªå»ºç«‹ä¸‰ä¸ªç‰¹å¾å˜é‡ã€‚é¦–å…ˆæˆ‘ä»¬åœ¨ $x_1,x_2$ åæ ‡è½´ä¸Šæ‰‹åŠ¨é€‰æ‹©3ä¸ªä¸åŒçš„ç‚¹ï¼š $l^{(1)},l^{(2)},l^{(3)}$ ã€‚</p><p>ç„¶åæˆ‘ä»¬å°†ç¬¬ä¸€ä¸ªç‰¹å¾é‡å®šä¹‰ä¸ºï¼š $f_1=similarity(x,l^{(1)})$ ï¼Œå¯ä»¥çœ‹åšæ˜¯æ ·æœ¬ x å’Œç¬¬ä¸€ä¸ªæ ‡è®° $l^{(1)}$ çš„ç›¸ä¼¼åº¦ã€‚å…¶ä¸­å¯ä»¥ç”¨è¿™ä¸ªå…¬å¼è¡¨è¾¾è¿™ç§å…³ç³»ï¼š $f_1=similarity(x,l^{(1)})=exp(-\frac{||x-l^{(1)}||^2}{2\sigma^2})$ (expï¼šè‡ªç„¶å¸¸æ•°eä¸ºåº•çš„æŒ‡æ•°å‡½æ•°)</p><p>ç±»ä¼¼çš„æœ‰ï¼š $f_2=similarity(x,l^{(2)})=exp(-\frac{||x-l^{(2)}||^2}{2\sigma^2})$ ï¼Œ</p>$f_3=similarity(x,l^{(3)})=exp(-\frac{||x-l^{(3)}||^2}{2\sigma^2})$ ã€‚<p>è¿™ä¸ªè¡¨è¾¾å¼æˆ‘ä»¬ç§°ä¹‹ä¸ºæ ¸å‡½æ•°ï¼ˆKernelsï¼‰ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬é€‰ç”¨çš„æ ¸å‡½æ•°æ˜¯é«˜æ–¯æ ¸å‡½æ•°ï¼ˆGaussian Kernelsï¼‰ã€‚</p><p>é‚£ä¹ˆé«˜æ–¯æ ¸å‡½æ•°ä¸ç›¸ä¼¼æ€§åˆæœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿ</p><p>å…ˆæ¥çœ‹ç¬¬ä¸€ä¸ªç‰¹å¾é‡ $f_1$ ï¼Œ<br>$f_1=similarity(x,l^{(1)})=exp(-\frac{||x-l^{(1)}||^2}{2\sigma^2})=exp(\frac{\sum_{j=1}^{n}{(x_j-l_j^{(1)})^2}}{2\sigma^2})$</p><p>å‡å¦‚æ ·æœ¬ x éå¸¸æ¥è¿‘ $l^{(1)}$ ï¼Œå³$x\approx l^{(1)}$ ï¼Œé‚£ä¹ˆï¼š$ f_1\approx exp(-\frac{0^2}{2\sigma^2})\approx 1$ ã€‚</p><p>å‡å¦‚æ ·æœ¬ x ç¦» $l^{(1)}$ éå¸¸è¿œï¼Œå³ $x\gg l^{(1)}$ ï¼Œé‚£ä¹ˆï¼š$ f_1\approx exp(-\frac{\infty^2}{2\sigma^2})\approx 0$ ã€‚</p><p>å¯è§†åŒ–å¦‚ä¸‹ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_8.png" alt=""></p><p>ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°è¶Šæ¥è¿‘ $l^{(1)} , f_1$ çš„å€¼è¶Šå¤§ã€‚</p><p>è¿™é‡Œé¡ºå¸¦è¯´ä¸€ä¸‹ $\sigma^2$ è¿™ä¸ªé«˜æ–¯æ ¸å‡½æ•°çš„å‚æ•°å¯¹å‡½æ•°çš„å½±å“ã€‚ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œå‡å°æˆ–è€…å¢åŠ åªä¼šå¯¹å›¾åƒçš„è‚¥ç˜¦äº§ç”Ÿå½±å“ï¼Œä¹Ÿå°±æ˜¯å½±å“å¢åŠ æˆ–è€…å‡å°çš„é€Ÿåº¦è€Œå·²ã€‚</p><h3 id="2-æ ‡è®°ç‚¹é€‰å–"><a href="#2-æ ‡è®°ç‚¹é€‰å–" class="headerlink" title="2. æ ‡è®°ç‚¹é€‰å–"></a>2. æ ‡è®°ç‚¹é€‰å–</h3><p>é€šè¿‡æ ‡è®°ç‚¹ä»¥åŠæ ¸å‡½æ•°ï¼Œè®­ç»ƒå‡ºéå¸¸å¤æ‚çš„éçº¿æ€§åˆ¤åˆ«è¾¹ç•Œã€‚é‚£æ ‡è®°ç‚¹ $l^{(1)},l^{(2)},l^{(3)}$ è¿™äº›ç‚¹æ˜¯æ€ä¹ˆæ¥çš„ï¼Ÿ</p><p>å‡å®šæˆ‘ä»¬æœ‰å¦‚ä¸‹çš„æ•°æ®é›†ï¼š</p><p>$$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)})\cdots(x^{(m)},y^{(m)})$$</p><p>æˆ‘ä»¬å°±å°†æ¯ä¸ªæ ·æœ¬ä½œä¸ºä¸€ä¸ªæ ‡è®°ç‚¹ï¼š</p><p>$$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},l^{(3)}=x^{(3)}\cdots l^{(m)}=x^{(m)}$$</p><p>åˆ™å¯¹äºæ ·æœ¬ $(x^{(i)},y^{(i)})$ ï¼Œæˆ‘ä»¬è®¡ç®—å…¶ä¸å„ä¸ªæ ‡è®°ç‚¹çš„è·ç¦»ï¼š</p>$$\begin{matrix}f^{(i)}_1=sim(x^{(i)},l^{(1)})\\f^{(i)}_2=sim(x^{(i)},l^{(2)})\\\vdots \\f^{(i)}_m=sim(x^{(i)},l^{(3)})\\\end{matrix}$$<p>å¾—åˆ°æ–°çš„ç‰¹å¾å‘é‡ï¼š $f \in \mathbb{R}^{m+1} $</p>$$f = \begin{bmatrix}f_0\\ f_1\\ f_2\\ \vdots \\ f_m\end{bmatrix}$$<p>å…¶ä¸­ $f_0=1$</p><p>åˆ™å…·å¤‡æ ¸å‡½æ•°çš„ SVM çš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š</p><p>$$min_{\theta} C[\sum_{i=1}^{m}{y^{(i)}}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})]+\frac{1}{2}\sum_{j=1}^{n}{\theta_j^2}$$</p><hr><h2 id="å››-SVMs-in-Practice"><a href="#å››-SVMs-in-Practice" class="headerlink" title="å››. SVMs in Practice"></a>å››. SVMs in Practice</h2><h3 id="1-ä½¿ç”¨æµè¡Œåº“"><a href="#1-ä½¿ç”¨æµè¡Œåº“" class="headerlink" title="1. ä½¿ç”¨æµè¡Œåº“"></a>1. ä½¿ç”¨æµè¡Œåº“</h3><p>ä½œä¸ºå½“ä»Šæœ€ä¸ºæµè¡Œçš„åˆ†ç±»ç®—æ³•ä¹‹ä¸€ï¼ŒSVM å·²ç»æ‹¥æœ‰äº†ä¸å°‘ä¼˜ç§€çš„å®ç°åº“ï¼Œå¦‚ libsvm ç­‰ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬ä¸å†éœ€è¦è‡ªå·±æ‰‹åŠ¨å®ç° SVMï¼ˆè¦çŸ¥é“ï¼Œä¸€ä¸ªèƒ½ç”¨äºç”Ÿäº§ç¯å¢ƒçš„ SVM æ¨¡å‹å¹¶éè¯¾ç¨‹ä¸­ä»‹ç»çš„é‚£ä¹ˆç®€å•ï¼‰ã€‚</p><p>åœ¨ä½¿ç”¨è¿™äº›åº“æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦å£°æ˜ SVM éœ€è¦çš„ä¸¤ä¸ªå…³é”®éƒ¨åˆ†ï¼š</p><ul><li>å‚æ•°  C </li><li>æ ¸å‡½æ•°ï¼ˆKernelï¼‰</li></ul><p>ç”±äº C å¯ä»¥çœ‹åšä¸æ­£è§„åŒ–å‚æ•° $\lambda $ ä½œç”¨ç›¸åï¼Œåˆ™å¯¹äº C çš„è°ƒèŠ‚ï¼š</p><p><strong>ä½åå·®</strong>ï¼Œ<strong>é«˜æ–¹å·®</strong>ï¼Œå³é‡åˆ°äº†è¿‡æ‹Ÿåˆæ—¶ï¼šå‡å° C å€¼ã€‚<br><strong>é«˜åå·®</strong>ï¼Œ<strong>ä½æ–¹å·®</strong>ï¼Œå³é‡åˆ°äº†æ¬ æ‹Ÿåˆæ—¶ï¼šå¢å¤§ C å€¼ã€‚  </p><p>è€Œå¯¹äºæ ¸å‡½æ•°çš„é€‰æ‹©æœ‰è¿™ä¹ˆä¸€äº› tipsï¼š</p><ul><li>å½“ç‰¹å¾ç»´åº¦ n è¾ƒé«˜ï¼Œè€Œæ ·æœ¬è§„æ¨¡ m è¾ƒå°æ—¶ï¼Œä¸å®œä½¿ç”¨æ ¸å‡½æ•°ï¼Œå¦åˆ™å®¹æ˜“å¼•èµ·è¿‡æ‹Ÿåˆã€‚</li><li>å½“ç‰¹å¾ç»´åº¦ n è¾ƒä½ï¼Œè€Œæ ·æœ¬è§„æ¨¡ m è¶³å¤Ÿå¤§æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°ã€‚ä¸è¿‡åœ¨ä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°å‰ï¼Œéœ€è¦è¿›è¡Œç‰¹å¾ç¼©æ”¾ï¼ˆfeature scalingï¼‰ã€‚</li><li>å½“æ ¸å‡½æ•°çš„å‚æ•° $\sigma^2$ è¾ƒå¤§æ—¶ï¼Œç‰¹å¾ $f_i$ è¾ƒä¸ºå¹³ç¼“ï¼Œå³å„ä¸ªæ ·æœ¬çš„ç‰¹å¾å·®å¼‚å˜å°ï¼Œæ­¤æ—¶ä¼šé€ æˆæ¬ æ‹Ÿåˆï¼ˆé«˜åå·®ï¼Œä½æ–¹å·®ï¼‰ï¼Œå¦‚ä¸‹å›¾ä¸Šè¾¹çš„å›¾ï¼Œ</li><li>å½“ $\sigma^2$ è¾ƒå°æ—¶ï¼Œç‰¹å¾ $f_i$ æ›²çº¿å˜åŒ–å‰§çƒˆï¼Œå³å„ä¸ªæ ·æœ¬çš„ç‰¹å¾å·®å¼‚å˜å¤§ï¼Œæ­¤æ—¶ä¼šé€ æˆè¿‡æ‹Ÿåˆï¼ˆä½åå·®ï¼Œé«˜æ–¹å·®ï¼‰ï¼Œå¦‚ä¸‹å›¾ä¸‹è¾¹çš„å›¾ï¼š</li></ul><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_9.png" alt=""></p><h3 id="2-å¤šåˆ†ç±»é—®é¢˜"><a href="#2-å¤šåˆ†ç±»é—®é¢˜" class="headerlink" title="2. å¤šåˆ†ç±»é—®é¢˜"></a>2. å¤šåˆ†ç±»é—®é¢˜</h3><p>é€šå¸¸ï¼Œæµè¡Œçš„SVMåº“å·²ç»å†…ç½®äº†å¤šåˆ†ç±»ç›¸å…³çš„ apiï¼Œå¦‚æœå…¶ä¸æ”¯æŒå¤šåˆ†ç±»ï¼Œåˆ™ä¸é€»è¾‘å›å½’ä¸€æ ·ï¼Œä½¿ç”¨ One-vs-All ç­–ç•¥æ¥è¿›è¡Œå¤šåˆ†ç±»ï¼š</p><ol><li>è½®æµé€‰ä¸­æŸä¸€ç±»å‹ i ï¼Œå°†å…¶è§†ä¸ºæ­£æ ·æœ¬ï¼Œå³ â€œ1â€ åˆ†ç±»ï¼Œå‰©ä¸‹æ ·æœ¬éƒ½çœ‹åšæ˜¯è´Ÿæ ·æœ¬ï¼Œå³ â€œ0â€ åˆ†ç±»ã€‚</li><li>è®­ç»ƒ SVM å¾—åˆ°å‚æ•° $\theta^{(1)},\theta^{(2)},\cdots,\theta^{(K)}$  ï¼Œå³æ€»å…±è·å¾—äº† Kâˆ’1 ä¸ªå†³ç­–è¾¹ç•Œã€‚</li></ol><p><img src="https://img.halfrost.com/Blog/ArticleImage/76_10.png" alt=""></p><h3 id="3-åˆ†ç±»æ¨¡å‹çš„é€‰æ‹©"><a href="#3-åˆ†ç±»æ¨¡å‹çš„é€‰æ‹©" class="headerlink" title="3. åˆ†ç±»æ¨¡å‹çš„é€‰æ‹©"></a>3. åˆ†ç±»æ¨¡å‹çš„é€‰æ‹©</h3><p>ç›®å‰ï¼Œæˆ‘ä»¬å­¦åˆ°çš„åˆ†ç±»æ¨¡å‹æœ‰ï¼š</p><p>ï¼ˆ1ï¼‰é€»è¾‘å›å½’ï¼›<br>ï¼ˆ2ï¼‰ç¥ç»ç½‘ç»œï¼›<br>ï¼ˆ3ï¼‰SVM  </p><p>æ€ä¹ˆé€‰æ‹©åœ¨è¿™ä¸‰è€…ä¸­åšå‡ºé€‰æ‹©å‘¢ï¼Ÿæˆ‘ä»¬è€ƒè™‘ç‰¹å¾ç»´åº¦ n åŠæ ·æœ¬è§„æ¨¡ m ï¼š</p><p>å¦‚æœ n ç›¸å¯¹äº m éå¸¸å¤§ï¼Œä¾‹å¦‚ n=10000 ï¼Œè€Œ $m\in(10,1000)$ ï¼šæ­¤æ—¶é€‰ç”¨é€»è¾‘å›å½’æˆ–è€…æ— æ ¸çš„ SVMã€‚  </p><p>å¦‚æœ n è¾ƒå°ï¼Œm é€‚ä¸­ï¼Œå¦‚  $n\in(1,1000)$ ï¼Œè€Œ  $m\in(10,10000)$ ï¼šæ­¤æ—¶é€‰ç”¨æ ¸å‡½æ•°ä¸ºé«˜æ–¯æ ¸å‡½æ•°çš„ SVMã€‚  </p><p>å¦‚æœ n è¾ƒå°ï¼Œm è¾ƒå¤§ï¼Œå¦‚  $n\in(1,1000)$ ï¼Œè€Œ  m&gt;50000 ï¼šæ­¤æ—¶ï¼Œéœ€è¦åˆ›å»ºæ›´å¤šçš„ç‰¹å¾ï¼ˆæ¯”å¦‚é€šè¿‡å¤šé¡¹å¼æ‰©å±•ï¼‰ï¼Œå†ä½¿ç”¨é€»è¾‘å›å½’æˆ–è€…æ— æ ¸çš„ SVMã€‚<br>ç¥ç»ç½‘ç»œå¯¹äºä¸Šè¿°æƒ…å½¢éƒ½æœ‰ä¸é”™çš„é€‚åº”æ€§ï¼Œä½†æ˜¯è®¡ç®—æ€§èƒ½ä¸Šè¾ƒæ…¢ã€‚  </p><hr><h2 id="å››-Support-Vector-Machines-æµ‹è¯•"><a href="#å››-Support-Vector-Machines-æµ‹è¯•" class="headerlink" title="å››. Support_Vector_Machines æµ‹è¯•"></a>å››. Support_Vector_Machines æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose you have trained an SVM classifier with a Gaussian kernel, and it learned the following decision boundary on the training set:</p><p><img src="http://spark-public.s3.amazonaws.com/ml/images/12.1-b.jpg" alt=""></p><p>When you measure the SVMâ€™s performance on a cross validation set, it does poorly. Should you try increasing or decreasing C? Increasing or decreasing $\sigma^{2}$?</p><p>A. It would be reasonable to try <strong>decreasing</strong> C. It would also be reasonable to try <strong>increasing</strong> $\sigma^{2}$.</p><p>B. It would be reasonable to try <strong>increasing</strong> C. It would also be reasonable to try <strong>increasing</strong> $\sigma^{2}$.</p><p>C. It would be reasonable to try <strong>increasing</strong> C. It would also be reasonable to try <strong>decreasing</strong> $\sigma^{2}$.</p><p>D. It would be reasonable to try <strong>decreasing</strong> C. It would also be reasonable to try <strong>decreasing</strong> $\sigma^{2}$.</p><p>è§£ç­”ï¼šA</p><p>è¿‡æ‹Ÿåˆåº”è¯¥å‡å° C å’Œå¢å¤§ $\sigma^2$</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>The formula for the Gaussian kernel is given by similarity $(x,l^{(1)})=exp(-\frac{\left \| x-l^{(1)} \right \|^{2}}{2\sigma^{2} })$ .</p><p>The figure below shows a plot of f1=similarity $(x,l^{(1)})$ when $\sigma^{2} = 1$.</p><p><img src="http://spark-public.s3.amazonaws.com/ml/images/12.2-question.jpg" alt=""></p><p>Which of the following is a plot of f1 when $\sigma^{2} = 0.25$?</p><p>A. <img src="http://spark-public.s3.amazonaws.com/ml/images/12.2-b.jpg" alt=""></p><p>B. <img src="http://spark-public.s3.amazonaws.com/ml/images/12.2-a.jpg" alt=""></p><p>C. <img src="http://spark-public.s3.amazonaws.com/ml/images/12.2-d.jpg" alt=""></p><p>D. <img src="http://spark-public.s3.amazonaws.com/ml/images/12.2-c.jpg" alt=""></p><p>è§£ç­”ï¼šA</p><p> $\sigma^{2} $ å˜å°å›¾åƒå˜ç˜¦é«˜ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>The SVM solves</p>$$min_{\theta} C \sum^{m}_{i=1}y^{(i)}cost_{1}(\theta^{T}x^{(i)})+(1-y^{(i)})cost_{0}(\theta^{T}x^{(i)})+\sum^{n}_{j=1}\theta^{2}_{j}$$<p>where the functions $cost_0(z)$ and $cost_1(z)$ look like this:</p><p>The first term in the objective is:</p>$$C \sum^{m}_{i=1}y^{(i)}cost_{1}(\theta^{T} x^{(i)})+(1-y^{(i)})cost_{0}(\theta^{T}x^{(i)})$$<p>This first term will be zero if two of the following four conditions hold true. Which are the two conditions that would guarantee that this term equals zero?</p><p>A. For every example with $y^{(i)}=0$, we have that $\theta^{T}x(i) \leqslant 0$.</p><p>B. For every example with $y^{(i)}=1$, we have that $\theta^{T}x(i) \geqslant 0$.</p><p>C. For every example with $y^{(i)}=0$, we have that $\theta^{T}x(i)\leqslant-1$.</p><p>D. For every example with $y^{(i)}=1$, we have that $\theta^{T}x(i)\geqslant 1$.</p><p>è§£ç­”ï¼šCã€D</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Suppose you have a dataset with n = 10 features and m = 5000 examples.</p><p>After training your logistic regression classifier with gradient descent, you find that it has underfit the training set and does not achieve the desired performance on the training or cross validation sets.</p><p>Which of the following might be promising steps to take? Check all that apply.</p><p>A. Try using a neural network with a large number of hidden units.</p><p>B. Create / add new polynomial features.</p><p>C. Reduce the number of examples in the training set.</p><p>D. Use a different optimization method since using gradient descent to train logistic regression might result in a local minimum.</p><p>è§£ç­”ï¼š Aã€B</p><p>é¢˜å¹²ä¸­è¦æ±‚è§£å†³æ¬ æ‹Ÿåˆçš„é—®é¢˜ã€‚</p><p>A.å¢å¤šç¥ç»ç½‘ç»œçš„éšè—å±‚å¯ä»¥è§£å†³æ¬ æ‹Ÿåˆé—®é¢˜ã€‚<br>B.å¢åŠ ç‰¹å¾é‡å¯ä»¥è§£å†³æ¬ æ‹Ÿåˆé—®é¢˜ã€‚<br>C.å‡å°‘è®­ç»ƒé›†æ ·æœ¬ï¼Œä¸è¡Œã€‚<br>D.ä¸æ˜¯æ¢¯åº¦ä¸‹é™å‡½æ•°åˆ°è¾¾æœ€ä½å€¼æ˜¯ä»£ä»·å‡½æ•°ã€‚  </p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you have 2D input examples (ie, $x^{(i)} \in \mathbb{R}^2$). The decision boundary of the SVM (with the linear kernel) is a straight line.</p><p>B. If the data are linearly separable, an SVM using a linear kernel will return the same parameters $\theta$ regardless of the chosen value of C (i.e., the resulting value of $\theta$ does not depend on C).</p><p>C. If you are training multi-class SVMs with the one-vs-all method, it is not possible to use a kernel.</p><p>D. The maximum value of the Gaussian kernel (i.e., $sim(x,l^{(1)})$) is 1.</p><p>è§£ç­”ï¼šAã€D</p><p>A. çº¿æ€§æ˜¯ä¸€æ¡ç›´çº¿ã€‚<br>B. $min_{\theta} C[\sum_{i=1}^{m}{y^{(i)}}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{j=1}^{n}{\theta_j^2}$ï¼Œ $\theta$æ­£æ˜¯ç”± C çš„å¤§å°å†³å®šçš„ã€‚<br>C. è§£å†³å¤šåˆ†ç±»é—®é¢˜å¯ä»¥ç”¨ SVM ã€‚<br>D. é«˜æ–¯æ ¸å‡½æ•°èŒƒå›´ï¼š[0,1]ã€‚  </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Support_Vector_Machines.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Support_Vector_Machines.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.2_Machine_Learning_System_Design</title>
      <link href="/2020/02/05/6-2-machine-learning-system-design/"/>
      <url>/2020/02/05/6-2-machine-learning-system-design/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-9f4d6b21aaf9f39f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-Building-a-Spam-Classifier"><a href="#ä¸€-Building-a-Spam-Classifier" class="headerlink" title="ä¸€. Building a Spam Classifier"></a>ä¸€. Building a Spam Classifier</h2><p>åƒåœ¾é‚®ä»¶åˆ†ç±»å°±æ˜¯ä¸€ä¸ª 0/1 åˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥ç”¨é€»è¾‘å›å½’å®Œæˆï¼Œè¿™é‡Œä¸å†é‡å¤ä»‹ç»é€»è¾‘å›å½’çš„è¿‡ç¨‹äº†ï¼Œæˆ‘ä»¬è€ƒè™‘å¦‚ä½•é™ä½åˆ†ç±»é”™è¯¯ç‡ï¼š</p><ul><li>å°½å¯èƒ½çš„æ‰©å¤§æ•°æ®æ ·æœ¬ï¼šHonypot åšäº†è¿™æ ·ä¸€ä»¶äº‹ï¼ŒæŠŠè‡ªå·±åŒ…è£…æˆä¸€ä¸ªå¯¹é»‘å®¢æå…·å¸å¼•åŠ›çš„æœºå™¨ï¼Œæ¥è¯±ä½¿é»‘å®¢è¿›è¡Œæ”»å‡»ï¼Œå°±åƒèœœç½ï¼ˆhoney potï¼‰å¸å¼•å¯†å°é‚£æ ·ï¼Œä»è€Œè®°å½•æ”»å‡»è¡Œä¸ºå’Œæ‰‹æ®µã€‚</li><li>æ·»åŠ æ›´å¤šç‰¹å¾ï¼šä¾‹å¦‚æˆ‘ä»¬å¯ä»¥å¢åŠ é‚®ä»¶çš„å‘é€è€…é‚®ç®±ä½œä¸ºç‰¹å¾ï¼Œå¯ä»¥å¢åŠ æ ‡ç‚¹ç¬¦å·ä½œä¸ºç‰¹å¾ï¼ˆåƒåœ¾é‚®ä»¶æ€»ä¼šå……æ–¥äº†ï¼Ÿï¼Œï¼ç­‰å¸å¼•çœ¼çƒçš„æ ‡ç‚¹ï¼‰ã€‚</li><li>é¢„å¤„ç†æ ·æœ¬ï¼šæ­£å¦‚æˆ‘ä»¬åœ¨åƒåœ¾é‚®ä»¶çœ‹åˆ°çš„ï¼Œé“é«˜ä¸€å°ºï¼Œé­”é«˜ä¸€ä¸ˆï¼Œåƒåœ¾é‚®ä»¶çš„åˆ¶é€ è€…ä¹Ÿä¼šå‡çº§è‡ªå·±çš„æ”»å‡»æ‰‹æ®µï¼Œå¦‚åœ¨å•è¯æ‹¼å†™ä¸Šåšæ‰‹è„šæ¥é˜²æ­¢é‚®ä»¶å†…å®¹è¢«çœ‹å‡ºé—®é¢˜ï¼Œä¾‹å¦‚æŠŠ medicine æ‹¼å†™ä¸º med1cinie ç­‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°±è¦æœ‰æ‰‹æ®µæ¥è¯†åˆ«è¿™äº›é”™è¯¯æ‹¼å†™ï¼Œä»è€Œä¼˜åŒ–æˆ‘ä»¬è¾“å…¥åˆ°é€»è¾‘å›å½’ä¸­çš„æ ·æœ¬ã€‚</li></ul><p>å‡å¦‚æˆ‘ä»¬è¦ç”¨æœºå™¨å­¦ä¹ è§£å†³ä¸€ä¸ªé—®é¢˜ï¼Œé‚£ä¹ˆæœ€å¥½çš„å®è·µæ–¹æ³•å°±æ˜¯ï¼š</p><p>1.å»ºç«‹ä¸€ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œç”¨ç®€å•çš„ç®—æ³•å¿«é€Ÿå®ç°å®ƒã€‚</p><p>2.é€šè¿‡ç”»å‡ºå­¦ä¹ æ›²çº¿ï¼Œä»¥åŠæ£€éªŒè¯¯å·®ï¼Œæ¥æ‰¾å‡ºæˆ‘ä»¬çš„ç®—æ³•æ˜¯å¦å­˜åœ¨é«˜åå·®æˆ–è€…é«˜æ–¹å·®çš„é—®é¢˜ï¼Œç„¶åå†é€šè¿‡å‡å¦‚æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€ç‰¹å¾å˜é‡ç­‰ç­‰æ¥å®Œå–„ç®—æ³•ã€‚</p><p>3.è¯¯å·®åˆ†æã€‚ä¾‹å¦‚åœ¨æ„å»ºåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ï¼Œæˆ‘ä»¬æ£€æŸ¥å“ªä¸€ç±»å‹çš„é‚®ä»¶æˆ–è€…é‚£äº›ç‰¹å¾å€¼æ€»æ˜¯å¯¼è‡´é‚®ä»¶è¢«é”™è¯¯åˆ†ç±»ï¼Œä»è€Œå»çº æ­£å®ƒã€‚å½“ç„¶ï¼Œè¯¯å·®çš„åº¦é‡å€¼ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ï¼Œä¾‹å¦‚æˆ‘ä»¬å¯ä»¥å°†é”™è¯¯ç‡è¡¨ç¤ºå‡ºæ¥ï¼Œç”¨æ¥åˆ¤æ–­ç®—æ³•çš„ä¼˜åŠ£ã€‚</p><hr><h2 id="äºŒ-Handling-Skewed-Data"><a href="#äºŒ-Handling-Skewed-Data" class="headerlink" title="äºŒ. Handling Skewed Data"></a>äºŒ. Handling Skewed Data</h2><p>è¯„ä¼°ä¸€ä¸ªæ¨¡å‹çš„å¥½åï¼Œé€šå¸¸ä½¿ç”¨è¯¯å·®åˆ†æå¯è§†åŒ–ï¼Œå³æŠŠé¢„æµ‹çš„å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰æ˜¾ç¤ºå‡ºæ¥ï¼Œå…¶å®è¿™æ ·æ˜¯æœ‰ç¼ºé™·çš„ã€‚è¿™ç§è¯¯å·®åº¦é‡åˆè¢«ç§°ä¸ºåæ–œç±»ï¼ˆSkewed Classesï¼‰é—®é¢˜ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/75_1.png" alt=""></p><p>ä¸¾ä¸ªä¾‹å­ï¼šå‡å¦‚æˆ‘ä»¬åšç™Œç—‡åˆ†æï¼Œæœ€åå¾—å‡ºè¯¥ç®—æ³•åªæœ‰1%çš„è¯¯å·®ï¼Œä¹Ÿå°±æ˜¯è¯´å‡†ç¡®ç‡è¾¾åˆ°äº†99% ã€‚è¿™æ ·çœ‹èµ·æ¥99%ç®—æ˜¯éå¸¸é«˜çš„äº†ï¼Œä½†æ˜¯æˆ‘ä»¬å‘ç°åœ¨è®­ç»ƒé›†é‡Œé¢åªæœ‰0.5%çš„æ‚£è€…æ‚£æœ‰ç™Œç—‡ï¼Œé‚£ä¹ˆè¿™1%çš„é”™è¯¯ç‡å°±å˜å¾—é‚£ä¹ˆå‡†ç¡®äº†ã€‚æˆ‘ä»¬å†ä¸¾ä¸ªæç«¯ä¸€ç‚¹çš„ä¾‹å­ï¼Œæ— è®ºè¾“å…¥æ˜¯ä»€ä¹ˆï¼Œæ‰€æœ‰é¢„æµ‹è¾“å‡ºçš„æ•°æ®éƒ½ä¸º0ï¼ˆä¹Ÿå°±æ˜¯éç™Œç—‡ï¼‰ï¼Œé‚£ä¹ˆæˆ‘ä»¬è¿™é‡Œçš„æ­£ç¡®ç‡æ˜¯99.5%ï¼Œä½†æ˜¯è¿™æ ·çš„åˆ¤æ–­æ ‡å‡†æ˜¾ç„¶ä¸èƒ½ä½“ç°åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚</p><p>è¿™æ˜¯å› ä¸ºä¸¤è€…çš„æ•°æ®ç›¸å·®éå¸¸å¤§ï¼Œåœ¨è¿™é‡Œå› ä¸ºç™Œç—‡çš„æ ·æœ¬éå¸¸å°‘ï¼Œæ‰€ä»¥å¯¼è‡´äº†é¢„æµ‹çš„ç»“æœå°±ä¼šåå‘ä¸€ä¸ªæç«¯ï¼Œæˆ‘ä»¬æŠŠè¿™ç±»çš„æƒ…å†µå«åšåæ–œç±»ï¼ˆSkewed Classesï¼‰é—®é¢˜ã€‚</p><p>æ‰€ä»¥æˆ‘ä»¬éœ€è¦å¦ä¸€ç§çš„è¯„ä¼°æ–¹æ³•ï¼Œå…¶ä¸­ä¸€ç§è¯„ä¼°åº¦é‡å€¼å«åšæŸ¥å‡†ç‡ï¼ˆPrecisionï¼‰å’Œå¬å›ç‡ï¼ˆRecallï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/75_2.png" alt=""></p><p>å»ºç«‹ä¸€ä¸ª2 x 2çš„è¡¨æ ¼ï¼Œæ¨ªåæ ‡ä¸ºçœŸå®å€¼ï¼Œçºµåæ ‡ä¸ºé¢„æµ‹å€¼ï¼Œè¡¨æ ¼å•å…ƒ1-4åˆ†åˆ«ä»£è¡¨ï¼šé¢„æµ‹å‡†ç¡®çš„æ­£æ ·æœ¬ï¼ˆTrue positiveï¼‰ã€é¢„æµ‹é”™è¯¯çš„æ­£æ ·æœ¬ï¼ˆFalse positiveï¼‰ã€é¢„æµ‹é”™è¯¯çš„è´Ÿæ ·æœ¬ï¼ˆFalse negativeï¼‰ã€é¢„æµ‹æ­£ç¡®çš„è´Ÿæ ·æœ¬ï¼ˆTrue negativeï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/75_3.png" alt=""></p><p>æŸ¥å‡†ç‡ï¼ˆPrecisionï¼‰= é¢„æµ‹å‡†ç¡®çš„æ­£æ ·æœ¬ï¼ˆTrue positiveï¼‰/é¢„æµ‹çš„æ­£æ ·æœ¬ï¼ˆpredicted positiveï¼‰,è€Œå…¶ä¸­é¢„æµ‹çš„æ­£æ ·æœ¬è‡ªç„¶å°±åŒ…æ‹¬äº† é¢„æµ‹å‡†ç¡®çš„æ­£æ ·æœ¬+ é¢„æµ‹é”™è¯¯çš„æ­£æ ·æœ¬ã€‚</p><p>$$Precision=\frac{True;positive}{Predicated;as;positive }=\frac{True;positive}{True;positive+False;positive}$$</p><p>å¬å›ç‡ï¼ˆRecallï¼‰= é¢„æµ‹å‡†ç¡®çš„æ­£æ ·æœ¬ï¼ˆTrue positiveï¼‰/å®é™…çš„æ­£æ ·æœ¬ï¼ˆactual positiveï¼‰,è€Œå…¶ä¸­å®é™…çš„æ­£æ ·æœ¬è‡ªç„¶å°±åŒ…æ‹¬äº† é¢„æµ‹å‡†ç¡®çš„æ­£æ ·æœ¬+ é¢„æµ‹é”™è¯¯çš„è´Ÿæ ·æœ¬ã€‚</p><p>$$Recall=\frac{True;positive}{Actual;positive}=\frac{True;positive}{True;positive+False;negative}$$</p><p>å‡å¦‚åƒä¹‹å‰çš„yä¸€ç›´ä¸º0ï¼Œè™½ç„¶å…¶å‡†ç¡®ç‡ä¸º99%ï¼Œä½†æ˜¯å…¶å¬å›ç‡æ˜¯0%ã€‚æ‰€ä»¥è¿™å¯¹äºè¯„ä¼°ç®—æ³•çš„æ­£ç¡®æ€§æ˜¯éå¸¸æœ‰å¸®åŠ©çš„ã€‚</p><p>é‚£ä¹ˆæŸ¥å‡†ç‡ï¼ˆPrecisionï¼‰å’Œå¬å›ç‡ï¼ˆRecallï¼‰åº”è¯¥å¦‚ä½•è¯„ä¼°å‘¢ï¼Ÿ</p><p>å‡å¦‚æˆ‘ä»¬é€‰ç”¨ä¸¤è€…çš„å¹³å‡å€¼ï¼Œè¿™æ ·çœ‹èµ·æ¥å¯è¡Œï¼Œä½†æ˜¯å¯¹äºä¹‹å‰çš„æç«¯ä¾‹å­è¿˜æ˜¯ä¸é€‚ç”¨ã€‚å‡å¦‚æˆ‘ä»¬é¢„æµ‹çš„yä¸€ç›´ä¸º1ï¼Œé‚£ä¹ˆå…¶å¬å›ç‡å°±100%äº†ï¼Œè€ŒæŸ¥å‡†ç‡éå¸¸ä½ï¼Œä½†æ˜¯å¹³å‡ä¸‹æ¥è¿˜æ˜¯ç›¸å¯¹ä¸é”™ã€‚æ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨ä¸‹é¢ä¸€ç§è¯„ä¼°æ–¹æ³•ï¼Œå«åš F å€¼ï¼š</p><p>$$F_1;Score = 2\frac{PR}{P+R}$$</p><p>P æŒ‡çš„æ˜¯ Precisionï¼ŒR æŒ‡çš„æ˜¯ Recallã€‚</p><hr><h2 id="ä¸‰-Using-Large-Data-Sets"><a href="#ä¸‰-Using-Large-Data-Sets" class="headerlink" title="ä¸‰. Using Large Data Sets"></a>ä¸‰. Using Large Data Sets</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/75_4.png" alt=""></p><p>åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œæµä¼ ç€è¿™æ ·ä¸€å¥è¯ï¼š</p><blockquote><p>Itâ€™s not who has the best algorithm that wins. Itâ€™s who has the most data.</p></blockquote><p>å–å¾—æˆåŠŸçš„äººä¸æ˜¯æ‹¥æœ‰æœ€å¥½ç®—æ³•çš„äººï¼Œè€Œæ˜¯æ‹¥æœ‰æœ€å¤šæ•°æ®çš„äººã€‚</p><p>è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ</p><p>é¦–å…ˆæˆ‘ä»¬å› ä¸ºæœ‰å¤§é‡çš„ç‰¹å¾é‡ï¼Œå»è®­ç»ƒæ•°æ®ï¼Œè¿™æ ·å°±å¯¼è‡´äº†æˆ‘ä»¬çš„è®­ç»ƒé›†è¯¯å·®éå¸¸å°ï¼Œä¹Ÿå°±æ˜¯ $J_{train}(\theta)$ éå¸¸å°ã€‚ç„¶åæˆ‘ä»¬æä¾›äº†å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè¿™æ ·æœ‰åˆ©äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå¯ä»¥ä½¿å¾— $J_{train}(\theta)\approx J_{test}(\theta)$ ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬çš„å‡è®¾å‡½æ•°æ—¢ä¸ä¼šå­˜åœ¨é«˜åå·®ï¼Œä¹Ÿä¸ä¼šå­˜åœ¨é«˜æ–¹å·®ï¼Œæ‰€ä»¥ç›¸å¯¹è€Œè¨€ï¼Œå¤§æ•°æ®è®­ç»ƒå‡ºæ¥ä¼šæ›´åŠ å‡†ç¡®ã€‚</p><p>æ³¨æ„äº†ï¼Œè¿™é‡Œä¸ä»…æ˜¯ç”±å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œä¸”è¿˜è¦æœ‰æ›´å¤šçš„ç‰¹å¾é‡ã€‚å› ä¸ºå‡å¦‚åªæœ‰ä¸€äº›ç‰¹å¾é‡ï¼Œä¾‹å¦‚åªæœ‰æˆ¿å­çš„å¤§å°ï¼Œå»é¢„æµ‹æˆ¿å­çš„ä»·æ ¼ï¼Œé‚£ä¹ˆå°±è¿ä¸–ç•Œæœ€å¥½çš„é”€å”®å‘˜ä¹Ÿä¸èƒ½åªå‡­æˆ¿å­å¤§å°å°±èƒ½å‘Šè¯‰ä½ æˆ¿å­çš„ä»·æ ¼æ˜¯å¤šå°‘ã€‚</p><p>ä»€ä¹ˆæ—¶å€™é‡‡ç”¨å¤§è§„æ¨¡çš„æ•°æ®é›†å‘¢ï¼Œä¸€å®šè¦ä¿è¯æ¨¡å‹æ‹¥æœ‰è¶³å¤Ÿçš„å‚æ•°ï¼ˆçº¿ç´¢ï¼‰ï¼Œå¯¹äºçº¿æ€§å›å½’/é€»è¾‘å›å½’æ¥è¯´ï¼Œå°±æ˜¯å…·å¤‡è¶³å¤Ÿå¤šçš„ç‰¹å¾ï¼Œè€Œå¯¹äºç¥ç»ç½‘ç»œæ¥è¯´ï¼Œå°±æ˜¯æ›´å¤šçš„éšå±‚å•å…ƒã€‚è¿™æ ·ï¼Œè¶³å¤Ÿå¤šçš„ç‰¹å¾é¿å…äº†é«˜åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰é—®é¢˜ï¼Œè€Œè¶³å¤Ÿå¤§æ•°æ®é›†é¿å…äº†å¤šç‰¹å¾å®¹æ˜“å¼•èµ·çš„é«˜æ–¹å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰é—®é¢˜ã€‚</p><hr><h2 id="å››-Machine-Learning-System-Design-æµ‹è¯•"><a href="#å››-Machine-Learning-System-Design-æµ‹è¯•" class="headerlink" title="å››. Machine Learning System Design æµ‹è¯•"></a>å››. Machine Learning System Design æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You are working on a spam classification system using regularized logistic regression. â€œSpamâ€ is a positive class (y = 1) and â€œnot spamâ€ is the negative class (y = 0). You have trained your classifier and there are m = 1000 examples in the cross-validation set. The chart of predicted class vs. actual class is:</p><p>Actual Class: 1    Actual Class: 0<br>Predicted Class: 1    85    890<br>Predicted Class: 0    15    10</p><p>For reference:</p><ul><li>Accuracy = (true positives + true negatives) / (total examples)</li><li>Precision = (true positives) / (true positives + false positives)</li><li>Recall = (true positives) / (true positives + false negatives)</li><li>F1 score = (2 * precision * recall) / (precision + recall)</li></ul><p>What is the classifierâ€™s F1 score (as a value from 0 to 1)?</p><p>Enter your answer in the box below. If necessary, provide at least two values after the decimal point.</p><p>è§£ç­”ï¼š0.158</p><p>ä»£å…¥å…¬å¼ $2\frac{PR}{P+R}$ è®¡ç®—å³å¯ã€‚</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose a massive dataset is available for training a learning algorithm. Training on a lot of data is likely to give good performance when two of the following conditions hold true.</p><p>Which are the two?</p><p>A. When we are willing to include high order polynomial features of x (such as $x_{1}^{2}$, $x_{2}^{2}$,$x_{1}$,$x_{2}$, etc.).</p><p>B. The features x contain sufficient information to predict y accurately. (For example, one way to verify this is if a human expert on the domain can confidently predict y when given only x).</p><p>C. We train a learning algorithm with a small number of parameters (that is thus unlikely to overfit).</p><p>D. We train a learning algorithm with a large number of parameters (that is able to learn/represent fairly complex functions).</p><p>è§£ç­”ï¼šBã€D</p><p>A. éœ€è¦çš„æ˜¯è¶³å¤Ÿçš„ç‰¹å¾é‡è€Œä¸æ˜¯é«˜é˜¶ã€‚<br>B. ç‰¹å¾é‡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å‡†ç¡®é¢„æµ‹ã€‚<br>C. å°‘é‡çš„ç‰¹å¾é‡æ˜¾ç„¶æ˜¯ä¸è¡Œçš„ã€‚<br>D. è¦æœ‰è¶³å¤Ÿå¤šçš„å˜é‡ï¼ˆç‰¹å¾é‡ï¼‰ã€‚  </p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you have trained a logistic regression classifier which is outputing hÎ¸(x).</p><p>Currently, you predict 1 if $h_{\theta}(x)\geqslant threshold$, and predict 0 if $h_{\theta}(x)&lt;threshold$, where currently the threshold is set to 0.5.</p><p>Suppose you decrease the threshold to 0.3. Which of the following are true? Check all that apply.</p><p>A. The classifier is likely to have unchanged precision and recall, but higher accuracy.</p><p>B. The classifier is likely to now have higher precision.</p><p>C. The classifier is likely to now have higher recall.</p><p>D. The classifier is likely to have unchanged precision and recall, but lower accuracy.</p><p>è§£ç­”ï¼šC</p><blockquote><p><strong>å°†é˜ˆå€¼è°ƒä½çš„ç»“æœåªä¼šå¯¼è‡´å¬å›ç‡å¢å¤§ï¼ŒæŸ¥å‡†ç‡é™ä½ã€‚</strong></p></blockquote><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Suppose you are working on a spam classifier, where spam emails are positive examples (y=1) and non-spam emails are negative examples (y=0). You have a training set of emails in which 99% of the emails are non-spam and the other 1% is spam. Which of the following statements are true? Check all that apply.</p><p>A. If you always predict non-spam (output y=0), your classifier will have 99% accuracy on the training set, but it will do much worse on the cross validation set because it has overfit the training data.</p><p>B. If you always predict non-spam (output y=0), your classifier will have 99% accuracy on the training set, and it will likely perform similarly on the cross validation set.</p><p>C. A good classifier should have both a high precision and high recall on the cross validation set.</p><p>D. If you always predict non-spam (output y=0), your classifier will have an accuracy of 99%.</p><p>è§£ç­”ï¼šBã€Cã€D</p><p>A. åœ¨äº¤å‰éªŒè¯é›†å› ä¸ºè¿‡æ‹Ÿåˆçš„é—®é¢˜ä¼šä½¿å‡†ç¡®ç‡ä¸‹é™ï¼Œè¿™ä¸æ˜¯è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæ˜¯åæ–œç±»çš„é—®é¢˜ã€‚<br>B. å‡å¦‚è®­ç»ƒé›†æœ‰99%å‡†ç¡®ç‡ï¼Œé‚£ä¹ˆäº¤å‰éªŒè¯é›†ä¹Ÿæœ‰å¾ˆå¤§å¯èƒ½æœ‰99%çš„å‡†ç¡®ç‡ï¼Œè¿™æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºæ•°æ®æ˜¯éšæœºåˆ†å¸ƒçš„ï¼Œè®­ç»ƒé›†çš„æ•°æ®åˆ†å¸ƒè·Ÿäº¤å‰éªŒè¯é›†çš„æ•°æ®åˆ†å¸ƒç›¸ä¼¼ã€‚<br>C. ä¸€ä¸ªå¥½çš„åˆ†ç±»å™¨åº”è¯¥æŸ¥å‡†ç‡å’Œå¬å›ç‡éƒ½æ¯”è¾ƒé«˜ï¼Œæ­£ç¡®ã€‚<br>D. å‡å¦‚æˆ‘ä»¬éƒ½æŠŠç»“æœè®¾ä¸ºå…¨ä¸ºéåƒåœ¾é‚®ä»¶ï¼Œé‚£ä¹ˆå‡†ç¡®ç‡å°†è¾¾åˆ°99%ï¼Œæ­£ç¡®ã€‚  </p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. On skewed datasets (e.g., when there are more positive examples than negative examples), accuracy is not a good measure of performance and you should instead use F1 score based on the precision and recall.</p><p>B. If your model is underfitting the training set, then obtaining more data is likely to help.</p><p>C. After training a logistic regression classifier, you must use 0.5 as your threshold for predicting whether an example is positive or negative.</p><p>D. It is a good idea to spend a lot of time collecting a large amount of data before building your first version of a learning algorithm.</p><p>E. Using a very large training set makes it unlikely for model to overfit the training data.</p><p>è§£ç­”ï¼šAã€E</p><p>A.åˆ©ç”¨ F1 score å»è¡¡é‡å‡†ç¡®æ€§ï¼Œæ­£ç¡®ã€‚<br>B.æ¨¡å‹ä¸é€‚åˆè®­ç»ƒé›†ï¼Œæ˜¯æ¬ æ‹Ÿåˆï¼Œæ¬ æ‹Ÿåˆå¢å¤§æ•°æ®æ ·æœ¬æ²¡ç”¨ã€‚<br>C.é˜ˆå€¼ä¸ä¸€å®šæ˜¯0.5ã€‚<br>D.åœ¨å»ºç«‹ç¬¬ä¸€ä¸ªå­¦ä¹ ç®—æ³•å‰èŠ±å¤§é‡æ—¶é—´æ”¶é›†æ•°æ®æ˜¾ç„¶æœ‰å¯èƒ½èµ°å‘æµªè´¹æ—¶é—´çš„ä¸å½’è·¯ã€‚<br>E.ç”¨æ›´å¤šçš„æ•°æ®æ ·æœ¬å¯ä»¥è§£å†³è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œæ­£ç¡®ã€‚  </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Machine_Learning_System_Design.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Machine_Learning_System_Design.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.1_Advice_for_Applying_Machine_Learning</title>
      <link href="/2020/02/05/6-1-advice-for-applying-machine-learning/"/>
      <url>/2020/02/05/6-1-advice-for-applying-machine-learning/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-0a2226926cdd4e8e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-Evaluating-a-Learning-Algorithm"><a href="#ä¸€-Evaluating-a-Learning-Algorithm" class="headerlink" title="ä¸€. Evaluating a Learning Algorithm"></a>ä¸€. Evaluating a Learning Algorithm</h2><p>æƒ³è¦é™ä½é¢„æµ‹è¯¯å·®ï¼Œå³æé«˜é¢„æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šé‡‡ç”¨è¿™äº›æ‰‹æ®µï¼š</p><ul><li>é‡‡é›†æ›´å¤šçš„æ ·æœ¬<br>é”™è¯¯çš„è®¤ä¸ºæ ·æœ¬è¶Šå¤šè¶Šå¥½ï¼Œå…¶å®æ•°æ®å¤šå¹¶ä¸æ˜¯è¶Šå¥½ã€‚</li><li>é™ä½ç‰¹å¾ç»´åº¦<br>é™ç»´å¯èƒ½å»æ‰äº†æœ‰ç”¨çš„ç‰¹å¾ã€‚</li><li>é‡‡é›†æ›´å¤šçš„ç‰¹å¾<br>å¢åŠ äº†è®¡ç®—è´Ÿæ‹…ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li><li>è¿›è¡Œé«˜æ¬¡å¤šé¡¹å¼å›å½’<br>è¿‡é«˜çš„å¤šé¡¹å¼å¯èƒ½é€ æˆè¿‡æ‹Ÿåˆã€‚</li><li>è°ƒè¯•æ­£è§„åŒ–å‚æ•° $\lambda$,å¢å¤§æˆ–è€…å‡å°‘ $\lambda$<br>å¢å¤§æˆ–è€…å‡å°‘éƒ½æ˜¯å‡­æ„Ÿè§‰ã€‚</li></ul><p>æœ‰è¿™ä¹ˆå¤šç§è§£å†³åŠæ³•æˆ‘ä»¬æ€ä¹ˆçŸ¥é“æ˜¯å“ªä¸€ç§å‘¢ï¼Ÿå¾ˆå¤šäººé€‰æ‹©è¿™äº›æ–¹æ³•çš„æ ‡å‡†å°±æ˜¯å‡­æ„Ÿè§‰éšä¾¿é€‰æ‹©ä¸€ç§ï¼Œç„¶åèŠ±å¾ˆé•¿çš„æ—¶é—´æœ€åå‘ç°æ˜¯æ²¡ç”¨çš„ï¼Œèµ°ä¸Šäº†ä¸å½’è·¯ã€‚æ‰€ä»¥ä¸‹é¢æˆ‘ä»¬ä»‹ç»ä¸€æˆ‘ä»¬éœ€è¦ä¸€ç§ç®€å•æœ‰æ•ˆçš„åŠæ³•ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•è¯Šæ–­ï¼ˆMachine learning diagnosticï¼‰ã€‚</p><h3 id="1-Evaluating-a-Hypothesis-è¯„ä»·å‡è®¾å‡½æ•°"><a href="#1-Evaluating-a-Hypothesis-è¯„ä»·å‡è®¾å‡½æ•°" class="headerlink" title="1. Evaluating a Hypothesis è¯„ä»·å‡è®¾å‡½æ•°"></a>1. Evaluating a Hypothesis è¯„ä»·å‡è®¾å‡½æ•°</h3><p>é¦–å…ˆæˆ‘ä»¬è¦è¯„ä¼°çš„æ˜¯æˆ‘ä»¬çš„å‡è®¾å‡½æ•°ï¼ˆHypothesisï¼‰ã€‚å½“æˆ‘ä»¬é€‰æ‹©ç‰¹å¾å€¼æˆ–è€…å‚æ•°æ¥ä½¿è®­ç»ƒé›†è¯¯å·®æœ€å°åŒ–ï¼Œä½†æ˜¯æˆ‘ä»¬ä¼šé‡åˆ°è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæ¨å¹¿åˆ°æ–°çš„è®­ç»ƒé›†å°±ä¸å†ä½¿ç”¨äº†ã€‚è€Œä¸”å½“ç‰¹å¾é‡å¾ˆå¤šçš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±ä¸èƒ½å°† $J(\theta)$ å¯è§†åŒ–çœ‹å‡ºå…¶æ˜¯å¦éšç€è¿­ä»£æ¬¡æ•°è€Œä¸‹é™äº†ã€‚æ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹çš„æ–¹æ³•æ¥è¯„ä¼°æˆ‘ä»¬çš„å‡è®¾å‡½æ•°ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_1.png" alt=""></p><p>å‡è®¾æœ‰ 10 ç»„æ•°æ®ï¼ŒéšæœºæŠŠ 70% åšä¸ºè®­ç»ƒé›†ï¼Œå‰©ä¸‹çš„ 30% åšä¸ºæµ‹è¯•é›†ã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†å°½é‡ä¿è¯æ˜¯éšæœºæ’åˆ—ã€‚</p><p>æ¥ä¸‹æ¥ï¼š</p><ol><li>å¯¹è®­ç»ƒé›†è¿›è¡Œå­¦ä¹ å¾—åˆ°å‚æ•° $\Theta$ ï¼Œä¹Ÿå°±æ˜¯åˆ©ç”¨è®­ç»ƒé›†æœ€å°åŒ–è®­ç»ƒè¯¯å·® $J_{train}(\Theta)$</li><li>è®¡ç®—å‡ºæµ‹è¯•è¯¯å·® $J_{test}(\Theta)$ï¼Œå–å‡ºä¹‹å‰ä»è®­ç»ƒé›†ä¸­å­¦ä¹ å¾—åˆ°çš„å‚æ•° $\Theta$ æ”¾åœ¨è¿™é‡Œï¼Œæ¥è®¡ç®—æµ‹è¯•è¯¯å·®ã€‚</li></ol><p>å¯¹äºçº¿æ€§å›å½’ï¼š $$J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}{(h_\theta(x^{(i)}_{test})-y^{(i)}_{test})^2}$$</p><p>å¯¹äºé€»è¾‘å›å½’ï¼š  $$J_{test}(\theta)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}{y^{(i)}_{test}logh_\theta(x^{(i)}_{test})+(1-y^{(i)}_{test})logh_\theta(x^{(i)}_{test})}$$</p><p>é€»è¾‘å›å½’ä¸åŒäºçº¿æ€§å›å½’ï¼Œå› ä¸ºå®ƒåªæœ‰0å’Œ1ä¸¤ä¸ªå€¼ï¼Œ æ‰€ä»¥æ€ä¹ˆåˆ¤æ–­è¯¯å·®å¦‚ä¸‹ï¼š</p>$$err(h_\theta(x),y)=\left\{\begin{matrix}1 \;\;\;( if \;\;\; h_\theta(x) \geqslant 0.5 , y=0 \;\;\;or\;\;\; if\;\;\; h_\theta(x) &lt; 0.5 ï¼Œ y=1 )\\ 0 \;\;\;( otherwise ) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\end{matrix}\right.$$<p>è¿™é‡Œçš„è¯¯å·®ä¹Ÿå«è¯¯åˆ†ç±»ç‡ï¼Œä¹Ÿå« $0/1$ é”™åˆ†ç‡ã€‚</p><p>$( if ;;; h_\theta(x) \geqslant 0.5 , y=0 ;;;or;;; if;;; h_\theta(x) &lt; 0.5 ï¼Œ y=1 )$</p><p>è¿™ç§æƒ…å†µä¸‹ï¼Œå‡è®¾ç»“æœæ›´è¶‹å‘äº1ï¼Œä½†æ˜¯å®é™…ç»™å‡ºçš„åˆ¤æ–­å´æ˜¯0ï¼Œæˆ–è€…å‡è®¾ç»“æœæ›´è¶‹å‘äº0ï¼Œå®é™…ç»™å‡ºçš„åˆ¤æ–­å´æ˜¯1 ã€‚</p><p>å¦‚æœä»¥ä¸Šæƒ…å†µéƒ½æ²¡æœ‰ï¼Œé‚£ä¹ˆå°±æ²¡æœ‰è¯¯å·®ï¼Œå³ä¸º0 ï¼Œä¹Ÿä»£è¡¨äº†å‡è®¾å€¼èƒ½å¤Ÿæ­£ç¡®çš„å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ã€‚</p><p>æµ‹è¯•é›†çš„å¹³å‡æµ‹è¯•è¯¯å·®ä¸ºï¼š</p>$$Test\;Error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_{\theta}(x^{(i)}_{test}),y^{(i)}_{test})$$<hr><h3 id="2-Model-Selection-and-Train-Validation-Test-Sets-æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†-éªŒè¯é›†-æµ‹è¯•é›†"><a href="#2-Model-Selection-and-Train-Validation-Test-Sets-æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†-éªŒè¯é›†-æµ‹è¯•é›†" class="headerlink" title="2. Model Selection and Train/Validation/Test Sets æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†"></a>2. Model Selection and Train/Validation/Test Sets æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_2.png" alt=""></p><p>æˆ‘ä»¬è¿™é‡Œç”¨ d è¡¨ç¤ºå¤šé¡¹å¼çš„ä¸ªæ•°ã€‚æˆ‘ä»¬å¯ä»¥æ”¹å˜å¤šé¡¹å¼æ¬¡æ•°çš„å¤šå°‘æ¥é€‰æ‹©åˆé€‚æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¾‹å¦‚ä¸Šé¢çš„ $h_\theta(x)=\theta_0+\theta_1x$ ï¼Œè¿™ä¸ªå¤šé¡¹å¼ $d=1$ ã€‚</p><p>æˆ‘ä»¬å¯ä»¥æµ‹è¯•æ¯ä¸€ä¸ªæ¨¡å‹å¾—åˆ°ä»–ä»¬çš„ $J_{test}(\theta)$ ï¼Œåˆ¤æ–­å“ªä¸€ä¸ªæ¨¡å‹æ¯”è¾ƒå¥½ã€‚</p><p>å½“é€‰æ‹©å‡ºäº†ä¸€ä¸ªå¤šé¡¹å¼ d èƒ½å¾ˆå®Œç¾çš„æ‹Ÿåˆæµ‹è¯•é›†ï¼Œæ¥ä¸‹æ¥å°±ä¸èƒ½å†ç”¨æµ‹è¯•é›†äº†ï¼Œå› ä¸º d æœ¬æ¥å°±å·²ç»å®Œç¾æ‹Ÿåˆæµ‹è¯•é›†äº†ï¼Œå†æµ‹è¯•å°±æ²¡æœ‰æ„ä¹‰äº†ï¼Œéœ€è¦æ¢ä¸€ä¸ªæµ‹è¯•é›†ã€‚æ‰€ä»¥æ›´éœ€è¦å…³å¿ƒçš„å¯¹æ–°æ ·æœ¬çš„æ‹Ÿåˆæ•ˆæœã€‚</p><p>ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æŠŠæ•°æ®åˆ†ä¸º 3 ç±»ï¼Œè®­ç»ƒé›† 60% /äº¤å‰éªŒè¯é›† 20% /æµ‹è¯•é›† 20%ã€‚</p><p>é€šè¿‡ä¸‰ä¸ªé›†åˆï¼Œå¯ä»¥ç®—å‡ºè®­ç»ƒè¯¯å·®ï¼š</p><p>$$J_{train}(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^{2}$$</p><p>äº¤å‰éªŒè¯è¯¯å·®ï¼š</p>$$J_{cv}(\theta) = \frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x^{(i)}_{cv})-y^{(i)}_{cv})^{2}$$<p>æµ‹è¯•è¯¯å·®ï¼š</p>$$J_{test}(\theta) = \frac{1}{2m_{test}}\sum_{i=1}^{m}(h_\theta(x^{(i)}_{test})-y^{(i)}_{test})^{2}$$<p>äºæ˜¯æˆ‘ä»¬é€‰æ‹©æ¨¡å‹ä¸åœ¨ä»…ä»…é€šè¿‡æµ‹è¯•é›†æ¥é€‰æ‹©äº†ï¼Œè€Œæ˜¯ï¼š</p><ol><li>åˆ©ç”¨è®­ç»ƒé›†çš„æ•°æ®ä»£å…¥æ¯ä¸€ä¸ªå¤šé¡¹å¼æ¨¡å‹ã€‚</li><li>ç”¨äº¤å‰éªŒè¯é›†çš„æ•°æ®æ‰¾å‡ºæœ€å°è¯¯å·®çš„å¤šé¡¹å¼æ¨¡å‹ã€‚</li><li>æœ€ååœ¨æµ‹è¯•é›†å†æ‰¾å‡ºç›¸å¯¹è¾ƒå°‘è¯¯å·®çš„é‚£ä¸ªæ¨¡å‹ã€‚</li></ol><hr><h2 id="äºŒ-Bias-vs-Variance"><a href="#äºŒ-Bias-vs-Variance" class="headerlink" title="äºŒ. Bias vs. Variance"></a>äºŒ. Bias vs. Variance</h2><h3 id="1-Diagnosing-Bias-vs-Variance-è¯Šæ–­åå·®å’Œæ–¹å·®"><a href="#1-Diagnosing-Bias-vs-Variance-è¯Šæ–­åå·®å’Œæ–¹å·®" class="headerlink" title="1. Diagnosing Bias vs. Variance è¯Šæ–­åå·®å’Œæ–¹å·®"></a>1. Diagnosing Bias vs. Variance è¯Šæ–­åå·®å’Œæ–¹å·®</h3><p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œåå·®ï¼ˆbiasï¼‰åæ˜ äº†æ¨¡å‹æ— æ³•æè¿°æ•°æ®è§„å¾‹ï¼Œè€Œæ–¹å·®ï¼ˆvarianceï¼‰åæ˜ äº†æ¨¡å‹å¯¹è®­ç»ƒé›†è¿‡åº¦æ•æ„Ÿï¼Œè€Œä¸¢å¤±äº†æ•°æ®è§„å¾‹ï¼Œé«˜åå·®å’Œé«˜æ–¹å·®éƒ½ä¼šé€ æˆæ–°æ•°æ®åˆ°æ¥æ—¶ï¼Œæ¨¡å‹ç»™å‡ºé”™è¯¯çš„é¢„æµ‹ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_3.png" alt=""></p><p>è¿˜æ˜¯ä»¥è¿™ä¸ªå›¾ä¸ºä¾‹ï¼Œæœ€å·¦è¾¹çš„å›¾æ˜¯æ¬ æ‹Ÿåˆï¼Œæœ€å³è¾¹çš„å›¾æ˜¯è¿‡æ‹Ÿåˆã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_4.png" alt=""></p><p>ä¸Šå›¾æ˜¯ è®­ç»ƒé›†ã€äº¤å‰éªŒè¯é›†è¯¯å·®éšå¤šé¡¹å¼æ¬¡æ•° d çš„å˜åŒ–è§„å¾‹ã€‚æ¨ªåæ ‡æ˜¯æˆ‘ä»¬çš„dï¼Œä¹Ÿå°±æ˜¯å¤šé¡¹å¼çš„ä¸ªæ•°ï¼Œçºµåæ ‡å°±æ˜¯æˆ‘ä»¬çš„ä»£ä»·å‡½æ•°ã€‚</p><p>æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹çº¢è‰²æ›²çº¿ $J_{training}(\theta)$ ï¼Œéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ ï¼Œå…¶å‡è®¾å‡½æ•°æ˜¯è¶Šæ¥è¶Šæ¥è¿‘è¦æ‹Ÿåˆçš„æ•°æ®ï¼Œæ‰€ä»¥å…¶ä»£ä»·å‡½æ•°ä¼šéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ ä¸‹é™ã€‚</p><p>ç„¶åç»¿è‰²çš„æ›²çº¿æ˜¯ $J_{cross-validation}(\theta)$ ,å½“å¤šé¡¹å¼ä¸ªæ•°æ¯”è¾ƒå°‘çš„æ—¶å€™ï¼Œé‚£å½“ç„¶ä¼šå‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ï¼Œæ‰€ä»¥ä¸€å¼€å§‹å…¶ä»£ä»·å‡½æ•° $J_{cross-validation}(\theta)$ æ˜¯å¾ˆå¤§çš„ï¼Œéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ è€Œä¸‹é™ï¼Œä½†æ˜¯å½“å…¶å¤šé¡¹å¼ä¸ªæ•°å†ç»§ç»­å¢åŠ çš„è¯ï¼Œå°±ä¼šå‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œ $J_{cross-validation}(\theta)$ å°±åˆä¼šå¢åŠ ã€‚æ‰€ä»¥ $J_{cross-validation}(\theta)$ å‡½æ•°æ˜¯å…ˆé€’å‡å†é€’å¢çš„ï¼Œåœ¨å…¶æœ€ä½ç‚¹å°±æ˜¯æœ€åˆé€‚çš„å¤šé¡¹å¼æ¬¡æ•°ã€‚</p><p>å¤šé¡¹å¼å›å½’ä¸­ï¼Œå¦‚æœå¤šé¡¹å¼æ¬¡æ•°è¾ƒé«˜ï¼Œåˆ™å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆï¼Œæ­¤æ—¶è®­ç»ƒè¯¯å·®å¾ˆä½ï¼Œä½†æ˜¯å¯¹äºæ–°æ•°æ®çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œå¯¼è‡´äº¤å‰éªŒè¯é›†å’Œæµ‹è¯•é›†çš„è¯¯å·®éƒ½å¾ˆé«˜ï¼Œæ­¤æ—¶æ¨¡å‹å‡ºç°äº†<strong>é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</strong>ï¼š</p>$$\left\{\begin{matrix}J_{train}(\theta) \;\;\;is\;\; low\\ J_{cv}(\theta)&gt;&gt;J_{test}(\theta)\end{matrix}\right.$$<p>è¿‡æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒé›†è¯¯å·®é€šå¸¸æ¯”è¾ƒå°ï¼Œå¹¶ä¸”è¿œå°äºäº¤å‰éªŒè¯è¯¯å·®ã€‚</p><p>è€Œå½“æ¬¡æ•°è¾ƒä½æ—¶ï¼Œåˆæ˜“å‡ºç°æ¬ æ‹Ÿåˆçš„çŠ¶å†µï¼Œæ­¤æ—¶æ— è®ºæ˜¯è®­ç»ƒé›†ï¼Œäº¤å‰éªŒè¯é›†ï¼Œè¿˜æ˜¯æµ‹è¯•é›†ï¼Œéƒ½ä¼šæœ‰å¾ˆé«˜çš„è¯¯å·®ï¼Œæ­¤æ—¶æ¨¡å‹å‡ºç°äº†<strong>é«˜åå·®(æ¬ æ‹Ÿåˆ)</strong>ï¼š</p>$$\left\{\begin{matrix}J_{train}(\theta),J_{cv}(\theta)\;\;\; is \;\; high\\ J_{cv}(\theta) \approx J_{test}(\theta)\end{matrix}\right.$$<p>æ¬ æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒé›†è¯¯å·®ä¼šå¾ˆå¤§ã€‚</p><p>ä¸ºä»€ä¹ˆ $J_{cross-validation}(\theta)$ ä¼šå…ˆé™åå‡ï¼Œè€Œ $J_{training}(\theta)$ ä¸€ç›´ä¸‹é™ï¼Ÿ</p><p>åŸå› æ˜¯ $\theta$ æ˜¯åªé’ˆå¯¹è®­ç»ƒé›†æ‰€è®­ç»ƒå‡ºæ¥çš„ï¼Œå½“å…¶ä»£å…¥åˆ° $J_{cross-validation}(\theta)$ åï¼Œå°±ä¼šéšç€å¤šé¡¹å¼çš„å¢åŠ æ•°æ®åå·®å°±ä¼šè¶Šæ¥è¶Šå¤§ã€‚</p><hr><h3 id="2-Regularization-and-Bias-Variance-æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®"><a href="#2-Regularization-and-Bias-Variance-æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®" class="headerlink" title="2. Regularization and Bias/Variance æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®"></a>2. Regularization and Bias/Variance æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_5.png" alt=""></p><p>ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œæˆ‘ä»¬åŠ ä¸Šä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œä½†æ˜¯æ­£åˆ™åŒ–å‚æ•° $\lambda$ ä¸è¿‡æ‹Ÿåˆåˆæœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿ</p><p>å½“ $\lambda$ å¾ˆå¤§çš„æ—¶å€™ï¼Œå°±ä¼šä½¿å¾—åé¢çš„æ¯ä¸€ä¸ª $\theta_i$ éƒ½è¢«æƒ©ç½šäº†ï¼Œæ‰€ä»¥åªå‰©ä¸‹ $\theta_0$ ï¼Œé‚£ä¹ˆå…¶å‡è®¾å‡½æ•°å°±ä¼šå˜æˆä¸€æ¡ç›´çº¿ï¼Œå‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ã€‚</p><p>å½“ $\lambda$ å¾ˆå°çš„è¯ï¼Œä¸€ä¸ªæç«¯ä¾‹å­å°±æ˜¯ $\lambda=0$ ï¼Œä¹Ÿå°±æ˜¯ç›¸å½“äºæ²¡æœ‰åŠ æ­£åˆ™åŒ–é‚£é¡¹ï¼Œè¿™å°±ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚</p><p>$\lambda$çš„å–å€¼ä¸èƒ½è¿‡å¤§ä¹Ÿä¸èƒ½è¿‡å°ã€‚</p><p>$\lambda$çš„å–å€¼å¯ä»¥åœ¨ $\left[0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24\right]$ï¼Œåœ¨è¿™12ä¸ªä¸åŒçš„æ¨¡å‹ä¸­é’ˆå¯¹æ¯ä¸€ä¸ª $\lambda$ çš„å€¼ï¼Œéƒ½å»è®¡ç®—å‡ºä¸€ä¸ªæœ€å°ä»£ä»·å‡½æ•°,ä»è€Œå¾—åˆ° $\Theta^{(i)}$</p><p>å¾—åˆ°äº†12ä¸ª $\Theta^{(i)}$ ä»¥åï¼Œå°±å†ç”¨äº¤å‰éªŒè¯é›†å»è¯„ä»·å®ƒä»¬ã€‚å³è®¡ç®—æ¯ä¸ª $\Theta$ åœ¨äº¤å‰éªŒè¯é›†ä¸Šçš„å¹³å‡è¯¯å·®å¹³æ–¹å’Œ $J_{cv}(\Theta^{(i)})$</p><p>é€‰æ‹©ä¸€ä¸ªäº¤å‰éªŒè¯é›†è¯¯å·®æœ€å°çš„ $\lambda$ æœ€èƒ½æ‹Ÿåˆæ•°æ®çš„ä½œä¸ºæ­£åˆ™åŒ–å‚æ•°ã€‚</p><p>æœ€åæ‹¿è¿™ä¸ªæ­£åˆ™åŒ–å‚æ•°å»æµ‹è¯•é›†é‡Œé¢éªŒè¯ $J_{test}(\Theta^{(i)})$ é¢„æµ‹æ•ˆæœå¦‚ä½•ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_6.png" alt=""></p><p>éšç€ $\lambda$ å‚æ•°çš„å¢å¤§ï¼Œ $J_{train}(\theta)$ è‡ªç„¶ä¹Ÿä¼šéšä¹‹å¢å¤§ï¼Œè¿™æ˜¯å› ä¸ºå½“ $\lambda=0$ çš„æ—¶å€™ï¼Œ $J_{train}(\theta)$ æ˜¯æ²¡æœ‰æ­£åˆ™åŒ–é¡¹çš„ã€‚</p><p>ä½†æ˜¯å¯¹äº $J_{cv}(\theta)$ æ¥è¯´ï¼Œå®ƒå‡è®¾å‡½æ•°é‡Œé¢çš„ $\theta$ æ˜¯æ ¹æ®è®­ç»ƒé›†é‡Œé¢æ‹Ÿåˆå‡ºæ¥çš„ï¼Œæ‰€ä»¥åœ¨æ²¡æœ‰åŠ å…¥æ­£åˆ™åŒ–å‰ï¼Œ $J_{cv}(\theta)$ æ˜¯å¾ˆå¤§çš„ã€‚ä½†æ˜¯éšç€ $\lambda$ çš„é€æ¸å¢å¤§ï¼Œä¹Ÿå°±æ˜¯éšç€æ­£åˆ™åŒ–çš„æ•ˆæœé€æ¸ä½“ç°å‡ºæ¥ï¼Œåœ¨äº¤å‰éªŒè¯é›†é‡Œé¢ä¸æµ‹è¯•æ•°æ®å°±ä¼šè¶Šæ¥è¶Šæ‹Ÿåˆï¼Œè¿™æ—¶å€™çš„ $J_{cv}(\theta)$ è‡ªç„¶ä¼šæ…¢æ…¢ä¸‹é™ã€‚ä½†æ˜¯å½“ $\lambda$ å˜å¾—è¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œäº¤å‰è®­ç»ƒé›†çš„ $h_\theta(x)$ å°±ä¼šè¶‹è¿‘ä¸€æ¡ç›´çº¿ï¼Œ$J_{cv}(\theta)$ è‡ªç„¶ä¼šéšä¹‹ä¸Šå‡ã€‚</p><hr><h3 id="3-Learning-Curves-å­¦ä¹ æ›²çº¿"><a href="#3-Learning-Curves-å­¦ä¹ æ›²çº¿" class="headerlink" title="3. Learning Curves å­¦ä¹ æ›²çº¿"></a>3. Learning Curves å­¦ä¹ æ›²çº¿</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_7.png" alt=""></p><p>å‡è®¾æˆ‘ä»¬ç”¨ $h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2$ å»æ‹Ÿåˆæ•°æ®ï¼Œå½“æ•°æ®åªæœ‰å‡ ä¸ªçš„æ—¶å€™ï¼Œæ‹Ÿåˆæ•ˆæœé‚£è‚¯å®šçš„éå¸¸å¥½çš„ï¼Œä½†æ˜¯ï¼Œå½“æ•°æ®è¶Šæ¥è¶Šå¤šï¼Œæˆ‘ä»¬çš„å‡è®¾å‡½æ•°å› ä¸ºå¤šé¡¹å¼å¤ªå°‘å°±ä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®äº†ã€‚æ‰€ä»¥è®­ç»ƒé›†çš„è¯¯å·® $J_{train}(\theta)$ ä¼šéšç€æ•°æ®çš„å¢å¤šè€Œå¢å¤§ã€‚å¦‚ä¸Šå›¾è“è‰²çš„æ›²çº¿ã€‚</p><p>ä½†æ˜¯å¯¹äºäº¤å‰éªŒè¯é›†å‘¢ï¼Ÿå› ä¸ºä¸€å¼€å§‹åªæœ‰å‡ ä¸ªæ•°æ®ï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒé›†æ‹Ÿåˆå‡ºæ¥çš„å‚æ•°å°±æœ‰å¾ˆå¤§çš„å¯èƒ½ä¸é€‚åˆäº¤å‰éªŒè¯é›†ï¼Œæ‰€ä»¥åœ¨æ•°æ®å¾ˆå°çš„æƒ…å†µä¸‹å…¶è¯¯å·®æ˜¯å¾ˆå¤§çš„ï¼Œä½†æ˜¯éšç€æ•°æ®çš„æ…¢æ…¢å¢å¤šï¼Œè™½ç„¶ä¸ªåˆ«çš„æ•°æ®æ‹Ÿåˆä¸ä¸Šï¼Œä½†æ˜¯æ•´ä½“çš„æ‹Ÿåˆæ•ˆæœé‚£è‚¯å®šæ¯”åªæœ‰å‡ ä¸ªæ•°æ®çš„æ—¶å€™å¥½äº†ï¼Œæ‰€ä»¥å…¶æ•´ä½“è¯¯å·®æ˜¯é€æ­¥ä¸‹é™çš„ã€‚å¦‚ä¸Šå›¾ç²‰è‰²çš„æ›²çº¿ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_8.png" alt=""></p><p>å½“æ•°æ®å­˜åœ¨é«˜åå·®ä¹Ÿå°±æ˜¯æ¬ æ‹Ÿåˆçš„æ—¶å€™ï¼Œå³ä½¿æ•°æ®å†ç»§ç»­å¢å¤šä¹Ÿæ— è¡¥äºäº‹ï¼Œæ‰€ä»¥å…¶è¯¯å·®ä¼šè¶‹äºä¸€ä¸ªå¹³è¡¡çš„ä½ç½®ï¼Œè€Œä¸” $J_{train}(\theta)$ å’Œ $J_{cv}(\theta)$ çš„è¯¯å·®éƒ½ä¼šå¾ˆå¤§ã€‚</p><p>æ‰€ä»¥ï¼Œå½“æ•°æ®å­˜åœ¨æ¬ æ‹Ÿåˆçš„é—®é¢˜ï¼Œæˆ‘ä»¬é€‰ç”¨æ›´å¤šçš„è®­ç»ƒæ ·æœ¬æ˜¯æ²¡æœ‰åŠæ³•è§£å†³é—®é¢˜çš„ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_9.png" alt=""></p><p>å½“æ•°æ®å­˜åœ¨é«˜æ–¹å·®ä¹Ÿå°±æ˜¯è¿‡æ‹Ÿåˆçš„æ—¶å€™ï¼Œéšç€æ•°æ®çš„å¢å¤šï¼Œå› ä¸ºè¿‡æ‹Ÿåˆæ‰€ä»¥åœ¨è®­ç»ƒé›†åŸºæœ¬èƒ½å®Œç¾æ‹Ÿåˆå…¶æ•°æ®ï¼Œæ‰€ä»¥è®­ç»ƒé›†çš„è¯¯å·®è™½ç„¶ä¼šä¸Šå‡ï¼Œä½†æ˜¯å…¶å¹…åº¦æ˜¯éå¸¸ç¼“æ…¢çš„ï¼Œåœ¨äº¤å‰éªŒè¯é›†ä¹Ÿä¸€æ ·ï¼Œæ‰€ä»¥è¿‡æ‹Ÿåˆçš„æ—¶å€™å…¶å›¾åƒå¦‚ä¸Šï¼Œåœ¨ $J_{train}(\theta)$ å’Œ $J_{cv}(\theta)$ ä¹‹é—´æœ‰ä¸€å¤§æ®µç©ºéš™ã€‚</p><p>æ‰€ä»¥ï¼Œå½“æ•°æ®å­˜åœ¨è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œé€‰ç”¨æ›´å¤šçš„æ ·æœ¬æœ‰åˆ©äºæˆ‘ä»¬è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p><hr><h3 id="4-Deciding-What-to-Do-Next-Revisited-å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ"><a href="#4-Deciding-What-to-Do-Next-Revisited-å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ" class="headerlink" title="4. Deciding What to Do Next Revisited å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ"></a>4. Deciding What to Do Next Revisited å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ</h3><p>æ€»ç»“ ï¼š</p><table><thead><tr><th align="left">æ‰‹æ®µ</th><th align="center">ä½¿ç”¨åœºæ™¯</th></tr></thead><tbody><tr><td align="left">é‡‡é›†æ›´å¤šçš„æ ·æœ¬</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr><tr><td align="left">é™ä½ç‰¹å¾ç»´åº¦</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr><tr><td align="left">é‡‡é›†æ›´å¤šçš„ç‰¹å¾</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">è¿›è¡Œé«˜æ¬¡å¤šé¡¹å¼å›å½’</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">é™ä½å‚æ•°  Î»</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">å¢å¤§å‚æ•°  Î»</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr></tbody></table><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_10.png" alt=""></p><p>å½“æˆ‘ä»¬é€‰ç”¨ä¸€äº›è¾ƒå°çš„ç¥ç»ç½‘ç»œï¼Œè™½ç„¶å…¶è®¡ç®—é‡è¾ƒå°‘ï¼Œä½†æ˜¯å®¹æ˜“å‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ã€‚ç›¸åï¼Œæˆ‘ä»¬é€‰ç”¨ä¸€äº›å±‚æ•°æ¯”è¾ƒå¤šï¼Œå±‚çš„å•å…ƒæ¯”è¾ƒå¤šçš„ç¥ç»ç½‘ç»œï¼Œå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚æˆ‘ä»¬ä¹‹å‰æåˆ°è¶Šå¤§å‹çš„ç¥ç»ç½‘ç»œæ•ˆæœè¶Šå¥½ï¼Œä¸ºäº†é˜²æ­¢å‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ­£åˆ™åŒ–çš„æ–¹æ³•æ¥ä¿®æ­£ã€‚</p><p>ä½¿ç”¨å•ä¸ªéšè—å±‚æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é»˜è®¤å¼€å§‹ã€‚æ‚¨å¯ä»¥ä½¿ç”¨äº¤å‰éªŒè¯é›†åœ¨è®¸å¤šéšè—å±‚ä¸Šè®­ç»ƒæ‚¨çš„ç¥ç»ç½‘ç»œã€‚ç„¶åæ‚¨å¯ä»¥é€‰æ‹©æ€§èƒ½æœ€å¥½çš„ä¸€ä¸ªã€‚</p><p>æ¨¡å‹å¤æ‚æ€§å½±å“ï¼š</p><ul><li>ä½é˜¶å¤šé¡¹å¼ï¼ˆä½æ¨¡å‹å¤æ‚åº¦ï¼‰å…·æœ‰é«˜åå·®å’Œä½æ–¹å·®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å‹å¾ˆéš¾ä¸€è‡´</li><li>é«˜é˜¶å¤šé¡¹å¼ï¼ˆé«˜æ¨¡å‹å¤æ‚åº¦ï¼‰éå¸¸é€‚åˆè®­ç»ƒæ•°æ®ï¼Œæµ‹è¯•æ•°æ®æå…¶ç³Ÿç³•ã€‚è¿™äº›å¯¹è®­ç»ƒæ•°æ®çš„åå€šä½ï¼Œä½†å·®å¼‚å¾ˆå¤§</li><li>å®é™…ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›é€‰æ‹©ä¸€ä¸ªä»‹äºä¸¤è€…ä¹‹é—´çš„æ¨¡å‹ï¼Œå®ƒå¯ä»¥å¾ˆå¥½åœ°æ¨å¹¿ï¼Œä½†ä¹Ÿå¯ä»¥å¾ˆå¥½åœ°é€‚åˆæ•°æ®ã€‚</li></ul><hr><h2 id="ä¸‰-Advice-for-Applying-Machine-Learning-æµ‹è¯•"><a href="#ä¸‰-Advice-for-Applying-Machine-Learning-æµ‹è¯•" class="headerlink" title="ä¸‰. Advice for Applying Machine Learning æµ‹è¯•"></a>ä¸‰. Advice for Applying Machine Learning æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?</p><p><img src="http://spark-public.s3.amazonaws.com/ml/images/10.1-c.png" alt=""></p><p>A. High variance</p><p>B. Neither</p><p>C. High bias</p><p>è§£ç­”ï¼šA</p><p>é«˜æ–¹å·®çš„å›¾åƒ</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you have implemented regularized logistic regression to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large errors with its predictions on the new images. However, your hypothesis performs well (has low error) on the training set. Which of the following are promising steps to take? Check all that apply.</p><p>A. Try adding polynomial features.</p><p>B. Get more training examples.</p><p>C. Try using a smaller set of features.</p><p>D. Use fewer training examples.</p><p>è§£ç­”ï¼šBã€C</p><p>è¿‡æ‹Ÿåˆå¯ä»¥å‡å°‘ç‰¹å¾é‡å’Œå¢åŠ è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œæˆ–è€…å¢å¤§æ­£åˆ™åŒ–å‚æ•° $\lambda$ ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you have implemented regularized logistic regression to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis performs poorly on the training set. Which of the following might be promising steps to take? Check all that apply.</p><p>A. Try using a smaller set of features.</p><p>B. Try adding polynomial features.</p><p>C. Try to obtain and use additional features.</p><p>D. Try increasing the regularization parameter $\lambda$.</p><p>è§£ç­”ï¼šBã€C</p><p>æ¬ æ‹Ÿåˆå¯ä»¥å¢åŠ ç‰¹å¾é‡å’Œå‡è®¾å‡½æ•°çš„å¤šé¡¹å¼ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest test set error.</p><p>B. The performance of a learning algorithm on the training set will typically be better than its performance on the test set.</p><p>C. Suppose you are training a regularized linear regression model.The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest training set error.</p><p>D. Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest cross validation error.</p><p>è§£ç­”ï¼šBã€D</p><p>åœ¨æ­£åˆ™åŒ–çº¿æ€§å›å½’ä¸­ï¼Œ$\lambda$ é€‰æ‹©ä¸€ä¸ªäº¤å‰éªŒè¯é›†è¯¯å·®æœ€å°çš„  Î»Î»  æœ€èƒ½æ‹Ÿåˆæ•°æ®çš„ä½œä¸ºæ­£åˆ™åŒ–å‚æ•°ã€‚</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.</p><p>B. We always prefer models with high variance (over those with high bias) as they will able to better fit the training set.</p><p>C. If a learning algorithm is suffering from high bias, only adding more training examples may not improve the test error significantly.</p><p>D. When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem.</p><p>è§£ç­”ï¼šAã€Cã€D</p><p>A è¿‡æ‹Ÿåˆé«˜æ–¹å·®ï¼Œå¢åŠ æ ·æœ¬æ•°é‡æœ‰ç”¨ã€‚<br>B é«˜åå·®å’Œé«˜æ–¹å·®çš„æ¨¡å‹éƒ½ä¸å¥½ã€‚<br>C å¢åŠ è®­ç»ƒæ ·æœ¬å¯¹äºæ¬ æ‹Ÿåˆæ˜¯æ²¡ç”¨çš„æ­£ç¡®ã€‚<br>D ç»˜åˆ¶å­¦ä¹ æ›²çº¿æœ‰åˆ©äºå¸®åŠ©æˆ‘ä»¬åˆ†æé—®é¢˜æ­£ç¡®ã€‚  </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.2_Backpropagation_in_Practice</title>
      <link href="/2020/02/05/5-2-backpropagation-in-practice/"/>
      <url>/2020/02/05/5-2-backpropagation-in-practice/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-da4ab697bff80db9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h1 id="5-2-Backpropagation-in-Practice"><a href="#5-2-Backpropagation-in-Practice" class="headerlink" title="5.2 Backpropagation_in_Practice"></a>5.2 Backpropagation_in_Practice</h1><h2 id="ä¸€-Backpropagation-in-Practice"><a href="#ä¸€-Backpropagation-in-Practice" class="headerlink" title="ä¸€. Backpropagation in Practice"></a>ä¸€. Backpropagation in Practice</h2><p>ä¸ºäº†åˆ©ç”¨æ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–ç®—æ³•ï¼Œéœ€è¦ç”¨åˆ° fminunc å‡½æ•°ã€‚å…¶è¾“å…¥çš„å‚æ•°æ˜¯ $\theta$ ï¼Œå‡½æ•°çš„è¿”å›å€¼æ˜¯ä»£ä»·å‡½æ•° jVal å’Œå¯¼æ•°å€¼ gradientã€‚ç„¶åå°†è¿”å›å€¼ä¼ é€’ç»™é«˜çº§ä¼˜åŒ–ç®—æ³• fminuncï¼Œç„¶åè¾“å‡ºä¸ºè¾“å…¥å€¼ @costFunctionï¼Œä»¥åŠ $\theta$ å€¼çš„åˆå§‹å€¼ã€‚</p><p>å…¶ä¸­å‚æ•° $\Theta_1,\Theta_2,\Theta_3,\cdots$ å’Œ $D^{(1)},D^{(2)},D^{(3)},\cdots$ éƒ½ä¸ºçŸ©é˜µï¼Œé‚£ä¹ˆä¸ºäº†èƒ½è°ƒç”¨ fminunc å‡½æ•°ï¼Œæˆ‘ä»¬è¦å°†å…¶å˜æˆå‘é‡ï¼Œ</p><p>å‡å¦‚æˆ‘ä»¬ $\Theta_1,\Theta_2,\Theta_3$ å‚æ•°å’Œ $D^{(1)},D^{(2)},D^{(3)}$ å‚æ•°ï¼ŒTheta1 æ˜¯ $10 * 11$ï¼ŒTheta2 æ˜¯ $10 * 11$ï¼ŒTheta3 æ˜¯ $1 * 11$ã€‚</p><pre class=" language-c"><code class="language-c"><span class="token operator">%</span> æ‰“åŒ…æˆä¸€ä¸ªå‘é‡thetaVector <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">Theta3</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">]</span>deltaVector <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token function">D1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">D2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">D3</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span> <span class="token punctuation">]</span><span class="token operator">%</span> è§£åŒ…è¿˜åŸTheta1 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">110</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span>Theta2 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">:</span><span class="token number">220</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span>Theta3 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">:</span><span class="token number">231</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span></code></pre><p>æ‰€ä»¥<strong>å¥—è·¯</strong>æ˜¯ï¼š</p><ol><li>å…ˆå°† $\Theta_1,\Theta_2,\Theta_3$ ,è¿™äº›çŸ©é˜µå±•å¼€ä¸ºä¸€ä¸ªé•¿å‘é‡èµ‹å€¼ç»™ initialThetaï¼Œç„¶åä½œä¸ºthetaå‚æ•°çš„åˆå§‹è®¾ç½®ä¼ å…¥ä¼˜åŒ–å‡½æ•° fminuncã€‚</li><li>å†å®ç°ä»£ä»·å‡½æ•° costFunctionã€‚costFunction å‡½æ•°å°†ä¼ å…¥å‚æ•° thetaVecï¼ˆå°±æ˜¯åˆšæ‰åŒ…å«æ‰€æœ‰ $\Theta$ å‚æ•°çš„å‘é‡ï¼‰ï¼Œç„¶åé€šè¿‡ reshape å‡½æ•°å¾—åˆ°åˆå§‹çš„çŸ©é˜µï¼Œè¿™æ ·å¯ä»¥æ›´æ–¹ä¾¿åœ°é€šè¿‡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä»¥æ±‚å¾—å¯¼æ•° $D^{(1)},D^{(2)},D^{(3)}$ å’Œä»£ä»·å‡½æ•° $F(\Theta)$ ã€‚</li><li>æœ€åæŒ‰é¡ºåºå±•å¼€å¾—åˆ° gradientVecï¼Œè®©å®ƒä»¬ä¿æŒå’Œä¹‹å‰å±•å¼€çš„ $\theta$ å€¼åŒæ ·çš„é¡ºåºã€‚ä»¥ä¸€ä¸ªå‘é‡çš„å½¢å¼è¿”å›è¿™äº›å¯¼æ•°å€¼ã€‚</li></ol><hr><h2 id="äºŒ-Gradient-Checking"><a href="#äºŒ-Gradient-Checking" class="headerlink" title="äºŒ. Gradient Checking"></a>äºŒ. Gradient Checking</h2><p>åœ¨è®¡ç®—å¯¼æ•°çš„æ—¶å€™ï¼Œä¹ æƒ¯å°†å…¶ç­‰äºåœ¨è¯¥ç‚¹çš„å¯¼æ•°ï¼Œåœ¨æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™è®¡ç®—å¯¼æ•°çš„æ—¶å€™ï¼Œè™½ç„¶å¯èƒ½ $F(\Theta)$ æ¯æ¬¡è¿­ä»£éƒ½åœ¨ä¸‹é™ï¼Œä½†æ˜¯å› ä¸ºåå‘ä¼ æ’­çš„å¤æ‚æ€§ï¼Œå¯èƒ½å¯¼è‡´æˆ‘ä»¬çš„ä»£ç å­˜åœ¨ BUGã€‚æœ‰ä¸€ä¸ªåŠæ³•å«åšæ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰ï¼Œå®ƒèƒ½å‡å°‘è¿™ç§é”™è¯¯çš„æ¦‚ç‡ï¼ˆå‡ºç°è¿™ä¸ªé—®é¢˜çš„åŸå› éƒ½å’Œåå‘ä¼ æ’­çš„é”™è¯¯å®ç°æœ‰å…³ï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_1.png" alt=""></p><p>åœ¨æˆ‘ä»¬æ±‚è¯¥ç‚¹çš„æ–œç‡çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸ç›´æ¥ä½¿ç”¨å…¶å¯¼æ•°ï¼Œè€Œæ˜¯ç”¨ $$\frac{d}{d\Theta}F(\Theta)\approx\frac{F(\Theta+\epsilon)-F(\Theta-\epsilon)}{2\epsilon}$$ ä»£æ›¿ã€‚é€šå¸¸ $\epsilon$ å–è¾ƒå°çš„ä¸€ä¸ªæ•°ã€‚ï¼ˆå…¶å®å°±æ˜¯ä½¿ç”¨å¯¼æ•°çš„å®šä¹‰ï¼‰</p><p>ä¸Šé¢è¿™ç§ç®—æ³•æ˜¯åŒä¾§å·®åˆ†ç®—æ³•ï¼Œä¸ä¹‹ç›¸å¯¹çš„æ˜¯å•ä¾§å·®åˆ†ç®—æ³•</p><p>$$\frac{d}{d\Theta}F(\Theta)\approx\frac{F(\Theta+\epsilon)-F(\Theta)}{\epsilon}$$</p><p>å•ä¾§å·®åˆ†å’ŒåŒä¾§å·®åˆ†ç›¸æ¯”ï¼ŒåŒä¾§å·®åˆ†å¯ä»¥å¾—åˆ°æ›´åŠ å‡†ç¡®çš„ç»“æœã€‚</p><p>æ¨å¹¿ä¸€ä¸‹åŒä¾§å·®åˆ†ï¼š</p><p>$$\frac{d}{d\Theta_j}J(\Theta)\approx\frac{J(\Theta_1,â€¦,+\Theta_j+\epsilon,â€¦,\Theta_n)-J(\Theta_1,â€¦,+\Theta_j-\epsilon,â€¦,\Theta_n)}{2\epsilon}$$</p><p>å¯¹åº”ä»£ç å®ç°å¦‚ä¸‹ï¼š</p><pre class=" language-c"><code class="language-c">epsilon <span class="token operator">=</span> <span class="token number">1e-4</span><span class="token punctuation">;</span><span class="token keyword">for</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">:</span>n<span class="token punctuation">,</span>  thetaPlus <span class="token operator">=</span> theta<span class="token punctuation">;</span>  <span class="token function">thetaPlus</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span><span class="token operator">=</span> epsilon<span class="token punctuation">;</span>  thetaMinus <span class="token operator">=</span> theta<span class="token punctuation">;</span>  <span class="token function">thetaMinus</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">=</span> epsilon<span class="token punctuation">;</span>  <span class="token function">gradApprox</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">J</span><span class="token punctuation">(</span>thetaPlus<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">J</span><span class="token punctuation">(</span>thetaMinus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>epsilon<span class="token punctuation">)</span>end<span class="token punctuation">;</span></code></pre><p>æ£€æŸ¥åå‘ä¼ æ’­è®¡ç®—å‡ºæ¥çš„å¯¼æ•° DVec å’Œ ä¸Šé¢ç¨‹åºè®¡ç®—å‡ºæ¥çš„ gradApprox ç›¸æ¯”è¾ƒï¼Œå¦‚æœ $gradApprox \approx DVec$ ä»£è¡¨åå‘ä¼ æ’­çš„å®ç°æ˜¯æ­£ç¡®çš„ã€‚</p><p>æœ€ååœ¨ä½¿ç”¨ç®—æ³•å­¦ä¹ çš„æ—¶å€™å…³é—­æ¢¯åº¦æ£€éªŒã€‚å› ä¸ºæ¢¯åº¦æ£€éªŒä¸»è¦æ˜¯ä¸ºäº†è®©æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬å†™çš„ç¨‹åºç®—æ³•æ˜¯å¦å­˜åœ¨é”™è¯¯ï¼Œè€Œä¸æ˜¯ç”¨æ¥è®¡ç®—å¯¼æ•°çš„ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•è®¡ç®—å¯¼æ•°ç›¸æ¯”äºä¹‹å‰çš„ä¼šéå¸¸æ…¢ã€‚</p><p>æ€»ç»“ä¸€ä¸‹ï¼š</p><ol><li>é€šè¿‡åå‘ä¼ æ’­æ¥è®¡ç®— DVecï¼ŒDVec æ˜¯æ¯ä¸ªçŸ©é˜µæ‰“åŒ…å±•å¼€çš„å½¢å¼ã€‚</li><li>å®ç°æ•°å€¼ä¸Šçš„æ¢¯åº¦æ£€æµ‹ï¼Œè®¡ç®—å‡º gradApproxã€‚</li><li>æ¯”è¾ƒ $gradApprox \approx DVec$ æ˜¯å¦ç›¸ç­‰æˆ–è€…çº¦ç­‰äºã€‚</li><li>ä½¿ç”¨ç®—æ³•å­¦ä¹ çš„æ—¶å€™è®°å¾—è¦å…³é—­è¿™ä¸ªæ¢¯åº¦æ£€éªŒï¼Œæ¢¯åº¦æ£€éªŒåªåœ¨ä»£ç æµ‹è¯•é˜¶æ®µè¿›è¡Œã€‚</li></ol><hr><h2 id="ä¸‰-Random-Initialization"><a href="#ä¸‰-Random-Initialization" class="headerlink" title="ä¸‰. Random Initialization"></a>ä¸‰. Random Initialization</h2><p>ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ—¶å€™ï¼Œéœ€è¦è®¾ç½® $\Theta$ åˆå§‹å€¼ã€‚</p><pre class=" language-c"><code class="language-c">optTheta <span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span>@costFunction<span class="token punctuation">,</span> initialTheta<span class="token punctuation">,</span> options<span class="token punctuation">)</span></code></pre><p>è°ƒç”¨ fminunc å‡½æ•°çš„æ—¶å€™ï¼ŒinitialTheta å¦‚æœå…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Œ</p><pre class=" language-c"><code class="language-c">initialTheta <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><p>åœ¨ä¹‹å‰çš„çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’ä¸­ï¼Œä½¿ç”¨æ¢¯åº¦å‡½æ•°ï¼Œåˆå§‹å€¼è®¾ç½®ä¸º0æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æ˜¯åˆ°äº†ç¥ç»ç½‘ç»œé‡Œé¢ï¼Œå¦‚æœè¿˜è¿™ä¹ˆè®¾ç½®ï¼Œä¼šå‡ºç°é«˜åº¦å†—ä½™ç°è±¡ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_2.png" alt=""></p><p>å‡è®¾æˆ‘ä»¬æœ‰è¿™æ ·ä¸€ä¸ªç½‘ç»œï¼Œå…¶åˆå§‹å‚æ•°éƒ½è®¾ä¸º0ã€‚é‚£ä¹ˆæˆ‘ä»¬ä¼šå‘ç°å…¶æ¿€åŠ± $a_1^{(2)}=a_2^{(2)}$ ,ä¸”è¯¯å·® $\delta_1^{(2)}=\delta_2^{(2)}$ ,ä¸”å¯¼æ•° $\frac{d}{d\Theta^{(1)}_{01}}J(\Theta)=\frac{d}{d\Theta^{(1)}_{02}}J(\Theta)$ ã€‚è¿™å°±å¯¼è‡´äº†åœ¨å‚æ•°æ›´æ–°çš„æƒ…å†µä¸‹ï¼Œä¸¤ä¸ªå‚æ•°æ˜¯ä¸€æ ·çš„ã€‚æ— è®ºæ€ä¹ˆé‡å¤è®¡ç®—å…¶ä¸¤è¾¹çš„æ¿€åŠ±è¿˜æ˜¯ä¸€æ ·çš„ã€‚</p><p>ä¸Šè¿°é—®é¢˜è¢«ç§°ä¸ºï¼Œå¯¹ç§°æƒé‡é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯æ‰€æœ‰æƒé‡éƒ½æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥éšæœºåˆå§‹åŒ–æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚</p><p>æˆ‘ä»¬å°†åˆå§‹åŒ–æƒå€¼ $\Theta_{ij}^{(l)}$ çš„èŒƒå›´é™å®šåœ¨ $[-\Phi ,\Phi ]$ ã€‚</p><p>å…¶ä»£ç è¡¨ç¤ºå¦‚ä¸‹ï¼š</p><pre class=" language-c"><code class="language-c"><span class="token operator">%</span>If the dimensions of Theta1 is 10x11<span class="token punctuation">,</span> Theta2 is 10x11 and Theta3 is 1x11<span class="token punctuation">.</span>Theta1 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span>Theta2 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span>Theta3 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span></code></pre><p>rand(xï¼Œy)æ˜¯éšæœºå‡½æ•°ï¼Œå®ƒå°†åˆå§‹åŒ–ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„éšæœºå®æ•°çŸ©é˜µã€‚</p><hr><h2 id="å››-æ€»ç»“"><a href="#å››-æ€»ç»“" class="headerlink" title="å››. æ€»ç»“"></a>å››. æ€»ç»“</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_3.png" alt=""></p><h3 id="1-å‡†å¤‡"><a href="#1-å‡†å¤‡" class="headerlink" title="1. å‡†å¤‡"></a>1. å‡†å¤‡</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç¡®å®šç¥ç»ç½‘ç»œæœ‰å¤šå°‘è¾“å…¥å•å…ƒï¼Œæœ‰å¤šå°‘éšè—å±‚ï¼Œæ¯ä¸€å±‚éšè—å±‚åˆæœ‰å¤šå°‘ä¸ªå•å…ƒï¼Œè¿˜æœ‰å¤šå°‘è¾“å‡ºå•å…ƒã€‚é‚£æˆ‘ä»¬æ€ä¹ˆå»é€‰æ‹©å‘¢ï¼Ÿ</p><ul><li>è¾“å…¥å•å…ƒæ˜¯ç‰¹å¾å‘é‡ $x^{(i)}$ çš„ç»´åº¦</li><li>è¾“å‡ºå•å…ƒæ˜¯åˆ†ç±»çš„ä¸ªæ•°</li><li>æ¯ä¸ªéšè—å±‚çš„å•å…ƒæ•°é€šå¸¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼ˆå¿…é¡»ä¸è®¡ç®—æˆæœ¬å¹³è¡¡ï¼Œå› ä¸ºéšç€æ›´å¤šéšè—å•å…ƒçš„å¢åŠ è€Œå¢åŠ ï¼‰</li><li>é»˜è®¤å€¼ï¼š1ä¸ªéšè—å±‚ã€‚å¦‚æœæœ‰å¤šä¸ªéšè—å±‚ï¼Œé‚£ä¹ˆå»ºè®®æ‚¨åœ¨æ¯ä¸ªéšè—å±‚ä¸­éƒ½æœ‰ç›¸åŒæ•°é‡çš„å•å…ƒã€‚</li></ul><p>è¾“å‡ºå•å…ƒå¦‚æœæ˜¯å¤šå…ƒåˆ†ç±»é—®é¢˜ï¼Œè¾“å‡ºå•å…ƒéœ€è¦å†™æˆçŸ©é˜µçš„å½¢å¼ï¼š</p><p>ä¾‹å¦‚æœ‰3ä¸ªåˆ†ç±»ï¼Œ è¾“å‡ºå•å…ƒåº”è¯¥å†™æˆ</p> $$\begin{align*}y = \begin{bmatrix} 1\\ 0\\ 0 \\ \end{bmatrix} or\begin{bmatrix} 0\\ 1\\ 0 \\ \end{bmatrix} or\begin{bmatrix} 0\\ 0\\ 1\\ \end{bmatrix}\end{align*}$$<h3 id="2-è®­ç»ƒ"><a href="#2-è®­ç»ƒ" class="headerlink" title="2. è®­ç»ƒ"></a>2. è®­ç»ƒ</h3><p>ç¬¬ä¸€æ­¥ï¼šéšæœºåˆå§‹åŒ–æƒé‡ã€‚åˆå§‹åŒ–çš„å€¼æ˜¯éšæœºçš„ï¼Œå€¼å¾ˆå°ï¼Œæ¥è¿‘äºé›¶ã€‚</p><p>ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå‰å‘ä¼ æ’­ç®—æ³•ï¼Œå¯¹äºæ¯ä¸€ä¸ª $x^{(i)}$ è®¡ç®—å‡ºå‡è®¾å‡½æ•° $h_\Theta(x^{(i)})$ ã€‚</p><p>ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—å‡ºä»£ä»·å‡½æ•° $F(\Theta)$ ã€‚</p><p>ç¬¬å››æ­¥ï¼šæ‰§è¡Œåå‘ä¼ æ’­ç®—æ³•ï¼Œè®¡ç®—å‡ºåå¯¼æ•° $\frac{\partial}{\partial\Theta_{jk}^{(l)}}F(\Theta)$ ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_4.png" alt=""></p><p>å…·ä½“æ“ä½œå°±æ˜¯ä½¿ç”¨ä¸€ä¸ªforå¾ªç¯ï¼Œå…ˆå°† $(x^{(1)},y^{(1)})$ è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„æ“ä½œï¼Œç„¶åå†å¯¹ $(x^{(2)},y^{(2)})$ è¿›è¡Œç›¸åŒçš„æ“ä½œä¸€ç›´åˆ° $(x^{(n)},y^{(n)})$ ï¼Œè¿™æ ·å°±èƒ½å¾—åˆ°ç¥ç»ç½‘ç»œä¸­æ¯ä¸€å±‚ä¸­æ¯ä¸ªå•å…ƒå¯¹åº”çš„æ¿€åŠ±å€¼ï¼Œå’Œæ¯ä¸€å±‚æ¿€åŠ±çš„è¯¯å·® $\delta^{(l)}$ ã€‚</p><p>ç¬¬äº”æ­¥ï¼šåˆ©ç”¨æ¢¯åº¦æ£€æŸ¥ï¼Œå¯¹æ¯”åå‘ä¼ æ’­ç®—æ³•è®¡ç®—å¾—åˆ°çš„åå¯¼æ•°é¡¹æ˜¯å¦ä¸æ¢¯åº¦æ£€éªŒç®—æ³•è®¡ç®—å‡ºçš„å¯¼æ•°é¡¹åŸºæœ¬ç›¸ç­‰ã€‚<strong>æ£€æŸ¥å®Œè®°å¾—åˆ é™¤æ‰è¿™æ®µæ£€æŸ¥çš„ä»£ç </strong>ã€‚</p><p>ç¬¬å…­æ­¥ï¼šæœ€åæˆ‘ä»¬åˆ©ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æˆ–è€…æ›´é«˜çº§çš„ç®—æ³•ä¾‹å¦‚ LBFGSã€å…±è½­æ¢¯åº¦æ³•ç­‰ï¼Œç»“åˆä¹‹å‰ç®—å‡ºçš„åå¯¼æ•°é¡¹ï¼Œæœ€å°åŒ–ä»£ä»·å‡½æ•° $F(\Theta)$ ç®—å‡ºæƒå€¼çš„å¤§å° $\Theta$ ã€‚</p><p>ç†æƒ³æƒ…å†µä¸‹ï¼Œåªè¦æ»¡è¶³äº† $h_{\Theta}(x^{(i)})\approx y^{(i)}$ï¼Œå°±èƒ½ä½¿æˆ‘ä»¬çš„ä»£ä»·å‡½æ•°æœ€å°ã€‚ä½†æ˜¯ï¼Œä»£ä»·å‡½æ•° $F(\Theta)$ ä¸æ˜¯å‡¸çš„ï¼Œå› æ­¤æˆ‘ä»¬æœ€ç»ˆå¯ä»¥ç”¨å±€éƒ¨æœ€å°å€¼ä»£æ›¿å…¨å±€æœ€å°å€¼ã€‚</p><hr><h2 id="äº”-Neural-Networks-Learning-æµ‹è¯•"><a href="#äº”-Neural-Networks-Learning-æµ‹è¯•" class="headerlink" title="äº”. Neural Networks: Learning æµ‹è¯•"></a>äº”. Neural Networks: Learning æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update</p>$\Delta^{(2)}_{ij}:=\Delta^{(2)}_{ij}+\delta^{(3)}_{i}*(a^{(2)})_{j}$  <p>for every i,j. Which of the following is a correct vectorization of this step?</p><p>A. $\Delta^{(2)}:=\Delta^{(2)}+(a^{(3)})^T * \delta^{(2)} $<br>B. $\Delta^{(2)}:=\Delta^{(2)}+(a^{(2)})^T * \delta^{(3)} $<br>C. $\Delta^{(2)}:=\Delta^{(2)}+\delta^{(3)}*(a^{(3)})^T $</p><p>D. $\Delta^{(2)}:=\Delta^{(2)}+\delta^{(3)}*(a^{(2)})^T $    </p><p>è§£ç­”ï¼š D</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose ğšƒğš‘ğšğšğšŠğŸ· is a 5x3 matrix, and ğšƒğš‘ğšğšğšŠğŸ¸ is a 4x6 matrix. You set ğšğš‘ğšğšğšŠğš…ğšğšŒ=[ğšƒğš‘ğšğšğšŠğŸ·(:);ğšƒğš‘ğšğšğšŠğŸ¸(:)]. Which of the following correctly recovers ğšƒğš‘ğšğšğšŠğŸ¸?</p><p>A. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¹ğŸ¿),ğŸº,ğŸ¼)<br>B. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ»:ğŸ¹ğŸ¾),ğŸº,ğŸ¼)<br>C. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¸ğŸº),ğŸº,ğŸ¼)<br>D. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ»:ğŸ¹ğŸ¿),ğŸº,ğŸ¼)<br>E. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¹ğŸ¿),ğŸ¼,ğŸº)  </p><p>è§£ç­”ï¼šA</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Let $J(\theta)=2\theta^3+2$ . Let $\theta=1$ , and  $\epsilon=0.01$ . Use the formula $\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$ to numerically compute an approximation to the derivative at $\theta=1$ . What value do you get? (When $\theta=1$ , the true/exact derivati ve is $\frac{dJ(\theta)}{d\theta}=6$ .)</p><p>A.6<br>B.8<br>C.5.9998<br>D.6.0002  </p><p>è§£ç­”ï¼š D</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Gradient checking is useful if we are using gradient descent as our optimization algorithm. However, it serves little purpose if we are using one of the advanced optimization methods (such as in fminunc).  </p><p>B. If our neural network overfits the training set, one reasonable step to take is to increase the regularization parameter Î» .  </p><p>C. Using gradient checking can help verify if oneâ€™s implementation of backpropagation is bug-free.  </p><p>D. Using a large value of Î» cannot hurt the performance of your neural network; the only reason we do not set Î» to be too large is to avoid numerical problems.  </p><p>E. For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network.  </p><p>F. Computing the gradient of the cost function in a neural network has the same efficiency when we use backpropagation or when we numerically compute it using the method of gradient checking.  </p><p>è§£ç­”ï¼šBã€Cã€E</p><p>A.æ¢¯åº¦æ£€éªŒåªæ˜¯ç”¨æ¥æ£€éªŒæˆ‘ä»¬ç®—åå¯¼æ•°çš„ç®—æ³•æ˜¯å¦æ­£ç¡®ï¼Œè€Œä¸æ˜¯ç”¨æ¥è®¡ç®—çš„ã€‚<br>B.è¿‡æ‹Ÿåˆå¢å¤§æ­£åˆ™åŒ–å‚æ•° Î» æ­£ç¡®ã€‚<br>C.æ¢¯åº¦æ£€éªŒèƒ½æ£€éªŒåå‘ä¼ æ’­ç®—æ³•æ˜¯å¦æ­£ç¡®ã€‚<br>D.æ­£åˆ™åŒ–å‚æ•° Î» å¤ªå¤§ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚<br>E.è¿˜æ˜¯åœ¨è¯´æ¢¯åº¦æ£€éªŒèƒ½éªŒè¯åå‘ä¼ æ’­ç®—æ³•çš„æ­£ç¡®æ€§ã€‚<br>F.è¿˜æ˜¯åœ¨è¯´æ¢¯åº¦æ£€éªŒå¯ä»¥ç”¨æ¥åœ¨ç®—æ³•é‡Œç®—åå¯¼æ•°ã€‚  </p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you have a three layer network with parameters  $\Theta^{(1)}$ (controlling the function mapping from the inputs to the hidden units) and  $\Theta^{(2)}$ (controlling the mapping from the hidden units to the outputs). If we set all the elements of  $\Theta^{(1)}$ to be 0, and all the elements of  $\Theta^{(2)}$ to be 1, then this suffices for symmetry breaking, since the neurons are no longer all computing the same function of the input.</p><p>B. If we are training a neural network using gradient descent, one reasonable â€œdebuggingâ€ step to make sure it is working is to plot $J(\Theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.</p><p>C. Suppose you are training a neural network using gradient descent. Depending on your random initialization, your algorithm may converge to different local optima (i.e., if you run the algorithm twice with different random initializations, gradient descent may converge to two different solutions).</p><p>D. If we initialize all the parameters of a neural network to ones instead of zeros, this will suffice for the purpose of â€œsymmetry breakingâ€ because the parameters are no longer symmetrically equal to zero.</p><p>E. If we are training a neural network using gradient descent, one reasonable â€œdebuggingâ€ step to make sure it is working is to plot $J(\Theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.</p><p>F. Suppose we have a correct implementation of backpropagation, and are training a neural network using gradient descent. Suppose we plot $J(\Theta)$ as a function of the number of iterations, and find that it is increasing rather than decreasing. One possible cause of this is that the learning rate $\alpha$ is too large.</p><p>G. Suppose that the parameter $\Theta^{(1)}$ is a square matrix (meaning the number of rows equals the number of columns). If we replace $\Theta^{(1)}$ with its transpose $(\Theta^{(1)})^T$ , then we have not changed the function that the network is computing.</p><p>H. Suppose we are using gradient descent with learning rate $\alpha$ . For logistic regression and linear regression, $J(\Theta)$ was a convex optimization problem and thus we did not want to choose a learning rate $\alpha$ that is too large. For a neural network however, $J(\Theta)$ may not be convex, and thus choosing a very large value of $\alpha$ can only speed up convergence.</p><p>è§£ç­”ï¼šBã€Cã€F</p><p>A.ä¸€å±‚çš„æƒé‡éƒ½æ˜¯ä¸€æ ·çš„æ•°å­—ä¸èƒ½æ‰“ç ´å¯¹ç§°ã€‚<br>B.è¿­ä»£æ¬¡æ•°çš„è¶Šå¤šï¼Œä»£ä»·å‡½æ•° $J(\Theta)$ ä¸‹é™æ­£ç¡®ã€‚<br>C.å­¦ä¹ é€Ÿç‡ $\alpha$ å¤ªå¤§ä¼šå¯¼è‡´ä»£ä»·å‡½æ•°éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ ä¹Ÿå¢åŠ æ­£ç¡®ã€‚<br>D.æƒé‡å…¨éƒ¨ä¸º1ä¹Ÿä¸èƒ½æ‰“ç ´å¯¹ç§°çš„ã€‚<br>E.ä¿è¯ $J(\Theta)$ éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ è€Œä¸‹é™ç”¨ä»¥éªŒè¯ç®—æ³•çš„æ­£ç¡®ã€‚<br>F.åŒBã€‚<br>G.çŸ©é˜µçš„å€’ç½®ä¸€èˆ¬ä¸ç›¸ç­‰ã€‚<br>H.é€‰æ‹©å¤§çš„å­¦ä¹ é€Ÿç‡ $\alpha$ ä¼šå¯¼è‡´ $J(\Theta)$ ä¸æ”¶æ•›çš„ã€‚  </p><hr><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.1_Neural_Networks_Learning</title>
      <link href="/2020/02/05/5-1-neural-networks-learning/"/>
      <url>/2020/02/05/5-1-neural-networks-learning/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-03b47f040418215a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h1 id="5-1-Neural-Networks-Learning"><a href="#5-1-Neural-Networks-Learning" class="headerlink" title="5.1_Neural_Networks_Learning"></a>5.1_Neural_Networks_Learning</h1><h2 id="ä¸€-Cost-Function-and-Backpropagation"><a href="#ä¸€-Cost-Function-and-Backpropagation" class="headerlink" title="ä¸€. Cost Function and Backpropagation"></a>ä¸€. Cost Function and Backpropagation</h2><h3 id="1-Cost-Function"><a href="#1-Cost-Function" class="headerlink" title="1. Cost Function"></a>1. Cost Function</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_3.png" alt=""></p><p>å‡è®¾è®­ç»ƒé›†ä¸­æœ‰ m ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œ$\begin{Bmatrix} (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \cdots ,(x^{(m)},y^{(m)}) \end{Bmatrix}$ï¼ŒL è¡¨ç¤ºç¥ç»ç½‘ç»œçš„æ€»å±‚æ•° Layerï¼Œç”¨ $S_{l}$ è¡¨ç¤ºç¬¬ L å±‚çš„å•å…ƒæ•°(ç¥ç»å…ƒçš„æ•°é‡)ï¼Œä½†æ˜¯ä¸åŒ…æ‹¬ç¬¬ L å±‚çš„åå·®å•å…ƒ(å¸¸æ•°é¡¹)ã€‚ä»¤ K ä¸ºè¾“å‡ºå±‚çš„å•å…ƒæ•°ç›®ï¼Œå³ æœ€åä¸€å±‚çš„å•å…ƒæ•°ã€‚</p><p><strong>ç¬¦å·çº¦å®š</strong>ï¼š</p><p>$z_i^{(j)}$ =  ç¬¬ $j$ å±‚çš„ç¬¬ $i$ ä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œè®¡ç®—å€¼â€<br>$a_i^{(j)}$ = ç¬¬ $j$ å±‚çš„ç¬¬ $i$ ä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œæ¿€æ´»å€¼â€;</p> $\Theta^{(l)}_{i,j}$  = æ˜ å°„ç¬¬ $l$ å±‚åˆ°ç¬¬ $l+1$ å±‚çš„æƒå€¼çŸ©é˜µçš„ç¬¬ $i$ è¡Œç¬¬ $j$ åˆ—çš„åˆ†é‡<p>$L$ = ç¥ç»ç½‘ç»œæ€»å±‚æ•°ï¼ˆåŒ…æ‹¬è¾“å…¥å±‚ã€éšå±‚å’Œè¾“å‡ºå±‚ï¼‰<br>$s_l$ = ç¬¬ $l$ å±‚èŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰ä¸ªæ•°ï¼Œä¸åŒ…æ‹¬åç§»é‡èŠ‚ç‚¹ã€‚<br>$K$ = è¾“å‡ºèŠ‚ç‚¹ä¸ªæ•°<br>$h_{\theta}(x)_k$ = ç¬¬ $k$ ä¸ªé¢„æµ‹è¾“å‡ºç»“æœ<br>$x^{(i)}$ = ç¬¬ $i$ ä¸ªæ ·æœ¬ç‰¹å¾å‘é‡<br>$x^{(i)}_k$ = ç¬¬ $i$ ä¸ªæ ·æœ¬çš„ç¬¬ $k$ ä¸ªç‰¹å¾å€¼<br>$y^{(i)}$ = ç¬¬ $i$ ä¸ªæ ·æœ¬å®é™…ç»“æœå‘é‡<br>$y^{(i)}_k$ = ç¬¬ $i$ ä¸ªæ ·æœ¬ç»“æœå‘é‡çš„ç¬¬ $k$ ä¸ªåˆ†é‡   </p><p>ä¹‹å‰è®¨è®ºçš„é€»è¾‘å›å½’ä¸­ä»£ä»·å‡½æ•°å¦‚ä¸‹ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] +\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_{j}^{2}  \\\end{align*}$$<p>æ‰©å±•åˆ°ç¥ç»ç½‘ç»œä¸­ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\Theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} \sum_{k=1}^{K} y^{(i)}_{k} log(h_{\Theta}(x^{(i)}))_{k} + (1-y^{(i)}_{k})log(1-(h_{\Theta}(x^{(i)}))_{k}) \right ] +\frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{S_{l}}\sum_{j=1}^{S_{l} +1}(\Theta_{j,i}^{(l)})^{2}  \\h_{\Theta}(x) &amp;\in \mathbb{R}^{K} \;\;\;\;\;\;\;\;\; (h_{\Theta}(x))_{i} = i^{th} \;\;output \\\end{align*}$$<p>$h_{\Theta}(x)$ æ˜¯ä¸€ä¸ª K ç»´å‘é‡ï¼Œ$ i $ è¡¨ç¤ºé€‰æ‹©è¾“å‡ºç¥ç»ç½‘ç»œè¾“å‡ºå‘é‡ä¸­çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚</p><p>ç¥ç»ç½‘ç»œçš„ä»£ä»·å‡½æ•°ç›¸æ¯”é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°ï¼Œå‰ä¸€é¡¹çš„æ±‚å’Œè¿‡ç¨‹ä¸­å¤šäº†ä¸€ä¸ª $ \sum_{k=1}^{K} $ ,ç”±äº K ä»£è¡¨äº†æœ€åä¸€å±‚çš„å•å…ƒæ•°ï¼Œæ‰€ä»¥è¿™é‡Œå°±æ˜¯ç´¯åŠ äº† k ä¸ªè¾“å‡ºå±‚çš„ä»£ä»·å‡½æ•°ã€‚</p><p>åä¸€é¡¹æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œç¥ç»ç½‘ç»œçš„æ­£åˆ™åŒ–é¡¹çœ‹èµ·æ¥ç‰¹åˆ«å¤æ‚ï¼Œå…¶å®å°±æ˜¯å¯¹ $ (\Theta_{j,i}^{(l)})^{2} $ é¡¹å¯¹æ‰€æœ‰çš„ iï¼Œjï¼Œlçš„å€¼æ±‚å’Œã€‚æ­£å¦‚åœ¨é€»è¾‘å›å½’ä¸­çš„ä¸€æ ·ï¼Œè¿™é‡Œè¦é™¤å»é‚£äº›å¯¹åº”äºåå·®å€¼çš„é¡¹ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¯¹å®ƒä»¬è¿›è¡Œæ±‚å’Œï¼Œå³ä¸å¯¹ $ (\Theta_{j,0}^{(l)})^{2} ;;;;(i=0) $ é¡¹æ±‚å’Œã€‚</p><h3 id="2-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•"><a href="#2-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•" class="headerlink" title="2. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•"></a>2. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•</h3><p>ä»¤ $ \delta_{j}^{(l)} $ è¡¨ç¤ºç¬¬ $l$ å±‚ç¬¬ $j$ ä¸ªç»“ç‚¹çš„è¯¯å·®ã€‚</p><p>åå‘ä¼ æ’­ä»æœ€åä¸€å±‚å¼€å§‹å¾€å‰æ¨ï¼š</p>$$\begin{align*}\delta_{j}^{(L)} &amp;= a_{j}^{(L)} - y_{j} \\&amp;=(h_{\theta}(x))_{j} - y_{j} \\\end{align*}$$<p>å¾€å‰è®¡ç®—å‡ æ­¥ï¼š</p>$$\begin{align*}\delta^{(3)} &amp;= (\Theta^{(3)})^{T}\delta^{(4)} . * g^{'}(z^{(3)}) \\\delta^{(2)} &amp;= (\Theta^{(2)})^{T}\delta^{(3)} . * g^{'}(z^{(2)}) \\\end{align*}$$<p>é€»è¾‘å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰æ±‚å¯¼ï¼š</p>$$\begin{align*}\sigma(x)'&amp;=\left(\frac{1}{1+e^{-x}}\right)'=\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}=\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline &amp;=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)\\&amp;=\sigma(x)(1 - \sigma(x))\\\end{align*}$$<p>å¯ä»¥ç®—å‡º $g^{â€˜}(z^{(3)}) = a^{(3)} . * (1-a^{(3)})$ ï¼Œ $g^{â€˜}(z^{(2)}) = a^{(2)} . * (1-a^{(2)})$ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_4.png" alt=""></p><p>äºæ˜¯å¯ä»¥ç»™å‡ºåå‘ä¼ æ’­çš„ç®—æ³•æ­¥éª¤ï¼š</p><p>é¦–å…ˆæœ‰ä¸€ä¸ªè®­ç»ƒé›† $\begin{Bmatrix} (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \cdots ,(x^{(m)},y^{(m)}) \end{Bmatrix}$ï¼Œåˆå§‹å€¼å¯¹æ¯ä¸€ä¸ª $(l,i,j)$ éƒ½è®¾ç½® $\Delta^{(l)}_{i,j} := 0$ ï¼Œå³åˆå§‹çŸ©é˜µæ˜¯å…¨é›¶çŸ©é˜µã€‚</p><p>é’ˆå¯¹ $1-m$ è®­ç»ƒé›†å¼€å§‹ä»¥ä¸‹æ­¥éª¤çš„è®­ç»ƒï¼š</p><h3 id="1-å‰å‘ä¼ æ’­"><a href="#1-å‰å‘ä¼ æ’­" class="headerlink" title="(1) å‰å‘ä¼ æ’­"></a>(1) å‰å‘ä¼ æ’­</h3><p>è®¾ç½® $ a^{(1)} := x^{(t)} $ï¼Œå¹¶æŒ‰ç…§å‰å‘ä¼ æ’­çš„æ–¹æ³•ï¼Œè®¡ç®—å‡ºæ¯ä¸€å±‚çš„æ¿€åŠ± $a^{(l)}$ ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_5.png" alt=""></p><h3 id="2-è®¡ç®—è¯¯å·®"><a href="#2-è®¡ç®—è¯¯å·®" class="headerlink" title="(2) è®¡ç®—è¯¯å·®"></a>(2) è®¡ç®—è¯¯å·®</h3><p>åˆ©ç”¨ $y^{(t)}$ï¼Œè®¡ç®— $\delta^{(L)} = a^{(L)} - y^{t}$</p><p>å…¶ä¸­ $L$ æ˜¯æˆ‘ä»¬çš„æ€»å±‚æ•°ï¼Œ$a^{(L)}$ æ˜¯æœ€åä¸€å±‚æ¿€æ´»å•å…ƒè¾“å‡ºçš„å‘é‡ã€‚æ‰€ä»¥æˆ‘ä»¬æœ€åä¸€å±‚çš„â€œè¯¯å·®å€¼â€ä»…ä»…æ˜¯æˆ‘ä»¬åœ¨æœ€åä¸€å±‚çš„å®é™…ç»“æœå’Œ y ä¸­çš„æ­£ç¡®è¾“å‡ºçš„å·®å¼‚ã€‚ä¸ºäº†è·å¾—æœ€åä¸€å±‚ä¹‹å‰çš„å›¾å±‚çš„å¢é‡å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢æ­¥éª¤ä¸­çš„æ–¹ç¨‹ï¼Œè®©æˆ‘ä»¬ä»å³å‘å·¦å‰è¿›ï¼š</p><h3 id="3-åå‘ä¼ æ’­"><a href="#3-åå‘ä¼ æ’­" class="headerlink" title="(3) åå‘ä¼ æ’­"></a>(3) åå‘ä¼ æ’­</h3><p>é€šè¿‡ $\delta^{(l)} = ((\Theta^{(l)})^{(T)}\delta^{(l+1)}).* a^{(l)} .*(1-a^{(l)})$ï¼Œè®¡ç®— $\delta^{(L-1)},\delta^{(L-2)},\cdots,\delta^{(2)}$ è®¡ç®—å‡ºæ¯ä¸€å±‚ç¥ç»èŠ‚ç‚¹çš„è¯¯å·®ã€‚</p><h3 id="4-è®¡ç®—åå¯¼æ•°"><a href="#4-è®¡ç®—åå¯¼æ•°" class="headerlink" title="(4) è®¡ç®—åå¯¼æ•°"></a>(4) è®¡ç®—åå¯¼æ•°</h3><p>æœ€ååˆ©ç”¨ $\Delta^{(l)}_{i,j} := \Delta^{(l)}_{i,j} + a_{j}^{(l)}\delta_{i}^{(l+1)}$ï¼Œæˆ–è€…çŸ¢é‡è¡¨ç¤ºä¸º $\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^{T}$ã€‚</p>$$\frac{\partial }{\partial \Theta_{i,j}^{(l)} }F(\Theta) = D_{i,j}^{(l)} := \left\{\begin{matrix}\frac{1}{m} \left( \Delta_{i,j}^{(l)} + \lambda\Theta_{i,j}^{(l)}  \right) \;\;\;\;\;\;\;\; j\neq 0\\ \frac{1}{m}\Delta_{i,j}^{(l)} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; j = 0\end{matrix}\right.$$<h3 id="5-æ›´æ–°çŸ©é˜µ"><a href="#5-æ›´æ–°çŸ©é˜µ" class="headerlink" title="(5) æ›´æ–°çŸ©é˜µ"></a>(5) æ›´æ–°çŸ©é˜µ</h3><p>æ›´æ–°å„å±‚çš„æƒå€¼çŸ©é˜µ $\Theta^{(l)}$ ï¼Œå…¶ä¸­ $\alpha$  ä¸ºå­¦ä¹ ç‡ï¼š</p><p>$$\Theta^{(l)} = \Theta^{(l)} - \alpha D^{(l)}$$</p><hr><h2 id="äºŒ-æ¨å¯¼"><a href="#äºŒ-æ¨å¯¼" class="headerlink" title="äºŒ. æ¨å¯¼"></a>äºŒ. æ¨å¯¼</h2><h3 id="1-ç›®æ ‡"><a href="#1-ç›®æ ‡" class="headerlink" title="1. ç›®æ ‡"></a>1. ç›®æ ‡</h3><p>æ±‚ $\min_\Theta F(\Theta)$</p><h3 id="2-æ€è·¯"><a href="#2-æ€è·¯" class="headerlink" title="2. æ€è·¯"></a>2. æ€è·¯</h3><p>ç±»ä¼¼æ¢¯åº¦ä¸‹é™æ³•ï¼Œç»™å®šä¸€ä¸ªåˆå€¼åï¼Œè®¡ç®—å‡ºæ‰€æœ‰èŠ‚ç‚¹çš„è®¡ç®—å€¼å’Œæ¿€æ´»å€¼ï¼Œç„¶åæ ¹æ®ä»£ä»·å‡½æ•°çš„å˜åŒ–ä¸æ–­è°ƒæ•´å‚æ•°å€¼ï¼ˆæƒå€¼ï¼‰ï¼Œæœ€ç»ˆä¸æ–­é€¼è¿‘æœ€ä¼˜ç»“æœï¼Œä½¿ä»£ä»·å‡½æ•°å€¼æœ€å°ã€‚</p><h3 id="3-æ¨å¯¼è¿‡ç¨‹"><a href="#3-æ¨å¯¼è¿‡ç¨‹" class="headerlink" title="3. æ¨å¯¼è¿‡ç¨‹"></a>3. æ¨å¯¼è¿‡ç¨‹</h3><p>ä¸ºäº†å®ç°ä¸Šè¿°æ€è·¯ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—ä»£ä»·å‡½æ•°çš„åå¯¼æ•°ï¼š</p><p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta)$$</p><p>è¿™ä¸ªåå¯¼å¹¶ä¸å¥½æ±‚ï¼Œä¸ºäº†æ–¹ä¾¿æ¨å¯¼ï¼Œæˆ‘ä»¬å‡è®¾åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼ˆ$m=1$ï¼Œå¯å¿½ç•¥ä»£ä»·å‡½æ•°ä¸­çš„å¤–éƒ¨æ±‚å’Œï¼‰ï¼Œå¹¶èˆå¼ƒæ­£è§„åŒ–éƒ¨åˆ†ï¼Œç„¶ååˆ†ä¸ºä¸¤ç§æƒ…å†µæ¥æ±‚ã€‚</p><h3 id="æƒ…å†µ1-éšè—å±‚-â†’-è¾“å‡ºå±‚"><a href="#æƒ…å†µ1-éšè—å±‚-â†’-è¾“å‡ºå±‚" class="headerlink" title="æƒ…å†µ1 éšè—å±‚ â†’ è¾“å‡ºå±‚"></a>æƒ…å†µ1 éšè—å±‚ â†’ è¾“å‡ºå±‚</h3><p>æˆ‘ä»¬çŸ¥é“ï¼š</p>$$\begin{align*}h_\Theta(x) &amp;= a^{(j+1)} = g(z^{(j+1)}) \\z^{(j)} &amp;= \Theta^{(j-1)}a^{(j-1)} \\\end{align*}$$<p>å¦å¤–ï¼Œè¾“å‡ºå±‚å³ç¬¬$L$å±‚ã€‚</p><p>æ‰€ä»¥ï¼š</p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(L)}}F(\Theta)= \dfrac{\partial F(\Theta)}{\partial h_{\Theta}(x)_i} \dfrac{\partial h_{\Theta}(x)_i}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial  \Theta_{i,j}^{(L)}}= \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}}$$<p>å…¶ä¸­ï¼š</p>$$\begin{align*}\dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} &amp;= \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} \\\dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} &amp;= \dfrac{\partial g(z_i^{(L)})}{\partial z_i^{(L)}} = \dfrac{e^{z_i^{(L)}}}{(e^{z_i^{(L)}}+1)^2} = a_i^{(L)} (1 - a_i^{(L)}) \\\dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}} &amp;= \dfrac{\partial ( \sum_{k=0}^{s_{(L-1)}}\; \Theta_{i,k}^{(L)} a_k^{(L-1)})}{\partial  \Theta_{i,j}^{(L)}} = a_j^{(L-1)} \\\end{align*}$$<p>ç»¼ä¸Šï¼š</p>$$\begin{split}\dfrac{\partial}{\partial \Theta_{i,j}^{(L)}}F(\Theta)=&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}} \newline  =&amp; \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} a_i^{(L)} (1 - a_i^{(L)}) a_j^{(L-1)} \newline  =&amp; (a_i^{(L)} - y_i)a_j^{(L-1)}\end{split}$$<h3 id="æƒ…å†µ2-éšè—å±‚-è¾“å…¥å±‚-â†’-éšè—å±‚"><a href="#æƒ…å†µ2-éšè—å±‚-è¾“å…¥å±‚-â†’-éšè—å±‚" class="headerlink" title="æƒ…å†µ2 éšè—å±‚ / è¾“å…¥å±‚ â†’ éšè—å±‚"></a>æƒ…å†µ2 éšè—å±‚ / è¾“å…¥å±‚ â†’ éšè—å±‚</h3><p>å› ä¸º $a^{(1)}=x$ï¼Œæ‰€ä»¥å¯ä»¥å°†è¾“å…¥å±‚å’Œéšè—å±‚åŒæ ·å¯¹å¾…ã€‚</p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta)=\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}}\ (l = 1, 2, ..., L-1)$$<p>å…¶ä¸­åä¸¤éƒ¨åˆ†åå¯¼å¾ˆå®¹æ˜“æ ¹æ®å‰é¢æ‰€å¾—ç±»æ¨å‡ºæ¥ï¼š</p>$$\begin{align*}\dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} &amp;= \dfrac{e^{z_i^{(l)}}}{(e^{z_i^{(l)}}+1)^2} = a_i^{(l)} (1 - a_i^{(l)}) \\\dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} &amp;= a_j^{(l-1)} \\\end{align*}$$<p>ç¬¬ä¸€éƒ¨åˆ†åå¯¼æ˜¯ä¸å¥½æ±‚è§£çš„ï¼Œæˆ–è€…è¯´æ˜¯æ²¡æ³•ç›´æ¥æ±‚è§£çš„ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨å¼ï¼š</p>$$\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} = \sum_{k=1}^{s_{(l+1)}} \Bigg[\dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}}\Bigg]$$<blockquote><p>å› ä¸ºè¯¥å±‚çš„æ¿€æ´»å€¼ä¸ä¸‹ä¸€å±‚å„èŠ‚ç‚¹éƒ½æœ‰å…³ï¼Œé“¾å¼æ³•åˆ™æ±‚å¯¼æ—¶éœ€ä¸€ä¸€æ±‚å¯¼ï¼Œæ‰€ä»¥æœ‰ä¸Šå¼ä¸­çš„æ±‚å’Œã€‚</p></blockquote><p>é€’æ¨å¼ä¸­ç¬¬ä¸€éƒ¨åˆ†æ˜¯é€’æ¨é¡¹ï¼Œåä¸¤éƒ¨åˆ†åŒæ ·æ˜“æ±‚ï¼š</p>$$\begin{align*}\dfrac{\partial a_k^{(l+1)}}{\partial z_{k}^{(l+1)}} &amp;= \dfrac{e^{z_{k}^{(l+1)}}}{(e^{z_{k}^{(l+1)}}+1)^2} = a_k^{(l+1)} (1 - a_k^{(l+1)}) \\\dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}} &amp;= \dfrac{\partial ( \sum_{j=0}^{s_l} \Theta_{k,j}^{(l+1)} a_j^{(l)})}{\partial a_i^{(l)}} = \Theta_{k,i}^{(l+1)} \\\end{align*}$$<p>æ‰€ä»¥ï¼Œé€’æ¨å¼ä¸ºï¼š</p>$$\begin{split}\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[\dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}}\Bigg] \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \Theta_{k,i}^{(l+1)} \Bigg] \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} a_k^{(l+1)} (1 - a_k^{(l+1)}) \Theta_{k,i}^{(l+1)} \Bigg]\end{split}$$<p>ä¸ºäº†ç®€åŒ–è¡¨è¾¾å¼ï¼Œå®šä¹‰ç¬¬ $l$ å±‚ç¬¬ $i$ ä¸ªèŠ‚ç‚¹çš„è¯¯å·®ï¼š</p>$$\begin{split}\delta^{(l)}_i =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \newline  =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} a_i^{(l)} (1 - a_i^{(l)})  \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \Theta_{k,i}^{(l+1)} \Bigg] a_i^{(l)} (1 - a_i^{(l)}) \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Big[\delta^{(l+1)}_k \Theta_{k,i}^{(l+1)} \Big] a_i^{(l)} (1 - a_i^{(l)})\end{split}$$<p>å¯çŸ¥ï¼Œ<strong>æƒ…å†µ1</strong>çš„è¯¯å·®ä¸ºï¼š</p>$$\begin{split}\delta^{(L)}_i =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \newline  =&amp; \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} a_i^{(L)} (1 - a_i^{(L)}) \newline  =&amp; a_i^{(L)} - y_i\end{split}$$<p>æœ€ç»ˆçš„ä»£ä»·å‡½æ•°çš„åå¯¼ä¸ºï¼š</p>$$\begin{split}\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta) =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} \newline  =&amp; \delta^{(l)}_i \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} \newline  =&amp; \delta^{(l)}_i a_j^{(l-1)} \end{split}$$<p>æˆ‘ä»¬å‘ç°ï¼Œå¼•å…¥è¯¯å·® $\delta^{(l)}_i$ åï¼Œè¿™ä¸ªå…¬å¼å¯ä»¥é€šç”¨äº<strong>æƒ…å†µ1</strong>å’Œ<strong>æƒ…å†µ2</strong>ã€‚</p><p>å¯ä»¥çœ‹å‡ºï¼Œå½“å‰å±‚çš„ä»£ä»·å‡½æ•°åå¯¼ï¼Œéœ€è¦ä¾èµ–äºåä¸€å±‚çš„è®¡ç®—ç»“æœã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆè¿™ä¸ªç®—æ³•çš„åç§°å«åšâ€œåå‘ä¼ æ’­ç®—æ³•â€ã€‚</p><h3 id="4-æ€»ç»“ç®—æ³•å…¬å¼"><a href="#4-æ€»ç»“ç®—æ³•å…¬å¼" class="headerlink" title="4. æ€»ç»“ç®—æ³•å…¬å¼"></a>4. æ€»ç»“ç®—æ³•å…¬å¼</h3><ul><li>è¾“å‡ºå±‚è¯¯å·®</li></ul><p>$$\delta^{(L)}_i = a_i^{(L)} - y_i$$</p><ul><li><p>éšè—å±‚è¯¯å·®ï¼ˆåå‘ä¼ æ’­è®¡ç®—ï¼‰</p>$$\delta^{(l)}_i = \sum_{k=1}^{s_{(l+1)}} \Big[\delta^{(l+1)}_k \Theta_{k,i}^{(l+1)} \Big] a_i^{(l)} (1 - a_i^{(l)})$$</li><li><p>ä»£ä»·å‡½æ•°åå¯¼è®¡ç®—ï¼ˆé€šç”¨ï¼‰</p></li></ul><p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta) = \delta^{(l)}_i a_j^{(l-1)}$$</p><hr><h2 id="ä¸‰-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹"><a href="#ä¸‰-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹" class="headerlink" title="ä¸‰. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹"></a>ä¸‰. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_2_.png" alt=""></p><p>æœ‰äº†ä¸Šè¿°æ¨å¯¼ï¼Œæˆ‘ä»¬æè¿°ä¸€ä¸‹ç®—æ³•å…·ä½“çš„æ“ä½œæµç¨‹ï¼š</p><ul><li>è¾“å…¥ï¼šè¾“å…¥æ ·æœ¬æ•°æ®ï¼Œåˆå§‹åŒ–æƒå€¼å‚æ•°ï¼ˆå»ºè®®éšæœºç”Ÿæˆè¾ƒå°çš„æ•°ï¼‰ã€‚</li><li>å‰é¦ˆï¼šè®¡ç®—å„å±‚ï¼ˆ$l=2, 3, â€¦, L$ï¼‰å„èŠ‚ç‚¹çš„è®¡ç®—å€¼ï¼ˆ$z^{(l)}=\Theta^{(l-1)}a^{(l-1)}$ï¼‰å’Œæ¿€æ´»å€¼ï¼ˆ$a^{(l)}=g(z^{(l)})$ï¼‰ã€‚</li><li>è¾“å‡ºå±‚è¯¯å·®ï¼šè®¡ç®—è¾“å‡ºå±‚è¯¯å·®<script type="math/tex">\delta^{(L)}</script>ï¼ˆå…¬å¼è§å‰æ–‡ï¼‰ã€‚</li><li>åå‘ä¼ æ’­è¯¯å·®ï¼šè®¡ç®—å„å±‚ï¼ˆ$l=L-1, L-2, â€¦, 2$ï¼‰çš„è¯¯å·® $\delta^{(l)}$ï¼ˆå…¬å¼è§å‰æ–‡ï¼‰ã€‚</li><li>è¾“å‡ºï¼šå¾—åˆ°ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ $\nabla F(\Theta)$ï¼ˆå‚è€ƒå‰æ–‡åå¯¼è®¡ç®—å…¬å¼ï¼‰ã€‚</li></ul><p>åå‘ä¼ æ’­ç®—æ³•å¸®åŠ©æˆ‘ä»¬å¾—åˆ°äº†ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±å¯ä»¥å€ŸåŠ©æ¢¯åº¦ä¸‹é™æ³•è®­ç»ƒç¥ç»ç½‘ç»œäº†ã€‚</p><p>$$\Theta := \Theta - \alpha  \nabla F(\Theta)$$</p><p>$\alpha $ ä¸ºå­¦ä¹ é€Ÿç‡ã€‚</p><hr><h2 id="å››-Backpropagation-Algorithm-implementation-ç®—æ³•å®ç°"><a href="#å››-Backpropagation-Algorithm-implementation-ç®—æ³•å®ç°" class="headerlink" title="å››. Backpropagation Algorithm implementation ç®—æ³•å®ç°"></a>å››. Backpropagation Algorithm implementation ç®—æ³•å®ç°</h2><p>ä»¥3å±‚ç¥ç»ç½‘ç»œï¼ˆè¾“å…¥å±‚ã€éšå±‚ã€è¾“å‡ºå±‚å„ä¸€ï¼‰ä¸ºä¾‹ã€‚</p><ul><li>X ä¸ºå¤§å°ä¸ºæ ·æœ¬æ•°âˆ—ç‰¹å¾æ•°çš„æ ·æœ¬ç‰¹å¾çŸ©é˜µ</li><li>Y ä¸ºå¤§å°ä¸ºæ ·æœ¬æ•°âˆ—è¾“å‡ºèŠ‚ç‚¹æ•°çš„æ ·æœ¬ç±»åˆ«ï¼ˆç»“æœï¼‰çŸ©é˜µ</li><li>Theta1 ä¸ºè¾“å…¥å±‚â†’éšå±‚çš„æƒå€¼çŸ©é˜µ</li><li>Theta2 ä¸ºéšè—å±‚â†’è¾“å‡ºå±‚çš„æƒå€¼çŸ©é˜µ</li><li>m ä¸ºæ ·æœ¬æ•°</li><li>K ä¸ºè¾“å‡ºå±‚èŠ‚ç‚¹æ•°</li><li>H ä¸ºéšè—å±‚èŠ‚ç‚¹æ•°</li><li>sigmoid å‡½æ•°å³é€»è¾‘å‡½æ•°ï¼ˆSå‹å‡½æ•°ï¼ŒSigmoidå‡½æ•°ï¼‰</li><li>sigmoidGradient å‡½æ•°å³ Sigmoid å‡½æ•°çš„å¯¼å‡½æ•°</li><li>ä»£ç å®ç°ä¸­ï¼Œè€ƒè™‘äº†æ­£è§„åŒ–ï¼Œé¿å…å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li></ul><h3 id="1-å‰é¦ˆé˜¶æ®µ"><a href="#1-å‰é¦ˆé˜¶æ®µ" class="headerlink" title="1. å‰é¦ˆé˜¶æ®µ"></a>1. å‰é¦ˆé˜¶æ®µ</h3><p>é€å±‚è®¡ç®—å„èŠ‚ç‚¹å€¼å’Œæ¿€æ´»å€¼ã€‚</p><pre class=" language-c"><code class="language-c">a1 <span class="token operator">=</span> X<span class="token punctuation">;</span>z2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a1<span class="token punctuation">]</span> <span class="token operator">*</span> Theta1'<span class="token punctuation">;</span>a2 <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z2<span class="token punctuation">)</span><span class="token punctuation">;</span>z3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a2<span class="token punctuation">]</span> <span class="token operator">*</span> Theta2'<span class="token punctuation">;</span>a3 <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z3<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="2-ä»£ä»·å‡½æ•°"><a href="#2-ä»£ä»·å‡½æ•°" class="headerlink" title="2. ä»£ä»·å‡½æ•°"></a>2. ä»£ä»·å‡½æ•°</h3><p>æ­£è§„åŒ–éƒ¨åˆ†éœ€æ³¨æ„ä»£ä»·å‡½æ•°ä¸æƒ©ç½šåç§»å‚æ•°ï¼Œå³ $\Theta_{i,0}$ï¼ˆä»£ç è¡¨ç¤ºä¸º $Theta(:,1)$ï¼‰ã€‚</p><pre class=" language-c"><code class="language-c">F <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token function">log</span><span class="token punctuation">(</span>a3<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> Y <span class="token operator">-</span> <span class="token function">log</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token punctuation">.</span><span class="token operator">-</span> a3<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> # ä»£ä»·éƒ¨åˆ† lambda <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">^</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">^</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  # æ­£è§„åŒ–éƒ¨åˆ†ï¼Œlambdaä¸ºæ­£è§„å‚æ•°ï¼Œéœ€é™¤å»åç§»å‚æ•°Theta<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><h3 id="3-åå‘ä¼ æ’­-1"><a href="#3-åå‘ä¼ æ’­-1" class="headerlink" title="3. åå‘ä¼ æ’­"></a>3. åå‘ä¼ æ’­</h3><p>è¾“å‡ºå±‚è¯¯å·®å’Œ $\Theta^{(2)}$ æ¢¯åº¦è®¡ç®—ï¼Œåå‘ä¼ æ’­è®¡ç®—éšå±‚è¯¯å·®å’Œ $\Theta^{(1)}$ æ¢¯åº¦ã€‚</p><p>ä»éœ€æ³¨æ„æ­£è§„åŒ–æ—¶æ’é™¤åç§»å‚æ•°ï¼Œå¦å¤–æ³¨æ„ä¸ºæ¿€æ´»å€¼è¡¥ä¸€ä¸ªåç§»é‡ $1$ã€‚</p><pre class=" language-c"><code class="language-c">function g <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    g <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token punctuation">.</span><span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> <span class="token function">exp</span><span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>endfunction g <span class="token operator">=</span> <span class="token function">sigmoidGradient</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    g <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>enddelta3 <span class="token operator">=</span> a3 <span class="token operator">-</span> Y<span class="token punctuation">;</span>Theta2_grad <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> delta3' <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a2<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  lambda <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> # æ­£è§„åŒ–éƒ¨åˆ†delta2 <span class="token operator">=</span> <span class="token punctuation">(</span>delta3 <span class="token operator">*</span> Theta2 <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token function">sigmoidGradient</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> z2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>delta2 <span class="token operator">=</span> <span class="token function">delta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">;</span> # åå‘è®¡ç®—å¤šä¸€ä¸ªåç§»å‚æ•°è¯¯å·®ï¼Œé™¤å»Theta1_grad <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span>  delta2' <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a1<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  lambda <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span>H<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> # æ­£è§„åŒ–éƒ¨åˆ†</code></pre><hr><p>æ¨èé˜…è¯»ï¼š</p><p>[Principles of training multi-layer neural network using backpropagation</p><p>](<a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="noopener">http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</a>)</p><p><a href="https://www.zhihu.com/question/27239198" target="_blank" rel="noopener">å¦‚ä½•ç›´è§‚åœ°è§£é‡Š back propagation ç®—æ³•ï¼Ÿ</a></p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.1_Neural_Networks_Representation</title>
      <link href="/2020/02/03/4-1-neural-networks-representation/"/>
      <url>/2020/02/03/4-1-neural-networks-representation/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1.png" alt=""></p><h1 id="4-1-Neural-Networks-Representation"><a href="#4-1-Neural-Networks-Representation" class="headerlink" title="4.1_Neural_Networks_Representation"></a>4.1_Neural_Networks_Representation</h1><h2 id="ä¸€-Motivations"><a href="#ä¸€-Motivations" class="headerlink" title="ä¸€. Motivations"></a>ä¸€. Motivations</h2><p>å‡å¦‚æˆ‘ä»¬ç”¨ä¹‹å‰çš„é€»è¾‘å›å½’è§£å†³ä»¥ä¸‹åˆ†ç±»é—®é¢˜ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_1.png" alt=""></p><p>æˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸ªæœ‰å¾ˆå¤šé¡¹çš„éçº¿æ€§çš„é€»è¾‘å›å½’å‡½æ•°ã€‚å½“åªæœ‰ä¸¤ä¸ªç‰¹å¾é‡çš„æ—¶å€™ï¼Œè¿™è¿˜ç®—æ¯”è¾ƒç®€å•çš„ï¼Œä½†æ˜¯å‡å¦‚æˆ‘ä»¬æœ‰100ä¸ªç‰¹å¾é‡å‘¢ï¼Ÿæˆ‘ä»¬åªè€ƒè™‘äºŒé˜¶é¡¹çš„è¯ï¼Œå…¶äºŒé˜¶é¡¹çš„ä¸ªæ•°å¤§çº¦æ˜¯ $\frac{n^2}{2}$ ã€‚å‡å¦‚æˆ‘ä»¬è¦åŒ…å«æ‰€æœ‰çš„äºŒé˜¶é¡¹çš„è¯è¿™æ ·çœ‹èµ·æ¥ä¸æ˜¯ä¸€ä¸ªå¥½åŠæ³•ï¼Œå› ä¸ºé¡¹æ•°å®åœ¨å¤ªå¤šè¿ç®—é‡ä¹Ÿå¾ˆå¤šï¼Œè€Œä¸”æœ€åç»“æœå¾€å¾€å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆã€‚å½“ç„¶æˆ‘ä»¬åªæ˜¯è€ƒè™‘äº†äºŒé˜¶é¡¹ï¼Œè€ƒè™‘äºŒé˜¶é¡¹ä»¥ä¸Šçš„å°±æ›´å¤šäº†ã€‚</p><p>å½“åˆå§‹ç‰¹å¾ä¸ªæ•° n å¢å¤§æ—¶ï¼Œè¿™äº›é«˜é˜¶å¤šé¡¹å¼é¡¹æ•°å°†ä»¥å‡ ä½•çº§æ•°ä¸Šå‡ï¼Œç‰¹å¾ç©ºé—´ä¹Ÿä¼šéšä¹‹æ€¥å‰§è†¨èƒ€ ã€‚æ‰€ä»¥å½“ç‰¹å¾ä¸ªæ•° næ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œç”¨è¿™ä¸ªæ–¹æ³•å»ºç«‹åˆ†ç±»å™¨å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½çš„åšæ³•ã€‚</p><p>è€Œå¯¹äºå¤§å¤šæ•°çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œ n  ä¸€èˆ¬æ˜¯æ¯”è¾ƒå¤§çš„ã€‚</p><p>å¯¹ä¸€ä¸ªæ‹¥æœ‰å¾ˆå¤šç‰¹å¾çš„å¤æ‚æ•°æ®é›†è¿›è¡Œçº¿æ€§å›å½’æ˜¯ä»£ä»·å¾ˆé«˜çš„ã€‚æ¯”å¦‚æˆ‘ä»¬å¯¹ 50 * 50 åƒç´ çš„é»‘ç™½å›¾åˆ†ç±»ï¼Œæˆ‘ä»¬å°±æ‹¥æœ‰äº† 2500 ä¸ªç‰¹å¾ã€‚å¦‚æœæˆ‘ä»¬è¿˜è¦åŒ…å«æ‰€æœ‰äºŒæ¬¡ç‰¹å¾ï¼Œå¤æ‚åº¦ä¸º $O(n^{2}/2)$ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€å…±è¦æœ‰ $2500^{2}/2=3125000$ ä¸ªç‰¹å¾ã€‚è¿™æ ·è®¡ç®—çš„ä»£ä»·æ˜¯é«˜æ˜‚çš„ã€‚</p><p>äººå·¥ç¥ç»ç½‘ç»œæ˜¯å¯¹å…·æœ‰å¾ˆå¤šç‰¹å¾çš„å¤æ‚é—®é¢˜è¿›è¡Œæœºå™¨å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ã€‚</p><hr><h2 id="äºŒ-Neural-Networks"><a href="#äºŒ-Neural-Networks" class="headerlink" title="äºŒ. Neural Networks"></a>äºŒ. Neural Networks</h2><p>äººå·¥ç¥ç»ç½‘ç»œæ˜¯å¯¹ç”Ÿç‰©ç¥ç»ç½‘ç»œçš„ä¸€ç§ç®€åŒ–çš„æ¨¡æ‹Ÿã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å…ˆä»ç”Ÿç‰©ä¸­çš„ç¥ç»å…ƒå…¥æ‰‹ï¼Œè¿›è€Œäº†è§£ç¥ç»ç½‘ç»œçš„å·¥ä½œæ–¹å¼ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_6.svg" alt=""></p><p>ç”¨ä¸€ä¸ªç®€å•çš„æ¨¡å‹æ¥æ¨¡æ‹Ÿç¥ç»å…ƒçš„å·¥ä½œï¼Œæˆ‘ä»¬å°†ç¥ç»å…ƒæ¨¡æ‹Ÿæˆä¸€ä¸ªé€»è¾‘å•å…ƒï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_2.png" alt=""></p><p>$x_{1},x_{2},x_{3}$ å¯ä»¥å°†å…¶çœ‹æˆè¾“å…¥ç¥ç»æ ‘çªï¼Œé»„è‰²çš„åœ†åœˆåˆ™å¯ä»¥çœ‹æˆä¸­å¿ƒå¤„ç†å™¨ç»†èƒæ ¸ï¼Œ $h_\theta(x)$ åˆ™å¯çœ‹æˆè¾“å‡ºç¥ç»è½´çªã€‚å› ä¸ºè¿™é‡Œæ˜¯é€»è¾‘å•å…ƒï¼Œæ‰€ä»¥æˆ‘ä»¬çš„è¾“å‡ºå‡½æ•°ä¸ºï¼š $h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$ ã€‚ä¸€èˆ¬æˆ‘ä»¬æŠŠè¿™ç§°ä¸ºä¸€ä¸ªæœ‰ s å‹å‡½æ•°ï¼ˆé€»è¾‘å‡½æ•°ï¼‰ä½œä¸ºæ¿€åŠ±çš„äººå·¥ç¥ç»å…ƒã€‚</p><p>é‚£ä¹ˆç¥ç»ç½‘ç»œå…¶å®å°±æ˜¯è¿™äº›ç¥ç»å…ƒç»„åˆåœ¨ä¸€èµ·çš„é›†åˆï¼Œå¦‚ä¸‹å›¾ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_2.png" alt=""></p><p>å·¦è¾¹ç¬¬ä¸€å±‚ Layer1 è¢«ç§°ä¸º<strong>è¾“å…¥å±‚</strong>ã€‚åœ¨è¾“å…¥å±‚æˆ‘ä»¬è¾“å…¥æˆ‘ä»¬çš„ç‰¹å¾é¡¹ $x_{1},x_{2},x_{3}$ ã€‚</p><p>å³è¾¹æœ€åä¸€å±‚è¢«ç§°ä¸º<strong>è¾“å‡ºå±‚</strong>ã€‚è¾“å‡ºå‡½æ•°ä¸ºï¼š $h_\Theta(x)$ ã€‚</p><p>ä¸­é—´è¿™å±‚è¢«ç§°ä¸º<strong>éšè—å±‚</strong>ã€‚</p><p>æˆ‘ä»¬ç°åœ¨è¦è®¡ç®—å½“å‰ç¥ç»å…ƒçš„å€¼ï¼Œåœ¨å½“å‰ç¥ç»å…ƒæ‰€åœ¨å±‚çš„å‰ä¸€å±‚ï¼Œæœ‰å¾ˆå¤šä¸ªçªè§¦å‰ç¥ç»å…ƒï¼ˆå½“å‰ç¥ç»å…ƒä¹Ÿæ˜¯ç›¸å¯¹äºä»–ä»¬çš„çªè§¦åç¥ç»å…ƒï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_7.png" alt=""></p><p>å¯¹äºå‰ä¸€å±‚çš„æ¯ä¸€ä¸ªçªè§¦å‰ç¥ç»å…ƒï¼Œéƒ½æœ‰ä¸€ä¸ªè¾“å‡ºå€¼ï¼Œä½œä¸ºå½“å‰ç¥ç»å…ƒçš„è¾“å…¥å€¼ï¼Œç»è¿‡è½´çªä¼ é€’åˆ°å½“å‰ç¥ç»å…ƒã€‚å½“ç„¶ï¼Œå¦‚æœæ˜¯ç¬¬ä¸€å±‚ç¥ç»å…ƒï¼Œåˆ™ç›´æ¥ä»è¾“å…¥æ ·æœ¬æ•°æ®ä¸­æ¥å—åˆºæ¿€ï¼ˆå¯¹åº”å›¾ä¸­çš„ $x_{i}$ï¼‰ã€‚</p><p>è½´çªå…·æœ‰æƒå€¼ï¼ˆå¯¹åº”å›¾ä¸­çš„æƒå€¼ weights åˆ—ï¼š$w_{ij}$ï¼‰ï¼Œå¯¹æ¯ä¸€ä¸ªè¾“å‡ºå€¼åŠ æƒæ±‚å’Œï¼Œå¾—åˆ°è¯¥ç¥ç»å…ƒçš„è¾“å…¥å€¼ã€‚è¿™ä¸ªåŠ æƒæ±‚å’Œå¯¹åº”å›¾ä¸­çš„transfer functionï¼ˆè½¬ç§»å‡½æ•°ï¼‰ï¼Œä½†è¿™ä¸ªå‡½æ•°çš„åç§°å¹¶ä¸æ˜ç¡®ï¼Œæœ‰äººæŠŠå®ƒç§°ä½œæ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰ï¼Œä¸åŒçš„äººå¯èƒ½æœ‰ä¸åŒçš„å«æ³•ï¼Œè¿™é‡Œä»…ä¾›å‚è€ƒã€‚</p><p>å¾—åˆ°äº†è¯¥ç¥ç»å…ƒçš„å€¼ï¼Œå°±è¦åˆ¤å®šè¯¥ç¥ç»å…ƒæ˜¯å¦æ¿€æ´»å…´å¥‹ã€‚è¿™å¯¹åº”äºå›¾ä¸­çš„activation functionï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ï¼Œä½†ä¹Ÿæœ‰äººå°†è¿™ä¸ªå‡½æ•°å«åšè¾“å‡ºå‡½æ•°ï¼ˆoutput functionï¼‰ï¼Œè€ŒæŠŠå‰é¢è¯´çš„é‚£ä¸€éƒ¨åˆ†å«åšæ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰ï¼Œå¹¶æŠŠè¿™ä¸¤éƒ¨åˆ†åˆç§°ä¸ºè½¬ç§»å‡½æ•°ï¼ˆtransfer functionï¼‰ã€‚</p><p>æœ‰å‡ ç§å‡½æ•°å¯ä»¥ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼š</p><ul><li>é˜¶è·ƒå‡½æ•°ã€‚è¿™æ˜¯æœ€ç®€å•ç›´æ¥çš„å½¢å¼ï¼Œä¹Ÿæ˜¯äººå·¥ç¥ç»ç½‘ç»œå®šä¹‰æ—¶ä¸€èˆ¬é‡‡ç”¨çš„ã€‚</li><li>é€»è¾‘å‡½æ•°ã€‚å°±æ˜¯Så‹å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰ï¼Œå…·æœ‰å¯æ— é™å¾®åˆ†çš„ä¼˜åŠ¿ã€‚</li><li>æ–œå¡å‡½æ•°</li><li>é«˜æ–¯å‡½æ•°</li><li>â€¦</li></ul><p>å¯ä»¥æ³¨æ„åˆ°å›¾ä¸­çš„thresholdï¼ˆé˜ˆå€¼ï¼‰ï¼Œ$\theta_{j}$ï¼Œå³æ¿€æ´»é˜ˆå€¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä»…å½“ç¥ç»å…ƒçš„å€¼å¤§äºè¿™ä¸ªé˜ˆå€¼æ—¶ï¼Œè¯¥ç¥ç»å…ƒæ¿€æ´»å…´å¥‹ï¼Œè¾“å‡º1ï¼›å¦åˆ™æ— æ³•æ¿€æ´»ï¼Œè¾“å‡º0ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_3.png" alt=""></p><p>å…¶ä¸­éšè—å±‚ä¸­çš„å…ƒç´ æˆ‘ä»¬ç”¨ $a_i^{(j)}$ è¡¨ç¤ºã€‚ä¸Šæ ‡ j è¡¨ç¤ºçš„æ˜¯ç¬¬å‡ å±‚ï¼ˆæœ‰æ—¶å€™æˆ‘ä»¬å¹¶ä¸åªæœ‰ç®€å•ä¸€å±‚ï¼‰ï¼Œä¸‹æ ‡ i è¡¨ç¤ºç¬¬å‡ ä¸ªï¼Œ<strong>ç¬¬jå±‚çš„ç¬¬iä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œæ¿€æ´»å€¼â€</strong>ã€‚</p><p>ä¸Šé¢çš„ç¥ç»ç½‘ç»œå¯ä»¥ç®€å•çš„è¡¨ç¤ºä¸ºï¼š</p><p>$$\begin{bmatrix} x_{0}\ x_{1}\ x_{2}\ x_{3} \end{bmatrix} \rightarrow \begin{bmatrix} a_{1}^{(2)}\ a_{2}^{(2)}\ a_{3}^{(2)} \end{bmatrix} \rightarrow h_{\theta}(x) $$</p><p>å·¦è¾¹è¾“å…¥å±‚å¤šå¢åŠ äº†ä¸€ä¸ªåç½®å•å…ƒ(åç½®ç¥ç»å…ƒ)ï¼Œ$x_{0}$</p><p>ç”¨ $\Theta^{(j)}$ è¡¨ç¤ºç‰¹å¾é‡å‰çš„å‚æ•°ï¼Œæ˜¯ä¸€ä¸ªæœ‰æƒé‡çš„çŸ©é˜µæ§åˆ¶ç€ä¸€å±‚å‚æ•°çš„å¤§å°ï¼Œ<strong>æ˜ å°„ç¬¬jå±‚åˆ°ç¬¬j+1å±‚çš„æƒå€¼çŸ©é˜µ</strong>ã€‚</p><p>ä¸Šè¿°çš„ç¥ç»ç½‘ç»œå¯ç”¨æ•°å­¦è¡¨è¾¾ï¼Œå¦‚ä¸‹ï¼š</p>$$\begin{align*}a_{1}^{(2)} &amp;= g(\Theta_{10}^{(1)}x_{0}+\Theta_{11}^{(1)}x_{1}+\Theta_{12}^{(1)}x_{2}+\Theta_{13}^{(1)}x_{3}) \\a_{2}^{(2)} &amp;= g(\Theta_{20}^{(1)}x_{0}+\Theta_{21}^{(1)}x_{1}+\Theta_{22}^{(1)}x_{2}+\Theta_{23}^{(1)}x_{3}) \\a_{3}^{(2)} &amp;= g(\Theta_{30}^{(1)}x_{0}+\Theta_{31}^{(1)}x_{1}+\Theta_{32}^{(1)}x_{2}+\Theta_{33}^{(1)}x_{3}) \\h_{\Theta}(x) &amp;= a_{1}^{(3)} = g(\Theta_{10}^{(2)}a_{0}^{(2)}+\Theta_{11}^{(2)}a_{1}^{(2)}+\Theta_{12}^{(2)}a_{2}^{(2)}+\Theta_{13}^{(2)}a_{3}^{(2)}) \\\end{align*}$$<p>$\Theta$ çŸ©é˜µä¹Ÿè¢«ç§°ä½œä¸ºæ¨¡å‹çš„æƒé‡ã€‚è¿™é‡Œçš„ $g(x)$ éƒ½æ˜¯ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå³ $g(x) = \frac{1}{1+e^{-x}}$</p><p>å¯¹ä¸Šé¢çš„ç¥ç»ç½‘ç»œæ•°å­¦è¡¨è¾¾æ–¹å¼è¿›è¡Œå‘é‡åŒ–æ¨å¯¼ï¼Œä»¤ï¼š</p>$$\begin{align*}z_{1}^{(2)} &amp;= \Theta_{10}^{(1)}x_{0}+\Theta_{11}^{(1)}x_{1}+\Theta_{12}^{(1)}x_{2}+\Theta_{13}^{(1)}x_{3} \\z_{2}^{(2)} &amp;= \Theta_{20}^{(1)}x_{0}+\Theta_{21}^{(1)}x_{1}+\Theta_{22}^{(1)}x_{2}+\Theta_{23}^{(1)}x_{3} \\z_{3}^{(2)} &amp;= \Theta_{30}^{(1)}x_{0}+\Theta_{31}^{(1)}x_{1}+\Theta_{32}^{(1)}x_{2}+\Theta_{33}^{(1)}x_{3} \\\vdots \\z_{k}^{(2)} &amp;= \Theta_{k,0}^{(1)}x_{0}+\Theta_{k,1}^{(1)}x_{1}+\Theta_{k,2}^{(1)}x_{2}+\Theta_{k,3}^{(1)}x_{3} \\\end{align*}$$<p>äºæ˜¯å¯ä»¥å¾—åˆ°ï¼š</p>$$\begin{align*}a_{1}^{(2)} &amp;= g(z_{1}^{(2)}) \\a_{2}^{(2)} &amp;= g(z_{2}^{(2)}) \\a_{3}^{(2)} &amp;= g(z_{3}^{(2)}) \\\end{align*}$$<p>ç”¨å‘é‡å³å¯è¡¨ç¤ºä¸ºï¼š</p>$$x = \begin{bmatrix}x_{0}\\ x_{1}\\ x_{2}\\ x_{3}\end{bmatrix},z^{(2)} = \begin{bmatrix}z_{1}^{(2)}\\ z_{2}^{(2)}\\ z_{3}^{(2)}\\ \end{bmatrix} = \Theta^{(1)}x$${% raw %}ç»Ÿä¸€ä¸€ä¸‹å‰åä¸¤å±‚çš„è¾“å…¥è¾“å‡ºå…³ç³»ï¼Œå°† $x=a^{(1)}$ï¼Œå³å¯å¾—åˆ°ï¼š{% raw %}$$\begin{align*}x &amp;= \begin{bmatrix}x_{0}\\ x_{1}\\ \vdots \\ x_{n}\end{bmatrix},z^{(j)} = \begin{bmatrix}z_{1}^{(j)}\\ z_{2}^{(j)}\\\vdots \\ z_{3}^{(j)}\\ \end{bmatrix}, \\ \Rightarrow  z^{(j)} &amp;=\Theta^{(j-1)}a^{(j-1)}\\\end{align*}$${% endraw %}<p>è¿™é‡Œä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªç»“è®ºï¼š</p><p>å‡å¦‚ä¸€ä¸ªç½‘ç»œé‡Œé¢åœ¨ç¬¬ j  å±‚æœ‰ $s_j$ ä¸ªå•å…ƒï¼Œåœ¨ç¬¬ j+1 å±‚æœ‰ $s_{j+1}$ ä¸ªå•å…ƒï¼Œé‚£ä¹ˆ $\Theta^{(j)}$ åˆ™æ§åˆ¶ç€ç¬¬ j å±‚åˆ°ç¬¬ j+1 å±‚çš„æ˜ å°„çŸ©é˜µï¼ŒçŸ©é˜µçš„ç»´åº¦æ˜¯ï¼š $s_{j+1} * (s_j + 1)$ ã€‚(ä¾‹å¦‚ï¼š j=1 , $s_j=1$ï¼Œ $s_{j+1}$=1 ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬ä¸€å±‚åªæœ‰ä¸€ä¸ªå•å…ƒï¼Œç¬¬äºŒå±‚ä¹Ÿåªæœ‰ä¸€ä¸ªå•å…ƒï¼Œé‚£ä¹ˆ $\Theta^{(1)}$ çŸ©é˜µç»´åº¦å°±æ˜¯ 1 * 2 ,å› ä¸ºè¦ç®—ä¸Šåç½®å•å…ƒ)</p><p>å› ä¸ºæˆ‘ä»¬é€šå¸¸æœ‰ $a_0^{(j)}=1$ ï¼Œæ‰€ä»¥ï¼š</p>{% raw %}$$\begin{align*}a^{(j)}&amp;=g(z^{(j)})\\z^{(j+1)}&amp;=\Theta^{(j)}a^{(j)}\\h_\Theta(x)&amp;=a^{(j+1)}=g(z^{(j+1)})\\\end{align*}$${% endraw %}<p>ç”±è¿™ä¸ªå…³ç³»å…¶å®å¯ä»¥çœ‹å‡ºï¼Œç¥ç»ç½‘ç»œè·Ÿä¹‹å‰æ‰€å­¦çš„é€»è¾‘å›å½’æ ¹æœ¬åŒºåˆ«åœ¨äºï¼Œå®ƒæ˜¯å°†ä¸Šä¸€å±‚çš„è¾“å‡ºå½“åšä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œè¿™ä¸ªä»è¾“å…¥å±‚åˆ°éšè—å±‚å†åˆ°è¾“å‡ºå±‚ä¸€æ¬¡è®¡ç®—æ¿€åŠ±çš„è¿‡ç¨‹å«åš <strong>forward propagationï¼ˆå‰å‘ä¼ æ’­ï¼‰</strong>ã€‚</p><hr><h2 id="ä¸‰-Applications"><a href="#ä¸‰-Applications" class="headerlink" title="ä¸‰. Applications"></a>ä¸‰. Applications</h2><h3 id="1-é€»è¾‘è¿ç®—"><a href="#1-é€»è¾‘è¿ç®—" class="headerlink" title="1. é€»è¾‘è¿ç®—"></a>1. é€»è¾‘è¿ç®—</h3><p>åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œ é€»è¾‘ä¸è¿ç®—</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_4.png" alt=""></p><p>åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œ é€»è¾‘éè¿ç®—</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_3.png" alt=""></p><p>ä½†æ˜¯å•ä¸€ä¸€å±‚æ— æ³•å®Œæˆå¼‚æˆ–è¿ç®—ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_4.png" alt=""></p><p>å¼‚æˆ–åœ¨å‡ ä½•ä¸Šçš„é—®é¢˜å…¶å®æ˜¯å°†çº¢å‰å’Œè“åœˆåˆ†å¼€ï¼Œä½†æ˜¯æˆ‘ä»¬çš„è¾“å‡ºå‡½æ•°æ˜¯ï¼š $h_\Theta(x)=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2)$ ,è¿™æ˜¯çº¿æ€§çš„ï¼Œé‚£ä¹ˆåœ¨å›¾ä¸Šæ— è®ºæ€ä¹ˆç”»ä¸€æ¡ç›´çº¿ï¼Œä¹Ÿæ²¡æœ‰åŠæ³•å°†ä¸¤ä¸ªä¸åŒçš„è®­ç»ƒé›†åˆ†å¼€ã€‚æ—¢ç„¶ä¸€æ¡ç›´çº¿ä¸è¡Œï¼Œé‚£ä¹ˆç¥ç»ç½‘ç»œå¢åŠ ä¸€å±‚ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_5.png" alt=""></p><p>å¦‚ä¸Šå›¾ï¼Œå°†ç¬¬äºŒå±‚ç¬¬ä¸€ä¸ªå…ƒç´  $a_1^{(2)}$ ä½œä¸ºä¸è¿ç®—çš„ç»“æœï¼Œç¬¬äºŒä¸ªå…ƒç´  $a_2^{(2)}$ ä½œä¸ºæˆ–éè¿ç®—çš„ç»“æœï¼Œ $a_1^{(2)}$ å’Œ $a_2^{(2)}$ å†ä½œä¸ºè¾“å…¥ï¼Œè¿›è¡Œæˆ–è¿ç®—ï¼Œä½œä¸ºç¬¬ä¸‰å±‚è¾“å‡ºçš„ç»“æœï¼Œæœ€åå¾—åˆ°çš„ç»“æœä¸è¾“å…¥çš„å…³ç³»æ­£æ˜¯å¼‚æˆ–è¿ç®—çš„å…³ç³»ã€‚</p><h3 id="2-æœ¬è´¨"><a href="#2-æœ¬è´¨" class="headerlink" title="2. æœ¬è´¨"></a>2. æœ¬è´¨</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_5.png" alt=""></p><p>ç¥ç»ç½‘ç»œæ­£æ˜¯è¿™æ ·è§£å†³æ¯”è¾ƒå¤æ‚çš„å‡½æ•°ï¼Œå½“å±‚æ•°å¾ˆå¤šçš„æ—¶å€™ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªç›¸å¯¹ç®€å•çš„è¾“å…¥é‡ï¼Œé€šè¿‡åŠ ä»¥æƒé‡å’Œä¸åŒçš„è¿ç®—é€åˆ°ç¬¬äºŒå±‚ï¼Œè€Œç¬¬ä¸‰å±‚åœ¨ç¬¬äºŒå±‚ä½œä¸ºè¾“å…¥çš„åŸºç¡€ä¸Šå†æ¥è¿›è¡Œä¸€äº›æ›´å¤æ‚çš„è¿ç®—ï¼Œä¸€å±‚ä¸€å±‚ä¸‹å»è§£å†³é—®é¢˜ã€‚</p><hr><h2 id="å››-Neural-Networks-Representation-æµ‹è¯•"><a href="#å››-Neural-Networks-Representation-æµ‹è¯•" class="headerlink" title="å››. Neural Networks: Representation æµ‹è¯•"></a>å››. Neural Networks: Representation æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you have a multi-class classification problem with three classes, trained with a 3 layer network. Let a(3)1=(hÎ˜(x))1 be the activation of the first output unit, and similarly a(3)2=(hÎ˜(x))2 and a(3)3=(hÎ˜(x))3. Then for any input x, it must be the case that a(3)1+a(3)2+a(3)3=1.</p><p>B. The activation values of the hidden units in a neural network, with the sigmoid activation function applied at every layer, are always in the range (0, 1).</p><p>C. A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function.</p><p>D. Any logical function over binary-valued (0 or 1) inputs x1 and x2 can be (approximately) represented using some neural network.</p><p>è§£ç­”ï¼š Bã€D</p><p>B.Så‹å‡½æ•°ä½œä¸ºåˆ¤æ–­å‡½æ•°è¿ç”¨åˆ°æ¯ä¸€å±‚ï¼Œå…¶èŒƒå›´æ˜¯[0,1]ï¼Œæ­£ç¡®ã€‚<br>D.ä»»ä½•äºŒè¿›åˆ¶è¾“å…¥çš„é€»è¾‘è¿ç®—éƒ½å¯ä»¥ç¥ç»ç½‘ç»œè§£å†³ï¼Œæ­£ç¡®ã€‚<br>C.å¼‚æˆ–ä¸å¯ä»¥ç”¨ä¸€å±‚ç¥ç»ç½‘ç»œè§£å†³ã€‚<br>A.ä¸ä¸€å®šï¼Œå†³ç­–å‡½æ•°ä¸æ˜¯Så‹å‡½æ•°çš„è¯æœ€åç»“æœç›¸åŠ å°±ä¸æ˜¯1äº†ã€‚   </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.2_Regularization</title>
      <link href="/2020/02/03/3-2-regularization/"/>
      <url>/2020/02/03/3-2-regularization/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-756b3fa02ecf03db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h1 id="3-2-Regularization"><a href="#3-2-Regularization" class="headerlink" title="3.2_Regularization"></a>3.2_Regularization</h1><h2 id="ä¸€-Solving-the-Problem-of-Overfitting"><a href="#ä¸€-Solving-the-Problem-of-Overfitting" class="headerlink" title="ä¸€. Solving the Problem of Overfitting"></a>ä¸€. Solving the Problem of Overfitting</h2><p>è€ƒè™‘ä» $x \in \mathbb{R}$ é¢„æµ‹ y çš„é—®é¢˜ã€‚ä¸‹é¢æœ€å·¦è¾¹çš„å›¾æ˜¾ç¤ºäº†å°† $y =\theta_{0}+\theta_{1}x$ æ‹Ÿåˆåˆ°æ•°æ®é›†çš„ç»“æœã€‚æˆ‘ä»¬çœ‹åˆ°è¿™äº›æ•°æ®å¹¶ä¸æ˜¯ç›´çº¿çš„ï¼Œæ‰€ä»¥è¿™ä¸ªæ•°æ®å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_2.png" alt=""></p><p>ç›¸åï¼Œå¦‚æœæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç‰¹å¾ x2ï¼Œå¹¶ä¸”æ‹Ÿåˆ $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$ï¼Œé‚£ä¹ˆæˆ‘ä»¬è·å¾—çš„æ•°æ®ç¨å¾®æ›´é€‚åˆ,å¦‚ä¸Šå›¾ã€‚</p><p>ä½†æ˜¯å¹¶ä¸æ˜¯æ·»åŠ çš„å¤šé¡¹å¼è¶Šå¤šè¶Šå¥½ã€‚ä½†æ˜¯ï¼Œæ·»åŠ å¤ªå¤šç‰¹å¾ä¹Ÿæ˜¯ä¸€ä¸ªå±é™©ï¼šæœ€å³è¾¹çš„æ•°å­—æ˜¯æ‹Ÿåˆäº”é˜¶å¤šé¡¹å¼ $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ çš„ç»“æœã€‚æˆ‘ä»¬çœ‹åˆ°å³ä½¿æ‹Ÿåˆæ›²çº¿å®Œç¾åœ°ä¼ é€’äº†æ•°æ®ï¼Œæˆ‘ä»¬ä¹Ÿä¸ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é¢„æµ‹ï¼Œä¸Šå›¾æœ€å³è¾¹çš„å›¾å°±æ˜¯è¿‡åº¦æ‹Ÿåˆçš„ä¾‹å­ã€‚</p><p>ä¸Šå›¾æœ€å³è¾¹çš„å›¾ä¹Ÿç§°æœ‰<strong>é«˜æ–¹å·®</strong>ã€‚å¦‚æœæˆ‘ä»¬æ‹Ÿåˆä¸€ä¸ªé«˜é˜¶å¤šé¡¹å¼ï¼Œæœ‰è¿‡åº¦çš„ç‰¹å¾ï¼Œå¹¶ä¸”è¿™ä¸ªå‡è®¾å‡½æ•°èƒ½æ‹Ÿåˆå‡ ä¹æ‰€æœ‰çš„æ•°æ®ï¼Œè¿™å°±é¢ä¸´å¯èƒ½çš„å‡½æ•°å¤ªè¿‡äºåºå¤§ï¼Œå˜é‡å¤ªå¤šçš„é—®é¢˜ã€‚æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®å»çº¦æŸå®ƒï¼Œæ¥è·å¾—ä¸€ä¸ªå¥½çš„å‡è®¾å‡½æ•°ï¼Œè¿™å°±æ˜¯è¿‡åº¦æ‹Ÿåˆã€‚</p><p>æ¬ æ‹Ÿåˆæˆ–é«˜åå€šæ˜¯å½“æˆ‘ä»¬çš„å‡è®¾å‡½æ•°hçš„å½¢å¼å¾ˆéš¾ä¸æ•°æ®çš„è¶‹åŠ¿ä½œå›¾æ—¶ã€‚å®ƒé€šå¸¸æ˜¯ç”±ä¸€ä¸ªåŠŸèƒ½å¤ªç®€å•æˆ–åŠŸèƒ½å¤ªå°‘é€ æˆçš„ã€‚å¦ä¸€æ–¹é¢ï¼Œè¿‡åº¦æ‹Ÿåˆæˆ–é«˜åº¦æ–¹å·®æ˜¯ç”±é€‚åˆç°æœ‰æ•°æ®çš„å‡è®¾å‡½æ•°å¼•èµ·çš„ï¼Œä½†ä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹æ–°æ•°æ®ã€‚å®ƒé€šå¸¸æ˜¯ç”±ä¸€ä¸ªå¤æ‚çš„å‡½æ•°é€ æˆçš„ï¼Œå®ƒä¼šäº§ç”Ÿå¤§é‡ä¸æ•°æ®æ— å…³çš„ä¸å¿…è¦çš„æ›²çº¿å’Œè§’åº¦ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_3.png" alt=""></p><p>è¿™ä¸ªæœ¯è¯­é€‚ç”¨äºçº¿æ€§å’Œé€»è¾‘å›å½’ã€‚è§£å†³è¿‡åº¦é…åˆé—®é¢˜æœ‰ä¸¤ä¸ªä¸»è¦é€‰é¡¹ï¼š</p><h3 id="1-å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š"><a href="#1-å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š" class="headerlink" title="1. å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š"></a>1. å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š</h3><ul><li>æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„ç‰¹å¾ï¼Œå“ªäº›å˜é‡æ›´ä¸ºé‡è¦ï¼Œå“ªäº›å˜é‡åº”è¯¥ä¿ç•™ï¼Œå“ªäº›åº”è¯¥èˆå¼ƒã€‚ </li><li>ä½¿ç”¨æ¨¡å‹é€‰æ‹©ç®—æ³•ï¼ˆç¨ååœ¨è¯¾ç¨‹ä¸­å­¦ä¹ ï¼‰ï¼Œç®—æ³•ä¼šè‡ªåŠ¨é€‰æ‹©å“ªäº›ç‰¹å¾å˜é‡ä¿ç•™ï¼Œå“ªäº›èˆå¼ƒã€‚</li></ul><p>ç¼ºç‚¹æ˜¯èˆå¼ƒäº†ä¸€äº›ç‰¹å¾ä»¥åï¼Œä¹Ÿå°±èˆå¼ƒäº†ä¸€äº›é—®é¢˜çš„å…³é”®ä¿¡æ¯ã€‚</p><h3 id="2-æ­£åˆ™åŒ–"><a href="#2-æ­£åˆ™åŒ–" class="headerlink" title="2. æ­£åˆ™åŒ–"></a>2. æ­£åˆ™åŒ–</h3><ul><li>ä¿ç•™æ‰€æœ‰çš„ç‰¹å¾ï¼Œä½†å‡å°‘å‚æ•° $\theta_{j}$ çš„å¤§å°æˆ–è€…å‡å°‘é‡çº§ã€‚ </li><li>å½“æœ‰å¾ˆå¤šä¸ªç‰¹å¾çš„æ—¶å€™ï¼Œå¹¶ä¸”æ¯ä¸ªç‰¹å¾éƒ½ä¼šå¯¹æœ€ç»ˆé¢„æµ‹å€¼äº§ç”Ÿå½±å“ï¼Œæ­£åˆ™åŒ–å¯ä»¥ä¿è¯è¿ä½œè‰¯å¥½ã€‚</li></ul><p>æ­£åˆ™åŒ–ç›®çš„æ˜¯å°½é‡å»ç®€åŒ–è¿™ä¸ªå‡è®¾æ¨¡å‹ã€‚å› ä¸ºè¿™äº›å‚æ•°éƒ½æ¥è¿‘0çš„æ—¶å€™ï¼Œè¶Šç®€å•çš„æ¨¡å‹ä¹Ÿè¢«è¯æ˜è¶Šä¸å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_4.png" alt=""></p><p>å‡å°‘ä¸€äº›æ•°é‡çº§çš„ç‰¹å¾ï¼ŒåŠ ä¸€äº›â€œæƒ©ç½šâ€é¡¹(ä¸ºäº†ä½¿ä»£ä»·å‡½æ•°æœ€å°ï¼Œä¹˜ä»¥ 1000 å°±æ˜¯æƒ©ç½š)ã€‚</p><p>ä»£ä»·å‡½æ•°ï¼š</p>$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$<p>$\lambda \sum_{i = 1}^{m} \theta_{j}^{2}$ æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œå®ƒç¼©å°æ¯ä¸ªå‚æ•°çš„å€¼ã€‚ $\lambda$ æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼Œ$\lambda$ æ§åˆ¶ä¸¤ä¸ªä¸åŒç›®æ ‡ä¹‹é—´çš„å–èˆï¼Œå³æ›´å¥½çš„å»æ‹Ÿåˆè®­ç»ƒé›†çš„ç›®æ ‡ å’Œ å°†å‚æ•°æ§åˆ¶çš„æ›´å°çš„ç›®æ ‡ï¼Œä»è€Œä¿æŒå‡è®¾æ¨¡å‹çš„ç›¸å¯¹ç®€å•ï¼Œé¿å…å‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚</p><p>ä½†æ˜¯å¦‚æœé€‰æ‹©çš„ $\lambda $ å¤ªå¤§ï¼Œå¯èƒ½ä¼šè¿‡å¤šåœ°æ¶ˆé™¤ç‰¹å¾ï¼Œå¯¼è‡´ $\theta$ éƒ½çº¦ç­‰äº 0 äº†ï¼Œæœ€ç»ˆé¢„æµ‹å‡½æ•°å˜æˆäº†æ°´å¹³ç›´çº¿äº†ã€‚è¿™å°±å˜æˆäº†æ¬ æ‹Ÿåˆçš„ä¾‹å­äº†(åè§æ€§å¤ªå¼ºï¼Œåå·®è¿‡é«˜)ã€‚</p><hr><h2 id="äºŒ-Regularized-Linear-Regression-çº¿æ€§å›å½’æ­£åˆ™åŒ–"><a href="#äºŒ-Regularized-Linear-Regression-çº¿æ€§å›å½’æ­£åˆ™åŒ–" class="headerlink" title="äºŒ. Regularized Linear Regression çº¿æ€§å›å½’æ­£åˆ™åŒ–"></a>äºŒ. Regularized Linear Regression çº¿æ€§å›å½’æ­£åˆ™åŒ–</h2><h3 id="1-Gradient-Descent-çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"><a href="#1-Gradient-Descent-çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–" class="headerlink" title="1. Gradient Descent çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"></a>1. Gradient Descent çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–</h3><p>$$\theta_{0} := \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)}$$</p>$$\theta_{j} := \theta_{j} - \alpha \left [ \left ( \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}\right ) + \frac{\lambda}{m}\theta_{j} \right ]  \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$<p>å°†ä¸Šé¢çš„å¼å­åŒ–ç®€å¾—ï¼š</p>$$\theta_{j} := \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}   \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$<p>åœ¨ä¸Šé¢çš„å¼å­ä¸­ $(1-\alpha \frac{\lambda}{m}) &lt; 1$ æ’å°äº 1ï¼Œçº¦ç­‰äº 1(0.999) ã€‚äºæ˜¯æ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹å°±æ˜¯æ¯æ¬¡æ›´æ–°éƒ½æŠŠå‚æ•°ä¹˜ä»¥ 0.999ï¼Œç¼©å°ä¸€ç‚¹ç‚¹ï¼Œç„¶åå†å‘æœ€å°ç‚¹çš„æ–¹å‘ç§»åŠ¨ä¸€ä¸‹ã€‚</p><h3 id="2-Normal-Equation-çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–"><a href="#2-Normal-Equation-çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–" class="headerlink" title="2. Normal Equation çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–"></a>2. Normal Equation çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–</h3><p>ä¹‹å‰æ¨å¯¼è¿‡çš„æ­£è§„æ–¹ç¨‹ç»“è®ºï¼š</p><p>$$\Theta = (X^{T}X)^{-1}X^{T}Y$$</p><p>æ­£åˆ™åŒ–ä»¥åï¼Œä¸Šè¿°å¼å­å˜æˆäº†ï¼š</p>$$\Theta = \left( X^{T}X +\lambda \begin{bmatrix}0 &amp;  &amp;  &amp;  &amp; \\  &amp; 1 &amp;  &amp;  &amp; \\  &amp;  &amp; 1 &amp;  &amp; \\  &amp;  &amp;  &amp; \ddots  &amp; \\  &amp;  &amp;  &amp;  &amp; 1\end{bmatrix} \right) ^{-1}X^{T}Y$$<p>åœ¨ä¹‹å‰çš„è®¨è®ºä¸­ï¼Œæœ‰ä¸€ä¸ª<strong>å‰ææ¡ä»¶æ˜¯ $X^{T}X$ æ˜¯éå¥‡å¼‚(éé€€åŒ–)çŸ©é˜µï¼Œ å³ $ \left | X^{T}X \right | \neq 0 $</strong></p><p>åœ¨ä¸Šè¿°æ­£åˆ™åŒ–çš„å¼å­é‡Œé¢ï¼Œåªè¦ $\lambda &gt; 0$ï¼Œå°±ä¸å­˜åœ¨ä¸å¯é€†çš„é—®é¢˜äº†ã€‚å› ä¸º $\left( X^{T}X +\lambda \begin{bmatrix}0 &amp;  &amp;  &amp;  &amp; \\  &amp; 1 &amp;  &amp;  &amp; \\  &amp;  &amp; 1 &amp;  &amp; \\  &amp;  &amp;  &amp; \ddots  &amp; \\  &amp;  &amp;  &amp;  &amp; 1\end{bmatrix} \right)$ è¿™ä¸€é¡¹ä¸€å®šæ˜¯å¯é€†çš„ï¼Œå› ä¸ºå®ƒä¸€å®šä¸æ˜¯å¥‡å¼‚çŸ©é˜µã€‚æ‰€ä»¥<strong>æ­£åˆ™åŒ–è¿˜èƒ½è§£å†³ä¸å¯é€†çš„æƒ…å†µ</strong>ã€‚</p><hr><h2 id="ä¸‰-Regularized-Logistic-Regression-é€»è¾‘å›å½’æ­£åˆ™åŒ–"><a href="#ä¸‰-Regularized-Logistic-Regression-é€»è¾‘å›å½’æ­£åˆ™åŒ–" class="headerlink" title="ä¸‰. Regularized Logistic Regression é€»è¾‘å›å½’æ­£åˆ™åŒ–"></a>ä¸‰. Regularized Logistic Regression é€»è¾‘å›å½’æ­£åˆ™åŒ–</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_5.png" alt=""></p><p>ä¹‹å‰è®¨è®ºè¿‡çš„ä»£ä»·å‡½æ•°æ˜¯ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] \\\left( h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} \right ) \end{align*}$$<p>æ­£åˆ™åŒ–ä»¥åï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] +\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_{j}^{2}  \\\end{align*}$$<h3 id="1-Gradient-Descent-é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"><a href="#1-Gradient-Descent-é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–" class="headerlink" title="1. Gradient Descent é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"></a>1. Gradient Descent é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–</h3><p>å¼å­ç­‰åŒäºçº¿æ€§å›å½’æ­£åˆ™åŒ–</p>$$\begin{align*}\theta_{0} &amp;:= \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;j = 1 \\\theta_{j} &amp;:= \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}   \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix} \\\end{align*}$$<p>è™½ç„¶å¼å­å’Œçº¿æ€§å›å½’çš„ä¸€æ¨¡ä¸€æ ·ï¼Œä¸è¿‡è¿™é‡Œçš„ $h_{\theta}(x)$ ä»£è¡¨çš„æ„ä¹‰ä¸åŒï¼Œé€»è¾‘å›å½’ä¸­ï¼š</p><p>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}}$$</p><hr><h2 id="å››-Regularization-æµ‹è¯•"><a href="#å››-Regularization-æµ‹è¯•" class="headerlink" title="å››. Regularization æµ‹è¯•"></a>å››. Regularization æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.</p><p>A. Introducing regularization to the model always results in equal or better performance on the training set.</p><p>B. Introducing regularization to the model always results in equal or better performance on examples not in the training set.</p><p>C. Adding many new features to the model makes it more likely to overfit the training set.</p><p>D. Adding a new feature to the model always results in equal or better performance on examples not in the training set.</p><p>è§£ç­”ï¼š D  </p><p>Aã€B æ­£åˆ™åŒ–çš„å¼•å…¥æ˜¯è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œè€Œè¿‡æ‹Ÿåˆæ­£æ˜¯è¿‡åº¦æ‹Ÿåˆæ•°æ®ä½†æ— æ³•æ³›åŒ–åˆ°æ–°çš„æ•°æ®æ ·æœ¬ä¸­ã€‚<br>D å¢åŠ ä¸€äº›ç‰¹å¾é‡å¯èƒ½å¯¼è‡´æ‹Ÿåˆåœ¨è®­ç»ƒé›†åŸæœ¬æ²¡æœ‰è¢«æ‹Ÿåˆåˆ°çš„æ•°æ®ï¼Œæ­£ç¡®ï¼Œè¿™å°±æ˜¯è¿‡æ‹Ÿåˆã€‚</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you ran logistic regression twice, once with Î»=0, and once with Î»=1. One of the times, you got</p><p>parameters $\theta = \begin{bmatrix}26.29\\ 65.41\end{bmatrix}$, and the other time you got $\theta = \begin{bmatrix}2.75\\ 1.32\end{bmatrix}$. However, you forgot which value of Î» corresponds to which value of Î¸. Which one do you think corresponds to Î»=1?</p><p>A. $\theta = \begin{bmatrix}26.29\\ 65.41\end{bmatrix}$   </p><p>B. $\theta = \begin{bmatrix}2.75\\ 1.32\end{bmatrix}$</p><p>è§£ç­”ï¼š B</p><p>$\lambda = 1$è¡¨ç¤ºæ­£åˆ™åŒ–ä»¥åã€‚æ­£åˆ™åŒ–å…¶å®è®©æˆ‘ä»¬çš„ $\theta_j$å˜å°ï¼Œæ‰€ä»¥é€‰Bã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Which of the following statements about regularization are true? Check all that apply.</p><p>A. Using too large a value of Î» can cause your hypothesis to overfit the data; this can be avoided by reducing Î».</p><p>B. Consider a classification problem. Adding regularization may cause your classifier to incorrectly classify some training examples (which it had correctly classified when not using regularization, i.e. when Î»=0).</p><p>C. Because logistic regression outputs values 0â‰¤hÎ¸(x)â‰¤1, its range of output values can only be â€œshrunkâ€ slightly by regularization anyway, so regularization is generally not helpful for it.</p><p>D. Using a very large value of Î» cannot hurt the performance of your hypothesis; the only reason we do not set Î» to be too large is to avoid numerical problems.</p><p>è§£ç­”ï¼š B</p><p>C æ­£åˆ™åŒ–å¯¹é€»è¾‘å›å½’æ²¡ç”¨ï¼Œé”™è¯¯ã€‚<br>Aã€D   $\lambda$è¿‡å¤§ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.1_Logistic_Regression</title>
      <link href="/2020/02/03/3-1-logistic-regression/"/>
      <url>/2020/02/03/3-1-logistic-regression/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/69_6.png" alt=""></p><h1 id="3-1-Logistic-Regression"><a href="#3-1-Logistic-Regression" class="headerlink" title="3.1_Logistic_Regression"></a>3.1_Logistic_Regression</h1><h2 id="ä¸€-Classification-and-Representation"><a href="#ä¸€-Classification-and-Representation" class="headerlink" title="ä¸€. Classification and Representation"></a>ä¸€. Classification and Representation</h2><p>è¦å°è¯•åˆ†ç±»ï¼Œä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨çº¿æ€§å›å½’ï¼Œå¹¶å°†æ‰€æœ‰å¤§äº0.5çš„é¢„æµ‹å€¼æ˜ å°„ä¸º1ï¼Œå°†å°äº0.5çš„æ‰€æœ‰é¢„æµ‹å€¼æ˜ å°„ä¸º0.ä½†æ˜¯ï¼Œæ­¤æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå› ä¸ºåˆ†ç±»å®é™…ä¸Šä¸æ˜¯çº¿æ€§å‡½æ•°ã€‚ åˆ†ç±»é—®é¢˜å°±åƒå›å½’é—®é¢˜ä¸€æ ·ï¼Œé™¤äº†æˆ‘ä»¬ç°åœ¨æƒ³è¦é¢„æµ‹çš„å€¼åªæœ‰å°‘æ•°ç¦»æ•£å€¼ã€‚</p><p><strong>çº¿æ€§å›å½’ç”¨æ¥è§£å†³åˆ†ç±»é—®é¢˜ï¼Œé€šå¸¸ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„</strong>ã€‚</p><p>æˆ‘ä»¬è§£å†³åˆ†ç±»é—®é¢˜ï¼Œå¿½ç•¥yæ˜¯ç¦»æ•£å€¼ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬çš„æ—§çº¿æ€§å›å½’ç®—æ³•æ¥å°è¯•é¢„æµ‹ç»™å®šçš„xã€‚ä½†æ˜¯ï¼Œæ„å»ºè¿™ç§æ–¹æ³•æ€§èƒ½å¾ˆå·®çš„ç¤ºä¾‹å¾ˆå®¹æ˜“ã€‚ç›´è§‚åœ°è¯´ï¼Œå½“çŸ¥é“$y\in \begin{Bmatrix}<br>0,1<br>\end{Bmatrix}$æ—¶ï¼Œ$h_{\theta}(x)$ å–å¤§äº1æˆ–å°äº0çš„å€¼ä¹Ÿæ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ä»¬æ”¹å˜æˆ‘ä»¬çš„å‡è®¾ $h_{\theta}(x)$ çš„å½¢å¼ä»¥æ»¡è¶³ $0\leqslant h_{\theta}(x)\leqslant 1$ã€‚è¿™æ˜¯é€šè¿‡å°† $\theta^{T}x$ æ’å…¥ Logistic å‡½æ•°æ¥å®Œæˆçš„ï¼š</p><p>$$g(x) = \frac{1}{1+e^{-x}}$$</p><p>ä¸Šå¼ç§°ä¸º Sigmoid Function æˆ–è€… Logistic Function</p><p>ä»¤ $h_{\theta}(x) = g(\theta^{T}x)$,$z = \theta^{T}x$,åˆ™:</p><p>$$g(x) = \frac{1}{1+e^{-\theta^{T}x}}$$</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/69_8.png" alt=""></p><p>è¿™é‡Œæ˜¾ç¤ºçš„å‡½æ•°$g(x)$å°†ä»»ä½•å®æ•°æ˜ å°„åˆ°ï¼ˆ0,1ï¼‰åŒºé—´ï¼Œä½¿å¾—å®ƒå¯ç”¨äºå°†ä»»æ„å€¼å‡½æ•°è½¬æ¢ä¸ºæ›´é€‚åˆåˆ†ç±»çš„å‡½æ•°ã€‚</p><p><strong>å†³ç­–è¾¹ç•Œä¸æ˜¯è®­ç»ƒé›†çš„å±æ€§ï¼Œè€Œæ˜¯å‡è®¾æœ¬èº«åŠå…¶å‚æ•°çš„å±æ€§</strong>ã€‚</p><hr><h2 id="äºŒ-Logistic-Regression-Model"><a href="#äºŒ-Logistic-Regression-Model" class="headerlink" title="äºŒ. Logistic Regression Model"></a>äºŒ. Logistic Regression Model</h2><h3 id="1-Cost-Function"><a href="#1-Cost-Function" class="headerlink" title="1. Cost Function"></a>1. Cost Function</h3><p>ä¹‹å‰å®šä¹‰çš„ä»£ä»·å‡½æ•°ï¼š</p><p>$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$</p><p>å¦‚æœå°† $$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} $$ ä»£å…¥åˆ°ä¸Šé¢çš„å¼å­ä¸­ï¼Œ$\rm{CostFunction}$ çš„å‡½æ•°å›¾åƒä¼šæ˜¯ä¸€ä¸ªéå‡¸å‡½æ•°ï¼Œä¼šæœ‰å¾ˆå¤šä¸ªå±€éƒ¨æå€¼ç‚¹ã€‚</p><p>äºæ˜¯æˆ‘ä»¬é‡æ–°å¯»æ‰¾ä¸€ä¸ªæ–°çš„ä»£ä»·å‡½æ•°ï¼š</p><p>$$\rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{m}\sum_{i = 1}^{m} \rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)})$$</p>$$\rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)}) = \left\{\begin{matrix}-log(h_{\theta}(x)) &amp;if \; y = 1 \\ -log(1-h_{\theta}(x)) &amp; if\; y = 0\end{matrix}\right.$$<p>éœ€è¦è¯´æ˜çš„ä¸€ç‚¹æ˜¯ï¼Œåœ¨æˆ‘ä»¬çš„è®­ç»ƒé›†ä¸­ï¼Œç”šè‡³ä¸åœ¨è®­ç»ƒé›†ä¸­çš„æ ·æœ¬ï¼Œy çš„å€¼æ€»æ˜¯ç­‰äº 0 æˆ–è€… 1 ã€‚</p><h3 id="2-Simplified-Cost-Function-and-Gradient-Descent"><a href="#2-Simplified-Cost-Function-and-Gradient-Descent" class="headerlink" title="2. Simplified Cost Function and Gradient Descent"></a>2. Simplified Cost Function and Gradient Descent</h3><p>äºæ˜¯è¿›ä¸€æ­¥æˆ‘ä»¬æŠŠä»£ä»·å‡½æ•°å†™æˆä¸€ä¸ªå¼å­ï¼š</p><p>$$\rm{Cost}(h_{\theta}(x),y) = - ylog(h_{\theta}(x)) - (1-y)log(1-h_{\theta}(x))$$</p><p>æ‰€ä»¥ä»£ä»·å‡½æ•°æœ€ç»ˆè¡¨ç¤ºä¸ºï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= \frac{1}{m}\sum_{i = 1}^{m} \rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)})\\&amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] \\\left( h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} \right ) \end{align*}$$<p>å‘é‡åŒ–å½¢å¼ï¼š</p>$$\begin{align*}h &amp;= g(X\theta)\\ \rm{CostFunction} = \rm{F}({\theta}) &amp;= \frac{1}{m} \left ( -\overrightarrow{y}^{T}log(h) - (1-\overrightarrow{y})^{T}log(1-h) \right ) \\ \end{align*}$$<p>ä¸ºäº†æŠŠå¼å­å†™æˆä¸Šé¢è¿™æ ·å­æ˜¯æ¥è‡ªäºç»Ÿè®¡å­¦çš„æå¤§ä¼¼ç„¶ä¼°è®¡æ³•å¾—æ¥çš„ï¼Œå®ƒæ˜¯ç»Ÿè®¡å­¦é‡Œä¸ºä¸åŒçš„æ¨¡å‹å¿«é€Ÿå¯»æ‰¾å‚æ•°çš„æ–¹æ³•ã€‚å®ƒçš„æ€§è´¨ä¹‹ä¸€æ˜¯å®ƒæ˜¯å‡¸å‡½æ•°ã€‚</p><p>åˆ©ç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•ï¼Œå¾—åˆ°ä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼š</p><p>$$ \theta_{j} := \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$$</p><p>çŸ¢é‡åŒ–ï¼Œå³ï¼š</p><p>$$ \theta := \theta - \alpha \frac{1}{m} X^{T}(g(X\Theta)-\vec{y})$$</p><p><strong>è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯</strong>ï¼Œ</p><p><strong>çº¿æ€§å›å½’ä¸­ï¼Œ$h_{\theta}(x) = \theta^{T}x $</strong>,</p><p><strong>è€Œ Logistic å›å½’ä¸­ï¼Œ$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}}$</strong> ã€‚</p><p>æœ€åï¼Œç‰¹å¾ç¼©æ”¾çš„æ–¹æ³•åŒæ ·é€‚ç”¨äº Logistic å›å½’ï¼Œè®©å…¶æ¢¯åº¦ä¸‹é™æ”¶æ•›æ›´å¿«ã€‚</p><hr><h3 id="3-æ±‚å¯¼è¿‡ç¨‹"><a href="#3-æ±‚å¯¼è¿‡ç¨‹" class="headerlink" title="3. æ±‚å¯¼è¿‡ç¨‹"></a>3. æ±‚å¯¼è¿‡ç¨‹</h3><p>é€»è¾‘å‡½æ•°</p><p>æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å¦‚ä½•å¯¹é€»è¾‘å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰æ±‚å¯¼ï¼š</p>$$\begin{align*}\sigma(x)'&amp;=\left(\frac{1}{1+e^{-x}}\right)'=\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}=\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline &amp;=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)\\&amp;=\sigma(x)(1 - \sigma(x))\\\end{align*}$$<p>ä»£ä»·å‡½æ•°</p><p>åˆ©ç”¨ä¸Šé¢çš„ç»“æœï¼Œå€ŸåŠ©å¤åˆå‡½æ•°æ±‚å¯¼å…¬å¼ç­‰ï¼Œå¯å¾—ï¼š</p>$$\begin{align*}\frac{\partial}{\partial \theta_j} J(\theta) &amp;= \frac{\partial}{\partial \theta_j} \frac{-1}{m}\sum_{i=1}^m \left [ y^{(i)} log (h_\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\theta(x^{(i)})) \right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} \frac{\partial}{\partial \theta_j} log (h_\theta(x^{(i)}))   + (1-y^{(i)}) \frac{\partial}{\partial \theta_j} log (1 - h_\theta(x^{(i)}))\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} h_\theta(x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - h_\theta(x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} \sigma(\theta^T x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - \sigma(\theta^T x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   + \frac{- (1-y^{(i)}) \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   - \frac{(1-y^{(i)}) h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\theta(x^{(i)}) x^{(i)}_j\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) - (1-y^{(i)}) h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} - y^{(i)} h_\theta(x^{(i)}) - h_\theta(x^{(i)}) + y^{(i)} h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} - h_\theta(x^{(i)}) \right ] x^{(i)}_j  \newline&amp;= \frac{1}{m}\sum_{i=1}^m \left [ h_\theta(x^{(i)}) - y^{(i)} \right ] x^{(i)}_j\end{align*}$$<p>å‘é‡åŒ–å½¢å¼ï¼š</p><p>$$\nabla J(\theta) = \frac{1}{m} \cdot  X^T \cdot \left(g\left(X\cdot\theta\right) - \vec{y}\right)$$</p><hr><h3 id="4-Advanced-Optimization"><a href="#4-Advanced-Optimization" class="headerlink" title="4. Advanced Optimization"></a>4. Advanced Optimization</h3><p>é™¤å»æ¢¯åº¦ä¸‹é™æ³•ï¼Œè¿˜æœ‰å…¶ä»–çš„ä¼˜åŒ–æ–¹æ³•ï¼Œ</p><p>conjugate gradient å…±è½­æ¢¯åº¦æ³•ï¼Œ<br>BFGSï¼Œ<br>L_BFGSï¼Œ  </p><p>ä¸Šè¿°3ç§ç®—æ³•åœ¨é«˜ç­‰æ•°å€¼è®¡ç®—ä¸­ã€‚å®ƒä»¬ç›¸æ¯”æ¢¯åº¦ä¸‹é™ï¼Œæœ‰ä»¥ä¸‹ä¸€äº›ä¼˜ç‚¹ï¼š</p><ol><li>ä¸éœ€è¦æ‰‹åŠ¨é€‰æ‹©å­¦ä¹ ç‡ $\alpha$ ã€‚å¯ä»¥ç†è§£ä¸ºå®ƒä»¬æœ‰ä¸€ä¸ªæ™ºèƒ½çš„å†…å¾ªç¯(çº¿æœç´¢ç®—æ³•)ï¼Œå®ƒä¼šè‡ªåŠ¨å°è¯•ä¸åŒçš„å­¦ä¹ é€Ÿç‡ $\alpha$ï¼Œå¹¶è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªæœ€å¥½çš„å­¦ä¹ é€Ÿç‡ $\alpha$ ã€‚ç”šè‡³è¿˜å¯ä»¥ä¸ºæ¯æ¬¡è¿­ä»£é€‰æ‹©ä¸åŒçš„å­¦ä¹ é€Ÿç‡ï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦è‡ªå·±é€‰æ‹©äº†ã€‚</li><li>æ”¶æ•›é€Ÿåº¦è¿œè¿œå¿«äºæ¢¯åº¦ä¸‹é™ã€‚</li></ol><p>ç¼ºç‚¹å°±æ˜¯ç›¸æ¯”æ¢¯åº¦ä¸‹é™è€Œè¨€ï¼Œæ›´åŠ å¤æ‚ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><pre class=" language-c"><code class="language-c">function <span class="token punctuation">[</span>jVal<span class="token punctuation">,</span> gradient<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">costFunction</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span>jVal <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">^</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">^</span><span class="token number">2</span><span class="token punctuation">;</span>gradient <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">gradient</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">gradient</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>è°ƒç”¨é«˜çº§å‡½æ•° fminunc:</p><pre class=" language-c"><code class="language-c">options <span class="token operator">=</span> <span class="token function">optimset</span><span class="token punctuation">(</span><span class="token string">'GrabObj'</span><span class="token punctuation">,</span><span class="token string">'on'</span><span class="token punctuation">,</span><span class="token string">'MaxIter'</span><span class="token punctuation">,</span><span class="token string">'100'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>initialTheta <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">[</span>optTheta<span class="token punctuation">,</span> functionVal<span class="token punctuation">,</span> exitFlag<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span>@costFunction<span class="token punctuation">,</span> initialTheta<span class="token punctuation">,</span> options<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>æœ€ç»ˆç»“æœ:</p><pre class=" language-c"><code class="language-c">optTheta <span class="token operator">=</span>     <span class="token number">5.0000</span>    <span class="token number">5.0000</span>functionVal <span class="token operator">=</span> <span class="token number">1.5777e-030</span>exitFlag <span class="token operator">=</span> <span class="token number">1</span></code></pre><p>optTheta è¡¨ç¤ºçš„æ˜¯æœ€ç»ˆæ±‚å¾—çš„ç»“æœï¼ŒfunctionVal è¡¨ç¤ºçš„æ˜¯ä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼Œè¿™é‡Œæ˜¯ 0ï¼Œæ˜¯æˆ‘ä»¬æœŸæœ›çš„ã€‚exitFlag è¡¨ç¤ºçš„æ˜¯æœ€ç»ˆæ˜¯å¦æ”¶æ•›ï¼Œ1è¡¨ç¤ºæ”¶æ•›ã€‚</p><p>è¿™é‡Œçš„ fminunc æ˜¯è¯•å›¾æ‰¾åˆ°ä¸€ä¸ªå¤šå˜é‡å‡½æ•°çš„æœ€å°å€¼ï¼Œä»ä¸€ä¸ªä¼°è®¡çš„åˆè¯•å€¼å¼€å§‹ï¼Œè¿™é€šå¸¸è¢«è®¤ä¸ºæ˜¯æ— çº¦æŸéçº¿æ€§ä¼˜åŒ–é—®é¢˜ã€‚</p><p>å¦å¤–ä¸€äº›ä¾‹å­ï¼š</p><pre class=" language-c"><code class="language-c">x <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>fun<span class="token punctuation">,</span>x0<span class="token punctuation">)</span>                                   <span class="token operator">%</span>è¯•å›¾ä»x0é™„è¿‘å¼€å§‹æ‰¾åˆ°å‡½æ•°çš„å±€éƒ¨æœ€å°å€¼ï¼Œx0å¯ä»¥æ˜¯æ ‡é‡ï¼Œå‘é‡æˆ–çŸ©é˜µx <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>fun<span class="token punctuation">,</span>x0<span class="token punctuation">,</span>options<span class="token punctuation">)</span>                           <span class="token operator">%</span>æ ¹æ®ç»“æ„ä½“optionsä¸­çš„è®¾ç½®æ¥æ‰¾åˆ°æœ€å°å€¼ï¼Œå¯ç”¨optimsetæ¥è®¾ç½®optionsx <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>problem<span class="token punctuation">)</span>                                  <span class="token operator">%</span>ä¸ºproblemæ‰¾åˆ°æœ€å°å€¼<span class="token punctuation">,</span>è€Œproblemæ˜¯åœ¨Input Argumentsä¸­å®šä¹‰çš„ç»“æ„ä½“<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                               <span class="token operator">%</span>è¿”å›ç›®æ ‡å‡½æ•°funåœ¨è§£xå¤„çš„å‡½æ•°å€¼<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                      <span class="token operator">%</span>è¿”å›ä¸€ä¸ªæè¿°é€€å‡ºæ¡ä»¶çš„å€¼exitflag<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>               <span class="token operator">%</span>è¿”å›ä¸€ä¸ªå«outputçš„ç»“æ„ä½“ï¼Œå®ƒåŒ…å«ç€ä¼˜åŒ–çš„ä¿¡æ¯<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">,</span>grad<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>          <span class="token operator">%</span>è¿”å›å‡½æ•°åœ¨è§£xå¤„çš„æ¢¯åº¦çš„å€¼ï¼Œå­˜å‚¨åœ¨gradä¸­<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">,</span>grad<span class="token punctuation">,</span>hessian<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>  <span class="token operator">%</span>è¿”å›å‡½æ•°åœ¨è§£xå¤„çš„HessiançŸ©é˜µçš„å€¼ï¼Œå­˜å‚¨åœ¨hessianä¸­</code></pre><hr><h2 id="ä¸‰-Multiclass-Classification"><a href="#ä¸‰-Multiclass-Classification" class="headerlink" title="ä¸‰. Multiclass Classification"></a>ä¸‰. Multiclass Classification</h2><p>è¿™ä¸€ç« èŠ‚æˆ‘ä»¬æ¥è®¨è®ºä¸€ä¸‹å¦‚ä½•åˆ©ç”¨é€»è¾‘å›å½’æ¥è§£å†³å¤šç±»åˆ«åˆ†ç±»é—®é¢˜ã€‚ä»‹ç»ä¸€ä¸ªä¸€å¯¹å¤šçš„åˆ†ç±»ç®—æ³•ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/69_7.png" alt=""></p><p>ç°åœ¨ï¼Œå½“æˆ‘ä»¬æœ‰ä¸¤ä¸ªä»¥ä¸Šçš„ç±»åˆ«æ—¶ï¼Œæˆ‘ä»¬å°†å¤„ç†æ•°æ®çš„åˆ†ç±»ã€‚æˆ‘ä»¬å°†æ‰©å±•æˆ‘ä»¬çš„å®šä¹‰ï¼Œä½¿å¾—y = {0,1 â€¦ n}ï¼Œè€Œä¸æ˜¯y = {0,1}ã€‚ ç”±äºy = {0,1 â€¦ n}ï¼Œæˆ‘ä»¬å°†é—®é¢˜åˆ†æˆn + 1ï¼ˆ+1ï¼Œå› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼‰äºŒå…ƒåˆ†ç±»é—®é¢˜;åœ¨æ¯ä¸€ä¸ªä¸­ï¼Œæˆ‘ä»¬éƒ½é¢„æµ‹â€™yâ€™æ˜¯æˆ‘ä»¬å…¶ä¸­ä¸€ä¸ªç±»çš„æˆå‘˜çš„æ¦‚ç‡ã€‚</p><p>æœ€ç»ˆåœ¨ n + 1 ä¸ªåˆ†ç±»å™¨ä¸­åˆ†åˆ«è¾“å…¥ x ï¼Œç„¶åå–è¿™ n + 1 ä¸ªåˆ†ç±»å™¨æ¦‚ç‡çš„æœ€å¤§å€¼,å³æ˜¯å¯¹åº” $y=i$ çš„æ¦‚ç‡å€¼ã€‚</p><hr><h2 id="å››-Logistic-Regression-æµ‹è¯•"><a href="#å››-Logistic-Regression-æµ‹è¯•" class="headerlink" title="å››. Logistic Regression æµ‹è¯•"></a>å››. Logistic Regression æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose that you have trained a logistic regression classifier, and it outputs on a new example x a prediction hÎ¸(x) = 0.7. This means (check all that apply):</p><p>A. Our estimate for P(y=1|x;Î¸) is 0.7.<br>B. Our estimate for P(y=0|x;Î¸) is 0.3.<br>C. Our estimate for P(y=1|x;Î¸) is 0.3.<br>D. Our estimate for P(y=0|x;Î¸) is 0.7.  </p><p>è§£ç­”ï¼š Aã€B  </p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you have the following training set, and fit a logistic regression classifier hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2).</p><p>Which of the following are true? Check all that apply.</p><p>A. Adding polynomial features (e.g., instead using hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2+Î¸3x21+Î¸4x1x2+Î¸5x22) ) could increase how well we can fit the training data.  </p><p>B. At the optimal value of Î¸ (e.g., found by fminunc), we will have J(Î¸)â‰¥0.  </p><p>C. Adding polynomial features (e.g., instead using hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2+Î¸3x21+Î¸4x1x2+Î¸5x22) ) would increase J(Î¸) because we are now summing over more terms.  </p><p>D. If we train gradient descent for enough iterations, for some examples x(i) in the training set it is possible to obtain hÎ¸(x(i))&gt;1.  </p><p>è§£ç­”ï¼š Aã€B</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>For logistic regression, the gradient is given by âˆ‚âˆ‚Î¸jJ(Î¸)=1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i)j. Which of these is a correct gradient descent update for logistic regression with a learning rate of Î±? Check all that apply.</p><p>A. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i) (simultaneously update for all j).  </p><p>B. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i)j (simultaneously update for all j).  </p><p>C. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(11+eâˆ’Î¸Tx(i)âˆ’y(i))x(i)j (simultaneously update for all j).  </p><p>D. Î¸:=Î¸âˆ’Î±1mâˆ‘mi=1(Î¸Txâˆ’y(i))x(i).  </p><p>è§£ç­”ï¼š Aã€D</p><p>çº¿æ€§å›å½’ä¸é€»è¾‘å›å½’çš„åŒºåˆ«</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. The cost function J(Î¸) for logistic regression trained with mâ‰¥1 examples is always greater than or equal to zero.  </p><p>B. Linear regression always works well for classification if you classify by using a threshold on the prediction made by linear regression.  </p><p>C. The one-vs-all technique allows you to use logistic regression for problems in which each y(i) comes from a fixed, discrete set of values.   </p><p>D. For logistic regression, sometimes gradient descent will converge to a local minimum (and fail to find the global minimum). This is the reason we prefer more advanced optimization algorithms such as fminunc (conjugate gradient/BFGS/L-BFGS/etc).  </p><p>è§£ç­”ï¼š Aã€C</p><p>Dç”±äºä½¿ç”¨ä»£ä»·å‡½æ•°ä¸ºçº¿æ€§å›å½’ä»£ä»·å‡½æ•°ï¼Œä¼šæœ‰å¾ˆå¤šå±€éƒ¨æœ€ä¼˜å€¼</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Suppose you train a logistic classifier hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2). Suppose Î¸0=6,Î¸1=0,Î¸2=âˆ’1. Which of the following figures represents the decision boundary found by your classifier?</p><p>è§£ç­”ï¼š C</p><p>6-x2&gt;=0 å³X2&lt;6æ—¶ä¸º1</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.2_Computing_Parameters_Analytically</title>
      <link href="/2020/01/27/2-2-computing-parameters-analytically/"/>
      <url>/2020/01/27/2-2-computing-parameters-analytically/</url>
      
        <content type="html"><![CDATA[<h1 id="2-2-Computing-Parameters-Analytically"><a href="#2-2-Computing-Parameters-Analytically" class="headerlink" title="2.2_Computing_Parameters_Analytically"></a>2.2_Computing_Parameters_Analytically</h1><h2 id="ä¸€-Normal-Equation"><a href="#ä¸€-Normal-Equation" class="headerlink" title="ä¸€. Normal Equation"></a>ä¸€. Normal Equation</h2><h3 id="1-æ­£è§„æ–¹ç¨‹"><a href="#1-æ­£è§„æ–¹ç¨‹" class="headerlink" title="1. æ­£è§„æ–¹ç¨‹"></a>1. æ­£è§„æ–¹ç¨‹</h3><p>æ­£è§„æ–¹ç¨‹æ³•ç›¸å¯¹æ¢¯åº¦ä¸‹é™æ³•ï¼Œå®ƒå¯ä»¥ä¸€æ­¥æ‰¾åˆ°æœ€å°å€¼ã€‚è€Œä¸”å®ƒä¹Ÿä¸éœ€è¦è¿›è¡Œç‰¹å¾å€¼çš„ç¼©æ”¾ã€‚</p><p>æ ·æœ¬é›†æ˜¯ $ m * n $ çš„çŸ©é˜µï¼Œæ¯è¡Œæ ·æœ¬è¡¨ç¤ºä¸º $ \vec{x^{(i)}} $ ,ç¬¬ i è¡Œç¬¬ n åˆ—åˆ†åˆ«è¡¨ç¤ºä¸º $ x^{(i)}_{0} , x^{(i)}_{1} , x^{(i)}_{2} , x^{(i)}_{3} \cdots x^{(i)}_{n} $, m è¡Œå‘é‡åˆ†åˆ«è¡¨ç¤ºä¸º $ \vec{x^{(1)}} , \vec{x^{(2)}} , \vec{x^{(3)}} , \cdots \vec{x^{(m)}} $</p><p>ä»¤ </p>$$ \vec{x^{(i)}} = \begin{bmatrix} x^{(i)}_{0}\\ x^{(i)}_{1}\\ \vdots \\ x^{(i)}_{n}\\ \end{bmatrix} $$<p>$ \vec{x^{(i)}} $ æ˜¯è¿™æ ·ä¸€ä¸ª $(n+1)*1$ ç»´å‘é‡ã€‚æ¯è¡Œéƒ½å¯¹åº”ç€ i è¡Œ 0-n ä¸ªå˜é‡ã€‚</p><p>å†æ„é€ å‡ ä¸ªçŸ©é˜µï¼š</p>$$ X = \begin{bmatrix} (\vec{x^{(1)}})^{T}\\  \vdots \\  (\vec{x^{(m)}})^{T} \end{bmatrix} \;\;\;\;\Theta = \begin{bmatrix} \theta_{0}\\ \theta_{1}\\ \vdots \\ \theta_{n}\\ \end{bmatrix} \;\;\;\;Y = \begin{bmatrix} y^{(1)}\\ y^{(2)}\\ \vdots \\ y^{(m)}\\ \end{bmatrix} $$<p>X æ˜¯ä¸€ä¸ª $ m * (n+1)$ çš„çŸ©é˜µï¼Œ$ \Theta $ æ˜¯ä¸€ä¸ª $ (n+1) * 1$ çš„å‘é‡ï¼ŒY æ˜¯ä¸€ä¸ª $ m * 1$çš„çŸ©é˜µã€‚</p><p>å¯¹æ¯”ä¹‹å‰ä»£ä»·å‡½æ•°ä¸­ï¼Œ$$ \rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$</p>  $$\begin{align*}X \cdot \Theta - Y = \begin{bmatrix}(\vec{x^{(1)}})^{T}\\ \vdots \\ (\vec{x^{(m)}})^{T}\end{bmatrix} \cdot \begin{bmatrix} \theta_{0}\\ \theta_{1}\\ \vdots \\ \theta_{n}\\ \end{bmatrix} - \begin{bmatrix} y^{(1)}\\ y^{(2)}\\ \vdots \\ y^{(m)}\\ \end{bmatrix} = \begin{bmatrix} h_{\theta}(x^{(1)})-y^{(1)}\\ h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots \\ h_{\theta}(x^{(m)})-y^{(m)}\\ \end{bmatrix}\end{align*}$$<p>ä»£å…¥åˆ°ä¹‹å‰ä»£ä»·å‡½æ•°ä¸­ï¼Œ</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) &amp;= \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\&amp; = \frac{1}{2m} (X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y)\\\end{align*}$$<hr><h3 id="2-çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹"><a href="#2-çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹" class="headerlink" title="2. çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹"></a>2. çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹</h3><p>æ¥ä¸‹æ¥åœ¨è¿›è¡Œæ¨å¯¼ä¹‹å‰ï¼Œéœ€è¦å¼•å…¥çŸ©é˜µè¿¹çš„æ¦‚å¿µï¼Œå› ä¸ºè¿¹æ˜¯æ±‚è§£ä¸€é˜¶çŸ©é˜µå¾®åˆ†çš„å·¥å…·ã€‚</p><p>çŸ©é˜µè¿¹çš„å®šä¹‰æ˜¯ </p><p>$$ \rm{tr} A =  \sum_{i=1}^{n}A_{ii}$$ </p><p>ç®€å•çš„è¯´å°±æ˜¯å·¦ä¸Šè§’åˆ°å³ä¸‹è§’å¯¹è§’çº¿ä¸Šå…ƒç´ çš„å’Œã€‚</p><p>æ¥ä¸‹æ¥æœ‰å‡ ä¸ªæ€§è´¨åœ¨ä¸‹é¢æ¨å¯¼è¿‡ç¨‹ä¸­éœ€è¦ç”¨åˆ°ï¼š</p><ol><li><p>$ \rm{tr};a = a $ ï¼Œ a æ˜¯æ ‡é‡ ( $ a \in \mathbb{R} $)  </p></li><li><p>$ \rm{tr};AB = \rm{tr};BA $ æ›´è¿‘ä¸€æ­¥ $ \rm{tr};ABC = \rm{tr};CAB = \rm{tr};BCA $<br>è¯æ˜ï¼šå‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µï¼Œ B æ˜¯ $m * n$ çŸ©é˜µï¼Œåˆ™æœ‰<br>$$ \rm{tr};AB = \sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji} = \sum_{j=1}^{n} \sum_{i=1}^{m}B_{ji}A_{ij}= \rm{tr};BA $$<br>åŒç†ï¼š$$ \rm{tr};ABC = \rm{tr};(AB)C = \rm{tr};C(AB) = \rm{tr};CAB$$<br>$$ \rm{tr};ABC = \rm{tr};A(BC) = \rm{tr};(BC)A = \rm{tr};BCA$$<br>è¿èµ·æ¥ï¼Œå³ $$ \rm{tr};ABC = \rm{tr};CAB = \rm{tr};BCA $$</p></li><li><p>$ \triangledown_{A}\rm{tr};AB = \triangledown_{A}\rm{tr};BA = B^{T}$<br>è¯æ˜ï¼šæŒ‰ç…§çŸ©é˜µæ¢¯åº¦çš„å®šä¹‰ï¼š</p>   $$\triangledown_{X}f(X) = \begin{bmatrix}   \frac{\partial f(X) }{\partial x_{11}} &amp; \cdots &amp; \frac{\partial f(X) }{\partial x_{1n}}\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial f(X) }{\partial x_{m1}} &amp; \cdots &amp; \frac{\partial f(X) }{\partial x_{mn}}   \end{bmatrix} = \frac{\partial f(X) }{\partial X}$$   <p>å‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µï¼Œ B æ˜¯ $m * n$ çŸ©é˜µï¼Œåˆ™æœ‰</p>   $$\begin{align*}\triangledown_{A}\rm{tr}\;AB &amp;= \triangledown_{A} \sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}  = \frac{\partial}{\partial A}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})\\ &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})   \end{bmatrix} \\ &amp; = \begin{bmatrix}   B_{11} &amp; \cdots &amp; B_{m1} \\    \vdots &amp; \ddots  &amp; \vdots \\    B_{1n} &amp; \cdots &amp; B_{mn}   \end{bmatrix} = B^{T}\\ \end{align*}$$   </li></ol>      $$\begin{align*}\triangledown_{A}\rm{tr}\;BA &amp;= \triangledown_{A} \sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}  = \frac{\partial}{\partial A}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})\\ &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})   \end{bmatrix} \\ &amp; = \begin{bmatrix}   B_{11} &amp; \cdots &amp; B_{m1} \\    \vdots &amp; \ddots  &amp; \vdots \\    B_{1n} &amp; \cdots &amp; B_{mn}   \end{bmatrix} = B^{T}\\ \end{align*}$$   <p>   æ‰€ä»¥æœ‰ $ \triangledown_{A}\rm{tr};AB = \triangledown_{A}\rm{tr};BA = B^{T}$</p><ol start="4"><li><p>$\triangledown_{A^{T}}a = (\triangledown_{A}a)^{T};;;; (a \in \mathbb{R})$<br>è¯æ˜ï¼šå‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µ</p>   $$\begin{align*}\triangledown_{A^{T}}a &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{1n}}a\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{m1}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{mn}}a   \end{bmatrix}  = (\begin{bmatrix}   \frac{\partial}{\partial A_{11}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}a\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}a   \end{bmatrix})^{T} \\ &amp; = (\triangledown_{A}a)^{T}\\ \end{align*}$$   </li><li><p>$\mathrm{d}(\rm{tr};A) = \rm{tr}(\mathrm{d}A)$<br>è¯æ˜ï¼š<br>$$\mathrm{d}(\rm{tr};A) = \mathrm{d}(\sum_{i=1}^{n}a_{ii}) = \sum_{i=1}^{n}\mathrm{d}a_{ii} = \rm{tr}(\mathrm{d}A)$$<br>çŸ©é˜µçš„è¿¹çš„å¾®åˆ†ç­‰äºçŸ©é˜µçš„å¾®åˆ†çš„è¿¹ã€‚</p></li><li><p>$\triangledown_{A}\rm{tr};ABA^{T}C = CAB + C^{T}AB^{T}$<br>è¯æ˜ï¼š<br>æ ¹æ®å®æ ‡é‡å‡½æ•°æ¢¯åº¦çš„ä¹˜æ³•æ³•åˆ™ï¼š<br>è‹¥ f(A)ã€g(A)ã€h(A) åˆ†åˆ«æ˜¯çŸ©é˜µ A çš„å®æ ‡é‡å‡½æ•°ï¼Œåˆ™æœ‰   $$\begin{align*}\frac{\partial f(A)g(A)}{\partial A} &amp;= g(A)\frac{\partial f(A)}{\partial A} + f(A)\frac{\partial g(A)}{\partial A}\\ \frac{\partial f(A)g(A)h(A)}{\partial A} &amp;= g(A)h(A)\frac{\partial f(A)}{\partial A} + f(A)h(A)\frac{\partial g(A)}{\partial A}+ f(A)g(A)\frac{\partial h(A)}{\partial A}\\ \end{align*}$$<br>ä»¤ $f(A) = AB,g(A) = A^{T}C$ï¼Œç”±æ€§è´¨5ï¼ŒçŸ©é˜µçš„è¿¹çš„å¾®åˆ†ç­‰äºçŸ©é˜µçš„å¾®åˆ†çš„è¿¹ï¼Œé‚£ä¹ˆåˆ™æœ‰ï¼š</p>   $$\begin{align*} \triangledown_{A}\rm{tr}\;ABA^{T}C &amp; = \rm{tr}(\triangledown_{A}ABA^{T}C) = \rm{tr}(\triangledown_{A}f(A)g(A)) = \rm{tr}\triangledown_{A_{1}}(A_{1}BA^{T}C) + \rm{tr}\triangledown_{A_{2}}(ABA_{2}^{T}C)  \\ &amp; = (BA^{T}C)^{T} + \rm{tr}\triangledown_{A_{2}}(ABA_{2}^{T}C) = C^{T}AB^{T} + \triangledown_{A_{2}}\rm{tr}(ABA_{2}^{T}C)\\ &amp; = C^{T}AB^{T} + \triangledown_{A_{2}}\rm{tr}(A_{2}^{T}CAB) = C^{T}AB^{T} + (\triangledown_{{A_{2}}^{T}}\;\rm{tr}\;A_{2}^{T}CAB)^{T} \\ &amp; = C^{T}AB^{T} + ((CAB)^{T})^{T}  \\ &amp; = C^{T}AB^{T} + CAB  \\ \end{align*}$$   </li></ol><hr><h3 id="3-æ¨å¯¼"><a href="#3-æ¨å¯¼" class="headerlink" title="3. æ¨å¯¼"></a>3. æ¨å¯¼</h3><p>å›åˆ°ä¹‹å‰çš„ä»£ä»·å‡½æ•°ä¸­ï¼š<br>$$<br>\rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m} (X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y)<br>$$<br>æ±‚å¯¼ï¼š</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{2m} \triangledown_{\theta}(X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y) = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}-Y^{T})(X\Theta-Y)\\&amp; = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}X\Theta-Y^{T}X\Theta-\Theta^{T}X^{T}Y+Y^{T}Y) \\ \end{align*}$$<p>ä¸Šå¼ä¸­ï¼Œå¯¹ $\Theta $çŸ©é˜µæ±‚å¯¼ï¼Œ$ Y^{T}Y $ ä¸ $\Theta $ æ— å…³ï¼Œæ‰€ä»¥è¿™ä¸€é¡¹ä¸º 0 ã€‚ $Y^{T}X\Theta$ æ˜¯æ ‡é‡ï¼Œç”±æ€§è´¨4å¯ä»¥çŸ¥é“ï¼Œ$Y^{T}X\Theta = (Y^{T}X\Theta)^{T} = \Theta^{T}X^{T}Y$ï¼Œå› ä¸º $\Theta^{T}X^{T}X\Theta , Y^{T}X\Theta $éƒ½æ˜¯æ ‡é‡ï¼Œæ‰€ä»¥å®ƒä»¬çš„ä¹Ÿç­‰äºå®ƒä»¬çš„è¿¹ï¼Œï¼ˆå¤„ç†çŸ©é˜µå¾®åˆ†çš„é—®é¢˜å¸¸å¸¸å¼•å…¥çŸ©é˜µçš„è¿¹ï¼‰ï¼Œäºæ˜¯æœ‰</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}X\Theta-2Y^{T}X\Theta) \\ &amp; = \frac{1}{2m}\triangledown_{\theta}\rm{tr}\;(\Theta^{T}X^{T}X\Theta-2Y^{T}X\Theta) \\ &amp; = \frac{1}{2m}\triangledown_{\theta}\rm{tr}\;(\Theta\Theta^{T}X^{T}X-2Y^{T}X\Theta) \\ &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -\triangledown_{\theta}\rm{tr}\;Y^{T}X\Theta) \\ &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -(Y^{T}X)^{T}) = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -X^{T}Y)\\ \end{align*}$$<p>ä¸Šé¢ç¬¬ä¸‰æ­¥ç”¨çš„æ€§è´¨2çŸ©é˜µè¿¹çš„äº¤æ¢å¾‹ï¼Œç¬¬äº”æ­¥ç”¨çš„æ€§è´¨3ã€‚</p><p>ä¸ºäº†èƒ½è¿›ä¸€æ­¥åŒ–ç®€çŸ©é˜µçš„å¾®åˆ†ï¼Œæˆ‘ä»¬åœ¨çŸ©é˜µçš„è¿¹ä¸Šé¢ä¹˜ä»¥ä¸€ä¸ªå•ä½çŸ©é˜µï¼Œä¸å½±å“ç»“æœã€‚äºæ˜¯ï¼š</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -X^{T}Y) \\ &amp;= \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta I \Theta^{T}X^{T}X -X^{T}Y) \end{align*}$$<p>åˆ©ç”¨æ€§è´¨6 å±•å¼€ä¸Šé¢çš„å¼å­ï¼Œä»¤ $ A = \Theta , B = I , C = X^{T}X $ã€‚</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp;= \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta I \Theta^{T}X^{T}X -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta I + (X^{T}X)^{T}\Theta I^{T}) -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta I + (X^{T}X)^{T}\Theta I^{T}) -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta + X^{T}X\Theta) -X^{T}Y)  = \frac{1}{m}(X^{T}X\Theta -X^{T}Y) \\ \end{align*}$$<p>ä»¤ $\triangledown_{\theta}\rm{F}(\theta) = 0$ï¼Œå³ $X^{T}X\Theta -X^{T}Y = 0$, äºæ˜¯ $ X^{T}X\Theta = X^{T}Y $ ï¼Œè¿™é‡Œå‡è®¾ $ X^{T}X$ è¿™ä¸ªçŸ©é˜µæ˜¯å¯é€†çš„ï¼Œç­‰å·ä¸¤è¾¹åŒæ—¶å·¦ä¹˜$ X^{T}X$çš„é€†çŸ©é˜µï¼Œå¾—åˆ° $\Theta = (X^{T}X)^{-1}X^{T}Y$</p><p>æœ€ç»ˆç»“æœä¹Ÿå°±æ¨å¯¼å‡ºæ¥äº†ï¼Œ$$\Theta = (X^{T}X)^{-1}X^{T}Y$$</p><p>ä½†æ˜¯è¿™é‡Œæœ‰ä¸€ä¸ª<strong>å‰ææ¡ä»¶æ˜¯ $X^{T}X$ æ˜¯éå¥‡å¼‚(éé€€åŒ–)çŸ©é˜µï¼Œ å³ $ \left | X^{T}X \right | \neq 0 $</strong></p><hr><h3 id="4-æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š"><a href="#4-æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š" class="headerlink" title="4. æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š"></a>4. æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š</h3><p>ä¼˜ç‚¹ï¼š<br>æ¢¯åº¦ä¸‹é™åœ¨è¶…å¤§æ•°æ®é›†é¢å‰ä¹Ÿèƒ½è¿è¡Œçš„å¾ˆè‰¯å¥½ã€‚<br>æ­£è§„æ–¹ç¨‹åœ¨è¶…å¤§æ•°æ®é›†åˆé¢å‰æ€§èƒ½ä¼šå˜å¾—å¾ˆå·®ï¼Œå› ä¸ºéœ€è¦è®¡ç®— $(x^{T}x)^{-1}$,æ—¶é—´å¤æ‚åº¦åœ¨ $O(n^{3})$ è¿™ä¸ªçº§åˆ«ã€‚  </p><p>ç¼ºç‚¹ï¼š<br>æ¢¯åº¦ä¸‹é™éœ€è¦åˆç†çš„é€‰æ‹©å­¦ä¹ é€Ÿç‡ $\alpha$ , éœ€è¦å¾ˆå¤šæ¬¡è¿­ä»£çš„æ“ä½œå»é€‰æ‹©åˆç†çš„ $\alpha$ï¼Œå¯»æ‰¾æœ€å°å€¼çš„æ—¶å€™ä¹Ÿéœ€è¦è¿­ä»£å¾ˆå¤šæ¬¡æ‰èƒ½æ”¶æ•›ã€‚<br>æ­£è§„æ–¹ç¨‹çš„ä¼˜åŠ¿ç›¸æ¯”è€Œè¨€ï¼Œä¸éœ€è¦é€‰æ‹©å­¦ä¹ é€Ÿç‡ $\alpha$ï¼Œä¹Ÿä¸éœ€è¦å¤šæ¬¡çš„è¿­ä»£æˆ–è€…ç”»å›¾æ£€æµ‹æ˜¯å¦æ”¶æ•›ã€‚</p><hr><h2 id="äºŒ-Normal-Equation-Noninvertibility"><a href="#äºŒ-Normal-Equation-Noninvertibility" class="headerlink" title="äºŒ. Normal Equation Noninvertibility"></a>äºŒ. Normal Equation Noninvertibility</h2><p>ä¸Šä¸€ç« è°ˆåˆ°äº†å¦‚ä½•åˆ©ç”¨æ­£è§„æ–¹ç¨‹æ³•æ±‚è§£ $\Theta $,ä½†æ˜¯åœ¨çº¿æ€§ä»£æ•°ä¸­å­˜åœ¨è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœæ˜¯å¥‡å¼‚(é€€åŒ–)çŸ©é˜µï¼Œæ˜¯ä¸å­˜åœ¨é€†çŸ©é˜µçš„ã€‚ä¹Ÿå°±æ˜¯è¯´ç”¨ä¸Šé¢æ­£è§„æ–¹ç¨‹çš„å…¬å¼æ˜¯ä¸ä¸€å®šèƒ½æ±‚è§£å‡ºæ­£ç¡®ç»“æœçš„ã€‚</p><p>åœ¨ Octave è½¯ä»¶ä¸­ï¼Œå­˜åœ¨2ä¸ªæ±‚è§£é€†çŸ©é˜µçš„å‡½æ•°ï¼Œä¸€ä¸ªæ˜¯ pinv å’Œ invã€‚pinv (pseudo-inverse)æ±‚è§£çš„æ˜¯<strong>ä¼ªé€†çŸ©é˜µ</strong>ï¼Œinv æ±‚è§£çš„æ˜¯é€†çŸ©é˜µï¼Œæ‰€ä»¥ç”¨ pinv æ±‚è§£é—®é¢˜ï¼Œå°±ç®—æ˜¯ $ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µï¼Œä¹Ÿä¸€æ ·å¯ä»¥å¾—åˆ°æœ€åçš„ç»“æœã€‚</p><p>å¯¼è‡´$ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µæœ‰2ç§æƒ…å†µï¼š</p><ol><li>å¤šä½™çš„ç‰¹å¾ã€‚ç‰¹å¾ä¹‹é—´å‘ˆå€æ•°å…³ç³»ï¼Œçº¿æ€§ä¾èµ–ã€‚</li><li>è¿‡å¤šçš„ç‰¹å¾ã€‚å½“ $ m \leqslant n $ çš„æ—¶å€™ï¼Œä¼šå¯¼è‡´è¿‡å¤šçš„ç‰¹å¾ã€‚è§£å†³åŠæ³•æ˜¯åˆ é™¤ä¸€äº›ç‰¹å¾ï¼Œæˆ–è€…è¿›è¡Œæ­£åˆ™åŒ–ã€‚</li></ol><p>æ‰€ä»¥è§£å†³$ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µçš„åŠæ³•ä¹Ÿå°±æ˜¯å¯¹åº”ä¸Šé¢2ç§æƒ…å†µï¼š</p><ol><li>åˆ æ‰å¤šä½™çš„ç‰¹å¾ï¼Œçº¿æ€§ç›¸å…³çš„ï¼Œå€æ•°å…³ç³»çš„ã€‚ç›´åˆ°æ²¡æœ‰å¤šä½™çš„ç‰¹å¾</li><li>å†åˆ é™¤ä¸€äº›ä¸å½±å“ç»“æœçš„ç‰¹å¾ï¼Œæˆ–è€…è¿›è¡Œæ­£åˆ™åŒ–ã€‚</li></ol><hr><h2 id="ä¸‰-Linear-Regression-with-Multiple-Variables-æµ‹è¯•"><a href="#ä¸‰-Linear-Regression-with-Multiple-Variables-æµ‹è¯•" class="headerlink" title="ä¸‰. Linear Regression with Multiple Variables æµ‹è¯•"></a>ä¸‰. Linear Regression with Multiple Variables æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose m=4 students have taken some class, and the class had a midterm exam and a final exam. You have collected a dataset of their scores on the two exams, which is as follows:</p><p>midterm exam    (midterm exam)2    final exam<br>89    7921    96<br>72    5184    74<br>94    8836    87<br>69    4761    78<br>Youâ€™d like to use polynomial regression to predict a studentâ€™s final exam score from their midterm exam score. Concretely, suppose you want to fit a model of the form hÎ¸(x)=Î¸0+Î¸1x1+Î¸2x2, where x1 is the midterm score and x2 is (midterm score)2. Further, you plan to use both feature scaling (dividing by the â€œmax-minâ€, or range, of a feature) and mean normalization.</p><p>What is the normalized feature x(2)2? (Hint: midterm = 72, final = 74 is training example 2.) Please round off your answer to two decimal places and enter in the text box below.</p><p>è§£ç­”ï¼š<br>æ ‡å‡†åŒ– $$x = \frac{x_{2}^{2}-\frac{(7921+5184+8836+4761)}{4}}{\max - \min } = \frac{5184 - 6675.5}{8836-4761} = -0.37$$</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>You run gradient descent for 15 iterations</p><p>with Î±=0.3 and compute J(Î¸) after each</p><p>iteration. You find that the value of J(Î¸) increases over</p><p>time. Based on this, which of the following conclusions seems</p><p>most plausible?</p><p>A. Rather than use the current value of Î±, itâ€™d be more promising to try a smaller value of Î± (say Î±=0.1).</p><p>B. Î±=0.3 is an effective choice of learning rate.</p><p>C. Rather than use the current value of Î±, itâ€™d be more promising to try a larger value of Î± (say Î±=1.0).</p><p>è§£ç­”ï¼š  A </p><p>ä¸‹é™å¤ªå¿«æ‰€ä»¥aä¸‹é™é€Ÿç‡è¿‡å¤§ï¼Œaè¶Šå¤§ä¸‹é™è¶Šå¿«ï¼Œaå°ä¸‹é™æ…¢ï¼Œåœ¨æœ¬é¢˜ä¸­ï¼Œä»£ä»·å‡½æ•°å¿«é€Ÿæ”¶æ•›åˆ°æœ€å°å€¼ï¼Œä»£è¡¨æ­¤æ—¶aæœ€åˆé€‚ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you have m=28 training examples with n=4 features (excluding the additional all-ones feature for the intercept term, which you should add). The normal equation is Î¸=(XTX)âˆ’1XTy. For the given values of m and n, what are the dimensions of Î¸, X, and y in this equation?</p><p>A. X is 28Ã—4, y is 28Ã—1, Î¸ is 4Ã—4</p><p>B. X is 28Ã—5, y is 28Ã—5, Î¸ is 5Ã—5</p><p>C. X is 28Ã—5, y is 28Ã—1, Î¸ is 5Ã—1</p><p>D. X is 28Ã—4, y is 28Ã—1, Î¸ is4Ã—1</p><p>è§£ç­”ï¼š  C </p><p>è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé¢˜ç›®ä¸­è¯´äº†é¢å¤–æ·»åŠ ä¸€åˆ—å…¨éƒ¨ä¸º1çš„ï¼Œæ‰€ä»¥åˆ—æ•°æ˜¯5 ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Suppose you have a dataset with m=50 examples and n=15 features for each example. You want to use multivariate linear regression to fit the parameters Î¸ to our data. Should you prefer gradient descent or the normal equation?</p><p>A. Gradient descent, since it will always converge to the optimal Î¸.</p><p>B. Gradient descent, since (XTX)âˆ’1 will be very slow to compute in the normal equation.</p><p>C. The normal equation, since it provides an efficient way to directly find the solution.</p><p>D. The normal equation, since gradient descent might be unable to find the optimal Î¸.</p><p>è§£ç­”ï¼š  C </p><p>æ•°æ®é‡å°‘ï¼Œé€‰æ‹©æ­£è§„æ–¹ç¨‹æ³•æ›´åŠ é«˜æ•ˆ</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following are reasons for using feature scaling?</p><p>A. It prevents the matrix XTX (used in the normal equation) from being non-invertable (singular/degenerate).</p><p>B. It is necessary to prevent the normal equation from getting stuck in local optima.</p><p>C. It speeds up gradient descent by making it require fewer iterations to get to a good solution.</p><p>D. It speeds up gradient descent by making each iteration of gradient descent less expensive to compute.</p><p>è§£ç­”ï¼š  C </p><p>normal equation ä¸éœ€è¦ Feature Scalingï¼Œæ’é™¤ABï¼Œ ç‰¹å¾ç¼©æ”¾å‡å°‘è¿­ä»£æ•°é‡ï¼ŒåŠ å¿«æ¢¯åº¦ä¸‹é™ï¼Œç„¶è€Œä¸èƒ½é˜²æ­¢æ¢¯åº¦ä¸‹é™é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.1_Multivariate_Linear_Regression</title>
      <link href="/2020/01/27/2-1-multivariate-linear-regression/"/>
      <url>/2020/01/27/2-1-multivariate-linear-regression/</url>
      
        <content type="html"><![CDATA[<h1 id="Multivariate-Linear-Regression"><a href="#Multivariate-Linear-Regression" class="headerlink" title="Multivariate Linear Regression"></a>Multivariate Linear Regression</h1><h2 id="ä¸€-Multiple-Features"><a href="#ä¸€-Multiple-Features" class="headerlink" title="ä¸€. Multiple Features"></a>ä¸€. Multiple Features</h2><p>å…·æœ‰å¤šä¸ªå˜é‡çš„çº¿æ€§å›å½’ä¹Ÿè¢«ç§°ä¸ºâ€œå¤šå…ƒçº¿æ€§å›å½’â€ã€‚</p><p>$x_{j}^{(i)}$: è®­ç»ƒé›†ç¬¬ i ä¸ªå‘é‡ä¸­çš„ç¬¬ j ä¸ªå…ƒç´ (ç¬¬ i è¡Œç¬¬ j åˆ—)<br>$x^{(i)}$: è®­ç»ƒé›†ç¬¬ i ä¸ªå‘é‡(ç¬¬ i è¡Œ)<br>$ m $: æ€»å…± m è¡Œ<br>$ n $: æ€»å…± n åˆ—  </p><p>é€‚åº”è¿™äº›å¤šç‰¹å¾çš„å‡è®¾å‡½æ•°çš„å¤šå˜é‡å½¢å¼å¦‚ä¸‹ï¼š</p><p>$$ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{3} + \cdots + \theta_{n}x_{n} $$</p><p>ä½¿ç”¨çŸ©é˜µä¹˜æ³•çš„å®šä¹‰ï¼Œæˆ‘ä»¬çš„å¤šå˜é‡å‡è®¾å‡½æ•°å¯ä»¥ç®€æ´åœ°è¡¨ç¤ºä¸ºï¼š</p><p>$$ h_{\theta}(x) = \begin{bmatrix}<br>\theta_{0} &amp; \theta_{1} &amp; \cdots  &amp; \theta_{n}<br>\end{bmatrix} \begin{bmatrix}<br>x_{0}\<br>x_{1}\<br> \vdots \<br>x_{n}<br>\end{bmatrix} = \theta^{T}x$$</p><p>å…¶ä¸­ $ x_{0}^{(i)} = 1 (i\in 1,\cdots,m)$</p><hr><h2 id="äºŒ-Gradient-Descent-for-Multiple-Variables"><a href="#äºŒ-Gradient-Descent-for-Multiple-Variables" class="headerlink" title="äºŒ. Gradient Descent for Multiple Variables"></a>äºŒ. Gradient Descent for Multiple Variables</h2><p>å¤šä¸ªå˜é‡çš„æ¢¯åº¦ä¸‹é™ï¼ŒåŒæ—¶æ›´æ–° n ä¸ªå˜é‡ã€‚</p><p>$$ \theta_{j} := \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$$</p><p>å…¶ä¸­ $ j \in [0,n]$</p><hr><h2 id="ä¸‰-Gradient-Descent-in-Practice-I-Feature-Scaling"><a href="#ä¸‰-Gradient-Descent-in-Practice-I-Feature-Scaling" class="headerlink" title="ä¸‰. Gradient Descent in Practice I - Feature Scaling"></a>ä¸‰. Gradient Descent in Practice I - Feature Scaling</h2><p>ç‰¹å¾ç¼©æ”¾åŒ…æ‹¬å°†è¾“å…¥å€¼é™¤ä»¥è¾“å…¥å˜é‡çš„èŒƒå›´ï¼ˆå³æœ€å¤§å€¼å‡å»æœ€å°å€¼ï¼‰ï¼Œå¯¼è‡´æ–°çš„èŒƒå›´ä»…ä¸º1ã€‚</p><p>å‡å€¼å½’ä¸€åŒ–åŒ…æ‹¬ä»è¾“å…¥å˜é‡çš„å€¼ä¸­å‡å»è¾“å…¥å˜é‡çš„å¹³å‡å€¼ï¼Œä»è€Œå¯¼è‡´è¾“å…¥å˜é‡çš„æ–°å¹³å‡å€¼ä¸ºé›¶ã€‚</p><h3 id="1-Feature-Scaling"><a href="#1-Feature-Scaling" class="headerlink" title="1. Feature Scaling"></a>1. Feature Scaling</h3><p>ç‰¹å¾ç¼©æ”¾è®©ç‰¹å¾å€¼å–å€¼èŒƒå›´éƒ½æ¯”è¾ƒä¸€è‡´ï¼Œè¿™æ ·åœ¨æ‰§è¡Œæ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼Œâ€œä¸‹å±±çš„è·¯çº¿â€ä¼šæ›´åŠ ç®€å•ï¼Œæ›´å¿«çš„æ”¶æ•›ã€‚é€šå¸¸è¿›è¡Œç‰¹å¾ç¼©æ”¾éƒ½ä¼šæŠŠç‰¹å¾å€¼ç¼©å°½é‡ç¼©æ”¾åˆ° [-1,1] ä¹‹é—´<strong>æˆ–è€…è¿™ä¸ªåŒºé—´é™„è¿‘</strong>ã€‚</p><p>å³ $ x_{i} = \frac{x_{i}}{s_{i}}$</p><h3 id="2-Mean-normalization"><a href="#2-Mean-normalization" class="headerlink" title="2. Mean normalization"></a>2. Mean normalization</h3><p>$ x_{i} = \frac{x_{i} - \mu_{i}}{s_{i}}$</p><p>å…¶ä¸­ï¼Œ$\mu_{i}$ æ˜¯ç‰¹å¾å€¼çš„æ‰€æœ‰å€¼çš„å¹³å‡å€¼ï¼Œ$s_{i}$ æ˜¯å€¼çš„èŒƒå›´ï¼ˆæœ€å¤§ - æœ€å°ï¼‰ï¼Œæˆ–è€… $s_{i}$ æ˜¯æ ‡å‡†åå·®</p><p>å½“ç„¶ $x_{0} = 1$ å°±ä¸éœ€è¦ç»è¿‡ä¸Šè¿°çš„å¤„ç†äº†ï¼Œå› ä¸ºå®ƒæ°¸è¿œç­‰äº1ï¼Œä¸èƒ½æœ‰å‡å€¼ç­‰äº0çš„æƒ…å†µã€‚</p><hr><h2 id="å››-Gradient-Descent-in-Practice-II-Learning-Rate"><a href="#å››-Gradient-Descent-in-Practice-II-Learning-Rate" class="headerlink" title="å››. Gradient Descent in Practice II - Learning Rate"></a>å››. Gradient Descent in Practice II - Learning Rate</h2><p>å¦‚æœå­¦ä¹ ç‡ $\alpha $ å¤ªå°çš„è¯ï¼Œå°±ä¼šå¯¼è‡´æ”¶æ•›é€Ÿåº¦è¿‡æ…¢çš„é—®é¢˜ã€‚<br>å¦‚æœå­¦ä¹ ç‡ $\alpha $ å¤ªå¤§çš„è¯ï¼Œä»£ä»·å‡½æ•°å¯èƒ½ä¸ä¼šåœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½ä¸‹é™ï¼Œç”šè‡³å¯èƒ½ä¸æ”¶æ•›ï¼Œåœ¨æŸç§æƒ…å†µä¸‹ï¼Œå­¦ä¹ ç‡ $\alpha $ è¿‡å¤§ï¼Œä¹Ÿæœ‰å¯èƒ½å‡ºç°æ”¶æ•›ç¼“æ…¢ã€‚</p><p>å¯ä»¥é€šè¿‡ç»˜åˆ¶ä»£ä»·å‡½æ•°éšè¿­ä»£æ­¥æ•°å˜åŒ–çš„æ›²çº¿å»è°ƒè¯•è¿™ä¸ªé—®é¢˜ã€‚</p><p>$\alpha $ çš„å–å€¼å¯ä»¥ä» 0.001ï¼Œ0.003ï¼Œ0.01ï¼Œ0.03ï¼Œ0.1ï¼Œ0.3ï¼Œ1 è¿™å‡ ä¸ªå€¼å»å°è¯•ï¼Œé€‰ä¸€ä¸ªæœ€ä¼˜çš„ã€‚</p><hr><h2 id="äº”-Features-and-Polynomial-Regression"><a href="#äº”-Features-and-Polynomial-Regression" class="headerlink" title="äº”. Features and Polynomial Regression"></a>äº”. Features and Polynomial Regression</h2><p>å¯ä»¥é€šè¿‡æ”¹é€ ç‰¹å¾å€¼ï¼Œä¾‹å¦‚åˆå¹¶2ä¸ªç‰¹å¾ï¼Œç”¨ $ x_{3}$ æ¥è¡¨ç¤º $ x_{1} * x_{2} $</p><p>åœ¨å¤šé¡¹å¼å›å½’ä¸­ï¼Œé’ˆå¯¹ $ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{1}^{2} + \theta_{3}x_{1}^{3} $ ï¼Œæˆ‘ä»¬å¯ä»¥ä»¤ $ x_{2} = x_{1}^{2} , x_{3} = x_{1}^{3} $ é™ä½æ¬¡æ•°ã€‚</p><p>è¿˜å¯ä»¥è€ƒè™‘ç”¨æ ¹å·çš„å¼å­ï¼Œä¾‹å¦‚é€‰ç”¨  $ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}\sqrt{x} $</p><p>é€šè¿‡ä¸Šè¿°è½¬æ¢ä»¥åï¼Œéœ€è¦è®°å¾—ç”¨<strong>ç‰¹å¾å€¼ç¼©æ”¾ï¼Œå‡å€¼å½’ä¸€åŒ–ï¼Œè°ƒæ•´å­¦ä¹ é€Ÿç‡çš„æ–¹å¼è°ƒæ•´ä¸€ä¸‹</strong>ã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p><a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Multivariate_Linear_Regression.ipynb" target="_blank" rel="noopener">Source</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.2_Linear_Regression_With_One_Variable(Gradient_Descent)</title>
      <link href="/2020/01/26/1-2-linear-regression-with-one-variable/"/>
      <url>/2020/01/26/1-2-linear-regression-with-one-variable/</url>
      
        <content type="html"><![CDATA[<h1 id="Linear-Regression-With-One-Variable-Gradient-Descent"><a href="#Linear-Regression-With-One-Variable-Gradient-Descent" class="headerlink" title="Linear Regression With One Variable(Gradient Descent)"></a>Linear Regression With One Variable(Gradient Descent)</h1><h2 id="ä¸€-Model-Representation"><a href="#ä¸€-Model-Representation" class="headerlink" title="ä¸€. Model Representation"></a>ä¸€. Model Representation</h2><p>åœ¨ç»™å®šè®­ç»ƒé›†çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ å‡½æ•°hï¼šXâ†’Yï¼Œä½¿å¾—hï¼ˆxï¼‰æ˜¯yçš„ç›¸åº”å€¼çš„â€œå¥½â€é¢„æµ‹å™¨ã€‚ç”±äºå†å²åŸå› ï¼Œè¿™ä¸ªå‡½æ•°hè¢«ç§°ä¸ºå‡è®¾ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_0_1.png" alt=""></p><p>é€šè¿‡è¾“å…¥ä½æˆ¿é¢ç§¯ xï¼Œé€šè¿‡å­¦ä¹ å¥½çš„å‡½æ•°ï¼Œè¾“å‡ºæˆ¿å­çš„ä¼°ä»·ã€‚</p><h2 id="äºŒ-Cost-Function"><a href="#äºŒ-Cost-Function" class="headerlink" title="äºŒ. Cost Function"></a>äºŒ. Cost Function</h2><p>ä»£ä»·å‡½æ•°æ˜¯çº¿æ€§å›å½’ä¸­çš„ä¸€ä¸ªåº”ç”¨ï¼Œåœ¨çº¿æ€§å›å½’ä¸­ï¼Œè¦è§£å†³çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯æœ€å°åŒ–é—®é¢˜ã€‚</p><p>å‡è®¾åœ¨ä¸€å…ƒçº¿æ€§å›å½’ä¸­ï¼Œåœ¨ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€æ¡ç›´çº¿èƒ½å’Œè¯¥è®­ç»ƒé›†ä¸­çš„ç‚¹æœ€æ¥è¿‘ã€‚å‡è®¾ç›´çº¿æ–¹ç¨‹ä¸º </p><p>$$h_{\theta}(x) = \theta_{0} + \theta_{1}x$$</p><p>å¦‚ä½•é€‰æ‹© $\theta_{0}$ã€$\theta_{1}$ï¼Œä½¿å¾— $h_{\theta}(x)$ æ›´æ¥è¿‘äºè®­ç»ƒé›† (x,y) ï¼Ÿ</p><p>ä¸Šè¿°é—®é¢˜å¯ä»¥è½¬æ¢ä¸ºæ±‚ $$ \rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$  æ±‚æœ€å°å€¼$$\min_{{\theta_{0}} {\theta_{1}}} \rm{F}({\theta_{0},{\theta_{1}})} $$</p><h2 id="ä¸‰-Gradient-Descent-æ¢¯åº¦ä¸‹é™"><a href="#ä¸‰-Gradient-Descent-æ¢¯åº¦ä¸‹é™" class="headerlink" title="ä¸‰. Gradient Descent æ¢¯åº¦ä¸‹é™"></a>ä¸‰. Gradient Descent æ¢¯åº¦ä¸‹é™</h2><p>æ¢¯åº¦ä¸‹é™çš„ä¸»è¦æ€æƒ³ï¼š</p><ol><li><p>åˆå§‹åŒ–<br>$$<br>{\theta_{0}}å’Œ {\theta_{1}} , {\theta_{0}} = 0 , {\theta_{1}}=0<br>$$</p></li><li><p>ä¸æ–­çš„æ”¹å˜ ${\theta_{0}}$ å’Œ ${\theta_{1}}$ å€¼ï¼Œä¸æ–­å‡å°‘ $F({\theta_{0}},{\theta_{1}})$ ç›´è‡³è¾¾åˆ°æœ€å°å€¼ï¼ˆæˆ–è€…å±€éƒ¨æœ€å°ï¼‰ã€‚</p></li></ol><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_1_0.png" alt=""></p><p>æƒ³è±¡æˆä¸‹å±±ï¼Œå¦‚ä½•ä¸‹å±±çš„é€Ÿåº¦æœ€å¿«ï¼Ÿè¿™é‡Œæ¶‰åŠåˆ°äº†ä¸‹å±±çš„é€Ÿåº¦ï¼Œå³æ­¥é•¿ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_2_.png" alt=""></p><p>æœ‰è¶£çš„æ˜¯æ¢æ—è¾¹ä¸€ä¸ªç‚¹ï¼Œä¸‹å±±ï¼Œæ‰¾åˆ°çš„æœ€ä¼˜è§£å¯èƒ½å°±æ˜¯å¦ä¸€ä¸ªäº†ã€‚è¿™ä¹Ÿæ˜¯æ¢¯åº¦ä¸‹é™çš„ä¸€ä¸ªç‰¹ç‚¹ã€‚å®ƒä¼šæ‰¾åˆ°æ‰€æœ‰çš„å±€éƒ¨æœ€ä¼˜è§£å‡ºæ¥ã€‚</p><p>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œä¸æ–­æ›´æ–°ï¼š</p>\begin{align*}\rm{temp}0 &amp;:= {\theta_{0}} - \alpha * \frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) \\\rm{temp}1 &amp;:= {\theta_{1}} - \alpha * \frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) \\{\theta_{0}} &amp;:= \rm{temp}0 \\{\theta_{1}} &amp;:= \rm{temp}1 \\\end{align*}<p>ç›´åˆ°æ”¶æ•›ã€‚æ³¨æ„ ${\theta_{0}}$ å’Œ ${\theta_{1}}$ å€¼è¦<strong>åŒæ—¶æ›´æ–°</strong>ï¼Œ<strong>åˆ‡è®°ä¸è¦æ±‚ä¸€æ¬¡å¯¼æ›´æ–°ä¸€æ¬¡ï¼</strong></p><p>$\alpha$ è¢«ç§°ä½œä¸ºå­¦ä¹ é€Ÿç‡ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_3.gif" alt=""></p><p>å¦‚æœ $\alpha$ è¢«è®¾ç½®çš„å¾ˆå°ï¼Œéœ€è¦å¾ˆå¤šæ¬¡å¾ªç¯æ‰èƒ½åˆ°åº•æœ€ä½ç‚¹ã€‚<br>å¦‚æœ $\alpha$ è¢«è®¾ç½®çš„å¾ˆå¤§ï¼Œæ¥æ¥å›å›å¯èƒ½å°±ä¼šç¦»æœ€ä½ç‚¹è¶Šæ¥è¶Šè¿œï¼Œ<strong>ä¼šå¯¼è‡´æ— æ³•æ”¶æ•›ï¼Œç”šè‡³å‘æ•£</strong>ã€‚</p><p>å½“å¿«è¦åˆ°æœ€ä½ç‚¹çš„æ—¶å€™ï¼Œæ¢¯åº¦ä¸‹é™ä¼šè¶Šæ¥è¶Šæ…¢ï¼Œå› ä¸º $ \frac{\partial }{\partial {\theta}}$ è¶Šæ¥è¶Šå°ã€‚</p><h2 id="å…³äº-æ¢¯åº¦-å’Œ-åå¯¼æ•°-çš„å…³ç³»"><a href="#å…³äº-æ¢¯åº¦-å’Œ-åå¯¼æ•°-çš„å…³ç³»" class="headerlink" title="å…³äº æ¢¯åº¦ å’Œ åå¯¼æ•° çš„å…³ç³»"></a>å…³äº æ¢¯åº¦ å’Œ åå¯¼æ•° çš„å…³ç³»</h2><p>åœ¨ä¸Šé¢æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´ç”¨çš„æ˜¯åå¯¼æ•°è¿›è¡Œè®¨è®ºçš„ï¼Œå¯èƒ½ä¼šæœ‰äººæœ‰ç–‘é—®ï¼Œåå¯¼æ•°å’Œæ¢¯åº¦æœ‰å•¥å…³ç³»ï¼Ÿ</p><h3 id="1-å¯¼æ•°"><a href="#1-å¯¼æ•°" class="headerlink" title="1. å¯¼æ•°"></a>1. å¯¼æ•°</h3><p>å¦‚æœæ˜¯ä¸€å…ƒçš„ï¼Œé‚£ä¹ˆåå¯¼æ•°å°±é™çº§æˆäº†æ±‚å¯¼æ•°</p>$$ f^{'}(x_{0}) = \lim_{\Delta x\rightarrow 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta x\rightarrow 0} \frac{f(x_{0} + \Delta x) - f(x_{0})}{\Delta x} $$<p>å¯¼æ•°çš„å‡ ä½•æ„ä¹‰æ˜¯åˆ‡çº¿åœ¨è¯¥ç‚¹çš„æ–œç‡ï¼Œç‰©ç†æ„ä¹‰æ˜¯å‡½æ•°åœ¨è¿™ä¸€ç‚¹çš„ (ç¬æ—¶) å˜åŒ–ç‡ã€‚</p><h3 id="2-åå¯¼æ•°"><a href="#2-åå¯¼æ•°" class="headerlink" title="2. åå¯¼æ•°"></a>2. åå¯¼æ•°</h3><p>åœ¨æ¥çœ‹çœ‹åå¯¼æ•°çš„å®šä¹‰ï¼š</p>$$\begin{align*}f_{x}(x_{0},y_{0}) &amp; = \lim_{\Delta x \rightarrow 0} \frac{f(x_{0} + \Delta x , y_{0}) - f(x_{0},y_{0})}{\Delta x} \\ f_{y}(x_{0},y_{0}) &amp; = \lim_{\Delta y \rightarrow 0} \frac{f(x_{0} , y_{0} + \Delta y) - f(x_{0},y_{0})}{\Delta y} \\\end{align*}$$<p><img src="https://img.halfrost.com/Blog/ArticleImage/68_4.png" alt=""></p><p>åå¯¼æ•°çš„å‡ ä½•æ„ä¹‰ä¹Ÿæ˜¯åˆ‡çº¿çš„æ–œç‡ï¼Œä¸è¿‡ç”±äºåœ¨æ›²é¢ä¸Šï¼Œåœ¨ä¸€ä¸ªç‚¹ä¸Šä¸è¯¥æ›²é¢æ›²çº¿ç›¸åˆ‡çš„æ˜¯ä¸€ä¸ªé¢ï¼Œå°±æ„å‘³ç€åˆ‡çº¿æœ‰æ— æ•°æ¡ã€‚è¿™é‡Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯2æ¡åˆ‡çº¿ï¼Œä¸€ä¸ªæ¡æ˜¯å‚ç›´äº y è½´ï¼ˆå¹³è¡Œäº xOz å¹³é¢ï¼‰çš„åˆ‡çº¿ï¼Œå¦å¤–ä¸€æ¡æ˜¯å‚ç›´äº x è½´ï¼ˆå¹³è¡Œäº yOz å¹³é¢ï¼‰çš„åˆ‡çº¿ã€‚è¿™ä¸¤æ¡åˆ‡çº¿å¯¹åº”çš„æ–œç‡å°±æ˜¯å¯¹ X æ±‚åå¯¼å’Œå¯¹ Y æ±‚åå¯¼ã€‚</p><p>ä¸€ä¸ªå¤šå˜é‡å‡½æ•°çš„åå¯¼æ•°æ˜¯å®ƒå…³äºå…¶ä¸­ä¸€ä¸ªå˜é‡çš„å¯¼æ•°ï¼Œè€Œä¿æŒå…¶ä»–å˜é‡æ’å®šï¼ˆç›¸å¯¹äºå…¨å¯¼æ•°ï¼Œåœ¨å…¶ä¸­æ‰€æœ‰å˜é‡éƒ½å…è®¸å˜åŒ–ï¼‰ã€‚</p><p>åå¯¼æ•°çš„ç‰©ç†æ„ä¹‰è¡¨ç¤ºå‡½æ•°æ²¿ç€åæ ‡è½´æ­£æ–¹å‘ä¸Šçš„å˜åŒ–ç‡ã€‚</p><h3 id="3-æ–¹å‘å¯¼æ•°"><a href="#3-æ–¹å‘å¯¼æ•°" class="headerlink" title="3. æ–¹å‘å¯¼æ•°"></a>3. æ–¹å‘å¯¼æ•°</h3><p>åœ¨è¯´æ¢¯åº¦ä¹‹å‰ï¼Œä¸åº”è¯¥æ¼æ‰æ–¹å‘å¯¼æ•°ã€‚åå¯¼æ•°æ˜¯æ±‚çš„åœ¨ç‰¹å®šçš„2ä¸ªæ–¹å‘ä¸Šçš„å¯¼æ•°ï¼Œä½†æ˜¯ä»»æ„ä¸€ä¸ªæ–¹å‘ä¸Šä¹Ÿæ˜¯å­˜åœ¨å¯¼æ•°çš„ã€‚è¿™é‡Œå°±å¼•å…¥äº†æ–¹å‘å¯¼æ•°çš„æ¦‚å¿µã€‚</p><blockquote><p>è®¾å‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ çš„æŸç©ºé—´ä¸´åŸŸ $ U \subset R^{2}$ å†…æœ‰å®šä¹‰ï¼Œ L ä¸ºä»ç‚¹ $p_{0}$ å‡ºå‘çš„å°„çº¿ï¼Œ$p(x_{0},y_{0})$ ä¸º L ä¸Šä¸”åœ¨ U å†…çš„ä»»ä¸€ç‚¹ï¼Œä»¥ $t = \sqrt{(\Delta x)^{2} +(\Delta y)^{2} }$ è¡¨ç¤º $p$ ä¸ $p_{0}$ ä¹‹é—´çš„è·ç¦»ï¼Œè‹¥æé™ ï¼š</p></blockquote><blockquote>$$ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} = \lim_{t \rightarrow 0^{+}} \frac{f(x_{0} + tcos \alpha , y_{0}  +   tcos \beta) - f(x_{0},y_{0})}{t}$$<p>å­˜åœ¨ï¼Œåˆ™ç§°æ­¤æé™ä¸ºå‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}$ æ²¿æ–¹å‘ L çš„æ–¹å‘å¯¼æ•°ï¼Œè®°ä½œ $ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}$ ã€‚</p></blockquote><p>æ–¹å‘å¯¼æ•°æ˜¯åå¯¼æ•°çš„æ¦‚å¿µçš„æ¨å¹¿, åå¯¼æ•°ç ”ç©¶çš„æ˜¯æŒ‡å®šæ–¹å‘ (åæ ‡è½´æ–¹å‘) çš„å˜åŒ–ç‡ï¼Œåˆ°äº†æ–¹å‘å¯¼æ•°ï¼ŒæŒ‡å®šçš„æ–¹å‘å¯ä»¥æ˜¯ä»»æ„æ–¹å‘äº†ã€‚</p><blockquote><p>å¦‚æœå‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ å¯å¾®åˆ†ï¼Œé‚£ä¹ˆå‡½æ•°åœ¨è¯¥ç‚¹æ²¿ä»»ä¸€æ–¹å‘ L çš„æ–¹å‘å¯¼æ•°å­˜åœ¨ï¼Œä¸”æœ‰</p></blockquote><blockquote>$$ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} = f_{x}(x_{0},y_{0})cos \alpha + f_{y}(x_{0},y_{0})cos \beta$$</blockquote><blockquote><p>å…¶ä¸­ï¼Œ $cos \alpha  $ ï¼Œ$cos \beta$ æ˜¯æ–¹å‘ L çš„æ–¹å‘ä½™å¼¦ã€‚</p></blockquote><p>ä¸€ä¸ªæ ‡é‡åœºåœ¨æŸç‚¹æ²¿ç€æŸä¸ªå‘é‡æ–¹å‘ä¸Šçš„æ–¹å‘å¯¼æ•°ï¼Œæç»˜äº†è¯¥ç‚¹é™„è¿‘æ ‡é‡åœºæ²¿ç€è¯¥å‘é‡æ–¹å‘å˜åŠ¨æ—¶çš„ç¬æ—¶å˜åŒ–ç‡ã€‚è¿™ä¸ªå‘é‡æ–¹å‘å¯ä»¥æ˜¯ä»»ä¸€æ–¹å‘ã€‚</p><p>æ–¹å‘å¯¼æ•°çš„ç‰©ç†æ„ä¹‰è¡¨ç¤ºå‡½æ•°åœ¨æŸç‚¹æ²¿ç€æŸä¸€ç‰¹å®šæ–¹å‘ä¸Šçš„å˜åŒ–ç‡ã€‚</p><h3 id="4-æ¢¯åº¦"><a href="#4-æ¢¯åº¦" class="headerlink" title="4. æ¢¯åº¦"></a>4. æ¢¯åº¦</h3><p>æœ€åæ¥è®²è®²æ¢¯åº¦ï¼Œæ¢¯åº¦çš„å®šä¹‰ï¼š</p><blockquote><p>åœ¨äºŒå…ƒå‡½æ•°çš„æƒ…å½¢ï¼Œè®¾å‡½æ•° $f(x,y)$ åœ¨å¹³é¢åŒºåŸŸ D å†…å…·æœ‰ä¸€é˜¶è¿ç»­åå¯¼æ•°ï¼Œåˆ™å¯¹äºæ¯ä¸€ç‚¹ $P_{0}(x_{0},y_{0}) \in D $,éƒ½å¯å®šå‡ºä¸€ä¸ªå‘é‡ï¼š</p></blockquote><blockquote>$$ f_{x}(x_{0},y_{0}) \vec{i} + f_{y}(x_{0},y_{0}) \vec{j} $$</blockquote><blockquote><p>è¿™ä¸ªå‘é‡ç§°ä¸ºå‡½æ•° $f(x,y)$ åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ çš„æ¢¯åº¦ï¼Œè®°ä½œ $ \textbf{grad}\;\;f(x_{0},y_{0}) $ æˆ– $ \triangledown f(x_{0},y_{0}) $ , å³</p></blockquote><blockquote>$$ \textbf{grad}\;\;f(x_{0},y_{0}) = \triangledown f(x_{0},y_{0}) = f_{x}(x_{0},y_{0}) \vec{i} + f_{y}(x_{0},y_{0}) \vec{j} $$</blockquote><blockquote><p>å…¶ä¸­ $ \triangledown = \frac{\partial }{\partial x} \vec{i} + \frac{\partial }{\partial y} \vec{j} $ ç§°ä¸º (äºŒç»´çš„) å‘é‡å¾®åˆ†ç®—å­ æˆ–è€… Nabla ç®—å­ï¼Œ $ \triangledown f = \frac{\partial f}{\partial x} \;\; \vec{i} + \frac{\partial f }{\partial y} \;\; \vec{j} $</p></blockquote><p>å¦‚æœå‡½æ•° $f(x,y)$ åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ å¯å¾®åˆ†ï¼Œ $\vec{e_{j}} = (cos \alpha,cos \beta)$ æ˜¯ä¸æ–¹å‘ L åŒå‘çš„å•ä½å‘é‡ï¼Œåˆ™ï¼š</p>$$\begin{align*}\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} &amp;= f_{x}(x_{0},y_{0})cos \alpha + f_{y}(x_{0},y_{0})cos \beta \\&amp;= \textbf{grad}\;\;f(x_{0},y_{0}) \cdot \vec{e_{j}} = \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right | cos \theta \\\end{align*}$$<p>å…¶ä¸­ $ \theta $ ä¸º $ \textbf{grad};;f(x_{0},y_{0}) $ ä¸ $ \vec{e_{j}} $ çš„å¤¹è§’ã€‚</p><ol><li>å½“ $\theta = 0 $ çš„æ—¶å€™ï¼Œ$\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}  = \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right |$</li></ol><p>å³ <strong>å‡½æ•° $f(x,y)$ åœ¨ä¸€ç‚¹çš„æ¢¯åº¦ $ \textbf{grad};;f $ æ˜¯è¿™æ ·çš„ä¸€ä¸ªå‘é‡ï¼Œå®ƒçš„æ–¹å‘æ˜¯å‡½æ•°åœ¨è¿™ç‚¹çš„æ–¹å‘å¯¼æ•°å–å¾—æœ€å¤§å€¼çš„æ–¹å‘ï¼Œå®ƒçš„æ¨¡å°±ç­‰äºæ–¹å‘å¯¼æ•°çš„æœ€å¤§å€¼</strong> ã€‚</p><ol start="2"><li>å½“ $\theta = \pi $ çš„æ—¶å€™ï¼Œ$\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}  = - \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right |$</li></ol><p>å³ $ \vec{e_{j}} $ ä¸ æ¢¯åº¦ æ–¹å‘ç›¸åçš„æ—¶å€™ï¼Œå‡½æ•°å‡å°‘æœ€å¿«ï¼Œåœ¨è¿™ä¸ªæ–¹å‘çš„æ–¹å‘å¯¼æ•°è¾¾åˆ°æœ€å°å€¼ã€‚</p><p><strong>æ‰€ä»¥æ¢¯åº¦ä¸‹é™å°±æ˜¯åŸºäºè¿™ä¸ªåŸç†</strong>ã€‚</p><p>å‡½æ•°åœ¨æŸä¸€ç‚¹å¤„çš„æ–¹å‘å¯¼æ•°åœ¨å…¶æ¢¯åº¦æ–¹å‘ä¸Šè¾¾åˆ°æœ€å¤§å€¼ï¼Œæ­¤æœ€å¤§å€¼å³æ¢¯åº¦çš„æ¨¡æ•°ã€‚</p><p>è¿™å°±æ˜¯è¯´ï¼Œæ²¿æ¢¯åº¦æ–¹å‘ï¼Œå‡½æ•°å€¼å¢åŠ æœ€å¿«ã€‚åŒæ ·å¯çŸ¥ï¼Œæ–¹å‘å¯¼æ•°çš„æœ€å°å€¼åœ¨æ¢¯åº¦çš„ç›¸åæ–¹å‘å–å¾—ï¼Œæ­¤æœ€å°å€¼ä¸ºæœ€å¤§å€¼çš„ç›¸åæ•°ï¼Œä»è€Œæ²¿æ¢¯åº¦ç›¸åæ–¹å‘å‡½æ•°å€¼çš„å‡å°‘æœ€å¿«ã€‚</p><table><thead><tr><th>æ¦‚å¿µ</th><th>ç‰©ç†æ„ä¹‰</th></tr></thead><tbody><tr><td>å¯¼æ•°   $ f^{â€˜}(x)  $</td><td>å‡½æ•°åœ¨è¯¥ç‚¹çš„ç¬æ—¶å˜åŒ–ç‡</td></tr><tr><td>åå¯¼æ•° $ \frac{\partial f(x,y) }{\partial x}  $</td><td>å‡½æ•°åœ¨åæ ‡è½´æ–¹å‘ä¸Šçš„å˜åŒ–ç‡</td></tr><tr><td>æ–¹å‘å¯¼æ•°</td><td>å‡½æ•°åœ¨æŸç‚¹æ²¿æŸä¸ªç‰¹å®šæ–¹å‘çš„å˜åŒ–ç‡</td></tr><tr><td>æ¢¯åº¦  $ \textbf{grad};;f(x,y)  $</td><td>å‡½æ•°åœ¨è¯¥ç‚¹æ²¿æ‰€æœ‰æ–¹å‘å˜åŒ–ç‡æœ€å¤§çš„é‚£ä¸ªæ–¹å‘</td></tr></tbody></table><h2 id="å››-Linear-Regression-çº¿æ€§å›å½’"><a href="#å››-Linear-Regression-çº¿æ€§å›å½’" class="headerlink" title="å››. Linear Regression çº¿æ€§å›å½’"></a>å››. Linear Regression çº¿æ€§å›å½’</h2><p>æ¢¯åº¦ä¸‹é™æ˜¯å¾ˆå¸¸ç”¨çš„ç®—æ³•ï¼Œå®ƒä¸ä»…è¢«ç”¨åœ¨çº¿æ€§å›å½’ï¼Œè¿˜ç”¨åœ¨çº¿æ€§å›å½’æ¨¡å‹ã€å¹³æ–¹è¯¯å·®ä»£ä»·å‡½æ•°ä¸­ã€‚</p>\begin{align*}\frac{\partial }{\partial {\theta_{j}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp; = \frac{\partial }{\partial {\theta_{j}}} \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\\end{align*}<p>ä»¤ $ z = (h_{\theta}(x^{(i)})-y^{(i)})^2$ , $ u = h_{\theta}(x^{(i)})-y^{(i)}$ , åˆ™ $ z = u^2 $ã€‚ è€ƒè™‘åˆ° $f(z)$  å’Œ $f(u)$ éƒ½æ˜¯è¿ç»­çš„ï¼Œåˆ™æœ‰ï¼š</p>\begin{align*}\frac{\partial }{\partial {\theta_{j}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp; = \frac{\partial }{\partial {\theta_{j}}} \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\&amp; = \frac{1}{2m}\sum_{i = 1}^{m} \frac{\partial z }{\partial u} \frac{\partial u }{\partial {\theta_{j}}} = \frac{1}{2m} * 2 \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{j}}}\\&amp; = \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{j}}} \\\end{align*}<p>++++++++++++</p><p>å°† u å±•å¼€ $ u = \theta_{0} + {\theta_{1}}x^{(i)}-y^{(i)}$ , ä»¤ j = 0,åˆ™æœ‰</p>\begin{align*}\frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp;= \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{0}}} \\&amp;= \frac{1}{m} \sum_{i = 1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)}) = \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) \\\end{align*}<p>ä»¤ j = 1,åˆ™æœ‰</p>\begin{align*}\frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp;=  \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{1}}}\\&amp;= \frac{1}{m} \sum_{i = 1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)}) * x^{(i)} = \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\\end{align*}<p>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼š</p> \begin{align*}\rm{temp}0 &amp;:= {\theta_{0}} - \alpha * \frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) = {\theta_{0}} - \alpha * \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})  \\\rm{temp}1 &amp;:= {\theta_{1}} - \alpha * \frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) = {\theta_{1}} - \alpha * \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\{\theta_{0}} &amp;:= \rm{temp}0  \\{\theta_{1}} &amp;:= \rm{temp}1  \\\end{align*}<p>å½“ç„¶é™¤äº†ç”¨æ¢¯åº¦ä¸‹é™çš„è¿­ä»£ç®—æ³•ï¼Œè¿˜æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥ç®—å‡ºä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼Œæ¯”å¦‚çº¿æ€§ä»£æ•°é‡Œé¢çš„ æ­£è§„æ–¹ç¨‹ç»„æ³•ã€‚ä½†æ˜¯ä¸¤è€…ç›¸æ¯”è¾ƒè€Œè¨€ï¼Œæ¢¯åº¦ä¸‹é™é€‚åˆæ›´å¤§çš„æ•°æ®é›†ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ä¸æ–­æ›´æ–°ä»¥åï¼Œçº¿æ€§å›å½’ä»¥åçš„æ›²çº¿å’ŒåŸå§‹æ•°æ®é›†ä¼šè¶Šæ¥è¶Šæ‹Ÿåˆã€‚</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npx_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.91</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.23</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.923</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.941</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.543</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.744</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.674</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">5.33</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.31</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.68</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.99</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.54</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.89</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.86</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.63</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.6453</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.75</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.345</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.5754</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.35654</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.43646</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.6443</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.64534</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.7457</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.6464</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.74643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.42</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.1243</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.088</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.342</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.22</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.44</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.33</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.91</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.23</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.923</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.941</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.543</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.744</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.674</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">5.33</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.31</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.68</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.99</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.54</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.89</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inlineplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token string">'bo'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'real'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_data<span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'estimated'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>&lt;matplotlib.legend.Legend at 0x7fa6805ab128&gt;</code></pre><p><img src="/2020/01/26/1-2-linear-regression-with-one-variable/output_7_1.png" alt="output"></p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.1_What_is_Machine_Learning</title>
      <link href="/2020/01/19/1-1-what-is-machine-learning/"/>
      <url>/2020/01/19/1-1-what-is-machine-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="What-is-Machine-Learning"><a href="#What-is-Machine-Learning" class="headerlink" title="What is Machine Learning"></a>What is Machine Learning</h1><p><img src="/2020/01/19/1-1-what-is-machine-learning/machine-learning.png" alt="Machine_Learning"></p><h2 id="ä¸€ã€-Definition"><a href="#ä¸€ã€-Definition" class="headerlink" title="ä¸€ã€ Definition"></a>ä¸€ã€ Definition</h2><p>å®šä¹‰ï¼š</p><p>1997å¹´ï¼Œ<code>Tom Mitchell</code> ç»™å‡ºæœºå™¨å­¦ä¹ çš„å®šä¹‰ï¼š</p><pre><code>ç¨‹åºåˆ©ç”¨ç»éªŒEæ”¹å–„äº†åœ¨ä»»åŠ¡Tä¸­çš„æ€§èƒ½Pï¼Œå°±å¯ä»¥è¯´ï¼šå…³äºä»»åŠ¡Tå’Œæµ‹é‡æ€§èƒ½Pï¼Œè¯¥ç¨‹åºå¯¹ç»éªŒEè¿›è¡Œäº†å­¦ä¹ ã€‚</code></pre><h2 id="äºŒã€-Classify"><a href="#äºŒã€-Classify" class="headerlink" title="äºŒã€ Classify"></a>äºŒã€ Classify</h2><p>åˆ†ç±»ï¼š</p><ul><li>æœ‰ç›‘ç£å­¦ä¹ <code>supervised learning</code> :å·²çŸ¥çš„Data Setä¸­æ˜ç¡®äº†è¾“å…¥/è¾“å‡ºï¼Œä¸”è¾“å…¥å’Œè¾“å‡ºå­˜åœ¨å…³ç³»ã€‚ <ul><li><code>Supervised Learning</code>å¯ä»¥åˆ†ä¸ºï¼šåˆ†ç±»(Classification)å’Œå›å½’(Regression)é—®é¢˜ã€‚</li><li><ol><li>Classificationï¼š é¢„æµ‹ç¦»æ•£çš„ç»“æœã€‚å°†è¾“å…¥æ˜ å°„åˆ°ç¦»æ•£çš„ç±»åˆ«ä¸­ã€‚</li></ol></li><li><ol start="2"><li>Regressionï¼š é¢„æµ‹è¿ç»­è¾“å‡ºä¸­çš„ç»“æœã€‚ ä»è¾“å…¥æ˜ å°„åˆ°æŸä¸ªè¿ç»­çš„å‡½æ•°çš„è¾“å‡ºä¸­ã€‚</li></ol></li></ul></li></ul><blockquote><p>æ— ç›‘ç£å­¦ä¹ ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¾ˆå°‘æˆ–æ ¹æœ¬ä¸çŸ¥é“æˆ‘ä»¬çš„ç»“æœåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚<strong>æˆ‘ä»¬å¯ä»¥ä»æ•°æ®ä¸­å¾—å‡ºç»“æ„</strong>ï¼Œæˆ‘ä»¬ä¸ä¸€å®šçŸ¥é“å˜é‡çš„å½±å“ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡åŸºäºæ•°æ®ä¸­å˜é‡ä¹‹é—´çš„å…³ç³»å¯¹æ•°æ®è¿›è¡Œèšç±»æ¥æ¨å¯¼å‡ºè¿™ç§ç»“æ„ã€‚ åœ¨æ— ç›‘ç£å­¦ä¹ çš„æƒ…å†µä¸‹ï¼Œ<strong>æ²¡æœ‰åŸºäºé¢„æµ‹ç»“æœçš„åé¦ˆ</strong>ã€‚æ— ç›‘ç£å­¦ä¹ å¯ä»¥åˆ†ä¸ºâ€œèšç±»â€å’Œâ€œéèšç±»â€ã€‚</p></blockquote><ul><li>æ— ç›‘ç£å­¦ä¹ <code>unsupervised learning</code> : æ²¡æœ‰é¢„çŸ¥çš„labelï¼Œä»å˜é‡çš„ç»“æ„ä¸­å¯»æ‰¾å…³ç³»ï¼Œè€Œæ²¡æœ‰åŸºäºé¢„æµ‹ç»“æœçš„åé¦ˆã€‚<ul><li><code>Unspervised Learning</code>å¯ä»¥åˆ†ä¸º<code>èšç±»</code>ï¼Œ å’Œ <code>éèšç±»</code>ã€‚</li><li><ol><li>èšç±»ï¼š å¯ä»¥ç†è§£ä¸ºå¯¹æ•°æ®è‡ªåŠ¨åˆ†ç»„æˆä¸åŒå˜é‡çš„ç›¸ä¼¼æˆ–è€…ç›¸å…³çš„ç°‡ã€‚</li></ol></li><li><ol start="2"><li>éèšç±»ï¼š æ¯”å¦‚â€œé¸¡å°¾é…’ä¼šç®—æ³•â€â€“&gt;ä»æ··ä¹±çš„ç¯å¢ƒä¸­è¯†åˆ«å’ŒæŸ¥æ‰¾ç»“æœã€‚</li></ol></li></ul></li></ul><blockquote><p>å‚è€ƒï¼š GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19å¹´å²æœ«</title>
      <link href="/2019/12/31/19-nian-sui-mo/"/>
      <url>/2019/12/31/19-nian-sui-mo/</url>
      
        <content type="html"><![CDATA[<h1 id="æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–"><a href="#æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–" class="headerlink" title="æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–"></a>æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–</h1><p>2020æ˜¯ä¸ªå¾ˆæœ‰æ„æ€çš„å¹´ä»½ï¼ŒABABçš„å½¢å¼æœ—æœ—ä¸Šå£ï¼Œå¦‚æœè¦è¿™æ ·ä¸¥æ ¼çš„ç®—çš„è¯ï¼Œä¸Šä¸€ä¸ªè¿™æ ·çš„å¹´ä»½æ˜¯1919å¹´ï¼Œç›¸éš”101å¹´äº†å·²ç»ï¼Œä¸‹ä¸€æ¬¡è¦åˆ°2121ï¼Œåˆæ˜¯101å¹´ä»¥åï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬ä¸€ç”Ÿä¸­ï¼Œåªä¼šç»å†è¿™æ ·ä¸€æ¬¡çš„ABABå¹´ä»½ï¼Œå®åœ¨æ˜¯å€¼å¾—ç”¨åŠ›å»è®°å¿†å’Œæ„Ÿå—ã€‚</p><h2 id="2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ"><a href="#2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ" class="headerlink" title="2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ"></a>2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ</h2><blockquote><p>Sometimes it lasts in love, sometimes it hurt instead.</p></blockquote><p>ä¸€ä¸ªå¹¶ä¸æ“…é•¿çš„æŠ€èƒ½ï¼Œä¸€æ®µè¯´ä¸æ¸…é“ä¸æ˜çš„å…³ç³»ï¼Œä¸€ä¸ªä¸å¥½ä¸åçš„å·¥ä½œæœºä¼šã€‚è¿˜æœ‰ä¸€ä¸ªä¸çŸ¥é“æ˜¯åœ¨æˆé•¿è¿˜æ˜¯åœ¨å˜è€çš„è‡ªå·±ã€‚</p><h3 id="æŠ€èƒ½"><a href="#æŠ€èƒ½" class="headerlink" title="æŠ€èƒ½"></a>æŠ€èƒ½</h3><blockquote><p>å…³äºé¡¹ç›®</p></blockquote><p>åœ¨å¤æ—¦çš„ä¸€å¹´åŠï¼Œè¯´æ˜¯å­¦ä¹ NLPï¼Œå…¶å®åˆ°äº†æœ€åä¹Ÿåªæ˜¯ä¸€ç›´åœ¨çš®æ¯›çš„å±‚é¢æ™ƒæ‚ ï¼Œæ€»æ˜¯æ— æ³•æ·±å…¥ã€‚</p><p>å…¶å®è‡ªå·±ä¹Ÿæ¸…æ¥šè‡ªå·±çš„åŸå› åœ¨å“ªè¾¹ï¼Œå¾ˆéš¾ä¸“æ³¨ä¸€ä¸ªæ–¹å‘ï¼Œå„ç§éƒ½åœ¨å¥½å¥‡ï¼Œç»“æœå°±æ˜¯çœ‹ä¸¤ç¯‡è®ºæ–‡å°±ç®—äº†ï¼Œå…¶å®è¿‡ä¸¤å¤©ä¹Ÿå°±å¿˜äº†ã€‚NLPæˆ–è€…è¯´æ˜¯æ·±åº¦å­¦ä¹ ï¼Œæ–¹å‘åƒå¥‡ç™¾æ€ªï¼Œå…¶å®å‰æœŸæ‰¾å‡†ä¸€ä¸ªæœ‰å·¥ä¸šåº”ç”¨å‰æ™¯çš„æ–¹å‘ï¼Œæ¯”å¦‚å¯¹è¯ç³»ç»Ÿï¼Œæ‘˜è¦ï¼Œè¿™ç§ï¼Œæ²¿ç€ä¸€ç¯‡ç»¼è¿°ç‹¬ç«‹å¼€å±•ç ”ç©¶ï¼Œä»£ç å’Œè®ºæ–‡åŒæ—¶å¼€å§‹ï¼Œå†çœ‹äº›ç›¸å…³çš„æ¯”èµ›å¼€æºçš„ä»£ç ï¼Œåº”è¯¥åŠå¹´å°±èƒ½å…¥é—¨ã€‚è¿™ä¸ªäº‹æƒ…åªèƒ½è¯´æ˜è‡ªå·±æµ®èºï¼Œæµ®èºæ˜¯ç§‘ç ”çš„å¤§å¿Œï¼Œæ‰€ä»¥æˆ‘ä¸é€‚åˆè¯»åšäº†ï¼Œè‡³å°‘ç›®å‰çœ‹æ¥æ˜¯è¿™æ ·çš„ã€‚</p><p>å•Šæˆ‘çœŸæ˜¯ä¸ªæ†¨æ†¨ã€‚</p><p>æœ€æ°”çš„æ˜¯æœ€åTensorflowå’ŒPyTorchå±…ç„¶ä¸€ä¸ªéƒ½ä¸ç†Ÿâ€¦æˆ‘è¿™æ¸£æ¸£å·¥ç¨‹èƒ½åŠ›æ€»æ˜¯ä¼šç»™æˆ‘å·¨å¤§çš„æ‰“å‡»â€¦</p><blockquote><p>å…³äºå®éªŒå®¤</p></blockquote><p>2018å¹´5æœˆä»½å¼€å§‹åœ¨ç‹è€å¸ˆçš„EDAå®éªŒå®¤å‘†äº†ä¸€ä¸ªå¤šæœˆï¼Œè®¤è¯†äº†å¸ˆå…„åˆ˜æ·‡ï¼Œå’Œé’Ÿç¨‹åŒå­¦ä¸€èµ·æC++ç¼–è¯‘å™¨ï¼Œç»“æœæˆ‘æ€»æ˜¯éš¾ä»¥å…¥é—¨ï¼Œé‚£æ—¶å€™æˆ‘å¤§æ¦‚è¿æ€ä¹ˆæŸ¥èµ„æ–™éƒ½ä¸ä¼šã€‚è€Œä¸”è«åå…¶å¦™çš„å«‰å¦’é’Ÿç¨‹ï¼Œè¶Šæ¥è¶Šéš¾å—ï¼Œæ‰€ä»¥æœ€åè¿˜æ˜¯ç¦»å¼€äº†ã€‚</p><p>å½“æ—¶çš„å¥‘æœºæ˜¯å¬åˆ˜æ¶›è®²ç®—æ³•ä¼šæ›´æœ‰â€é’±é€”â€œï¼Œå°±å¿ƒåŠ¨æ¥äº†IBICASï¼Œå½“æ—¶å®éªŒå®¤è¿˜å«åšBCRCï¼Œäº‹å®è¯æ˜ï¼Œä¸ç®¡å“ªä¸€ä¸ªæ–¹å‘ï¼Œåªè¦å­¦å¾—å¥½å°±ç‰›é€¼ï¼ŒåŒä¸ºITåŸºæœ¬ä¸å­˜åœ¨å“ªä¸ªæ–¹å‘æ˜æ˜¾æ›´æœ‰â€˜â€™é’±é€”â€œï¼ŒæŠ„è¿‘è·¯çš„æ–¹å¼æ˜¯ä¸å¯å–çš„â€¦æœ€åæˆ‘çš„offerä¸å¦‚ä¸€ç›´åšICçš„åŒå­¦ï¼Œå¾ˆå¤§çš„æ•™è®­ï¼Œä»”ç»†æƒ³åšä»€ä¹ˆäº‹æƒ…éƒ½æ˜¯è¿™ä¸ªé“ç†å§â€¦<strong>è¦æ€€ç€åšåˆ°æœ€å¥½çš„å¿ƒæ€å»åšäº‹æƒ…</strong></p><p>æœ€æœ‰æ„æ€çš„æ˜¯æœ€åçš„offerå±…ç„¶è¿˜æ˜¯C++å¼€å‘ï¼Œæœç„¶æ˜¯æœ‰ä¸€ç§å¾ªç¯ã€‚</p><blockquote><p>å…³äºè¯¾ç¨‹</p></blockquote><p>å¤æ—¦å·¥ç¡•çš„è¯¾ç¨‹æœ¬æ¥è®¾ç½®çš„å°±å¾ˆå¤šï¼Œå„ç§è¯¾ç¨‹å„ç§å­¦åˆ†ï¼Œè®©äººå¤´å¤§â€¦</p><p>ç ”ä¸€çš„æ—¶å€™æˆ‘æ€»æ˜¯å¿ƒå¤§ï¼Œæƒ³ç€å°½å¿«ä¿®å®Œå­¦åˆ†å»å®ä¹ ï¼Œæ‰€ä»¥ç¬¬ä¸€å­¦æœŸé€‰è¯¾12é—¨ï¼ŒçœŸçš„ä½œæ­»ï¼Œè€Œä¸”ç´¯æ˜¯æ¬¡è¦ï¼Œå› ä¸ºåªæ˜¯ä¸ºäº†æ—¶é—´ä¸å†²çªé€‰äº†å¾ˆå¤šä¸ä¼šç”¨åˆ°çš„è¯¾ç¨‹ï¼Œæ¯”å¦‚MEMSï¼Œè´¼æ°”çš„ä¸€é—¨ï¼Œæœ€åç»©ç‚¹ä¹Ÿç›¸åº”çš„å¾ˆä½ã€‚</p><p>æ¯•ç«Ÿä¸æ˜¯è®¡ç®—æœºä¸“ä¸šï¼Œå¤§éƒ¨åˆ†çš„è¯¾ç¨‹éƒ½æ˜¯é›†æˆç”µè·¯ï¼Œå®é™…ä¸Šå¯¹æˆ‘çš„é¡¹ç›®å’Œå°†æ¥çš„å®ä¹ å·¥ä½œå¸®åŠ©éƒ½ä¸å¤§ï¼Œç°åœ¨å›å¿†ï¼Œè¿˜æ˜¯è§‰å¾—æ˜¯åœ¨æ··å­¦åˆ†ã€‚</p><p>ä¸è¿‡å®åœ¨æ˜¯å¯¹ICå…´è¶£ä¸å¤§ï¼Œé‚£æˆ‘å–œæ¬¢ä»€ä¹ˆå‘¢ï¼Ÿå¤§æ¦‚å°±æ˜¯æ–°é²œçš„èƒ½ç†è§£èƒ½çœ‹åˆ°çš„ç‚«é…·ä¸€ç‚¹çš„ä¸œè¥¿ã€‚è¿™æ ·æƒ³æƒ³æˆ‘æ¢äº†è½¯å¼€ï¼Œæ¢äº†ç®—æ³•ï¼Œä¹Ÿä¸èƒ½è¯´æ˜¯å®Œå…¨çœ‹åœ¨â€é’±é€”â€œçš„è¯±æƒ‘ä¸Šé¢â€¦hhh</p><h3 id="å…³ç³»"><a href="#å…³ç³»" class="headerlink" title="å…³ç³»"></a>å…³ç³»</h3><p>2019å¹´æ˜¯æˆ‘é¢ä¸´å„ç§å…³ç³»æœ€å¤šä¸€å¹´ï¼Œå½“ç„¶ä¸»è¦æ˜¯ç”·å¥³ç”Ÿçš„å…³ç³»å‘ç”Ÿäº†å·¨å¤§çš„å˜åŒ–ã€‚å¯¹äºè¿™äº›ï¼Œå½“æˆ‘èº«å¤„å…¶ä¸­çš„æ—¶å€™ï¼Œå†…å¿ƒå¿å¿‘ä¹Ÿæ¿€åŠ¨æœŸå¾…ï¼Œå¯æ˜¯åˆ°äº†ä»Šå¤©å½»åº•è„±ç¦»è¿™äº›ï¼Œç•™ä¸‹çš„åªæœ‰ç©ºè™šå’Œæ»¡åœ°çš„é¸¡æ¯›â€¦</p><blockquote><p>Chen Jiawen</p></blockquote><p>é™ˆè®¤è¯†åœ¨ä¸€å‘¨cpä¸Šï¼Œ2018.06ï¼Œåœ¨æˆ‘åˆšåˆšæ¥ä¸Šæµ·ï¼Œä¸€åˆ‡éƒ½æ˜¯å¾ˆå¥½å¥‡å¾ˆæ–°é²œï¼Œæˆ‘ä»¬ä»ç½‘ç»œä¸Šè®¤è¯†å’Œå¼€å§‹ï¼Œåˆ°2020.01.01ï¼Œä¹Ÿä»ç½‘ç»œä¸Šç»“æŸï¼Œä¸­é—´åˆ†åˆ†åˆåˆä¹‹ä¹…ï¼Œå®Œå…¨å†™ä¸€æœ¬è®©äººé¸¡çš®æ‰è½çš„çŸ«æƒ…å°è¯´ã€‚</p><p>2018.06å¥¹åŒæ„ä¸€èµ· â€”&gt; 2018.06å¥¹ç«‹åˆ»æ‚„æ‚„å›å®¶å‡†è€ƒç ”ï¼Œå¹¶æ²¡èƒ½è§é¢ â€”&gt; å¥¹åœ¨å®¶å­¦ä¹ ï¼Œä¸¤ä¸ªå¯‚å¯çš„äººæ€»æ˜¯äº’ç›¸é™ªä¼´ â€”&gt; å› ä¸ºçªç„¶èƒ–äº†å¾ˆå¤šæˆ–è€…å…¶ä»–ä¸€äº›çç¢çš„å°äº‹ï¼Œæˆ‘å¯¹å¥¹ç”Ÿæ°”è¿‡å¾ˆå¤šæ¬¡ â€”&gt; 2018.12è€ƒç ”ç»“æŸï¼Œæˆ‘æå‡ºåˆ†æ‰‹ â€”&gt; 2019.02æˆç»©å‡ºæ¥ï¼Œè½æ¦œï¼Œå¥¹æŒ½å›ï¼Œæˆ‘ä»¬åˆåœ¨ä¸€èµ· â€”&gt; å®šä¸‹å†é™ªä¸€å¹´ â€”&gt; ä¸­é—´å„ç§çŸ›ç›¾ï¼Œçº ç¼ ï¼Œåˆ†æ‰‹ä¸æ–­ â€”&gt; 2019.10æˆ‘å¯¹æ–‡åéœ²äº†ä¸€äº›å¿ƒäº‹ï¼Œå’Œé™ˆä¸å†æƒ³ç€æŒ½å› â€”&gt; 2019.11å½»åº•ç»“æŸ â€”&gt; 2019.12.31å› ä¸ºæ±ªï¼Œå¥¹æƒ³æŒ½å› â€”&gt; 2020.01.01,ç»ˆäºè½®åˆ°å¥¹ä¸»åŠ¨ææ‹œæ‹œï¼Œå¥½è¿ã€‚</p><p><strong><em>å…ƒæ—¦å¿«ä¹ï¼ŒCJWï¼ç¥ 2020å¹´ï¼Œå¿ƒæƒ³äº‹æˆ~</em></strong></p><p>å…¶å®æˆ‘å¯¹åˆ«äººçš„è¦æ±‚ï¼Œåœ¨è¿™ä¹‹åå†ä¹Ÿä¸ä¼šæœ‰äº†ï¼Œæ˜ç™½äº†ä¸€ä»¶äº‹æƒ…ï¼šå–œæ¬¢å°±æ˜¯å–œæ¬¢ï¼Œä¸å–œæ¬¢å°±æ˜¯ä¸å–œæ¬¢ï¼Œå–œæ¬¢çš„æ²¾æ»¡æ³¥åœŸä¹Ÿä¸ä¼šæŒ‘å‰”ã€‚</p><blockquote><p>Wang Lu</p></blockquote><p>æŠ±æ­‰ï¼Œ2019.11-2019.12ï¼Œä¸€ä¸ªå¤šæœˆï¼Œæ²¡èƒ½åˆ°æœ€åï¼Œæˆ‘çœŸçš„è ¢ã€‚</p><p>å”¯ä¸€æœ‹å‹åœˆå®˜å®£å®¶äººä¹ŸçŸ¥é“çš„ä¸€ä½ï¼Œç»“æœè¶Šæ¥è¶Šç´¯ï¼Œæˆ‘æƒ³è¦çš„æ„Ÿæƒ…ä¸æ˜¯è¿™ç§è¢«æ¯”è¾ƒè¡¡é‡ä¹‹åè§‰å¾—å¯¹æ–¹ä¸é”™å°±okçš„ï¼Œè¿™æ®µå…³ç³»é‡Œé¢ï¼Œæˆ‘æ˜¯æƒ³æŠ¤ä½ çˆ±ä½ çš„ï¼Œä¸€ä¸ªæ¯”æˆ‘å¹´é¾„å°çš„å¥³å­©å­æ¯”æˆ‘è¦æˆç†Ÿã€‚è¿›è¡Œä¸‹å»çœŸçš„å¤ªç´¯äº†ï¼Œèº«å¿ƒä¿±ç–²ï¼Œæ‰¿è®¤è‡ªå·±å¹¶ä¸æ˜¯ä¹‹å‰æƒ³çš„é‚£æ ·å¯¹å¥³ç”Ÿæ— è¦æ±‚ã€‚å–œæ¬¢è¿™ç§å°äº‹ï¼Œæ²¡æœ‰è§¦ç¢°åˆ°é‚£æ ¹å¼¦ï¼Œå°±æ³¨å®šæ²¡æœ‰å¯èƒ½å‘ç”Ÿäº†å§ã€‚</p><p>è™½ç„¶æˆ‘æ˜¯è¦è¯´æŠ±æ­‰çš„ä¸€æ–¹ï¼Œä½†æ˜¯å®é™…ä¸Šä½ ä¹Ÿå¹¶ä¸å–œæ¬¢æˆ‘çš„å§ã€‚</p><p><strong><em>å„è‡ªå®‰å¥½å•¦ï¼Œæœ¬å‘½å¹´å¼€å¿ƒå¹¸ç¦</em></strong></p><blockquote><p>Wen YZ</p></blockquote><p>æ— </p><p>æˆ‘ç†è§£ä½ äº†ã€‚</p><p>ä¸Šæµ·å¯¹æˆ‘çš„æ„ä¹‰å‡ ä¹æ¶ˆå¤±æ®†å°½äº†ï¼Œè°¢è°¢ä½ æ²¡ç”¨åŠ›æ‹’ç»ï¼Œåªæ˜¯è¿™æ ·ä¾æ—§ä¸ä¼šè§‰å¾—æ˜¯å¾ˆå¥½çš„æ–¹å¼ã€‚æˆ‘çŒœæˆ‘ä¼šåœ¨ç¦»å¼€ä¸Šæµ·ä¹‹å‰å†è§ä½ æœ€åä¸€æ¬¡å•¦ï¼Œä¸ä¼šæ‰“æ‰°ä½ å¾ˆä¹…çš„ã€‚YZåŒå­¦çœŸçœŸæ˜¯å¤©ä½¿ã€‚</p><blockquote><p>å®¶äºº</p></blockquote><p>æˆ‘å§æœ€æœ€é‡è¦ï¼Œå§å§å¿ƒçœ¼å¤ªå°‘äº†ï¼Œå¯¹å§å§å‘äº†ä¸€æ¬¡ç«ï¼Œæ„Ÿåˆ°å¾ˆéš¾å—ã€‚æƒ³ä¸€ç›´é™ªå§å§å“ˆå“ˆå“ˆå“ˆ</p><p>å¥¶å¥¶å’Œçˆ¸çˆ¸ï¼Œè¦å¤šå…³å¿ƒå®¶äººå•Šï¼Œè‡ªå·±æ—©å°±ä¸æ˜¯å°å­©äº†ã€‚</p><blockquote><p>ä¼™ä¼´</p></blockquote><p>ä¸ç®—å¤šï¼Œè¿˜ç®—å¥½ã€‚ä¹‹åä¼šåŠªåŠ›äº¤æœ‹å‹çš„ï¼Œè®©å¤§å®¶çœ‹åˆ°æˆ‘çš„â™¥ä¹Ÿä¸æ˜¯ä¸€ç›´å¾ˆæ¯ç‡¥ã€‚ä»¥å‰çš„ç°åœ¨çš„å„ä½å°ä¼™ä¼´ï¼Œæˆ‘ä»¬éƒ½è¦åŠªåŠ›ç©è€ï¼ŒåŠªåŠ›å­¦ä¹ å·¥ä½œï¼ŒåŠ æ²¹ã€‚</p><h3 id="å·¥ä½œ"><a href="#å·¥ä½œ" class="headerlink" title="å·¥ä½œ"></a>å·¥ä½œ</h3><blockquote><p>å®ä¹ </p></blockquote><p>ä»2019.04-2019.06ï¼Œå¤§æ¦‚é¢äº†4ï¼Œ5å®¶çš„ç®—æ³•ï¼Œéƒ½æ˜¯å¤§å‚ï¼Œè¢«å„ç§è¹‚èºï¼Œæˆ‘æ€‚äº†ï¼Œä¹‹åæš‘å‡å°±æ²¡å†ç»§ç»­äº†ã€‚è¿™æ˜¯æˆ‘æ‰¾å·¥ä½œä»¥æ¥æœ€å¤§çš„é”™ã€‚</p><p>æ€»ç»“å¤±è¯¯ï¼š</p><ul><li>ä¸åº”è¯¥ä¸Šæ¥å…ˆé¢å¤§å‚ï¼›</li><li>ä¸åº”è¯¥ä¸è®¤çœŸåˆ·é¢˜ï¼›</li><li>ä¸åº”è¯¥è‡ªæƒ­å½¢ç§½ï¼›</li></ul><p>æœ€ç»ˆ2019.09åœ¨ç™¾å§“ç½‘å®ä¹ äº†4å‘¨å·¦å³ï¼Œä¸€è¾¹å¿™ç€ç§‹æ‹›ä¸€è¾¹å®ä¹ ï¼ŒçœŸçš„å¿ƒéƒ½è¦æ“ç¢äº†ã€‚</p><p>è°¢è°¢å„ä½ã€‚æ‰€å¹¸æœ€ç»ˆçš„ç»“æœæ˜¯æˆ‘èƒ½æ¥å—çš„ã€‚</p><p>å› ä¸ºè¿™æ ·çš„æ¶ˆæå®³æ€•çš„å¿ƒç†ï¼Œç›´æ¥å¯¼è‡´è‡ªå·±é”™è¿‡æå‰æ‰¹ï¼Œæ­£å¼æ‰¹çš„ç¬”è¯•éƒ½æ²¡æœ‰é€šè¿‡ä¸€å®¶ï¼ŒçœŸçš„å¤ªèœäº†ã€‚è¿˜æ˜¯è¦åŠªåŠ›å¤šå­¦ä¹ å¤šåˆ·é¢˜ï¼ŒæŒæ¡åˆ°çš„ç¼–ç¨‹æŠ€èƒ½æ˜¯è‡ªå·±çš„ï¼Œä¼šæ˜¯æ°¸è¿œéƒ½æœ‰ç”¨çš„ã€‚</p><blockquote><p>Offer</p></blockquote><p>æœ€åæ‹¿åˆ°çš„offerå±…ç„¶æ˜¯æ—©æ—©å°±é¢çš„ç¬¬ä¸€å®¶ï¼ŒZTEï¼Œè¿™æ ·æƒ³æƒ³ï¼ŒçœŸçš„è®¤çœŸé¢è¯•çš„åªæœ‰ZTEå’Œåä¸ºä¸¤å®¶ï¼Œåä¸ºçš„ä¾ç„¶ä¸æ˜¯å¾ˆåŒ¹é…ï¼Œè¢«åˆ·æ‰äº†ã€‚ZTEçš„è¯´æ˜¯C++è½¯å¼€ï¼Œä½†æ˜¯åé€šä¿¡ç³»ç»Ÿåè®®ï¼Œä¾ç„¶ä¸èƒ½è¯´æ˜¯ç†æƒ³ã€‚è€Œä¸”è–ªæ°´æ¯”è¾ƒåŒå­¦å·®è·ä¹Ÿæœ‰ä¸€äº›ã€‚</p><p>è°å«æˆ‘æ˜¯èœé¸¡å‘¢..å“­â€¦</p><p>å…ˆæ‹¿åˆ°ä¸Šæµ·çš„æˆ·å£ï¼Œ2020.07å…¥èŒï¼Œ2021.04æˆ‘ä¸€å®šä¼šè¿›å…¥å¤´æ¡æˆ–è€…PDDå…¶ä¸­ä¹‹ä¸€çš„ï¼ŒFLAGç«‹åœ¨è¿™äº†ã€‚</p><h2 id="2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ"><a href="#2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ" class="headerlink" title="2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ"></a>2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ</h2><p>2020å¹´é¼ å¹´ï¼Œæˆ‘åˆšåˆšç»“æŸäº†è‡ªå·±çš„æœ¬å‘½å¹´ï¼Œåœ¨å®éªŒå®¤åšæ¯•è®¾ï¼Œæœ‰å‡ ä¸ªèŠå¾—æ¥çš„æœ‹å‹ï¼Œé©¬ä¸Šä¼šé¢ä¸´æ¯•ä¸šå’Œå·¥ä½œï¼Œå¸¦ç€è‡ªå·±å¹¶ä¸å¨´ç†Ÿçš„æŠ€èƒ½ï¼Œä¸€åˆ‡å¥½åƒæ²¡é‚£ä¹ˆå¥½ï¼Œä¹Ÿæ²¡é‚£ä¹ˆç³Ÿã€‚å…ƒæ—¦è¿™å¤©ï¼Œæˆ‘æƒ³è®¸å¾ˆå¤šçš„å¿ƒæ„¿ï¼Œå¸Œæœ›èƒ½åœ¨è¿™ä¸€å¹´å¾—åˆ°å›åº”ã€‚</p><p>å°å­©å­éƒ½ä¼šè´ªå¿ƒçš„ã€‚æˆ‘æƒ³è¦å¾ˆå¥½çš„æŠ€èƒ½ï¼Œå¾ˆå¤šçš„é’±ï¼Œå¾ˆå¤šçš„æœ‹å‹ï¼Œå¾ˆå……å®çš„æ—¶é—´ã€‚</p><p>æŠ€èƒ½æ–¹é¢ï¼š</p><ol><li>C++ï¼ˆå·¥ä½œå¿…é¡»ï¼‰</li><li>NLPï¼ŒPythonï¼ŒPyTorchï¼ˆæ¯•è®¾ä»¥åŠä¸ªäººå‘å±•ï¼‰</li><li>è‹±è¯­</li></ol><p>ç”Ÿæ´»æ–¹é¢ï¼š</p><ol><li>Kindleï¼ˆæƒ³æ¡èµ·é˜…è¯»çš„ä¹ æƒ¯ï¼‰</li><li>æ˜¾ç¤ºå™¨ï¼Œæ¡Œæ¤…ï¼ˆå’Œæˆ‘çš„Surfaceé…åˆåº”è¯¥ç®—ä¸ªä¸é”™çš„ç”Ÿäº§ç¯å¢ƒï¼‰</li><li>ç¾½æ¯›çƒæ‹ï¼Œçƒé‹</li></ol><p>å¦å¤–è¿˜æœ‰ï¼Œå¸Œæœ›é¡ºåˆ©æ¯•ä¸šï¼Œå¸Œæœ›å·¥ä½œåä¹Ÿèƒ½æœ‰ç”Ÿæ´»ï¼Œå¸Œæœ›æœ‹å‹ä¸€ç›´éƒ½èƒ½æ¯«æ— èŠ¥è’‚ï¼Œå¸Œæœ›æˆ‘å–œæ¬¢çš„äººä¹Ÿæ°å¥½çœ‹åˆ°äº†æˆ‘ã€‚</p><p>FLAG:</p><ol><li>æ–°å»ºä¸€ä¸ªGithubè´¦å·ï¼ŒæŠŠç°åœ¨çš„ä¸œè¥¿æ…¢æ…¢è‡ªå·±å†™ä¸€éï¼›</li><li>æ¯å¤©commitï¼Œå°‘ä¸€ä¸ªcommitå°±å‡é¤ä¸€é¡¿ï¼›</li><li>27wâ€”&gt;35wï¼Œè¦ç›¸ä¿¡è‡ªå·±åŠªåŠ›æé«˜å°±å¯ä»¥è¾¾åˆ°ã€‚</li></ol><p>æ€»ä¹‹ï¼Œ2020å¹´ï¼Œå„ä½ä¸€èµ·å˜å¾—æ›´å¥½å§~ æµå¹´ç¬‘æ·ï¼Œæœªæ¥å¯æœŸï¼</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æ—¥è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¹´ç»ˆæ€»ç»“ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_PyTorchåŸºç¡€ä½¿ç”¨</title>
      <link href="/2019/11/07/01-pytorch-ji-chu-shi-yong/"/>
      <url>/2019/11/07/01-pytorch-ji-chu-shi-yong/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>__version__</code></pre><pre><code>'1.3.0'</code></pre><a id="more"></a><h1 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h1><blockquote><p>Tensorçš„ä½¿ç”¨ï¼š</p></blockquote><ul><li><ol><li>æ„å»º</li></ol></li><li><ol start="2"><li>Tensorçš„åŸºæœ¬è¿ç®—</li></ol></li><li><ol start="3"><li>Tensorä¸Numpyè½¬æ¢</li></ol></li><li><ol start="4"><li>å…±äº«å†…å­˜çš„æƒ…å†µ</li></ol></li><li><ol start="5"><li>è‡ªåŠ¨å¾®åˆ†</li></ol></li></ul><h2 id="1-æ„å»ºTensor"><a href="#1-æ„å»ºTensor" class="headerlink" title="1. æ„å»ºTensor"></a>1. æ„å»ºTensor</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æ„å»º5Ã—3çŸ©é˜µï¼Œåˆ†é…ç©ºé—´ï¼Œä¸åˆå§‹åŒ–</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ä½¿ç”¨ç‰¹å®šæ•°æ®åˆå§‹åŒ–Tensor</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ä½¿ç”¨[0, 1]å‡åŒ€åˆ†å¸ƒéšæœºåˆå§‹åŒ–</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æŸ¥çœ‹Tensorå½¢çŠ¶çš„ä¸¤ç§æ–¹æ³•</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre><code>3</code></pre><h2 id="2-Tensorçš„åŸºæœ¬è¿ç®—"><a href="#2-Tensorçš„åŸºæœ¬è¿ç®—" class="headerlink" title="2. Tensorçš„åŸºæœ¬è¿ç®—"></a>2. Tensorçš„åŸºæœ¬è¿ç®—</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># åŠ æ³•</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬ä¸€ç§æ–¹å¼</span>z <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token comment" spellcheck="true"># ç¬¬äºŒç§æ–¹å¼</span>torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> out<span class="token operator">=</span>z<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬ä¸‰ç§æ–¹å¼</span>z <span class="token operator">=</span> y<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬å››ç§æ–¹å¼ï¼Œä¿®æ”¹yå€¼</span>y<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>x<span class="token punctuation">)</span></code></pre><pre><code>tensor([[1.4718, 0.5690, 1.1329],        [0.3453, 0.8727, 0.7226],        [1.2681, 0.8222, 1.8243],        [1.3840, 0.8803, 1.4788],        [1.5312, 1.0661, 0.9357]])</code></pre><h2 id="3-Tensorä¸Numpyè½¬æ¢"><a href="#3-Tensorä¸Numpyè½¬æ¢" class="headerlink" title="3. Tensorä¸Numpyè½¬æ¢"></a>3. Tensorä¸Numpyè½¬æ¢</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Tensorçš„åˆ‡ç‰‡ä¸Numpyç›¸ä¼¼,é€‰å‡ºindex=1çš„åˆ—</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ–°å»ºå…¨ä¸º1çš„Tensor</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Tensor->Numpy</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Numpy -> Tensor</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np a <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''è¦æ³¨æ„è¿™é‡Œçš„aå’Œbå†…å­˜å…±äº«ï¼Œä¸€ä¸ªæ”¹å˜ï¼Œå¦ä¸€ä¸ªä¼šåŒæ—¶è·Ÿéšæ”¹å˜'''</span><span class="token comment" spellcheck="true"># è·å–æŸä¸ªå…ƒç´ å€¼</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ³¨æ„ï¼štorch.tensorä¸torch.Tensoræœ‰å·®åˆ«ï¼Œè€Œä¸”ï¼Œtorch.tensoræ˜¯å¯¹åŸå§‹tensorçš„æ‹·è´ï¼Œä¸å†å…±äº«åŒæ ·çš„å†…å­˜</span>z_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>z_<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span></code></pre><pre><code>tensor([5., 3.])tensor([5., 3.])tensor([6., 4.])tensor([5., 3.])/home/xwjia/anaconda3/envs/Torch/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).</code></pre><h2 id="4-å…±äº«å†…å­˜æƒ…å†µ"><a href="#4-å…±äº«å†…å­˜æƒ…å†µ" class="headerlink" title="4. å…±äº«å†…å­˜æƒ…å†µ"></a>4. å…±äº«å†…å­˜æƒ…å†µ</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># å½“éœ€è¦å…±äº«å†…å­˜æ—¶ï¼Œå¯ä»¥ï¼š</span>a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æˆ–è€…</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è½¬æ¢ä¸ºGPUæ”¯æŒçš„Tensor</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>a <span class="token operator">=</span> a<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>c <span class="token operator">=</span> a <span class="token operator">+</span> b</code></pre><h2 id="5-è‡ªåŠ¨å¾®åˆ†"><a href="#5-è‡ªåŠ¨å¾®åˆ†" class="headerlink" title="5. è‡ªåŠ¨å¾®åˆ†"></a>5. è‡ªåŠ¨å¾®åˆ†</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ä¸ºTensorè®¾å®šå¯ä»¥æ±‚å¯¼</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token comment" spellcheck="true"># ç¬¬äºŒæ¬¡æ±‚å¯¼ä¹‹å‰è¦å½’é›¶ï¼Œä¸ç„¶ä¼šç´¯åŠ </span>x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad</code></pre><pre><code>tensor([[1., 1.],        [1., 1.]])</code></pre><pre class=" language-python"><code class="language-python"></code></pre><h1 id="ç¥ç»ç½‘ç»œ"><a href="#ç¥ç»ç½‘ç»œ" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h1><p>å¯¼å…¥<code>torch.nn</code>ï¼Œå°è£…å¯ä»¥è‡ªåŠ¨æ±‚å¯¼ï¼Œåªéœ€è¦åœ¨è‡ªå®šä¹‰çš„ç±»ç»§æ‰¿äº<code>nn.Module</code>,ç±»ä¸­éœ€è¦å®ç°<code>__init__</code>å’Œ<code>forward</code>æ–¹æ³•ï¼›</p><p>å…¶ä¸­ï¼š</p><ul><li><ol><li><code>__init__</code>ä¸­å­˜æ”¾ç½‘ç»œä¸­å¯ä»¥å­¦ä¹ çš„å‚æ•°ï¼›</li></ol></li><li><ol start="2"><li><code>super(Net, self).__init__()</code>ç­‰ä»·äºçˆ¶ç±»<code>nn.Module.__init__(self)</code></li></ol></li><li><ol start="3"><li>ç½‘ç»œä¸­ä¸å­¦ä¹ çš„å‚æ•°ï¼Œæ¯”å¦‚æœ€å¤§æ± åŒ–æˆ–è€…ReLUï¼Œå¯ä»¥æ”¾åœ¨<code>forward</code>æ–¹æ³•ä¸­</li></ol></li></ul><h2 id="1-è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ"><a href="#1-è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ" class="headerlink" title="1. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ"></a>1. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F <span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#reshape, '-1'è¡¨ç¤ºè‡ªé€‚åº”</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ‰“å°ç½‘ç»œå¯å­¦ä¹ çš„å‚æ•°</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">)</span>params <span class="token operator">=</span> list<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> parameters <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&lt;generator object Module.parameters at 0x7fb59472e7d0&gt;&lt;bound method Module.named_parameters of Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&gt;10conv1.weight : torch.Size([6, 1, 5, 5])conv1.bias : torch.Size([6])conv2.weight : torch.Size([16, 6, 5, 5])conv2.bias : torch.Size([16])fc1.weight : torch.Size([120, 400])fc1.bias : torch.Size([120])fc2.weight : torch.Size([84, 120])fc2.bias : torch.Size([84])fc3.weight : torch.Size([10, 84])fc3.bias : torch.Size([10])</code></pre><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>out<span class="token comment" spellcheck="true"># æ‰€æœ‰å‚æ•°æ¸…é›¶</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch-nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨-input-unsqueeze-0-å°†batch-sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚-nn-Conv2d-è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚"><a href="#éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch-nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨-input-unsqueeze-0-å°†batch-sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚-nn-Conv2d-è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚" class="headerlink" title="éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch.nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨ input.unsqueeze(0)å°†batch_sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚ nn.Conv2d è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚"></a>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch.nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨ <code>input.unsqueeze(0)</code>å°†batch_sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚ <code>nn.Conv2d</code> è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚</h3><p>$$<br>nSamples \times nChannels \times Height \times Width<br>$$</p><h3 id="å¯å°†nSampleè®¾ä¸º1ï¼Œå³"><a href="#å¯å°†nSampleè®¾ä¸º1ï¼Œå³" class="headerlink" title="å¯å°†nSampleè®¾ä¸º1ï¼Œå³"></a>å¯å°†nSampleè®¾ä¸º1ï¼Œå³</h3><p>$$<br>1 \times nChannels \times Height \times Width<br>$$</p><h2 id="2-æŸå¤±å‡½æ•°"><a href="#2-æŸå¤±å‡½æ•°" class="headerlink" title="2. æŸå¤±å‡½æ•°"></a>2. æŸå¤±å‡½æ•°</h2><ul><li><ol><li><code>nn.MSELoss</code>è®¡ç®—å‡æ–¹è¯¯å·®ï¼›</li></ol></li><li><ol start="2"><li><code>nn.CrossEntropyLoss</code>è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼›</li></ol></li></ul><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><pre><code>tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])tensor(28.4120, grad_fn=&lt;MseLossBackward&gt;)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è¿è¡Œ.backward,å¯ä»¥è§‚å¯Ÿè°ƒç”¨åå‘ä¼ æ’­ä¹‹å‰å’Œä¹‹åçš„grad</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># æŠŠnetä¸­çš„æ‰€æœ‰å¯å­¦ä¹ å‚æ•°çš„æ¢¯åº¦æ¸…é›¶</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"åå‘ä¼ æ’­ä¹‹å‰ conv1.bias çš„æ¢¯åº¦"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"åå‘ä¼ æ’­ä¹‹å...."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><pre><code>åå‘ä¼ æ’­ä¹‹å‰ conv1.bias çš„æ¢¯åº¦tensor([0., 0., 0., 0., 0., 0.])åå‘ä¼ æ’­ä¹‹å....tensor([ 0.0700, -0.0912,  0.0596,  0.0453,  0.0661,  0.0147])</code></pre><h2 id="3-ä¼˜åŒ–å™¨"><a href="#3-ä¼˜åŒ–å™¨" class="headerlink" title="3. ä¼˜åŒ–å™¨"></a>3. ä¼˜åŒ–å™¨</h2><p>åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ä¹‹åï¼Œè¿˜éœ€è¦è¦ä¼˜åŒ–æ–¹æ³•æ›´æ–°ç½‘ç»œçš„æƒé‡å’Œå‚æ•°ï¼Œæ¯”å¦‚<code>SGD</code>:</p><p><code>weight = weight - learning_rate * gradient</code></p><p>æ‰‹åŠ¨å®ç°å¦‚ä¸‹ï¼š</p><pre class=" language-python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># inplace å‡æ³•</span></code></pre><p><code>torch.optim</code>ä¸­å®ç°äº†æ·±åº¦å­¦ä¹ ä¸­ç»å¤§å¤šæ•°çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚RMSPropã€Adamã€SGDç­‰ï¼Œæ›´ä¾¿äºä½¿ç”¨ï¼Œå› æ­¤å¤§å¤šæ•°æ—¶å€™å¹¶ä¸éœ€è¦æ‰‹åŠ¨å†™ä¸Šè¿°ä»£ç ã€‚</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment" spellcheck="true"># æ–°å»ºä¼˜åŒ–å™¨ï¼Œ æŒ‡å®šéœ€è¦è°ƒæ•´çš„å‚æ•°å’Œå­¦ä¹ ç‡</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è®­ç»ƒæ—¶ï¼Œæ¢¯åº¦å…ˆæ¸…é›¶ï¼š</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è®¡ç®—loss</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># åå‘ä¼ æ’­</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ›´æ–°å‚æ•°</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="4-æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"><a href="#4-æ•°æ®åŠ è½½å’Œé¢„å¤„ç†" class="headerlink" title="4. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"></a>4. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†</h2><p><code>torchvision</code>å®ç°äº†å¸¸ç”¨çš„å›¾åƒæ•°æ®åŠ è½½åŠŸèƒ½ï¼Œä¾‹å¦‚Imagenetã€CIFAR10ã€MNISTç­‰ï¼Œä»¥åŠå¸¸ç”¨çš„æ•°æ®è½¬æ¢æ“ä½œï¼Œè¿™æå¤§åœ°æ–¹ä¾¿äº†æ•°æ®åŠ è½½ï¼Œå¹¶ä¸”ä»£ç å…·æœ‰å¯é‡ç”¨æ€§ã€‚</p><h3 id="å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»"><a href="#å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»" class="headerlink" title="å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»"></a>å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»</h3><p>ä¸‹é¢æˆ‘ä»¬æ¥å°è¯•å®ç°å¯¹CIFAR-10æ•°æ®é›†çš„åˆ†ç±»ï¼Œæ­¥éª¤å¦‚ä¸‹: </p><ol><li>ä½¿ç”¨torchvisionåŠ è½½å¹¶é¢„å¤„ç†CIFAR-10æ•°æ®é›†</li><li>å®šä¹‰ç½‘ç»œ</li><li>å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</li><li>è®­ç»ƒç½‘ç»œå¹¶æ›´æ–°ç½‘ç»œå‚æ•°</li><li>æµ‹è¯•ç½‘ç»œ</li></ol><h4 id="CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†"><a href="#CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†" class="headerlink" title="CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†"></a>CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†</h4><p>CIFAR-10<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">^3</a>æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„å½©è‰²å›¾ç‰‡æ•°æ®é›†ï¼Œå®ƒæœ‰10ä¸ªç±»åˆ«: â€˜airplaneâ€™, â€˜automobileâ€™, â€˜birdâ€™, â€˜catâ€™, â€˜deerâ€™, â€˜dogâ€™, â€˜frogâ€™, â€˜horseâ€™, â€˜shipâ€™, â€˜truckâ€™ã€‚æ¯å¼ å›¾ç‰‡éƒ½æ˜¯$3\times32\times32$ï¼Œä¹Ÿå³3-é€šé“å½©è‰²å›¾ç‰‡ï¼Œåˆ†è¾¨ç‡ä¸º$32\times32$ã€‚</p><h2 id="5-å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ "><a href="#5-å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ " class="headerlink" title="5. å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ "></a>5. å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ </h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchvision  <span class="token keyword">as</span> tv <span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToPILImageshow <span class="token operator">=</span> ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># å¯ä»¥æŠŠTensorè½¬æˆImageï¼Œæ–¹ä¾¿å¯è§†åŒ–</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#å½’ä¸€åŒ–</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®­ç»ƒé›†</span>trainset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span></code></pre><pre><code>0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/xwjia/tmp/data/cifar-10-python.tar.gz 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 169443328/170498071 [00:20&lt;00:00, 11268338.34it/s]Extracting /home/xwjia/tmp/data/cifar-10-python.tar.gz to /home/xwjia/tmp/data/</code></pre><pre class=" language-python"><code class="language-python">trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    trainset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æµ‹è¯•é›†</span>testset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    testset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span></code></pre><pre><code>Files already downloaded and verified</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æŸ¥çœ‹æŸä¸ªæ ·æœ¬</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token operator">=</span> trainset<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>ship</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_29_1.png" alt="png"></p><p>Dataloaderæ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„å¯¹è±¡ï¼Œå®ƒå°†datasetè¿”å›çš„æ¯ä¸€æ¡æ•°æ®æ‹¼æ¥æˆä¸€ä¸ªbatchï¼Œå¹¶æä¾›å¤šçº¿ç¨‹åŠ é€Ÿä¼˜åŒ–å’Œæ•°æ®æ‰“ä¹±ç­‰æ“ä½œã€‚å½“ç¨‹åºå¯¹datasetçš„æ‰€æœ‰æ•°æ®éå†å®Œä¸€éä¹‹åï¼Œç›¸åº”çš„å¯¹Dataloaderä¹Ÿå®Œæˆäº†ä¸€æ¬¡è¿­ä»£ã€‚</p><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#è¿”å›ä¸‹ä¸€ä¸ªbatchï¼Œ4å¼ å›¾ç‰‡å’Œæ ‡ç­¾</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%11s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span><span class="token punctuation">(</span>images<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>truck         cat       plane       truck</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_31_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è‡ªå®šä¹‰ç½‘ç»œç»“æ„</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc1   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc2   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®­ç»ƒç½‘ç»œ</span>torch<span class="token punctuation">.</span>set_num_threads<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># è¾“å…¥æ•°æ®</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment" spellcheck="true"># æ¢¯åº¦æ¸…é›¶</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># forward + backward</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># æ›´æ–°å‚æ•°</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># æ‰“å°logä¿¡æ¯</span>        <span class="token comment" spellcheck="true"># lossæ˜¯ä¸€ä¸ªscalarï¼Œ éœ€è¦ä½¿ç”¨loss.item()è·å–æ•°å€¼ï¼Œ ä¸èƒ½ä½¿ç”¨loss[0]</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true"># æ¯2000ä¸ªbatchæ‰“å°ä¸€ä¸‹è®­ç»ƒçŠ¶æ€</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span><span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> running_loss<span class="token operator">/</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></code></pre><pre><code>[1,  2000] loss: 2.163[1,  4000] loss: 1.823[1,  6000] loss: 1.656[1,  8000] loss: 1.586[1, 10000] loss: 1.495[1, 12000] loss: 1.467[2,  2000] loss: 1.405[2,  4000] loss: 1.376[2,  6000] loss: 1.343[2,  8000] loss: 1.322[2, 10000] loss: 1.320[2, 12000] loss: 1.311Finished Training</code></pre><h3 id="æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ"><a href="#æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ" class="headerlink" title="æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ"></a>æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ</h3><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'å®é™…çš„label: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%08s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token operator">/</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®¡ç®—å›¾ç‰‡åœ¨æ¯ä¸ªç±»åˆ«ä¸Šçš„åˆ†æ•°</span>outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># å¾—åˆ†æœ€é«˜çš„é‚£ä¸ªç±»</span>_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'é¢„æµ‹ç»“æœï¼š '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>é¢„æµ‹ç»“æœï¼š    cat  ship  ship plane</code></pre><pre class=" language-python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>   <span class="token comment" spellcheck="true"># é¢„æµ‹æ­£ç¡®çš„å›¾ç‰‡æ•°</span>total <span class="token operator">=</span> <span class="token number">0</span>     <span class="token comment" spellcheck="true"># æ€»å…±çš„å›¾ç‰‡æ•°</span><span class="token comment" spellcheck="true"># ç”±äºæµ‹è¯•æ—¶ä¸éœ€è¦æ±‚å¯¼ï¼Œ æ‰€ä»¥å¯ä»¥æš‚æ—¶å…³é—­autogradï¼Œ æé«˜é€Ÿåº¦ï¼Œ èŠ‚çº¦å†…å­˜</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"10000å¼ æµ‹è¯•é›†ä¸­çš„å‡†ç¡®ç‡æ˜¯ï¼š %d %%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token operator">/</span>total<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>10000å¼ æµ‹è¯•é›†ä¸­çš„å‡†ç¡®ç‡æ˜¯ï¼š 54 %</code></pre><h2 id="åœ¨GPUä¸Šè®­ç»ƒ"><a href="#åœ¨GPUä¸Šè®­ç»ƒ" class="headerlink" title="åœ¨GPUä¸Šè®­ç»ƒ"></a>åœ¨GPUä¸Šè®­ç»ƒ</h2><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><p>å¯¹PyTorchçš„åŸºç¡€ä»‹ç»è‡³æ­¤ç»“æŸã€‚æ€»ç»“ä¸€ä¸‹ï¼Œæœ¬èŠ‚ä¸»è¦åŒ…å«ä»¥ä¸‹å†…å®¹ã€‚</p><ol><li>Tensor: ç±»ä¼¼Numpyæ•°ç»„çš„æ•°æ®ç»“æ„ï¼Œä¸Numpyæ¥å£ç±»ä¼¼ï¼Œå¯æ–¹ä¾¿åœ°äº’ç›¸è½¬æ¢ã€‚</li><li>autograd/: ä¸ºtensoræä¾›è‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½ã€‚</li><li>nn: ä¸“é—¨ä¸ºç¥ç»ç½‘ç»œè®¾è®¡çš„æ¥å£ï¼Œæä¾›äº†å¾ˆå¤šæœ‰ç”¨çš„åŠŸèƒ½(ç¥ç»ç½‘ç»œå±‚ï¼ŒæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨ç­‰)ã€‚</li><li>ç¥ç»ç½‘ç»œè®­ç»ƒ: ä»¥CIFAR-10åˆ†ç±»ä¸ºä¾‹æ¼”ç¤ºäº†ç¥ç»ç½‘ç»œçš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€ç½‘ç»œæ­å»ºã€è®­ç»ƒåŠæµ‹è¯•ã€‚</li></ol><p>ä»ä¸‹ä¸€ç« å¼€å§‹ï¼Œæœ¬ä¹¦å°†æ·±å…¥ç³»ç»Ÿåœ°è®²è§£PyTorchçš„å„éƒ¨åˆ†çŸ¥è¯†ã€‚</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorchæ¡†æ¶å…¥é—¨ä¸å®æˆ˜ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/10/20/hello-world/"/>
      <url>/2019/10/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
