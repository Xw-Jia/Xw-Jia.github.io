<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>6.1_Advice_for_Applying_Machine_Learning</title>
      <link href="/2020/02/05/6-1-advice-for-applying-machine-learning/"/>
      <url>/2020/02/05/6-1-advice-for-applying-machine-learning/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-0a2226926cdd4e8e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><h2 id="ä¸€-Evaluating-a-Learning-Algorithm"><a href="#ä¸€-Evaluating-a-Learning-Algorithm" class="headerlink" title="ä¸€. Evaluating a Learning Algorithm"></a>ä¸€. Evaluating a Learning Algorithm</h2><p>æƒ³è¦é™ä½é¢„æµ‹è¯¯å·®ï¼Œå³æé«˜é¢„æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šé‡‡ç”¨è¿™äº›æ‰‹æ®µï¼š</p><ul><li>é‡‡é›†æ›´å¤šçš„æ ·æœ¬<br>é”™è¯¯çš„è®¤ä¸ºæ ·æœ¬è¶Šå¤šè¶Šå¥½ï¼Œå…¶å®æ•°æ®å¤šå¹¶ä¸æ˜¯è¶Šå¥½ã€‚</li><li>é™ä½ç‰¹å¾ç»´åº¦<br>é™ç»´å¯èƒ½å»æ‰äº†æœ‰ç”¨çš„ç‰¹å¾ã€‚</li><li>é‡‡é›†æ›´å¤šçš„ç‰¹å¾<br>å¢åŠ äº†è®¡ç®—è´Ÿæ‹…ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li><li>è¿›è¡Œé«˜æ¬¡å¤šé¡¹å¼å›å½’<br>è¿‡é«˜çš„å¤šé¡¹å¼å¯èƒ½é€ æˆè¿‡æ‹Ÿåˆã€‚</li><li>è°ƒè¯•æ­£è§„åŒ–å‚æ•° $\lambda$,å¢å¤§æˆ–è€…å‡å°‘ $\lambda$<br>å¢å¤§æˆ–è€…å‡å°‘éƒ½æ˜¯å‡­æ„Ÿè§‰ã€‚</li></ul><p>æœ‰è¿™ä¹ˆå¤šç§è§£å†³åŠæ³•æˆ‘ä»¬æ€ä¹ˆçŸ¥é“æ˜¯å“ªä¸€ç§å‘¢ï¼Ÿå¾ˆå¤šäººé€‰æ‹©è¿™äº›æ–¹æ³•çš„æ ‡å‡†å°±æ˜¯å‡­æ„Ÿè§‰éšä¾¿é€‰æ‹©ä¸€ç§ï¼Œç„¶åèŠ±å¾ˆé•¿çš„æ—¶é—´æœ€åå‘ç°æ˜¯æ²¡ç”¨çš„ï¼Œèµ°ä¸Šäº†ä¸å½’è·¯ã€‚æ‰€ä»¥ä¸‹é¢æˆ‘ä»¬ä»‹ç»ä¸€æˆ‘ä»¬éœ€è¦ä¸€ç§ç®€å•æœ‰æ•ˆçš„åŠæ³•ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•è¯Šæ–­ï¼ˆMachine learning diagnosticï¼‰ã€‚</p><h3 id="1-Evaluating-a-Hypothesis-è¯„ä»·å‡è®¾å‡½æ•°"><a href="#1-Evaluating-a-Hypothesis-è¯„ä»·å‡è®¾å‡½æ•°" class="headerlink" title="1. Evaluating a Hypothesis è¯„ä»·å‡è®¾å‡½æ•°"></a>1. Evaluating a Hypothesis è¯„ä»·å‡è®¾å‡½æ•°</h3><p>é¦–å…ˆæˆ‘ä»¬è¦è¯„ä¼°çš„æ˜¯æˆ‘ä»¬çš„å‡è®¾å‡½æ•°ï¼ˆHypothesisï¼‰ã€‚å½“æˆ‘ä»¬é€‰æ‹©ç‰¹å¾å€¼æˆ–è€…å‚æ•°æ¥ä½¿è®­ç»ƒé›†è¯¯å·®æœ€å°åŒ–ï¼Œä½†æ˜¯æˆ‘ä»¬ä¼šé‡åˆ°è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œæ¨å¹¿åˆ°æ–°çš„è®­ç»ƒé›†å°±ä¸å†ä½¿ç”¨äº†ã€‚è€Œä¸”å½“ç‰¹å¾é‡å¾ˆå¤šçš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±ä¸èƒ½å°† $J(\theta)$ å¯è§†åŒ–çœ‹å‡ºå…¶æ˜¯å¦éšç€è¿­ä»£æ¬¡æ•°è€Œä¸‹é™äº†ã€‚æ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹çš„æ–¹æ³•æ¥è¯„ä¼°æˆ‘ä»¬çš„å‡è®¾å‡½æ•°ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_1.png" alt=""></p><p>å‡è®¾æœ‰ 10 ç»„æ•°æ®ï¼ŒéšæœºæŠŠ 70% åšä¸ºè®­ç»ƒé›†ï¼Œå‰©ä¸‹çš„ 30% åšä¸ºæµ‹è¯•é›†ã€‚è®­ç»ƒé›†å’Œæµ‹è¯•é›†å°½é‡ä¿è¯æ˜¯éšæœºæ’åˆ—ã€‚</p><p>æ¥ä¸‹æ¥ï¼š</p><ol><li>å¯¹è®­ç»ƒé›†è¿›è¡Œå­¦ä¹ å¾—åˆ°å‚æ•° $\Theta$ ï¼Œä¹Ÿå°±æ˜¯åˆ©ç”¨è®­ç»ƒé›†æœ€å°åŒ–è®­ç»ƒè¯¯å·® $J_{train}(\Theta)$</li><li>è®¡ç®—å‡ºæµ‹è¯•è¯¯å·® $J_{test}(\Theta)$ï¼Œå–å‡ºä¹‹å‰ä»è®­ç»ƒé›†ä¸­å­¦ä¹ å¾—åˆ°çš„å‚æ•° $\Theta$ æ”¾åœ¨è¿™é‡Œï¼Œæ¥è®¡ç®—æµ‹è¯•è¯¯å·®ã€‚</li></ol><p>å¯¹äºçº¿æ€§å›å½’ï¼š $$J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}{(h_\theta(x^{(i)}_{test})-y^{(i)}_{test})^2}$$</p><p>å¯¹äºé€»è¾‘å›å½’ï¼š  $$J_{test}(\theta)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}{y^{(i)}_{test}logh_\theta(x^{(i)}_{test})+(1-y^{(i)}_{test})logh_\theta(x^{(i)}_{test})}$$</p><p>é€»è¾‘å›å½’ä¸åŒäºçº¿æ€§å›å½’ï¼Œå› ä¸ºå®ƒåªæœ‰0å’Œ1ä¸¤ä¸ªå€¼ï¼Œ æ‰€ä»¥æ€ä¹ˆåˆ¤æ–­è¯¯å·®å¦‚ä¸‹ï¼š</p>$$err(h_\theta(x),y)=\left\{\begin{matrix}1 \;\;\;( if \;\;\; h_\theta(x) \geqslant 0.5 , y=0 \;\;\;or\;\;\; if\;\;\; h_\theta(x) &lt; 0.5 ï¼Œ y=1 )\\ 0 \;\;\;( otherwise ) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\end{matrix}\right.$$<p>è¿™é‡Œçš„è¯¯å·®ä¹Ÿå«è¯¯åˆ†ç±»ç‡ï¼Œä¹Ÿå« $0/1$ é”™åˆ†ç‡ã€‚</p><p>$( if ;;; h_\theta(x) \geqslant 0.5 , y=0 ;;;or;;; if;;; h_\theta(x) &lt; 0.5 ï¼Œ y=1 )$</p><p>è¿™ç§æƒ…å†µä¸‹ï¼Œå‡è®¾ç»“æœæ›´è¶‹å‘äº1ï¼Œä½†æ˜¯å®é™…ç»™å‡ºçš„åˆ¤æ–­å´æ˜¯0ï¼Œæˆ–è€…å‡è®¾ç»“æœæ›´è¶‹å‘äº0ï¼Œå®é™…ç»™å‡ºçš„åˆ¤æ–­å´æ˜¯1 ã€‚</p><p>å¦‚æœä»¥ä¸Šæƒ…å†µéƒ½æ²¡æœ‰ï¼Œé‚£ä¹ˆå°±æ²¡æœ‰è¯¯å·®ï¼Œå³ä¸º0 ï¼Œä¹Ÿä»£è¡¨äº†å‡è®¾å€¼èƒ½å¤Ÿæ­£ç¡®çš„å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ã€‚</p><p>æµ‹è¯•é›†çš„å¹³å‡æµ‹è¯•è¯¯å·®ä¸ºï¼š</p>$$Test\;Error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_{\theta}(x^{(i)}_{test}),y^{(i)}_{test})$$<hr><h3 id="2-Model-Selection-and-Train-Validation-Test-Sets-æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†-éªŒè¯é›†-æµ‹è¯•é›†"><a href="#2-Model-Selection-and-Train-Validation-Test-Sets-æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†-éªŒè¯é›†-æµ‹è¯•é›†" class="headerlink" title="2. Model Selection and Train/Validation/Test Sets æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†"></a>2. Model Selection and Train/Validation/Test Sets æ¨¡å‹é€‰æ‹©å’Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_2.png" alt=""></p><p>æˆ‘ä»¬è¿™é‡Œç”¨ d è¡¨ç¤ºå¤šé¡¹å¼çš„ä¸ªæ•°ã€‚æˆ‘ä»¬å¯ä»¥æ”¹å˜å¤šé¡¹å¼æ¬¡æ•°çš„å¤šå°‘æ¥é€‰æ‹©åˆé€‚æˆ‘ä»¬çš„æ¨¡å‹ã€‚ä¾‹å¦‚ä¸Šé¢çš„ $h_\theta(x)=\theta_0+\theta_1x$ ï¼Œè¿™ä¸ªå¤šé¡¹å¼ $d=1$ ã€‚</p><p>æˆ‘ä»¬å¯ä»¥æµ‹è¯•æ¯ä¸€ä¸ªæ¨¡å‹å¾—åˆ°ä»–ä»¬çš„ $J_{test}(\theta)$ ï¼Œåˆ¤æ–­å“ªä¸€ä¸ªæ¨¡å‹æ¯”è¾ƒå¥½ã€‚</p><p>å½“é€‰æ‹©å‡ºäº†ä¸€ä¸ªå¤šé¡¹å¼ d èƒ½å¾ˆå®Œç¾çš„æ‹Ÿåˆæµ‹è¯•é›†ï¼Œæ¥ä¸‹æ¥å°±ä¸èƒ½å†ç”¨æµ‹è¯•é›†äº†ï¼Œå› ä¸º d æœ¬æ¥å°±å·²ç»å®Œç¾æ‹Ÿåˆæµ‹è¯•é›†äº†ï¼Œå†æµ‹è¯•å°±æ²¡æœ‰æ„ä¹‰äº†ï¼Œéœ€è¦æ¢ä¸€ä¸ªæµ‹è¯•é›†ã€‚æ‰€ä»¥æ›´éœ€è¦å…³å¿ƒçš„å¯¹æ–°æ ·æœ¬çš„æ‹Ÿåˆæ•ˆæœã€‚</p><p>ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æŠŠæ•°æ®åˆ†ä¸º 3 ç±»ï¼Œè®­ç»ƒé›† 60% /äº¤å‰éªŒè¯é›† 20% /æµ‹è¯•é›† 20%ã€‚</p><p>é€šè¿‡ä¸‰ä¸ªé›†åˆï¼Œå¯ä»¥ç®—å‡ºè®­ç»ƒè¯¯å·®ï¼š</p><p>$$J_{train}(\theta) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^{2}$$</p><p>äº¤å‰éªŒè¯è¯¯å·®ï¼š</p>$$J_{cv}(\theta) = \frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x^{(i)}_{cv})-y^{(i)}_{cv})^{2}$$<p>æµ‹è¯•è¯¯å·®ï¼š</p>$$J_{test}(\theta) = \frac{1}{2m_{test}}\sum_{i=1}^{m}(h_\theta(x^{(i)}_{test})-y^{(i)}_{test})^{2}$$<p>äºæ˜¯æˆ‘ä»¬é€‰æ‹©æ¨¡å‹ä¸åœ¨ä»…ä»…é€šè¿‡æµ‹è¯•é›†æ¥é€‰æ‹©äº†ï¼Œè€Œæ˜¯ï¼š</p><ol><li>åˆ©ç”¨è®­ç»ƒé›†çš„æ•°æ®ä»£å…¥æ¯ä¸€ä¸ªå¤šé¡¹å¼æ¨¡å‹ã€‚</li><li>ç”¨äº¤å‰éªŒè¯é›†çš„æ•°æ®æ‰¾å‡ºæœ€å°è¯¯å·®çš„å¤šé¡¹å¼æ¨¡å‹ã€‚</li><li>æœ€ååœ¨æµ‹è¯•é›†å†æ‰¾å‡ºç›¸å¯¹è¾ƒå°‘è¯¯å·®çš„é‚£ä¸ªæ¨¡å‹ã€‚</li></ol><hr><h2 id="äºŒ-Bias-vs-Variance"><a href="#äºŒ-Bias-vs-Variance" class="headerlink" title="äºŒ. Bias vs. Variance"></a>äºŒ. Bias vs. Variance</h2><h3 id="1-Diagnosing-Bias-vs-Variance-è¯Šæ–­åå·®å’Œæ–¹å·®"><a href="#1-Diagnosing-Bias-vs-Variance-è¯Šæ–­åå·®å’Œæ–¹å·®" class="headerlink" title="1. Diagnosing Bias vs. Variance è¯Šæ–­åå·®å’Œæ–¹å·®"></a>1. Diagnosing Bias vs. Variance è¯Šæ–­åå·®å’Œæ–¹å·®</h3><p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œåå·®ï¼ˆbiasï¼‰åæ˜ äº†æ¨¡å‹æ— æ³•æè¿°æ•°æ®è§„å¾‹ï¼Œè€Œæ–¹å·®ï¼ˆvarianceï¼‰åæ˜ äº†æ¨¡å‹å¯¹è®­ç»ƒé›†è¿‡åº¦æ•æ„Ÿï¼Œè€Œä¸¢å¤±äº†æ•°æ®è§„å¾‹ï¼Œé«˜åå·®å’Œé«˜æ–¹å·®éƒ½ä¼šé€ æˆæ–°æ•°æ®åˆ°æ¥æ—¶ï¼Œæ¨¡å‹ç»™å‡ºé”™è¯¯çš„é¢„æµ‹ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_3.png" alt=""></p><p>è¿˜æ˜¯ä»¥è¿™ä¸ªå›¾ä¸ºä¾‹ï¼Œæœ€å·¦è¾¹çš„å›¾æ˜¯æ¬ æ‹Ÿåˆï¼Œæœ€å³è¾¹çš„å›¾æ˜¯è¿‡æ‹Ÿåˆã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_4.png" alt=""></p><p>ä¸Šå›¾æ˜¯ è®­ç»ƒé›†ã€äº¤å‰éªŒè¯é›†è¯¯å·®éšå¤šé¡¹å¼æ¬¡æ•° d çš„å˜åŒ–è§„å¾‹ã€‚æ¨ªåæ ‡æ˜¯æˆ‘ä»¬çš„dï¼Œä¹Ÿå°±æ˜¯å¤šé¡¹å¼çš„ä¸ªæ•°ï¼Œçºµåæ ‡å°±æ˜¯æˆ‘ä»¬çš„ä»£ä»·å‡½æ•°ã€‚</p><p>æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹çº¢è‰²æ›²çº¿ $J_{training}(\theta)$ ï¼Œéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ ï¼Œå…¶å‡è®¾å‡½æ•°æ˜¯è¶Šæ¥è¶Šæ¥è¿‘è¦æ‹Ÿåˆçš„æ•°æ®ï¼Œæ‰€ä»¥å…¶ä»£ä»·å‡½æ•°ä¼šéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ ä¸‹é™ã€‚</p><p>ç„¶åç»¿è‰²çš„æ›²çº¿æ˜¯ $J_{cross-validation}(\theta)$ ,å½“å¤šé¡¹å¼ä¸ªæ•°æ¯”è¾ƒå°‘çš„æ—¶å€™ï¼Œé‚£å½“ç„¶ä¼šå‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ï¼Œæ‰€ä»¥ä¸€å¼€å§‹å…¶ä»£ä»·å‡½æ•° $J_{cross-validation}(\theta)$ æ˜¯å¾ˆå¤§çš„ï¼Œéšç€å¤šé¡¹å¼ä¸ªæ•°çš„å¢åŠ è€Œä¸‹é™ï¼Œä½†æ˜¯å½“å…¶å¤šé¡¹å¼ä¸ªæ•°å†ç»§ç»­å¢åŠ çš„è¯ï¼Œå°±ä¼šå‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œ $J_{cross-validation}(\theta)$ å°±åˆä¼šå¢åŠ ã€‚æ‰€ä»¥ $J_{cross-validation}(\theta)$ å‡½æ•°æ˜¯å…ˆé€’å‡å†é€’å¢çš„ï¼Œåœ¨å…¶æœ€ä½ç‚¹å°±æ˜¯æœ€åˆé€‚çš„å¤šé¡¹å¼æ¬¡æ•°ã€‚</p><p>å¤šé¡¹å¼å›å½’ä¸­ï¼Œå¦‚æœå¤šé¡¹å¼æ¬¡æ•°è¾ƒé«˜ï¼Œåˆ™å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆï¼Œæ­¤æ—¶è®­ç»ƒè¯¯å·®å¾ˆä½ï¼Œä½†æ˜¯å¯¹äºæ–°æ•°æ®çš„æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼Œå¯¼è‡´äº¤å‰éªŒè¯é›†å’Œæµ‹è¯•é›†çš„è¯¯å·®éƒ½å¾ˆé«˜ï¼Œæ­¤æ—¶æ¨¡å‹å‡ºç°äº†<strong>é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</strong>ï¼š</p>$$\left\{\begin{matrix}J_{train}(\theta) \;\;\;is\;\; low\\ J_{cv}(\theta)&gt;&gt;J_{test}(\theta)\end{matrix}\right.$$<p>è¿‡æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒé›†è¯¯å·®é€šå¸¸æ¯”è¾ƒå°ï¼Œå¹¶ä¸”è¿œå°äºäº¤å‰éªŒè¯è¯¯å·®ã€‚</p><p>è€Œå½“æ¬¡æ•°è¾ƒä½æ—¶ï¼Œåˆæ˜“å‡ºç°æ¬ æ‹Ÿåˆçš„çŠ¶å†µï¼Œæ­¤æ—¶æ— è®ºæ˜¯è®­ç»ƒé›†ï¼Œäº¤å‰éªŒè¯é›†ï¼Œè¿˜æ˜¯æµ‹è¯•é›†ï¼Œéƒ½ä¼šæœ‰å¾ˆé«˜çš„è¯¯å·®ï¼Œæ­¤æ—¶æ¨¡å‹å‡ºç°äº†<strong>é«˜åå·®(æ¬ æ‹Ÿåˆ)</strong>ï¼š</p>$$\left\{\begin{matrix}J_{train}(\theta),J_{cv}(\theta)\;\;\; is \;\; high\\ J_{cv}(\theta) \approx J_{test}(\theta)\end{matrix}\right.$$<p>æ¬ æ‹Ÿåˆçš„æƒ…å†µä¸‹ï¼Œè®­ç»ƒé›†è¯¯å·®ä¼šå¾ˆå¤§ã€‚</p><p>ä¸ºä»€ä¹ˆ $J_{cross-validation}(\theta)$ ä¼šå…ˆé™åå‡ï¼Œè€Œ $J_{training}(\theta)$ ä¸€ç›´ä¸‹é™ï¼Ÿ</p><p>åŸå› æ˜¯ $\theta$ æ˜¯åªé’ˆå¯¹è®­ç»ƒé›†æ‰€è®­ç»ƒå‡ºæ¥çš„ï¼Œå½“å…¶ä»£å…¥åˆ° $J_{cross-validation}(\theta)$ åï¼Œå°±ä¼šéšç€å¤šé¡¹å¼çš„å¢åŠ æ•°æ®åå·®å°±ä¼šè¶Šæ¥è¶Šå¤§ã€‚</p><hr><h3 id="2-Regularization-and-Bias-Variance-æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®"><a href="#2-Regularization-and-Bias-Variance-æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®" class="headerlink" title="2. Regularization and Bias/Variance æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®"></a>2. Regularization and Bias/Variance æ­£åˆ™åŒ–çš„åå·®å’Œæ–¹å·®</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_5.png" alt=""></p><p>ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œæˆ‘ä»¬åŠ ä¸Šä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œä½†æ˜¯æ­£åˆ™åŒ–å‚æ•° $\lambda$ ä¸è¿‡æ‹Ÿåˆåˆæœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿ</p><p>å½“ $\lambda$ å¾ˆå¤§çš„æ—¶å€™ï¼Œå°±ä¼šä½¿å¾—åé¢çš„æ¯ä¸€ä¸ª $\theta_i$ éƒ½è¢«æƒ©ç½šäº†ï¼Œæ‰€ä»¥åªå‰©ä¸‹ $\theta_0$ ï¼Œé‚£ä¹ˆå…¶å‡è®¾å‡½æ•°å°±ä¼šå˜æˆä¸€æ¡ç›´çº¿ï¼Œå‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ã€‚</p><p>å½“ $\lambda$ å¾ˆå°çš„è¯ï¼Œä¸€ä¸ªæç«¯ä¾‹å­å°±æ˜¯ $\lambda=0$ ï¼Œä¹Ÿå°±æ˜¯ç›¸å½“äºæ²¡æœ‰åŠ æ­£åˆ™åŒ–é‚£é¡¹ï¼Œè¿™å°±ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚</p><p>$\lambda$çš„å–å€¼ä¸èƒ½è¿‡å¤§ä¹Ÿä¸èƒ½è¿‡å°ã€‚</p><p>$\lambda$çš„å–å€¼å¯ä»¥åœ¨ $\left[0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24\right]$ï¼Œåœ¨è¿™12ä¸ªä¸åŒçš„æ¨¡å‹ä¸­é’ˆå¯¹æ¯ä¸€ä¸ª $\lambda$ çš„å€¼ï¼Œéƒ½å»è®¡ç®—å‡ºä¸€ä¸ªæœ€å°ä»£ä»·å‡½æ•°,ä»è€Œå¾—åˆ° $\Theta^{(i)}$</p><p>å¾—åˆ°äº†12ä¸ª $\Theta^{(i)}$ ä»¥åï¼Œå°±å†ç”¨äº¤å‰éªŒè¯é›†å»è¯„ä»·å®ƒä»¬ã€‚å³è®¡ç®—æ¯ä¸ª $\Theta$ åœ¨äº¤å‰éªŒè¯é›†ä¸Šçš„å¹³å‡è¯¯å·®å¹³æ–¹å’Œ $J_{cv}(\Theta^{(i)})$</p><p>é€‰æ‹©ä¸€ä¸ªäº¤å‰éªŒè¯é›†è¯¯å·®æœ€å°çš„ $\lambda$ æœ€èƒ½æ‹Ÿåˆæ•°æ®çš„ä½œä¸ºæ­£åˆ™åŒ–å‚æ•°ã€‚</p><p>æœ€åæ‹¿è¿™ä¸ªæ­£åˆ™åŒ–å‚æ•°å»æµ‹è¯•é›†é‡Œé¢éªŒè¯ $J_{test}(\Theta^{(i)})$ é¢„æµ‹æ•ˆæœå¦‚ä½•ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_6.png" alt=""></p><p>éšç€ $\lambda$ å‚æ•°çš„å¢å¤§ï¼Œ $J_{train}(\theta)$ è‡ªç„¶ä¹Ÿä¼šéšä¹‹å¢å¤§ï¼Œè¿™æ˜¯å› ä¸ºå½“ $\lambda=0$ çš„æ—¶å€™ï¼Œ $J_{train}(\theta)$ æ˜¯æ²¡æœ‰æ­£åˆ™åŒ–é¡¹çš„ã€‚</p><p>ä½†æ˜¯å¯¹äº $J_{cv}(\theta)$ æ¥è¯´ï¼Œå®ƒå‡è®¾å‡½æ•°é‡Œé¢çš„ $\theta$ æ˜¯æ ¹æ®è®­ç»ƒé›†é‡Œé¢æ‹Ÿåˆå‡ºæ¥çš„ï¼Œæ‰€ä»¥åœ¨æ²¡æœ‰åŠ å…¥æ­£åˆ™åŒ–å‰ï¼Œ $J_{cv}(\theta)$ æ˜¯å¾ˆå¤§çš„ã€‚ä½†æ˜¯éšç€ $\lambda$ çš„é€æ¸å¢å¤§ï¼Œä¹Ÿå°±æ˜¯éšç€æ­£åˆ™åŒ–çš„æ•ˆæœé€æ¸ä½“ç°å‡ºæ¥ï¼Œåœ¨äº¤å‰éªŒè¯é›†é‡Œé¢ä¸æµ‹è¯•æ•°æ®å°±ä¼šè¶Šæ¥è¶Šæ‹Ÿåˆï¼Œè¿™æ—¶å€™çš„ $J_{cv}(\theta)$ è‡ªç„¶ä¼šæ…¢æ…¢ä¸‹é™ã€‚ä½†æ˜¯å½“ $\lambda$ å˜å¾—è¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œäº¤å‰è®­ç»ƒé›†çš„ $h_\theta(x)$ å°±ä¼šè¶‹è¿‘ä¸€æ¡ç›´çº¿ï¼Œ$J_{cv}(\theta)$ è‡ªç„¶ä¼šéšä¹‹ä¸Šå‡ã€‚</p><hr><h3 id="3-Learning-Curves-å­¦ä¹ æ›²çº¿"><a href="#3-Learning-Curves-å­¦ä¹ æ›²çº¿" class="headerlink" title="3. Learning Curves å­¦ä¹ æ›²çº¿"></a>3. Learning Curves å­¦ä¹ æ›²çº¿</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_7.png" alt=""></p><p>å‡è®¾æˆ‘ä»¬ç”¨ $h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2$ å»æ‹Ÿåˆæ•°æ®ï¼Œå½“æ•°æ®åªæœ‰å‡ ä¸ªçš„æ—¶å€™ï¼Œæ‹Ÿåˆæ•ˆæœé‚£è‚¯å®šçš„éå¸¸å¥½çš„ï¼Œä½†æ˜¯ï¼Œå½“æ•°æ®è¶Šæ¥è¶Šå¤šï¼Œæˆ‘ä»¬çš„å‡è®¾å‡½æ•°å› ä¸ºå¤šé¡¹å¼å¤ªå°‘å°±ä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®äº†ã€‚æ‰€ä»¥è®­ç»ƒé›†çš„è¯¯å·® $J_{train}(\theta)$ ä¼šéšç€æ•°æ®çš„å¢å¤šè€Œå¢å¤§ã€‚å¦‚ä¸Šå›¾è“è‰²çš„æ›²çº¿ã€‚</p><p>ä½†æ˜¯å¯¹äºäº¤å‰éªŒè¯é›†å‘¢ï¼Ÿå› ä¸ºä¸€å¼€å§‹åªæœ‰å‡ ä¸ªæ•°æ®ï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒé›†æ‹Ÿåˆå‡ºæ¥çš„å‚æ•°å°±æœ‰å¾ˆå¤§çš„å¯èƒ½ä¸é€‚åˆäº¤å‰éªŒè¯é›†ï¼Œæ‰€ä»¥åœ¨æ•°æ®å¾ˆå°çš„æƒ…å†µä¸‹å…¶è¯¯å·®æ˜¯å¾ˆå¤§çš„ï¼Œä½†æ˜¯éšç€æ•°æ®çš„æ…¢æ…¢å¢å¤šï¼Œè™½ç„¶ä¸ªåˆ«çš„æ•°æ®æ‹Ÿåˆä¸ä¸Šï¼Œä½†æ˜¯æ•´ä½“çš„æ‹Ÿåˆæ•ˆæœé‚£è‚¯å®šæ¯”åªæœ‰å‡ ä¸ªæ•°æ®çš„æ—¶å€™å¥½äº†ï¼Œæ‰€ä»¥å…¶æ•´ä½“è¯¯å·®æ˜¯é€æ­¥ä¸‹é™çš„ã€‚å¦‚ä¸Šå›¾ç²‰è‰²çš„æ›²çº¿ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_8.png" alt=""></p><p>å½“æ•°æ®å­˜åœ¨é«˜åå·®ä¹Ÿå°±æ˜¯æ¬ æ‹Ÿåˆçš„æ—¶å€™ï¼Œå³ä½¿æ•°æ®å†ç»§ç»­å¢å¤šä¹Ÿæ— è¡¥äºäº‹ï¼Œæ‰€ä»¥å…¶è¯¯å·®ä¼šè¶‹äºä¸€ä¸ªå¹³è¡¡çš„ä½ç½®ï¼Œè€Œä¸” $J_{train}(\theta)$ å’Œ $J_{cv}(\theta)$ çš„è¯¯å·®éƒ½ä¼šå¾ˆå¤§ã€‚</p><p>æ‰€ä»¥ï¼Œå½“æ•°æ®å­˜åœ¨æ¬ æ‹Ÿåˆçš„é—®é¢˜ï¼Œæˆ‘ä»¬é€‰ç”¨æ›´å¤šçš„è®­ç»ƒæ ·æœ¬æ˜¯æ²¡æœ‰åŠæ³•è§£å†³é—®é¢˜çš„ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_9.png" alt=""></p><p>å½“æ•°æ®å­˜åœ¨é«˜æ–¹å·®ä¹Ÿå°±æ˜¯è¿‡æ‹Ÿåˆçš„æ—¶å€™ï¼Œéšç€æ•°æ®çš„å¢å¤šï¼Œå› ä¸ºè¿‡æ‹Ÿåˆæ‰€ä»¥åœ¨è®­ç»ƒé›†åŸºæœ¬èƒ½å®Œç¾æ‹Ÿåˆå…¶æ•°æ®ï¼Œæ‰€ä»¥è®­ç»ƒé›†çš„è¯¯å·®è™½ç„¶ä¼šä¸Šå‡ï¼Œä½†æ˜¯å…¶å¹…åº¦æ˜¯éå¸¸ç¼“æ…¢çš„ï¼Œåœ¨äº¤å‰éªŒè¯é›†ä¹Ÿä¸€æ ·ï¼Œæ‰€ä»¥è¿‡æ‹Ÿåˆçš„æ—¶å€™å…¶å›¾åƒå¦‚ä¸Šï¼Œåœ¨ $J_{train}(\theta)$ å’Œ $J_{cv}(\theta)$ ä¹‹é—´æœ‰ä¸€å¤§æ®µç©ºéš™ã€‚</p><p>æ‰€ä»¥ï¼Œå½“æ•°æ®å­˜åœ¨è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œé€‰ç”¨æ›´å¤šçš„æ ·æœ¬æœ‰åˆ©äºæˆ‘ä»¬è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p><hr><h3 id="4-Deciding-What-to-Do-Next-Revisited-å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ"><a href="#4-Deciding-What-to-Do-Next-Revisited-å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ" class="headerlink" title="4. Deciding What to Do Next Revisited å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ"></a>4. Deciding What to Do Next Revisited å†³å®šä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ</h3><p>æ€»ç»“ ï¼š</p><table><thead><tr><th align="left">æ‰‹æ®µ</th><th align="center">ä½¿ç”¨åœºæ™¯</th></tr></thead><tbody><tr><td align="left">é‡‡é›†æ›´å¤šçš„æ ·æœ¬</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr><tr><td align="left">é™ä½ç‰¹å¾ç»´åº¦</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr><tr><td align="left">é‡‡é›†æ›´å¤šçš„ç‰¹å¾</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">è¿›è¡Œé«˜æ¬¡å¤šé¡¹å¼å›å½’</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">é™ä½å‚æ•°  Î»</td><td align="center">é«˜åå·®(æ¬ æ‹Ÿåˆ)</td></tr><tr><td align="left">å¢å¤§å‚æ•°  Î»</td><td align="center">é«˜æ–¹å·®(è¿‡æ‹Ÿåˆ)</td></tr></tbody></table><p><img src="https://img.halfrost.com/Blog/ArticleImage/74_10.png" alt=""></p><p>å½“æˆ‘ä»¬é€‰ç”¨ä¸€äº›è¾ƒå°çš„ç¥ç»ç½‘ç»œï¼Œè™½ç„¶å…¶è®¡ç®—é‡è¾ƒå°‘ï¼Œä½†æ˜¯å®¹æ˜“å‡ºç°æ¬ æ‹Ÿåˆçš„ç°è±¡ã€‚ç›¸åï¼Œæˆ‘ä»¬é€‰ç”¨ä¸€äº›å±‚æ•°æ¯”è¾ƒå¤šï¼Œå±‚çš„å•å…ƒæ¯”è¾ƒå¤šçš„ç¥ç»ç½‘ç»œï¼Œå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ã€‚æˆ‘ä»¬ä¹‹å‰æåˆ°è¶Šå¤§å‹çš„ç¥ç»ç½‘ç»œæ•ˆæœè¶Šå¥½ï¼Œä¸ºäº†é˜²æ­¢å‡ºç°è¿‡æ‹Ÿåˆçš„ç°è±¡ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ­£åˆ™åŒ–çš„æ–¹æ³•æ¥ä¿®æ­£ã€‚</p><p>ä½¿ç”¨å•ä¸ªéšè—å±‚æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é»˜è®¤å¼€å§‹ã€‚æ‚¨å¯ä»¥ä½¿ç”¨äº¤å‰éªŒè¯é›†åœ¨è®¸å¤šéšè—å±‚ä¸Šè®­ç»ƒæ‚¨çš„ç¥ç»ç½‘ç»œã€‚ç„¶åæ‚¨å¯ä»¥é€‰æ‹©æ€§èƒ½æœ€å¥½çš„ä¸€ä¸ªã€‚</p><p>æ¨¡å‹å¤æ‚æ€§å½±å“ï¼š</p><ul><li>ä½é˜¶å¤šé¡¹å¼ï¼ˆä½æ¨¡å‹å¤æ‚åº¦ï¼‰å…·æœ‰é«˜åå·®å’Œä½æ–¹å·®ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å‹å¾ˆéš¾ä¸€è‡´</li><li>é«˜é˜¶å¤šé¡¹å¼ï¼ˆé«˜æ¨¡å‹å¤æ‚åº¦ï¼‰éå¸¸é€‚åˆè®­ç»ƒæ•°æ®ï¼Œæµ‹è¯•æ•°æ®æå…¶ç³Ÿç³•ã€‚è¿™äº›å¯¹è®­ç»ƒæ•°æ®çš„åå€šä½ï¼Œä½†å·®å¼‚å¾ˆå¤§</li><li>å®é™…ä¸Šï¼Œæˆ‘ä»¬å¸Œæœ›é€‰æ‹©ä¸€ä¸ªä»‹äºä¸¤è€…ä¹‹é—´çš„æ¨¡å‹ï¼Œå®ƒå¯ä»¥å¾ˆå¥½åœ°æ¨å¹¿ï¼Œä½†ä¹Ÿå¯ä»¥å¾ˆå¥½åœ°é€‚åˆæ•°æ®ã€‚</li></ul><hr><h2 id="ä¸‰-Advice-for-Applying-Machine-Learning-æµ‹è¯•"><a href="#ä¸‰-Advice-for-Applying-Machine-Learning-æµ‹è¯•" class="headerlink" title="ä¸‰. Advice for Applying Machine Learning æµ‹è¯•"></a>ä¸‰. Advice for Applying Machine Learning æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?</p><p><img src="http://spark-public.s3.amazonaws.com/ml/images/10.1-c.png" alt=""></p><p>A. High variance</p><p>B. Neither</p><p>C. High bias</p><p>è§£ç­”ï¼šA</p><p>é«˜æ–¹å·®çš„å›¾åƒ</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you have implemented regularized logistic regression to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large errors with its predictions on the new images. However, your hypothesis performs well (has low error) on the training set. Which of the following are promising steps to take? Check all that apply.</p><p>A. Try adding polynomial features.</p><p>B. Get more training examples.</p><p>C. Try using a smaller set of features.</p><p>D. Use fewer training examples.</p><p>è§£ç­”ï¼šBã€C</p><p>è¿‡æ‹Ÿåˆå¯ä»¥å‡å°‘ç‰¹å¾é‡å’Œå¢åŠ è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œæˆ–è€…å¢å¤§æ­£åˆ™åŒ–å‚æ•° $\lambda$ ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you have implemented regularized logistic regression to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis performs poorly on the training set. Which of the following might be promising steps to take? Check all that apply.</p><p>A. Try using a smaller set of features.</p><p>B. Try adding polynomial features.</p><p>C. Try to obtain and use additional features.</p><p>D. Try increasing the regularization parameter $\lambda$.</p><p>è§£ç­”ï¼šBã€C</p><p>æ¬ æ‹Ÿåˆå¯ä»¥å¢åŠ ç‰¹å¾é‡å’Œå‡è®¾å‡½æ•°çš„å¤šé¡¹å¼ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest test set error.</p><p>B. The performance of a learning algorithm on the training set will typically be better than its performance on the test set.</p><p>C. Suppose you are training a regularized linear regression model.The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest training set error.</p><p>D. Suppose you are training a regularized linear regression model. The recommended way to choose what value of regularization parameter $\lambda$ to use is to choose the value of $\lambda$ which gives the lowest cross validation error.</p><p>è§£ç­”ï¼šBã€D</p><p>åœ¨æ­£åˆ™åŒ–çº¿æ€§å›å½’ä¸­ï¼Œ$\lambda$ é€‰æ‹©ä¸€ä¸ªäº¤å‰éªŒè¯é›†è¯¯å·®æœ€å°çš„  Î»Î»  æœ€èƒ½æ‹Ÿåˆæ•°æ®çš„ä½œä¸ºæ­£åˆ™åŒ–å‚æ•°ã€‚</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.</p><p>B. We always prefer models with high variance (over those with high bias) as they will able to better fit the training set.</p><p>C. If a learning algorithm is suffering from high bias, only adding more training examples may not improve the test error significantly.</p><p>D. When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem.</p><p>è§£ç­”ï¼šAã€Cã€D</p><p>A è¿‡æ‹Ÿåˆé«˜æ–¹å·®ï¼Œå¢åŠ æ ·æœ¬æ•°é‡æœ‰ç”¨ã€‚<br>B é«˜åå·®å’Œé«˜æ–¹å·®çš„æ¨¡å‹éƒ½ä¸å¥½ã€‚<br>C å¢åŠ è®­ç»ƒæ ·æœ¬å¯¹äºæ¬ æ‹Ÿåˆæ˜¯æ²¡ç”¨çš„æ­£ç¡®ã€‚<br>D ç»˜åˆ¶å­¦ä¹ æ›²çº¿æœ‰åˆ©äºå¸®åŠ©æˆ‘ä»¬åˆ†æé—®é¢˜æ­£ç¡®ã€‚  </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Advice_for_Applying_Machine_Learning.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.2_Backpropagation_in_Practice</title>
      <link href="/2020/02/05/5-2-backpropagation-in-practice/"/>
      <url>/2020/02/05/5-2-backpropagation-in-practice/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-da4ab697bff80db9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h1 id="5-2-Backpropagation-in-Practice"><a href="#5-2-Backpropagation-in-Practice" class="headerlink" title="5.2 Backpropagation_in_Practice"></a>5.2 Backpropagation_in_Practice</h1><h2 id="ä¸€-Backpropagation-in-Practice"><a href="#ä¸€-Backpropagation-in-Practice" class="headerlink" title="ä¸€. Backpropagation in Practice"></a>ä¸€. Backpropagation in Practice</h2><p>ä¸ºäº†åˆ©ç”¨æ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–ç®—æ³•ï¼Œéœ€è¦ç”¨åˆ° fminunc å‡½æ•°ã€‚å…¶è¾“å…¥çš„å‚æ•°æ˜¯ $\theta$ ï¼Œå‡½æ•°çš„è¿”å›å€¼æ˜¯ä»£ä»·å‡½æ•° jVal å’Œå¯¼æ•°å€¼ gradientã€‚ç„¶åå°†è¿”å›å€¼ä¼ é€’ç»™é«˜çº§ä¼˜åŒ–ç®—æ³• fminuncï¼Œç„¶åè¾“å‡ºä¸ºè¾“å…¥å€¼ @costFunctionï¼Œä»¥åŠ $\theta$ å€¼çš„åˆå§‹å€¼ã€‚</p><p>å…¶ä¸­å‚æ•° $\Theta_1,\Theta_2,\Theta_3,\cdots$ å’Œ $D^{(1)},D^{(2)},D^{(3)},\cdots$ éƒ½ä¸ºçŸ©é˜µï¼Œé‚£ä¹ˆä¸ºäº†èƒ½è°ƒç”¨ fminunc å‡½æ•°ï¼Œæˆ‘ä»¬è¦å°†å…¶å˜æˆå‘é‡ï¼Œ</p><p>å‡å¦‚æˆ‘ä»¬ $\Theta_1,\Theta_2,\Theta_3$ å‚æ•°å’Œ $D^{(1)},D^{(2)},D^{(3)}$ å‚æ•°ï¼ŒTheta1 æ˜¯ $10 * 11$ï¼ŒTheta2 æ˜¯ $10 * 11$ï¼ŒTheta3 æ˜¯ $1 * 11$ã€‚</p><pre class=" language-c"><code class="language-c"><span class="token operator">%</span> æ‰“åŒ…æˆä¸€ä¸ªå‘é‡thetaVector <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">Theta3</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">]</span>deltaVector <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token function">D1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">D2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">D3</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span> <span class="token punctuation">]</span><span class="token operator">%</span> è§£åŒ…è¿˜åŸTheta1 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">110</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span>Theta2 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">:</span><span class="token number">220</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span>Theta3 <span class="token operator">=</span> <span class="token function">reshape</span><span class="token punctuation">(</span><span class="token function">thetaVector</span><span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">:</span><span class="token number">231</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span></code></pre><p>æ‰€ä»¥<strong>å¥—è·¯</strong>æ˜¯ï¼š</p><ol><li>å…ˆå°† $\Theta_1,\Theta_2,\Theta_3$ ,è¿™äº›çŸ©é˜µå±•å¼€ä¸ºä¸€ä¸ªé•¿å‘é‡èµ‹å€¼ç»™ initialThetaï¼Œç„¶åä½œä¸ºthetaå‚æ•°çš„åˆå§‹è®¾ç½®ä¼ å…¥ä¼˜åŒ–å‡½æ•° fminuncã€‚</li><li>å†å®ç°ä»£ä»·å‡½æ•° costFunctionã€‚costFunction å‡½æ•°å°†ä¼ å…¥å‚æ•° thetaVecï¼ˆå°±æ˜¯åˆšæ‰åŒ…å«æ‰€æœ‰ $\Theta$ å‚æ•°çš„å‘é‡ï¼‰ï¼Œç„¶åé€šè¿‡ reshape å‡½æ•°å¾—åˆ°åˆå§‹çš„çŸ©é˜µï¼Œè¿™æ ·å¯ä»¥æ›´æ–¹ä¾¿åœ°é€šè¿‡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä»¥æ±‚å¾—å¯¼æ•° $D^{(1)},D^{(2)},D^{(3)}$ å’Œä»£ä»·å‡½æ•° $F(\Theta)$ ã€‚</li><li>æœ€åæŒ‰é¡ºåºå±•å¼€å¾—åˆ° gradientVecï¼Œè®©å®ƒä»¬ä¿æŒå’Œä¹‹å‰å±•å¼€çš„ $\theta$ å€¼åŒæ ·çš„é¡ºåºã€‚ä»¥ä¸€ä¸ªå‘é‡çš„å½¢å¼è¿”å›è¿™äº›å¯¼æ•°å€¼ã€‚</li></ol><hr><h2 id="äºŒ-Gradient-Checking"><a href="#äºŒ-Gradient-Checking" class="headerlink" title="äºŒ. Gradient Checking"></a>äºŒ. Gradient Checking</h2><p>åœ¨è®¡ç®—å¯¼æ•°çš„æ—¶å€™ï¼Œä¹ æƒ¯å°†å…¶ç­‰äºåœ¨è¯¥ç‚¹çš„å¯¼æ•°ï¼Œåœ¨æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™è®¡ç®—å¯¼æ•°çš„æ—¶å€™ï¼Œè™½ç„¶å¯èƒ½ $F(\Theta)$ æ¯æ¬¡è¿­ä»£éƒ½åœ¨ä¸‹é™ï¼Œä½†æ˜¯å› ä¸ºåå‘ä¼ æ’­çš„å¤æ‚æ€§ï¼Œå¯èƒ½å¯¼è‡´æˆ‘ä»¬çš„ä»£ç å­˜åœ¨ BUGã€‚æœ‰ä¸€ä¸ªåŠæ³•å«åšæ¢¯åº¦æ£€éªŒï¼ˆGradient Checkingï¼‰ï¼Œå®ƒèƒ½å‡å°‘è¿™ç§é”™è¯¯çš„æ¦‚ç‡ï¼ˆå‡ºç°è¿™ä¸ªé—®é¢˜çš„åŸå› éƒ½å’Œåå‘ä¼ æ’­çš„é”™è¯¯å®ç°æœ‰å…³ï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_1.png" alt></p><p>åœ¨æˆ‘ä»¬æ±‚è¯¥ç‚¹çš„æ–œç‡çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¸ç›´æ¥ä½¿ç”¨å…¶å¯¼æ•°ï¼Œè€Œæ˜¯ç”¨ $$\frac{d}{d\Theta}F(\Theta)\approx\frac{F(\Theta+\epsilon)-F(\Theta-\epsilon)}{2\epsilon}$$ ä»£æ›¿ã€‚é€šå¸¸ $\epsilon$ å–è¾ƒå°çš„ä¸€ä¸ªæ•°ã€‚ï¼ˆå…¶å®å°±æ˜¯ä½¿ç”¨å¯¼æ•°çš„å®šä¹‰ï¼‰</p><p>ä¸Šé¢è¿™ç§ç®—æ³•æ˜¯åŒä¾§å·®åˆ†ç®—æ³•ï¼Œä¸ä¹‹ç›¸å¯¹çš„æ˜¯å•ä¾§å·®åˆ†ç®—æ³•</p><p>$$\frac{d}{d\Theta}F(\Theta)\approx\frac{F(\Theta+\epsilon)-F(\Theta)}{\epsilon}$$</p><p>å•ä¾§å·®åˆ†å’ŒåŒä¾§å·®åˆ†ç›¸æ¯”ï¼ŒåŒä¾§å·®åˆ†å¯ä»¥å¾—åˆ°æ›´åŠ å‡†ç¡®çš„ç»“æœã€‚</p><p>æ¨å¹¿ä¸€ä¸‹åŒä¾§å·®åˆ†ï¼š</p><p>$$\frac{d}{d\Theta_j}J(\Theta)\approx\frac{J(\Theta_1,â€¦,+\Theta_j+\epsilon,â€¦,\Theta_n)-J(\Theta_1,â€¦,+\Theta_j-\epsilon,â€¦,\Theta_n)}{2\epsilon}$$</p><p>å¯¹åº”ä»£ç å®ç°å¦‚ä¸‹ï¼š</p><pre class=" language-c"><code class="language-c">epsilon <span class="token operator">=</span> <span class="token number">1e-4</span><span class="token punctuation">;</span><span class="token keyword">for</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">:</span>n<span class="token punctuation">,</span>  thetaPlus <span class="token operator">=</span> theta<span class="token punctuation">;</span>  <span class="token function">thetaPlus</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span><span class="token operator">=</span> epsilon<span class="token punctuation">;</span>  thetaMinus <span class="token operator">=</span> theta<span class="token punctuation">;</span>  <span class="token function">thetaMinus</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">=</span> epsilon<span class="token punctuation">;</span>  <span class="token function">gradApprox</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">J</span><span class="token punctuation">(</span>thetaPlus<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token function">J</span><span class="token punctuation">(</span>thetaMinus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>epsilon<span class="token punctuation">)</span>end<span class="token punctuation">;</span></code></pre><p>æ£€æŸ¥åå‘ä¼ æ’­è®¡ç®—å‡ºæ¥çš„å¯¼æ•° DVec å’Œ ä¸Šé¢ç¨‹åºè®¡ç®—å‡ºæ¥çš„ gradApprox ç›¸æ¯”è¾ƒï¼Œå¦‚æœ $gradApprox \approx DVec$ ä»£è¡¨åå‘ä¼ æ’­çš„å®ç°æ˜¯æ­£ç¡®çš„ã€‚</p><p>æœ€ååœ¨ä½¿ç”¨ç®—æ³•å­¦ä¹ çš„æ—¶å€™å…³é—­æ¢¯åº¦æ£€éªŒã€‚å› ä¸ºæ¢¯åº¦æ£€éªŒä¸»è¦æ˜¯ä¸ºäº†è®©æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬å†™çš„ç¨‹åºç®—æ³•æ˜¯å¦å­˜åœ¨é”™è¯¯ï¼Œè€Œä¸æ˜¯ç”¨æ¥è®¡ç®—å¯¼æ•°çš„ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•è®¡ç®—å¯¼æ•°ç›¸æ¯”äºä¹‹å‰çš„ä¼šéå¸¸æ…¢ã€‚</p><p>æ€»ç»“ä¸€ä¸‹ï¼š</p><ol><li>é€šè¿‡åå‘ä¼ æ’­æ¥è®¡ç®— DVecï¼ŒDVec æ˜¯æ¯ä¸ªçŸ©é˜µæ‰“åŒ…å±•å¼€çš„å½¢å¼ã€‚</li><li>å®ç°æ•°å€¼ä¸Šçš„æ¢¯åº¦æ£€æµ‹ï¼Œè®¡ç®—å‡º gradApproxã€‚</li><li>æ¯”è¾ƒ $gradApprox \approx DVec$ æ˜¯å¦ç›¸ç­‰æˆ–è€…çº¦ç­‰äºã€‚</li><li>ä½¿ç”¨ç®—æ³•å­¦ä¹ çš„æ—¶å€™è®°å¾—è¦å…³é—­è¿™ä¸ªæ¢¯åº¦æ£€éªŒï¼Œæ¢¯åº¦æ£€éªŒåªåœ¨ä»£ç æµ‹è¯•é˜¶æ®µè¿›è¡Œã€‚</li></ol><hr><h2 id="ä¸‰-Random-Initialization"><a href="#ä¸‰-Random-Initialization" class="headerlink" title="ä¸‰. Random Initialization"></a>ä¸‰. Random Initialization</h2><p>ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•çš„æ—¶å€™ï¼Œéœ€è¦è®¾ç½® $\Theta$ åˆå§‹å€¼ã€‚</p><pre class=" language-c"><code class="language-c">optTheta <span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span>@costFunction<span class="token punctuation">,</span> initialTheta<span class="token punctuation">,</span> options<span class="token punctuation">)</span></code></pre><p>è°ƒç”¨ fminunc å‡½æ•°çš„æ—¶å€™ï¼ŒinitialTheta å¦‚æœå…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼Œ</p><pre class=" language-c"><code class="language-c">initialTheta <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><p>åœ¨ä¹‹å‰çš„çº¿æ€§å›å½’å’Œé€»è¾‘å›å½’ä¸­ï¼Œä½¿ç”¨æ¢¯åº¦å‡½æ•°ï¼Œåˆå§‹å€¼è®¾ç½®ä¸º0æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æ˜¯åˆ°äº†ç¥ç»ç½‘ç»œé‡Œé¢ï¼Œå¦‚æœè¿˜è¿™ä¹ˆè®¾ç½®ï¼Œä¼šå‡ºç°é«˜åº¦å†—ä½™ç°è±¡ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_2.png" alt></p><p>å‡è®¾æˆ‘ä»¬æœ‰è¿™æ ·ä¸€ä¸ªç½‘ç»œï¼Œå…¶åˆå§‹å‚æ•°éƒ½è®¾ä¸º0ã€‚é‚£ä¹ˆæˆ‘ä»¬ä¼šå‘ç°å…¶æ¿€åŠ± $a_1^{(2)}=a_2^{(2)}$ ,ä¸”è¯¯å·® $\delta_1^{(2)}=\delta_2^{(2)}$ ,ä¸”å¯¼æ•° $\frac{d}{d\Theta^{(1)}_{01}}J(\Theta)=\frac{d}{d\Theta^{(1)}_{02}}J(\Theta)$ ã€‚è¿™å°±å¯¼è‡´äº†åœ¨å‚æ•°æ›´æ–°çš„æƒ…å†µä¸‹ï¼Œä¸¤ä¸ªå‚æ•°æ˜¯ä¸€æ ·çš„ã€‚æ— è®ºæ€ä¹ˆé‡å¤è®¡ç®—å…¶ä¸¤è¾¹çš„æ¿€åŠ±è¿˜æ˜¯ä¸€æ ·çš„ã€‚</p><p>ä¸Šè¿°é—®é¢˜è¢«ç§°ä¸ºï¼Œå¯¹ç§°æƒé‡é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯æ‰€æœ‰æƒé‡éƒ½æ˜¯ä¸€æ ·çš„ã€‚æ‰€ä»¥éšæœºåˆå§‹åŒ–æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ã€‚</p><p>æˆ‘ä»¬å°†åˆå§‹åŒ–æƒå€¼ $\Theta_{ij}^{(l)}$ çš„èŒƒå›´é™å®šåœ¨ $[-\Phi ,\Phi ]$ ã€‚</p><p>å…¶ä»£ç è¡¨ç¤ºå¦‚ä¸‹ï¼š</p><pre class=" language-c"><code class="language-c"><span class="token operator">%</span>If the dimensions of Theta1 is 10x11<span class="token punctuation">,</span> Theta2 is 10x11 and Theta3 is 1x11<span class="token punctuation">.</span>Theta1 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span>Theta2 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span>Theta3 <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> INIT_EPSILON<span class="token punctuation">)</span> <span class="token operator">-</span> INIT_EPSILON<span class="token punctuation">;</span></code></pre><p>rand(xï¼Œy)æ˜¯éšæœºå‡½æ•°ï¼Œå®ƒå°†åˆå§‹åŒ–ä¸€ä¸ª0åˆ°1ä¹‹é—´çš„éšæœºå®æ•°çŸ©é˜µã€‚</p><hr><h2 id="å››-æ€»ç»“"><a href="#å››-æ€»ç»“" class="headerlink" title="å››. æ€»ç»“"></a>å››. æ€»ç»“</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_3.png" alt></p><h3 id="1-å‡†å¤‡"><a href="#1-å‡†å¤‡" class="headerlink" title="1. å‡†å¤‡"></a>1. å‡†å¤‡</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç¡®å®šç¥ç»ç½‘ç»œæœ‰å¤šå°‘è¾“å…¥å•å…ƒï¼Œæœ‰å¤šå°‘éšè—å±‚ï¼Œæ¯ä¸€å±‚éšè—å±‚åˆæœ‰å¤šå°‘ä¸ªå•å…ƒï¼Œè¿˜æœ‰å¤šå°‘è¾“å‡ºå•å…ƒã€‚é‚£æˆ‘ä»¬æ€ä¹ˆå»é€‰æ‹©å‘¢ï¼Ÿ</p><ul><li>è¾“å…¥å•å…ƒæ˜¯ç‰¹å¾å‘é‡ $x^{(i)}$ çš„ç»´åº¦</li><li>è¾“å‡ºå•å…ƒæ˜¯åˆ†ç±»çš„ä¸ªæ•°</li><li>æ¯ä¸ªéšè—å±‚çš„å•å…ƒæ•°é€šå¸¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼ˆå¿…é¡»ä¸è®¡ç®—æˆæœ¬å¹³è¡¡ï¼Œå› ä¸ºéšç€æ›´å¤šéšè—å•å…ƒçš„å¢åŠ è€Œå¢åŠ ï¼‰</li><li>é»˜è®¤å€¼ï¼š1ä¸ªéšè—å±‚ã€‚å¦‚æœæœ‰å¤šä¸ªéšè—å±‚ï¼Œé‚£ä¹ˆå»ºè®®æ‚¨åœ¨æ¯ä¸ªéšè—å±‚ä¸­éƒ½æœ‰ç›¸åŒæ•°é‡çš„å•å…ƒã€‚</li></ul><p>è¾“å‡ºå•å…ƒå¦‚æœæ˜¯å¤šå…ƒåˆ†ç±»é—®é¢˜ï¼Œè¾“å‡ºå•å…ƒéœ€è¦å†™æˆçŸ©é˜µçš„å½¢å¼ï¼š</p><p>ä¾‹å¦‚æœ‰3ä¸ªåˆ†ç±»ï¼Œ è¾“å‡ºå•å…ƒåº”è¯¥å†™æˆ</p> $$\begin{align*}y = \begin{bmatrix} 1\\ 0\\ 0 \\ \end{bmatrix} or\begin{bmatrix} 0\\ 1\\ 0 \\ \end{bmatrix} or\begin{bmatrix} 0\\ 0\\ 1\\ \end{bmatrix}\end{align*}$$<h3 id="2-è®­ç»ƒ"><a href="#2-è®­ç»ƒ" class="headerlink" title="2. è®­ç»ƒ"></a>2. è®­ç»ƒ</h3><p>ç¬¬ä¸€æ­¥ï¼šéšæœºåˆå§‹åŒ–æƒé‡ã€‚åˆå§‹åŒ–çš„å€¼æ˜¯éšæœºçš„ï¼Œå€¼å¾ˆå°ï¼Œæ¥è¿‘äºé›¶ã€‚</p><p>ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œå‰å‘ä¼ æ’­ç®—æ³•ï¼Œå¯¹äºæ¯ä¸€ä¸ª $x^{(i)}$ è®¡ç®—å‡ºå‡è®¾å‡½æ•° $h_\Theta(x^{(i)})$ ã€‚</p><p>ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—å‡ºä»£ä»·å‡½æ•° $F(\Theta)$ ã€‚</p><p>ç¬¬å››æ­¥ï¼šæ‰§è¡Œåå‘ä¼ æ’­ç®—æ³•ï¼Œè®¡ç®—å‡ºåå¯¼æ•° $\frac{\partial}{\partial\Theta_{jk}^{(l)}}F(\Theta)$ ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/73_4.png" alt></p><p>å…·ä½“æ“ä½œå°±æ˜¯ä½¿ç”¨ä¸€ä¸ªforå¾ªç¯ï¼Œå…ˆå°† $(x^{(1)},y^{(1)})$ è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„æ“ä½œï¼Œç„¶åå†å¯¹ $(x^{(2)},y^{(2)})$ è¿›è¡Œç›¸åŒçš„æ“ä½œä¸€ç›´åˆ° $(x^{(n)},y^{(n)})$ ï¼Œè¿™æ ·å°±èƒ½å¾—åˆ°ç¥ç»ç½‘ç»œä¸­æ¯ä¸€å±‚ä¸­æ¯ä¸ªå•å…ƒå¯¹åº”çš„æ¿€åŠ±å€¼ï¼Œå’Œæ¯ä¸€å±‚æ¿€åŠ±çš„è¯¯å·® $\delta^{(l)}$ ã€‚</p><p>ç¬¬äº”æ­¥ï¼šåˆ©ç”¨æ¢¯åº¦æ£€æŸ¥ï¼Œå¯¹æ¯”åå‘ä¼ æ’­ç®—æ³•è®¡ç®—å¾—åˆ°çš„åå¯¼æ•°é¡¹æ˜¯å¦ä¸æ¢¯åº¦æ£€éªŒç®—æ³•è®¡ç®—å‡ºçš„å¯¼æ•°é¡¹åŸºæœ¬ç›¸ç­‰ã€‚<strong>æ£€æŸ¥å®Œè®°å¾—åˆ é™¤æ‰è¿™æ®µæ£€æŸ¥çš„ä»£ç </strong>ã€‚</p><p>ç¬¬å…­æ­¥ï¼šæœ€åæˆ‘ä»¬åˆ©ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æˆ–è€…æ›´é«˜çº§çš„ç®—æ³•ä¾‹å¦‚ LBFGSã€å…±è½­æ¢¯åº¦æ³•ç­‰ï¼Œç»“åˆä¹‹å‰ç®—å‡ºçš„åå¯¼æ•°é¡¹ï¼Œæœ€å°åŒ–ä»£ä»·å‡½æ•° $F(\Theta)$ ç®—å‡ºæƒå€¼çš„å¤§å° $\Theta$ ã€‚</p><p>ç†æƒ³æƒ…å†µä¸‹ï¼Œåªè¦æ»¡è¶³äº† $h_{\Theta}(x^{(i)})\approx y^{(i)}$ï¼Œå°±èƒ½ä½¿æˆ‘ä»¬çš„ä»£ä»·å‡½æ•°æœ€å°ã€‚ä½†æ˜¯ï¼Œä»£ä»·å‡½æ•° $F(\Theta)$ ä¸æ˜¯å‡¸çš„ï¼Œå› æ­¤æˆ‘ä»¬æœ€ç»ˆå¯ä»¥ç”¨å±€éƒ¨æœ€å°å€¼ä»£æ›¿å…¨å±€æœ€å°å€¼ã€‚</p><hr><h2 id="äº”-Neural-Networks-Learning-æµ‹è¯•"><a href="#äº”-Neural-Networks-Learning-æµ‹è¯•" class="headerlink" title="äº”. Neural Networks: Learning æµ‹è¯•"></a>äº”. Neural Networks: Learning æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You are training a three layer neural network and would like to use backpropagation to compute the gradient of the cost function. In the backpropagation algorithm, one of the steps is to update</p>$\Delta^{(2)}_{ij}:=\Delta^{(2)}_{ij}+\delta^{(3)}_{i}*(a^{(2)})_{j}$  <p>for every i,j. Which of the following is a correct vectorization of this step?</p><p>A. $\Delta^{(2)}:=\Delta^{(2)}+(a^{(3)})^T * \delta^{(2)} $<br>B. $\Delta^{(2)}:=\Delta^{(2)}+(a^{(2)})^T * \delta^{(3)} $<br>C. $\Delta^{(2)}:=\Delta^{(2)}+\delta^{(3)}*(a^{(3)})^T $</p><p>D. $\Delta^{(2)}:=\Delta^{(2)}+\delta^{(3)}*(a^{(2)})^T $    </p><p>è§£ç­”ï¼š D</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose ğšƒğš‘ğšğšğšŠğŸ· is a 5x3 matrix, and ğšƒğš‘ğšğšğšŠğŸ¸ is a 4x6 matrix. You set ğšğš‘ğšğšğšŠğš…ğšğšŒ=[ğšƒğš‘ğšğšğšŠğŸ·(:);ğšƒğš‘ğšğšğšŠğŸ¸(:)]. Which of the following correctly recovers ğšƒğš‘ğšğšğšŠğŸ¸?</p><p>A. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¹ğŸ¿),ğŸº,ğŸ¼)<br>B. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ»:ğŸ¹ğŸ¾),ğŸº,ğŸ¼)<br>C. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¸ğŸº),ğŸº,ğŸ¼)<br>D. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ»:ğŸ¹ğŸ¿),ğŸº,ğŸ¼)<br>E. ğš›ğšğšœğš‘ğšŠğš™ğš(ğšğš‘ğšğšğšŠğš…ğšğšŒ(ğŸ·ğŸ¼:ğŸ¹ğŸ¿),ğŸ¼,ğŸº)  </p><p>è§£ç­”ï¼šA</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Let $J(\theta)=2\theta^3+2$ . Let $\theta=1$ , and  $\epsilon=0.01$ . Use the formula $\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$ to numerically compute an approximation to the derivative at $\theta=1$ . What value do you get? (When $\theta=1$ , the true/exact derivati ve is $\frac{dJ(\theta)}{d\theta}=6$ .)</p><p>A.6<br>B.8<br>C.5.9998<br>D.6.0002  </p><p>è§£ç­”ï¼š D</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Gradient checking is useful if we are using gradient descent as our optimization algorithm. However, it serves little purpose if we are using one of the advanced optimization methods (such as in fminunc).  </p><p>B. If our neural network overfits the training set, one reasonable step to take is to increase the regularization parameter Î» .  </p><p>C. Using gradient checking can help verify if oneâ€™s implementation of backpropagation is bug-free.  </p><p>D. Using a large value of Î» cannot hurt the performance of your neural network; the only reason we do not set Î» to be too large is to avoid numerical problems.  </p><p>E. For computational efficiency, after we have performed gradient checking to verify that our backpropagation code is correct, we usually disable gradient checking before using backpropagation to train the network.  </p><p>F. Computing the gradient of the cost function in a neural network has the same efficiency when we use backpropagation or when we numerically compute it using the method of gradient checking.  </p><p>è§£ç­”ï¼šBã€Cã€E</p><p>A.æ¢¯åº¦æ£€éªŒåªæ˜¯ç”¨æ¥æ£€éªŒæˆ‘ä»¬ç®—åå¯¼æ•°çš„ç®—æ³•æ˜¯å¦æ­£ç¡®ï¼Œè€Œä¸æ˜¯ç”¨æ¥è®¡ç®—çš„ã€‚<br>B.è¿‡æ‹Ÿåˆå¢å¤§æ­£åˆ™åŒ–å‚æ•° Î» æ­£ç¡®ã€‚<br>C.æ¢¯åº¦æ£€éªŒèƒ½æ£€éªŒåå‘ä¼ æ’­ç®—æ³•æ˜¯å¦æ­£ç¡®ã€‚<br>D.æ­£åˆ™åŒ–å‚æ•° Î» å¤ªå¤§ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚<br>E.è¿˜æ˜¯åœ¨è¯´æ¢¯åº¦æ£€éªŒèƒ½éªŒè¯åå‘ä¼ æ’­ç®—æ³•çš„æ­£ç¡®æ€§ã€‚<br>F.è¿˜æ˜¯åœ¨è¯´æ¢¯åº¦æ£€éªŒå¯ä»¥ç”¨æ¥åœ¨ç®—æ³•é‡Œç®—åå¯¼æ•°ã€‚  </p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you have a three layer network with parameters  $\Theta^{(1)}$ (controlling the function mapping from the inputs to the hidden units) and  $\Theta^{(2)}$ (controlling the mapping from the hidden units to the outputs). If we set all the elements of  $\Theta^{(1)}$ to be 0, and all the elements of  $\Theta^{(2)}$ to be 1, then this suffices for symmetry breaking, since the neurons are no longer all computing the same function of the input.</p><p>B. If we are training a neural network using gradient descent, one reasonable â€œdebuggingâ€ step to make sure it is working is to plot $J(\Theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.</p><p>C. Suppose you are training a neural network using gradient descent. Depending on your random initialization, your algorithm may converge to different local optima (i.e., if you run the algorithm twice with different random initializations, gradient descent may converge to two different solutions).</p><p>D. If we initialize all the parameters of a neural network to ones instead of zeros, this will suffice for the purpose of â€œsymmetry breakingâ€ because the parameters are no longer symmetrically equal to zero.</p><p>E. If we are training a neural network using gradient descent, one reasonable â€œdebuggingâ€ step to make sure it is working is to plot $J(\Theta)$ as a function of the number of iterations, and make sure it is decreasing (or at least non-increasing) after each iteration.</p><p>F. Suppose we have a correct implementation of backpropagation, and are training a neural network using gradient descent. Suppose we plot $J(\Theta)$ as a function of the number of iterations, and find that it is increasing rather than decreasing. One possible cause of this is that the learning rate $\alpha$ is too large.</p><p>G. Suppose that the parameter $\Theta^{(1)}$ is a square matrix (meaning the number of rows equals the number of columns). If we replace $\Theta^{(1)}$ with its transpose $(\Theta^{(1)})^T$ , then we have not changed the function that the network is computing.</p><p>H. Suppose we are using gradient descent with learning rate $\alpha$ . For logistic regression and linear regression, $J(\Theta)$ was a convex optimization problem and thus we did not want to choose a learning rate $\alpha$ that is too large. For a neural network however, $J(\Theta)$ may not be convex, and thus choosing a very large value of $\alpha$ can only speed up convergence.</p><p>è§£ç­”ï¼šBã€Cã€F</p><p>A.ä¸€å±‚çš„æƒé‡éƒ½æ˜¯ä¸€æ ·çš„æ•°å­—ä¸èƒ½æ‰“ç ´å¯¹ç§°ã€‚<br>B.è¿­ä»£æ¬¡æ•°çš„è¶Šå¤šï¼Œä»£ä»·å‡½æ•° $J(\Theta)$ ä¸‹é™æ­£ç¡®ã€‚<br>C.å­¦ä¹ é€Ÿç‡ $\alpha$ å¤ªå¤§ä¼šå¯¼è‡´ä»£ä»·å‡½æ•°éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ ä¹Ÿå¢åŠ æ­£ç¡®ã€‚<br>D.æƒé‡å…¨éƒ¨ä¸º1ä¹Ÿä¸èƒ½æ‰“ç ´å¯¹ç§°çš„ã€‚<br>E.ä¿è¯ $J(\Theta)$ éšç€è¿­ä»£æ¬¡æ•°çš„å¢åŠ è€Œä¸‹é™ç”¨ä»¥éªŒè¯ç®—æ³•çš„æ­£ç¡®ã€‚<br>F.åŒBã€‚<br>G.çŸ©é˜µçš„å€’ç½®ä¸€èˆ¬ä¸ç›¸ç­‰ã€‚<br>H.é€‰æ‹©å¤§çš„å­¦ä¹ é€Ÿç‡ $\alpha$ ä¼šå¯¼è‡´ $J(\Theta)$ ä¸æ”¶æ•›çš„ã€‚  </p><hr><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Backpropagation_in_Practice.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.1_Neural_Networks_Learning</title>
      <link href="/2020/02/05/5-1-neural-networks-learning/"/>
      <url>/2020/02/05/5-1-neural-networks-learning/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-03b47f040418215a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h1 id="5-1-Neural-Networks-Learning"><a href="#5-1-Neural-Networks-Learning" class="headerlink" title="5.1_Neural_Networks_Learning"></a>5.1_Neural_Networks_Learning</h1><h2 id="ä¸€-Cost-Function-and-Backpropagation"><a href="#ä¸€-Cost-Function-and-Backpropagation" class="headerlink" title="ä¸€. Cost Function and Backpropagation"></a>ä¸€. Cost Function and Backpropagation</h2><h3 id="1-Cost-Function"><a href="#1-Cost-Function" class="headerlink" title="1. Cost Function"></a>1. Cost Function</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_3.png" alt></p><p>å‡è®¾è®­ç»ƒé›†ä¸­æœ‰ m ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œ$\begin{Bmatrix} (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \cdots ,(x^{(m)},y^{(m)}) \end{Bmatrix}$ï¼ŒL è¡¨ç¤ºç¥ç»ç½‘ç»œçš„æ€»å±‚æ•° Layerï¼Œç”¨ $S_{l}$ è¡¨ç¤ºç¬¬ L å±‚çš„å•å…ƒæ•°(ç¥ç»å…ƒçš„æ•°é‡)ï¼Œä½†æ˜¯ä¸åŒ…æ‹¬ç¬¬ L å±‚çš„åå·®å•å…ƒ(å¸¸æ•°é¡¹)ã€‚ä»¤ K ä¸ºè¾“å‡ºå±‚çš„å•å…ƒæ•°ç›®ï¼Œå³ æœ€åä¸€å±‚çš„å•å…ƒæ•°ã€‚</p><p><strong>ç¬¦å·çº¦å®š</strong>ï¼š</p><p>$z_i^{(j)}$ =  ç¬¬ $j$ å±‚çš„ç¬¬ $i$ ä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œè®¡ç®—å€¼â€<br>$a_i^{(j)}$ = ç¬¬ $j$ å±‚çš„ç¬¬ $i$ ä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œæ¿€æ´»å€¼â€;</p> $\Theta^{(l)}_{i,j}$  = æ˜ å°„ç¬¬ $l$ å±‚åˆ°ç¬¬ $l+1$ å±‚çš„æƒå€¼çŸ©é˜µçš„ç¬¬ $i$ è¡Œç¬¬ $j$ åˆ—çš„åˆ†é‡<p>$L$ = ç¥ç»ç½‘ç»œæ€»å±‚æ•°ï¼ˆåŒ…æ‹¬è¾“å…¥å±‚ã€éšå±‚å’Œè¾“å‡ºå±‚ï¼‰<br>$s_l$ = ç¬¬ $l$ å±‚èŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰ä¸ªæ•°ï¼Œä¸åŒ…æ‹¬åç§»é‡èŠ‚ç‚¹ã€‚<br>$K$ = è¾“å‡ºèŠ‚ç‚¹ä¸ªæ•°<br>$h_{\theta}(x)_k$ = ç¬¬ $k$ ä¸ªé¢„æµ‹è¾“å‡ºç»“æœ<br>$x^{(i)}$ = ç¬¬ $i$ ä¸ªæ ·æœ¬ç‰¹å¾å‘é‡<br>$x^{(i)}_k$ = ç¬¬ $i$ ä¸ªæ ·æœ¬çš„ç¬¬ $k$ ä¸ªç‰¹å¾å€¼<br>$y^{(i)}$ = ç¬¬ $i$ ä¸ªæ ·æœ¬å®é™…ç»“æœå‘é‡<br>$y^{(i)}_k$ = ç¬¬ $i$ ä¸ªæ ·æœ¬ç»“æœå‘é‡çš„ç¬¬ $k$ ä¸ªåˆ†é‡   </p><p>ä¹‹å‰è®¨è®ºçš„é€»è¾‘å›å½’ä¸­ä»£ä»·å‡½æ•°å¦‚ä¸‹ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] +\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_{j}^{2}  \\\end{align*}$$<p>æ‰©å±•åˆ°ç¥ç»ç½‘ç»œä¸­ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\Theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} \sum_{k=1}^{K} y^{(i)}_{k} log(h_{\Theta}(x^{(i)}))_{k} + (1-y^{(i)}_{k})log(1-(h_{\Theta}(x^{(i)}))_{k}) \right ] +\frac{\lambda}{2m} \sum_{l=1}^{L-1} \sum_{i=1}^{S_{l}}\sum_{j=1}^{S_{l} +1}(\Theta_{j,i}^{(l)})^{2}  \\h_{\Theta}(x) &amp;\in \mathbb{R}^{K} \;\;\;\;\;\;\;\;\; (h_{\Theta}(x))_{i} = i^{th} \;\;output \\\end{align*}$$<p>$h_{\Theta}(x)$ æ˜¯ä¸€ä¸ª K ç»´å‘é‡ï¼Œ$ i $ è¡¨ç¤ºé€‰æ‹©è¾“å‡ºç¥ç»ç½‘ç»œè¾“å‡ºå‘é‡ä¸­çš„ç¬¬ i ä¸ªå…ƒç´ ã€‚</p><p>ç¥ç»ç½‘ç»œçš„ä»£ä»·å‡½æ•°ç›¸æ¯”é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°ï¼Œå‰ä¸€é¡¹çš„æ±‚å’Œè¿‡ç¨‹ä¸­å¤šäº†ä¸€ä¸ª $ \sum_{k=1}^{K} $ ,ç”±äº K ä»£è¡¨äº†æœ€åä¸€å±‚çš„å•å…ƒæ•°ï¼Œæ‰€ä»¥è¿™é‡Œå°±æ˜¯ç´¯åŠ äº† k ä¸ªè¾“å‡ºå±‚çš„ä»£ä»·å‡½æ•°ã€‚</p><p>åä¸€é¡¹æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œç¥ç»ç½‘ç»œçš„æ­£åˆ™åŒ–é¡¹çœ‹èµ·æ¥ç‰¹åˆ«å¤æ‚ï¼Œå…¶å®å°±æ˜¯å¯¹ $ (\Theta_{j,i}^{(l)})^{2} $ é¡¹å¯¹æ‰€æœ‰çš„ iï¼Œjï¼Œlçš„å€¼æ±‚å’Œã€‚æ­£å¦‚åœ¨é€»è¾‘å›å½’ä¸­çš„ä¸€æ ·ï¼Œè¿™é‡Œè¦é™¤å»é‚£äº›å¯¹åº”äºåå·®å€¼çš„é¡¹ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¯¹å®ƒä»¬è¿›è¡Œæ±‚å’Œï¼Œå³ä¸å¯¹ $ (\Theta_{j,0}^{(l)})^{2} ;;;;(i=0) $ é¡¹æ±‚å’Œã€‚</p><h3 id="2-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•"><a href="#2-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•" class="headerlink" title="2. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•"></a>2. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•</h3><p>ä»¤ $ \delta_{j}^{(l)} $ è¡¨ç¤ºç¬¬ $l$ å±‚ç¬¬ $j$ ä¸ªç»“ç‚¹çš„è¯¯å·®ã€‚</p><p>åå‘ä¼ æ’­ä»æœ€åä¸€å±‚å¼€å§‹å¾€å‰æ¨ï¼š</p>$$\begin{align*}\delta_{j}^{(L)} &amp;= a_{j}^{(L)} - y_{j} \\&amp;=(h_{\theta}(x))_{j} - y_{j} \\\end{align*}$$<p>å¾€å‰è®¡ç®—å‡ æ­¥ï¼š</p>$$\begin{align*}\delta^{(3)} &amp;= (\Theta^{(3)})^{T}\delta^{(4)} . * g^{'}(z^{(3)}) \\\delta^{(2)} &amp;= (\Theta^{(2)})^{T}\delta^{(3)} . * g^{'}(z^{(2)}) \\\end{align*}$$<p>é€»è¾‘å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰æ±‚å¯¼ï¼š</p>$$\begin{align*}\sigma(x)'&amp;=\left(\frac{1}{1+e^{-x}}\right)'=\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}=\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline &amp;=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)\\&amp;=\sigma(x)(1 - \sigma(x))\\\end{align*}$$<p>å¯ä»¥ç®—å‡º $g^{â€˜}(z^{(3)}) = a^{(3)} . * (1-a^{(3)})$ ï¼Œ $g^{â€˜}(z^{(2)}) = a^{(2)} . * (1-a^{(2)})$ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_4.png" alt></p><p>äºæ˜¯å¯ä»¥ç»™å‡ºåå‘ä¼ æ’­çš„ç®—æ³•æ­¥éª¤ï¼š</p><p>é¦–å…ˆæœ‰ä¸€ä¸ªè®­ç»ƒé›† $\begin{Bmatrix} (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \cdots ,(x^{(m)},y^{(m)}) \end{Bmatrix}$ï¼Œåˆå§‹å€¼å¯¹æ¯ä¸€ä¸ª $(l,i,j)$ éƒ½è®¾ç½® $\Delta^{(l)}_{i,j} := 0$ ï¼Œå³åˆå§‹çŸ©é˜µæ˜¯å…¨é›¶çŸ©é˜µã€‚</p><p>é’ˆå¯¹ $1-m$ è®­ç»ƒé›†å¼€å§‹ä»¥ä¸‹æ­¥éª¤çš„è®­ç»ƒï¼š</p><h3 id="1-å‰å‘ä¼ æ’­"><a href="#1-å‰å‘ä¼ æ’­" class="headerlink" title="(1) å‰å‘ä¼ æ’­"></a>(1) å‰å‘ä¼ æ’­</h3><p>è®¾ç½® $ a^{(1)} := x^{(t)} $ï¼Œå¹¶æŒ‰ç…§å‰å‘ä¼ æ’­çš„æ–¹æ³•ï¼Œè®¡ç®—å‡ºæ¯ä¸€å±‚çš„æ¿€åŠ± $a^{(l)}$ ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_5.png" alt></p><h3 id="2-è®¡ç®—è¯¯å·®"><a href="#2-è®¡ç®—è¯¯å·®" class="headerlink" title="(2) è®¡ç®—è¯¯å·®"></a>(2) è®¡ç®—è¯¯å·®</h3><p>åˆ©ç”¨ $y^{(t)}$ï¼Œè®¡ç®— $\delta^{(L)} = a^{(L)} - y^{t}$</p><p>å…¶ä¸­ $L$ æ˜¯æˆ‘ä»¬çš„æ€»å±‚æ•°ï¼Œ$a^{(L)}$ æ˜¯æœ€åä¸€å±‚æ¿€æ´»å•å…ƒè¾“å‡ºçš„å‘é‡ã€‚æ‰€ä»¥æˆ‘ä»¬æœ€åä¸€å±‚çš„â€œè¯¯å·®å€¼â€ä»…ä»…æ˜¯æˆ‘ä»¬åœ¨æœ€åä¸€å±‚çš„å®é™…ç»“æœå’Œ y ä¸­çš„æ­£ç¡®è¾“å‡ºçš„å·®å¼‚ã€‚ä¸ºäº†è·å¾—æœ€åä¸€å±‚ä¹‹å‰çš„å›¾å±‚çš„å¢é‡å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢æ­¥éª¤ä¸­çš„æ–¹ç¨‹ï¼Œè®©æˆ‘ä»¬ä»å³å‘å·¦å‰è¿›ï¼š</p><h3 id="3-åå‘ä¼ æ’­"><a href="#3-åå‘ä¼ æ’­" class="headerlink" title="(3) åå‘ä¼ æ’­"></a>(3) åå‘ä¼ æ’­</h3><p>é€šè¿‡ $\delta^{(l)} = ((\Theta^{(l)})^{(T)}\delta^{(l+1)}).* a^{(l)} .*(1-a^{(l)})$ï¼Œè®¡ç®— $\delta^{(L-1)},\delta^{(L-2)},\cdots,\delta^{(2)}$ è®¡ç®—å‡ºæ¯ä¸€å±‚ç¥ç»èŠ‚ç‚¹çš„è¯¯å·®ã€‚</p><h3 id="4-è®¡ç®—åå¯¼æ•°"><a href="#4-è®¡ç®—åå¯¼æ•°" class="headerlink" title="(4) è®¡ç®—åå¯¼æ•°"></a>(4) è®¡ç®—åå¯¼æ•°</h3><p>æœ€ååˆ©ç”¨ $\Delta^{(l)}_{i,j} := \Delta^{(l)}_{i,j} + a_{j}^{(l)}\delta_{i}^{(l+1)}$ï¼Œæˆ–è€…çŸ¢é‡è¡¨ç¤ºä¸º $\Delta^{(l)} := \Delta^{(l)} + \delta^{(l+1)}(a^{(l)})^{T}$ã€‚</p>$$\frac{\partial }{\partial \Theta_{i,j}^{(l)} }F(\Theta) = D_{i,j}^{(l)} := \left\{\begin{matrix}\frac{1}{m} \left( \Delta_{i,j}^{(l)} + \lambda\Theta_{i,j}^{(l)}  \right) \;\;\;\;\;\;\;\; j\neq 0\\ \frac{1}{m}\Delta_{i,j}^{(l)} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; j = 0\end{matrix}\right.$$<h3 id="5-æ›´æ–°çŸ©é˜µ"><a href="#5-æ›´æ–°çŸ©é˜µ" class="headerlink" title="(5) æ›´æ–°çŸ©é˜µ"></a>(5) æ›´æ–°çŸ©é˜µ</h3><p>æ›´æ–°å„å±‚çš„æƒå€¼çŸ©é˜µ $\Theta^{(l)}$ ï¼Œå…¶ä¸­ $\alpha$  ä¸ºå­¦ä¹ ç‡ï¼š</p><p>$$\Theta^{(l)} = \Theta^{(l)} - \alpha D^{(l)}$$</p><hr><h2 id="äºŒ-æ¨å¯¼"><a href="#äºŒ-æ¨å¯¼" class="headerlink" title="äºŒ. æ¨å¯¼"></a>äºŒ. æ¨å¯¼</h2><h3 id="1-ç›®æ ‡"><a href="#1-ç›®æ ‡" class="headerlink" title="1. ç›®æ ‡"></a>1. ç›®æ ‡</h3><p>æ±‚ $\min_\Theta F(\Theta)$</p><h3 id="2-æ€è·¯"><a href="#2-æ€è·¯" class="headerlink" title="2. æ€è·¯"></a>2. æ€è·¯</h3><p>ç±»ä¼¼æ¢¯åº¦ä¸‹é™æ³•ï¼Œç»™å®šä¸€ä¸ªåˆå€¼åï¼Œè®¡ç®—å‡ºæ‰€æœ‰èŠ‚ç‚¹çš„è®¡ç®—å€¼å’Œæ¿€æ´»å€¼ï¼Œç„¶åæ ¹æ®ä»£ä»·å‡½æ•°çš„å˜åŒ–ä¸æ–­è°ƒæ•´å‚æ•°å€¼ï¼ˆæƒå€¼ï¼‰ï¼Œæœ€ç»ˆä¸æ–­é€¼è¿‘æœ€ä¼˜ç»“æœï¼Œä½¿ä»£ä»·å‡½æ•°å€¼æœ€å°ã€‚</p><h3 id="3-æ¨å¯¼è¿‡ç¨‹"><a href="#3-æ¨å¯¼è¿‡ç¨‹" class="headerlink" title="3. æ¨å¯¼è¿‡ç¨‹"></a>3. æ¨å¯¼è¿‡ç¨‹</h3><p>ä¸ºäº†å®ç°ä¸Šè¿°æ€è·¯ï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆè®¡ç®—ä»£ä»·å‡½æ•°çš„åå¯¼æ•°ï¼š</p><p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta)$$</p><p>è¿™ä¸ªåå¯¼å¹¶ä¸å¥½æ±‚ï¼Œä¸ºäº†æ–¹ä¾¿æ¨å¯¼ï¼Œæˆ‘ä»¬å‡è®¾åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼ˆ$m=1$ï¼Œå¯å¿½ç•¥ä»£ä»·å‡½æ•°ä¸­çš„å¤–éƒ¨æ±‚å’Œï¼‰ï¼Œå¹¶èˆå¼ƒæ­£è§„åŒ–éƒ¨åˆ†ï¼Œç„¶ååˆ†ä¸ºä¸¤ç§æƒ…å†µæ¥æ±‚ã€‚</p><h3 id="æƒ…å†µ1-éšè—å±‚-â†’-è¾“å‡ºå±‚"><a href="#æƒ…å†µ1-éšè—å±‚-â†’-è¾“å‡ºå±‚" class="headerlink" title="æƒ…å†µ1 éšè—å±‚ â†’ è¾“å‡ºå±‚"></a>æƒ…å†µ1 éšè—å±‚ â†’ è¾“å‡ºå±‚</h3><p>æˆ‘ä»¬çŸ¥é“ï¼š</p>$$\begin{align*}h_\Theta(x) &amp;= a^{(j+1)} = g(z^{(j+1)}) \\z^{(j)} &amp;= \Theta^{(j-1)}a^{(j-1)} \\\end{align*}$$<p>å¦å¤–ï¼Œè¾“å‡ºå±‚å³ç¬¬$L$å±‚ã€‚</p><p>æ‰€ä»¥ï¼š</p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(L)}}F(\Theta)= \dfrac{\partial F(\Theta)}{\partial h_{\Theta}(x)_i} \dfrac{\partial h_{\Theta}(x)_i}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial  \Theta_{i,j}^{(L)}}= \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}}$$<p>å…¶ä¸­ï¼š</p>$$\begin{align*}\dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} &amp;= \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} \\\dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} &amp;= \dfrac{\partial g(z_i^{(L)})}{\partial z_i^{(L)}} = \dfrac{e^{z_i^{(L)}}}{(e^{z_i^{(L)}}+1)^2} = a_i^{(L)} (1 - a_i^{(L)}) \\\dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}} &amp;= \dfrac{\partial ( \sum_{k=0}^{s_{(L-1)}}\; \Theta_{i,k}^{(L)} a_k^{(L-1)})}{\partial  \Theta_{i,j}^{(L)}} = a_j^{(L-1)} \\\end{align*}$$<p>ç»¼ä¸Šï¼š</p>$$\begin{split}\dfrac{\partial}{\partial \Theta_{i,j}^{(L)}}F(\Theta)=&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \dfrac{\partial z_i^{(L)}}{\partial \Theta_{i,j}^{(L)}} \newline  =&amp; \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} a_i^{(L)} (1 - a_i^{(L)}) a_j^{(L-1)} \newline  =&amp; (a_i^{(L)} - y_i)a_j^{(L-1)}\end{split}$$<h3 id="æƒ…å†µ2-éšè—å±‚-è¾“å…¥å±‚-â†’-éšè—å±‚"><a href="#æƒ…å†µ2-éšè—å±‚-è¾“å…¥å±‚-â†’-éšè—å±‚" class="headerlink" title="æƒ…å†µ2 éšè—å±‚ / è¾“å…¥å±‚ â†’ éšè—å±‚"></a>æƒ…å†µ2 éšè—å±‚ / è¾“å…¥å±‚ â†’ éšè—å±‚</h3><p>å› ä¸º $a^{(1)}=x$ï¼Œæ‰€ä»¥å¯ä»¥å°†è¾“å…¥å±‚å’Œéšè—å±‚åŒæ ·å¯¹å¾…ã€‚</p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta)=\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}}\ (l = 1, 2, ..., L-1)$$<p>å…¶ä¸­åä¸¤éƒ¨åˆ†åå¯¼å¾ˆå®¹æ˜“æ ¹æ®å‰é¢æ‰€å¾—ç±»æ¨å‡ºæ¥ï¼š</p>$$\begin{align*}\dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} &amp;= \dfrac{e^{z_i^{(l)}}}{(e^{z_i^{(l)}}+1)^2} = a_i^{(l)} (1 - a_i^{(l)}) \\\dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} &amp;= a_j^{(l-1)} \\\end{align*}$$<p>ç¬¬ä¸€éƒ¨åˆ†åå¯¼æ˜¯ä¸å¥½æ±‚è§£çš„ï¼Œæˆ–è€…è¯´æ˜¯æ²¡æ³•ç›´æ¥æ±‚è§£çš„ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªé€’æ¨å¼ï¼š</p>$$\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} = \sum_{k=1}^{s_{(l+1)}} \Bigg[\dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}}\Bigg]$$<blockquote><p>å› ä¸ºè¯¥å±‚çš„æ¿€æ´»å€¼ä¸ä¸‹ä¸€å±‚å„èŠ‚ç‚¹éƒ½æœ‰å…³ï¼Œé“¾å¼æ³•åˆ™æ±‚å¯¼æ—¶éœ€ä¸€ä¸€æ±‚å¯¼ï¼Œæ‰€ä»¥æœ‰ä¸Šå¼ä¸­çš„æ±‚å’Œã€‚</p></blockquote><p>é€’æ¨å¼ä¸­ç¬¬ä¸€éƒ¨åˆ†æ˜¯é€’æ¨é¡¹ï¼Œåä¸¤éƒ¨åˆ†åŒæ ·æ˜“æ±‚ï¼š</p>$$\begin{align*}\dfrac{\partial a_k^{(l+1)}}{\partial z_{k}^{(l+1)}} &amp;= \dfrac{e^{z_{k}^{(l+1)}}}{(e^{z_{k}^{(l+1)}}+1)^2} = a_k^{(l+1)} (1 - a_k^{(l+1)}) \\\dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}} &amp;= \dfrac{\partial ( \sum_{j=0}^{s_l} \Theta_{k,j}^{(l+1)} a_j^{(l)})}{\partial a_i^{(l)}} = \Theta_{k,i}^{(l+1)} \\\end{align*}$$<p>æ‰€ä»¥ï¼Œé€’æ¨å¼ä¸ºï¼š</p>$$\begin{split}\dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[\dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \dfrac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}}\Bigg] \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \Theta_{k,i}^{(l+1)} \Bigg] \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} a_k^{(l+1)} (1 - a_k^{(l+1)}) \Theta_{k,i}^{(l+1)} \Bigg]\end{split}$$<p>ä¸ºäº†ç®€åŒ–è¡¨è¾¾å¼ï¼Œå®šä¹‰ç¬¬ $l$ å±‚ç¬¬ $i$ ä¸ªèŠ‚ç‚¹çš„è¯¯å·®ï¼š</p>$$\begin{split}\delta^{(l)}_i =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \newline  =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} a_i^{(l)} (1 - a_i^{(l)})  \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Bigg[ \dfrac{\partial F(\Theta)}{\partial a_k^{(l+1)}} \dfrac{\partial a_k^{(l+1)}}{\partial z_k^{(l+1)}} \Theta_{k,i}^{(l+1)} \Bigg] a_i^{(l)} (1 - a_i^{(l)}) \newline  =&amp; \sum_{k=1}^{s_{(l+1)}} \Big[\delta^{(l+1)}_k \Theta_{k,i}^{(l+1)} \Big] a_i^{(l)} (1 - a_i^{(l)})\end{split}$$<p>å¯çŸ¥ï¼Œ<strong>æƒ…å†µ1</strong>çš„è¯¯å·®ä¸ºï¼š</p>$$\begin{split}\delta^{(L)}_i =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(L)}} \dfrac{\partial a_i^{(L)}}{\partial z_i^{(L)}} \newline  =&amp; \dfrac{a_i^{(L)} - y_i}{(1 - a_i^{(L)})a_i^{(L)}} a_i^{(L)} (1 - a_i^{(L)}) \newline  =&amp; a_i^{(L)} - y_i\end{split}$$<p>æœ€ç»ˆçš„ä»£ä»·å‡½æ•°çš„åå¯¼ä¸ºï¼š</p>$$\begin{split}\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta) =&amp; \dfrac{\partial F(\Theta)}{\partial a_i^{(l)}} \dfrac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} \newline  =&amp; \delta^{(l)}_i \dfrac{\partial z_i^{(l)}}{\partial \Theta_{i,j}^{(l)}} \newline  =&amp; \delta^{(l)}_i a_j^{(l-1)} \end{split}$$<p>æˆ‘ä»¬å‘ç°ï¼Œå¼•å…¥è¯¯å·® $\delta^{(l)}_i$ åï¼Œè¿™ä¸ªå…¬å¼å¯ä»¥é€šç”¨äº<strong>æƒ…å†µ1</strong>å’Œ<strong>æƒ…å†µ2</strong>ã€‚</p><p>å¯ä»¥çœ‹å‡ºï¼Œå½“å‰å±‚çš„ä»£ä»·å‡½æ•°åå¯¼ï¼Œéœ€è¦ä¾èµ–äºåä¸€å±‚çš„è®¡ç®—ç»“æœã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆè¿™ä¸ªç®—æ³•çš„åç§°å«åšâ€œåå‘ä¼ æ’­ç®—æ³•â€ã€‚</p><h3 id="4-æ€»ç»“ç®—æ³•å…¬å¼"><a href="#4-æ€»ç»“ç®—æ³•å…¬å¼" class="headerlink" title="4. æ€»ç»“ç®—æ³•å…¬å¼"></a>4. æ€»ç»“ç®—æ³•å…¬å¼</h3><ul><li>è¾“å‡ºå±‚è¯¯å·®</li></ul><p>$$\delta^{(L)}_i = a_i^{(L)} - y_i$$</p><ul><li><p>éšè—å±‚è¯¯å·®ï¼ˆåå‘ä¼ æ’­è®¡ç®—ï¼‰</p>$$\delta^{(l)}_i = \sum_{k=1}^{s_{(l+1)}} \Big[\delta^{(l+1)}_k \Theta_{k,i}^{(l+1)} \Big] a_i^{(l)} (1 - a_i^{(l)})$$</li><li><p>ä»£ä»·å‡½æ•°åå¯¼è®¡ç®—ï¼ˆé€šç”¨ï¼‰</p></li></ul><p>$$\dfrac{\partial}{\partial \Theta_{i,j}^{(l)}}F(\Theta) = \delta^{(l)}_i a_j^{(l-1)}$$</p><hr><h2 id="ä¸‰-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹"><a href="#ä¸‰-Backpropagation-Algorithm-åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹" class="headerlink" title="ä¸‰. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹"></a>ä¸‰. Backpropagation Algorithm åå‘ä¼ æ’­ç®—æ³•è¿‡ç¨‹</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/72_2_.png" alt></p><p>æœ‰äº†ä¸Šè¿°æ¨å¯¼ï¼Œæˆ‘ä»¬æè¿°ä¸€ä¸‹ç®—æ³•å…·ä½“çš„æ“ä½œæµç¨‹ï¼š</p><ul><li>è¾“å…¥ï¼šè¾“å…¥æ ·æœ¬æ•°æ®ï¼Œåˆå§‹åŒ–æƒå€¼å‚æ•°ï¼ˆå»ºè®®éšæœºç”Ÿæˆè¾ƒå°çš„æ•°ï¼‰ã€‚</li><li>å‰é¦ˆï¼šè®¡ç®—å„å±‚ï¼ˆ$l=2, 3, â€¦, L$ï¼‰å„èŠ‚ç‚¹çš„è®¡ç®—å€¼ï¼ˆ$z^{(l)}=\Theta^{(l-1)}a^{(l-1)}$ï¼‰å’Œæ¿€æ´»å€¼ï¼ˆ$a^{(l)}=g(z^{(l)})$ï¼‰ã€‚</li><li>è¾“å‡ºå±‚è¯¯å·®ï¼šè®¡ç®—è¾“å‡ºå±‚è¯¯å·®<script type="math/tex">\delta^{(L)}</script>ï¼ˆå…¬å¼è§å‰æ–‡ï¼‰ã€‚</li><li>åå‘ä¼ æ’­è¯¯å·®ï¼šè®¡ç®—å„å±‚ï¼ˆ$l=L-1, L-2, â€¦, 2$ï¼‰çš„è¯¯å·® $\delta^{(l)}$ï¼ˆå…¬å¼è§å‰æ–‡ï¼‰ã€‚</li><li>è¾“å‡ºï¼šå¾—åˆ°ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ $\nabla F(\Theta)$ï¼ˆå‚è€ƒå‰æ–‡åå¯¼è®¡ç®—å…¬å¼ï¼‰ã€‚</li></ul><p>åå‘ä¼ æ’­ç®—æ³•å¸®åŠ©æˆ‘ä»¬å¾—åˆ°äº†ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±å¯ä»¥å€ŸåŠ©æ¢¯åº¦ä¸‹é™æ³•è®­ç»ƒç¥ç»ç½‘ç»œäº†ã€‚</p><p>$$\Theta := \Theta - \alpha  \nabla F(\Theta)$$</p><p>$\alpha $ ä¸ºå­¦ä¹ é€Ÿç‡ã€‚</p><hr><h2 id="å››-Backpropagation-Algorithm-implementation-ç®—æ³•å®ç°"><a href="#å››-Backpropagation-Algorithm-implementation-ç®—æ³•å®ç°" class="headerlink" title="å››. Backpropagation Algorithm implementation ç®—æ³•å®ç°"></a>å››. Backpropagation Algorithm implementation ç®—æ³•å®ç°</h2><p>ä»¥3å±‚ç¥ç»ç½‘ç»œï¼ˆè¾“å…¥å±‚ã€éšå±‚ã€è¾“å‡ºå±‚å„ä¸€ï¼‰ä¸ºä¾‹ã€‚</p><ul><li>X ä¸ºå¤§å°ä¸ºæ ·æœ¬æ•°âˆ—ç‰¹å¾æ•°çš„æ ·æœ¬ç‰¹å¾çŸ©é˜µ</li><li>Y ä¸ºå¤§å°ä¸ºæ ·æœ¬æ•°âˆ—è¾“å‡ºèŠ‚ç‚¹æ•°çš„æ ·æœ¬ç±»åˆ«ï¼ˆç»“æœï¼‰çŸ©é˜µ</li><li>Theta1 ä¸ºè¾“å…¥å±‚â†’éšå±‚çš„æƒå€¼çŸ©é˜µ</li><li>Theta2 ä¸ºéšè—å±‚â†’è¾“å‡ºå±‚çš„æƒå€¼çŸ©é˜µ</li><li>m ä¸ºæ ·æœ¬æ•°</li><li>K ä¸ºè¾“å‡ºå±‚èŠ‚ç‚¹æ•°</li><li>H ä¸ºéšè—å±‚èŠ‚ç‚¹æ•°</li><li>sigmoid å‡½æ•°å³é€»è¾‘å‡½æ•°ï¼ˆSå‹å‡½æ•°ï¼ŒSigmoidå‡½æ•°ï¼‰</li><li>sigmoidGradient å‡½æ•°å³ Sigmoid å‡½æ•°çš„å¯¼å‡½æ•°</li><li>ä»£ç å®ç°ä¸­ï¼Œè€ƒè™‘äº†æ­£è§„åŒ–ï¼Œé¿å…å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li></ul><h3 id="1-å‰é¦ˆé˜¶æ®µ"><a href="#1-å‰é¦ˆé˜¶æ®µ" class="headerlink" title="1. å‰é¦ˆé˜¶æ®µ"></a>1. å‰é¦ˆé˜¶æ®µ</h3><p>é€å±‚è®¡ç®—å„èŠ‚ç‚¹å€¼å’Œæ¿€æ´»å€¼ã€‚</p><pre class=" language-c"><code class="language-c">a1 <span class="token operator">=</span> X<span class="token punctuation">;</span>z2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a1<span class="token punctuation">]</span> <span class="token operator">*</span> Theta1'<span class="token punctuation">;</span>a2 <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z2<span class="token punctuation">)</span><span class="token punctuation">;</span>z3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a2<span class="token punctuation">]</span> <span class="token operator">*</span> Theta2'<span class="token punctuation">;</span>a3 <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z3<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="2-ä»£ä»·å‡½æ•°"><a href="#2-ä»£ä»·å‡½æ•°" class="headerlink" title="2. ä»£ä»·å‡½æ•°"></a>2. ä»£ä»·å‡½æ•°</h3><p>æ­£è§„åŒ–éƒ¨åˆ†éœ€æ³¨æ„ä»£ä»·å‡½æ•°ä¸æƒ©ç½šåç§»å‚æ•°ï¼Œå³ $\Theta_{i,0}$ï¼ˆä»£ç è¡¨ç¤ºä¸º $Theta(:,1)$ï¼‰ã€‚</p><pre class=" language-c"><code class="language-c">F <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token function">log</span><span class="token punctuation">(</span>a3<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> Y <span class="token operator">-</span> <span class="token function">log</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token punctuation">.</span><span class="token operator">-</span> a3<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> # ä»£ä»·éƒ¨åˆ† lambda <span class="token operator">/</span> <span class="token number">2</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">^</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">^</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  # æ­£è§„åŒ–éƒ¨åˆ†ï¼Œlambdaä¸ºæ­£è§„å‚æ•°ï¼Œéœ€é™¤å»åç§»å‚æ•°Theta<span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><h3 id="3-åå‘ä¼ æ’­-1"><a href="#3-åå‘ä¼ æ’­-1" class="headerlink" title="3. åå‘ä¼ æ’­"></a>3. åå‘ä¼ æ’­</h3><p>è¾“å‡ºå±‚è¯¯å·®å’Œ $\Theta^{(2)}$ æ¢¯åº¦è®¡ç®—ï¼Œåå‘ä¼ æ’­è®¡ç®—éšå±‚è¯¯å·®å’Œ $\Theta^{(1)}$ æ¢¯åº¦ã€‚</p><p>ä»éœ€æ³¨æ„æ­£è§„åŒ–æ—¶æ’é™¤åç§»å‚æ•°ï¼Œå¦å¤–æ³¨æ„ä¸ºæ¿€æ´»å€¼è¡¥ä¸€ä¸ªåç§»é‡ $1$ã€‚</p><pre class=" language-c"><code class="language-c">function g <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    g <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token punctuation">.</span><span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> <span class="token function">exp</span><span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>endfunction g <span class="token operator">=</span> <span class="token function">sigmoidGradient</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>    g <span class="token operator">=</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>enddelta3 <span class="token operator">=</span> a3 <span class="token operator">-</span> Y<span class="token punctuation">;</span>Theta2_grad <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> delta3' <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a2<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  lambda <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Theta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> # æ­£è§„åŒ–éƒ¨åˆ†delta2 <span class="token operator">=</span> <span class="token punctuation">(</span>delta3 <span class="token operator">*</span> Theta2 <span class="token punctuation">.</span><span class="token operator">*</span> <span class="token function">sigmoidGradient</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> z2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>delta2 <span class="token operator">=</span> <span class="token function">delta2</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">;</span> # åå‘è®¡ç®—å¤šä¸€ä¸ªåç§»å‚æ•°è¯¯å·®ï¼Œé™¤å»Theta1_grad <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span>  delta2' <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">ones</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a1<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  lambda <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token function">zeros</span><span class="token punctuation">(</span>H<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Theta1</span><span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span>end<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> # æ­£è§„åŒ–éƒ¨åˆ†</code></pre><hr><p>æ¨èé˜…è¯»ï¼š</p><p>[Principles of training multi-layer neural network using backpropagation</p><p>](<a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="noopener">http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</a>)</p><p><a href="https://www.zhihu.com/question/27239198" target="_blank" rel="noopener">å¦‚ä½•ç›´è§‚åœ°è§£é‡Š back propagation ç®—æ³•ï¼Ÿ</a></p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.1_Neural_Networks_Representation</title>
      <link href="/2020/02/03/4-1-neural-networks-representation/"/>
      <url>/2020/02/03/4-1-neural-networks-representation/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1.png" alt></p><h1 id="4-1-Neural-Networks-Representation"><a href="#4-1-Neural-Networks-Representation" class="headerlink" title="4.1_Neural_Networks_Representation"></a>4.1_Neural_Networks_Representation</h1><h2 id="ä¸€-Motivations"><a href="#ä¸€-Motivations" class="headerlink" title="ä¸€. Motivations"></a>ä¸€. Motivations</h2><p>å‡å¦‚æˆ‘ä»¬ç”¨ä¹‹å‰çš„é€»è¾‘å›å½’è§£å†³ä»¥ä¸‹åˆ†ç±»é—®é¢˜ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_1.png" alt></p><p>æˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸ªæœ‰å¾ˆå¤šé¡¹çš„éçº¿æ€§çš„é€»è¾‘å›å½’å‡½æ•°ã€‚å½“åªæœ‰ä¸¤ä¸ªç‰¹å¾é‡çš„æ—¶å€™ï¼Œè¿™è¿˜ç®—æ¯”è¾ƒç®€å•çš„ï¼Œä½†æ˜¯å‡å¦‚æˆ‘ä»¬æœ‰100ä¸ªç‰¹å¾é‡å‘¢ï¼Ÿæˆ‘ä»¬åªè€ƒè™‘äºŒé˜¶é¡¹çš„è¯ï¼Œå…¶äºŒé˜¶é¡¹çš„ä¸ªæ•°å¤§çº¦æ˜¯ $\frac{n^2}{2}$ ã€‚å‡å¦‚æˆ‘ä»¬è¦åŒ…å«æ‰€æœ‰çš„äºŒé˜¶é¡¹çš„è¯è¿™æ ·çœ‹èµ·æ¥ä¸æ˜¯ä¸€ä¸ªå¥½åŠæ³•ï¼Œå› ä¸ºé¡¹æ•°å®åœ¨å¤ªå¤šè¿ç®—é‡ä¹Ÿå¾ˆå¤šï¼Œè€Œä¸”æœ€åç»“æœå¾€å¾€å®¹æ˜“é€ æˆè¿‡æ‹Ÿåˆã€‚å½“ç„¶æˆ‘ä»¬åªæ˜¯è€ƒè™‘äº†äºŒé˜¶é¡¹ï¼Œè€ƒè™‘äºŒé˜¶é¡¹ä»¥ä¸Šçš„å°±æ›´å¤šäº†ã€‚</p><p>å½“åˆå§‹ç‰¹å¾ä¸ªæ•° n å¢å¤§æ—¶ï¼Œè¿™äº›é«˜é˜¶å¤šé¡¹å¼é¡¹æ•°å°†ä»¥å‡ ä½•çº§æ•°ä¸Šå‡ï¼Œç‰¹å¾ç©ºé—´ä¹Ÿä¼šéšä¹‹æ€¥å‰§è†¨èƒ€ ã€‚æ‰€ä»¥å½“ç‰¹å¾ä¸ªæ•° næ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œç”¨è¿™ä¸ªæ–¹æ³•å»ºç«‹åˆ†ç±»å™¨å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½çš„åšæ³•ã€‚</p><p>è€Œå¯¹äºå¤§å¤šæ•°çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œ n  ä¸€èˆ¬æ˜¯æ¯”è¾ƒå¤§çš„ã€‚</p><p>å¯¹ä¸€ä¸ªæ‹¥æœ‰å¾ˆå¤šç‰¹å¾çš„å¤æ‚æ•°æ®é›†è¿›è¡Œçº¿æ€§å›å½’æ˜¯ä»£ä»·å¾ˆé«˜çš„ã€‚æ¯”å¦‚æˆ‘ä»¬å¯¹ 50 * 50 åƒç´ çš„é»‘ç™½å›¾åˆ†ç±»ï¼Œæˆ‘ä»¬å°±æ‹¥æœ‰äº† 2500 ä¸ªç‰¹å¾ã€‚å¦‚æœæˆ‘ä»¬è¿˜è¦åŒ…å«æ‰€æœ‰äºŒæ¬¡ç‰¹å¾ï¼Œå¤æ‚åº¦ä¸º $O(n^{2}/2)$ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€å…±è¦æœ‰ $2500^{2}/2=3125000$ ä¸ªç‰¹å¾ã€‚è¿™æ ·è®¡ç®—çš„ä»£ä»·æ˜¯é«˜æ˜‚çš„ã€‚</p><p>äººå·¥ç¥ç»ç½‘ç»œæ˜¯å¯¹å…·æœ‰å¾ˆå¤šç‰¹å¾çš„å¤æ‚é—®é¢˜è¿›è¡Œæœºå™¨å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ã€‚</p><hr><h2 id="äºŒ-Neural-Networks"><a href="#äºŒ-Neural-Networks" class="headerlink" title="äºŒ. Neural Networks"></a>äºŒ. Neural Networks</h2><p>äººå·¥ç¥ç»ç½‘ç»œæ˜¯å¯¹ç”Ÿç‰©ç¥ç»ç½‘ç»œçš„ä¸€ç§ç®€åŒ–çš„æ¨¡æ‹Ÿã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å…ˆä»ç”Ÿç‰©ä¸­çš„ç¥ç»å…ƒå…¥æ‰‹ï¼Œè¿›è€Œäº†è§£ç¥ç»ç½‘ç»œçš„å·¥ä½œæ–¹å¼ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_6.svg" alt></p><p>ç”¨ä¸€ä¸ªç®€å•çš„æ¨¡å‹æ¥æ¨¡æ‹Ÿç¥ç»å…ƒçš„å·¥ä½œï¼Œæˆ‘ä»¬å°†ç¥ç»å…ƒæ¨¡æ‹Ÿæˆä¸€ä¸ªé€»è¾‘å•å…ƒï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_2.png" alt></p><p>$x_{1},x_{2},x_{3}$ å¯ä»¥å°†å…¶çœ‹æˆè¾“å…¥ç¥ç»æ ‘çªï¼Œé»„è‰²çš„åœ†åœˆåˆ™å¯ä»¥çœ‹æˆä¸­å¿ƒå¤„ç†å™¨ç»†èƒæ ¸ï¼Œ $h_\theta(x)$ åˆ™å¯çœ‹æˆè¾“å‡ºç¥ç»è½´çªã€‚å› ä¸ºè¿™é‡Œæ˜¯é€»è¾‘å•å…ƒï¼Œæ‰€ä»¥æˆ‘ä»¬çš„è¾“å‡ºå‡½æ•°ä¸ºï¼š $h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$ ã€‚ä¸€èˆ¬æˆ‘ä»¬æŠŠè¿™ç§°ä¸ºä¸€ä¸ªæœ‰ s å‹å‡½æ•°ï¼ˆé€»è¾‘å‡½æ•°ï¼‰ä½œä¸ºæ¿€åŠ±çš„äººå·¥ç¥ç»å…ƒã€‚</p><p>é‚£ä¹ˆç¥ç»ç½‘ç»œå…¶å®å°±æ˜¯è¿™äº›ç¥ç»å…ƒç»„åˆåœ¨ä¸€èµ·çš„é›†åˆï¼Œå¦‚ä¸‹å›¾ï¼š</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_2.png" alt></p><p>å·¦è¾¹ç¬¬ä¸€å±‚ Layer1 è¢«ç§°ä¸º<strong>è¾“å…¥å±‚</strong>ã€‚åœ¨è¾“å…¥å±‚æˆ‘ä»¬è¾“å…¥æˆ‘ä»¬çš„ç‰¹å¾é¡¹ $x_{1},x_{2},x_{3}$ ã€‚</p><p>å³è¾¹æœ€åä¸€å±‚è¢«ç§°ä¸º<strong>è¾“å‡ºå±‚</strong>ã€‚è¾“å‡ºå‡½æ•°ä¸ºï¼š $h_\Theta(x)$ ã€‚</p><p>ä¸­é—´è¿™å±‚è¢«ç§°ä¸º<strong>éšè—å±‚</strong>ã€‚</p><p>æˆ‘ä»¬ç°åœ¨è¦è®¡ç®—å½“å‰ç¥ç»å…ƒçš„å€¼ï¼Œåœ¨å½“å‰ç¥ç»å…ƒæ‰€åœ¨å±‚çš„å‰ä¸€å±‚ï¼Œæœ‰å¾ˆå¤šä¸ªçªè§¦å‰ç¥ç»å…ƒï¼ˆå½“å‰ç¥ç»å…ƒä¹Ÿæ˜¯ç›¸å¯¹äºä»–ä»¬çš„çªè§¦åç¥ç»å…ƒï¼‰ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_7.png" alt></p><p>å¯¹äºå‰ä¸€å±‚çš„æ¯ä¸€ä¸ªçªè§¦å‰ç¥ç»å…ƒï¼Œéƒ½æœ‰ä¸€ä¸ªè¾“å‡ºå€¼ï¼Œä½œä¸ºå½“å‰ç¥ç»å…ƒçš„è¾“å…¥å€¼ï¼Œç»è¿‡è½´çªä¼ é€’åˆ°å½“å‰ç¥ç»å…ƒã€‚å½“ç„¶ï¼Œå¦‚æœæ˜¯ç¬¬ä¸€å±‚ç¥ç»å…ƒï¼Œåˆ™ç›´æ¥ä»è¾“å…¥æ ·æœ¬æ•°æ®ä¸­æ¥å—åˆºæ¿€ï¼ˆå¯¹åº”å›¾ä¸­çš„ $x_{i}$ï¼‰ã€‚</p><p>è½´çªå…·æœ‰æƒå€¼ï¼ˆå¯¹åº”å›¾ä¸­çš„æƒå€¼ weights åˆ—ï¼š$w_{ij}$ï¼‰ï¼Œå¯¹æ¯ä¸€ä¸ªè¾“å‡ºå€¼åŠ æƒæ±‚å’Œï¼Œå¾—åˆ°è¯¥ç¥ç»å…ƒçš„è¾“å…¥å€¼ã€‚è¿™ä¸ªåŠ æƒæ±‚å’Œå¯¹åº”å›¾ä¸­çš„transfer functionï¼ˆè½¬ç§»å‡½æ•°ï¼‰ï¼Œä½†è¿™ä¸ªå‡½æ•°çš„åç§°å¹¶ä¸æ˜ç¡®ï¼Œæœ‰äººæŠŠå®ƒç§°ä½œæ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰ï¼Œä¸åŒçš„äººå¯èƒ½æœ‰ä¸åŒçš„å«æ³•ï¼Œè¿™é‡Œä»…ä¾›å‚è€ƒã€‚</p><p>å¾—åˆ°äº†è¯¥ç¥ç»å…ƒçš„å€¼ï¼Œå°±è¦åˆ¤å®šè¯¥ç¥ç»å…ƒæ˜¯å¦æ¿€æ´»å…´å¥‹ã€‚è¿™å¯¹åº”äºå›¾ä¸­çš„activation functionï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ï¼Œä½†ä¹Ÿæœ‰äººå°†è¿™ä¸ªå‡½æ•°å«åšè¾“å‡ºå‡½æ•°ï¼ˆoutput functionï¼‰ï¼Œè€ŒæŠŠå‰é¢è¯´çš„é‚£ä¸€éƒ¨åˆ†å«åšæ¿€æ´»å‡½æ•°ï¼ˆactivation functionï¼‰ï¼Œå¹¶æŠŠè¿™ä¸¤éƒ¨åˆ†åˆç§°ä¸ºè½¬ç§»å‡½æ•°ï¼ˆtransfer functionï¼‰ã€‚</p><p>æœ‰å‡ ç§å‡½æ•°å¯ä»¥ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼š</p><ul><li>é˜¶è·ƒå‡½æ•°ã€‚è¿™æ˜¯æœ€ç®€å•ç›´æ¥çš„å½¢å¼ï¼Œä¹Ÿæ˜¯äººå·¥ç¥ç»ç½‘ç»œå®šä¹‰æ—¶ä¸€èˆ¬é‡‡ç”¨çš„ã€‚</li><li>é€»è¾‘å‡½æ•°ã€‚å°±æ˜¯Så‹å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰ï¼Œå…·æœ‰å¯æ— é™å¾®åˆ†çš„ä¼˜åŠ¿ã€‚</li><li>æ–œå¡å‡½æ•°</li><li>é«˜æ–¯å‡½æ•°</li><li>â€¦</li></ul><p>å¯ä»¥æ³¨æ„åˆ°å›¾ä¸­çš„thresholdï¼ˆé˜ˆå€¼ï¼‰ï¼Œ$\theta_{j}$ï¼Œå³æ¿€æ´»é˜ˆå€¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä»…å½“ç¥ç»å…ƒçš„å€¼å¤§äºè¿™ä¸ªé˜ˆå€¼æ—¶ï¼Œè¯¥ç¥ç»å…ƒæ¿€æ´»å…´å¥‹ï¼Œè¾“å‡º1ï¼›å¦åˆ™æ— æ³•æ¿€æ´»ï¼Œè¾“å‡º0ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_3.png" alt></p><p>å…¶ä¸­éšè—å±‚ä¸­çš„å…ƒç´ æˆ‘ä»¬ç”¨ $a_i^{(j)}$ è¡¨ç¤ºã€‚ä¸Šæ ‡ j è¡¨ç¤ºçš„æ˜¯ç¬¬å‡ å±‚ï¼ˆæœ‰æ—¶å€™æˆ‘ä»¬å¹¶ä¸åªæœ‰ç®€å•ä¸€å±‚ï¼‰ï¼Œä¸‹æ ‡ i è¡¨ç¤ºç¬¬å‡ ä¸ªï¼Œ<strong>ç¬¬jå±‚çš„ç¬¬iä¸ªèŠ‚ç‚¹ï¼ˆç¥ç»å…ƒï¼‰çš„â€œæ¿€æ´»å€¼â€</strong>ã€‚</p><p>ä¸Šé¢çš„ç¥ç»ç½‘ç»œå¯ä»¥ç®€å•çš„è¡¨ç¤ºä¸ºï¼š</p><p>$$\begin{bmatrix} x_{0}\ x_{1}\ x_{2}\ x_{3} \end{bmatrix} \rightarrow \begin{bmatrix} a_{1}^{(2)}\ a_{2}^{(2)}\ a_{3}^{(2)} \end{bmatrix} \rightarrow h_{\theta}(x) $$</p><p>å·¦è¾¹è¾“å…¥å±‚å¤šå¢åŠ äº†ä¸€ä¸ªåç½®å•å…ƒ(åç½®ç¥ç»å…ƒ)ï¼Œ$x_{0}$</p><p>ç”¨ $\Theta^{(j)}$ è¡¨ç¤ºç‰¹å¾é‡å‰çš„å‚æ•°ï¼Œæ˜¯ä¸€ä¸ªæœ‰æƒé‡çš„çŸ©é˜µæ§åˆ¶ç€ä¸€å±‚å‚æ•°çš„å¤§å°ï¼Œ<strong>æ˜ å°„ç¬¬jå±‚åˆ°ç¬¬j+1å±‚çš„æƒå€¼çŸ©é˜µ</strong>ã€‚</p><p>ä¸Šè¿°çš„ç¥ç»ç½‘ç»œå¯ç”¨æ•°å­¦è¡¨è¾¾ï¼Œå¦‚ä¸‹ï¼š</p>$$\begin{align*}a_{1}^{(2)} &amp;= g(\Theta_{10}^{(1)}x_{0}+\Theta_{11}^{(1)}x_{1}+\Theta_{12}^{(1)}x_{2}+\Theta_{13}^{(1)}x_{3}) \\a_{2}^{(2)} &amp;= g(\Theta_{20}^{(1)}x_{0}+\Theta_{21}^{(1)}x_{1}+\Theta_{22}^{(1)}x_{2}+\Theta_{23}^{(1)}x_{3}) \\a_{3}^{(2)} &amp;= g(\Theta_{30}^{(1)}x_{0}+\Theta_{31}^{(1)}x_{1}+\Theta_{32}^{(1)}x_{2}+\Theta_{33}^{(1)}x_{3}) \\h_{\Theta}(x) &amp;= a_{1}^{(3)} = g(\Theta_{10}^{(2)}a_{0}^{(2)}+\Theta_{11}^{(2)}a_{1}^{(2)}+\Theta_{12}^{(2)}a_{2}^{(2)}+\Theta_{13}^{(2)}a_{3}^{(2)}) \\\end{align*}$$<p>$\Theta$ çŸ©é˜µä¹Ÿè¢«ç§°ä½œä¸ºæ¨¡å‹çš„æƒé‡ã€‚è¿™é‡Œçš„ $g(x)$ éƒ½æ˜¯ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå³ $g(x) = \frac{1}{1+e^{-x}}$</p><p>å¯¹ä¸Šé¢çš„ç¥ç»ç½‘ç»œæ•°å­¦è¡¨è¾¾æ–¹å¼è¿›è¡Œå‘é‡åŒ–æ¨å¯¼ï¼Œä»¤ï¼š</p>$$\begin{align*}z_{1}^{(2)} &amp;= \Theta_{10}^{(1)}x_{0}+\Theta_{11}^{(1)}x_{1}+\Theta_{12}^{(1)}x_{2}+\Theta_{13}^{(1)}x_{3} \\z_{2}^{(2)} &amp;= \Theta_{20}^{(1)}x_{0}+\Theta_{21}^{(1)}x_{1}+\Theta_{22}^{(1)}x_{2}+\Theta_{23}^{(1)}x_{3} \\z_{3}^{(2)} &amp;= \Theta_{30}^{(1)}x_{0}+\Theta_{31}^{(1)}x_{1}+\Theta_{32}^{(1)}x_{2}+\Theta_{33}^{(1)}x_{3} \\\vdots \\z_{k}^{(2)} &amp;= \Theta_{k,0}^{(1)}x_{0}+\Theta_{k,1}^{(1)}x_{1}+\Theta_{k,2}^{(1)}x_{2}+\Theta_{k,3}^{(1)}x_{3} \\\end{align*}$$<p>äºæ˜¯å¯ä»¥å¾—åˆ°ï¼š</p>$$\begin{align*}a_{1}^{(2)} &amp;= g(z_{1}^{(2)}) \\a_{2}^{(2)} &amp;= g(z_{2}^{(2)}) \\a_{3}^{(2)} &amp;= g(z_{3}^{(2)}) \\\end{align*}$$<p>ç”¨å‘é‡å³å¯è¡¨ç¤ºä¸ºï¼š</p>$$x = \begin{bmatrix}x_{0}\\ x_{1}\\ x_{2}\\ x_{3}\end{bmatrix},z^{(2)} = \begin{bmatrix}z_{1}^{(2)}\\ z_{2}^{(2)}\\ z_{3}^{(2)}\\ \end{bmatrix} = \Theta^{(1)}x$${% raw %}ç»Ÿä¸€ä¸€ä¸‹å‰åä¸¤å±‚çš„è¾“å…¥è¾“å‡ºå…³ç³»ï¼Œå°† $x=a^{(1)}$ï¼Œå³å¯å¾—åˆ°ï¼š{% raw %}$$\begin{align*}x &amp;= \begin{bmatrix}x_{0}\\ x_{1}\\ \vdots \\ x_{n}\end{bmatrix},z^{(j)} = \begin{bmatrix}z_{1}^{(j)}\\ z_{2}^{(j)}\\\vdots \\ z_{3}^{(j)}\\ \end{bmatrix}, \\ \Rightarrow  z^{(j)} &amp;=\Theta^{(j-1)}a^{(j-1)}\\\end{align*}$${% endraw %}<p>è¿™é‡Œä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªç»“è®ºï¼š</p><p>å‡å¦‚ä¸€ä¸ªç½‘ç»œé‡Œé¢åœ¨ç¬¬ j  å±‚æœ‰ $s_j$ ä¸ªå•å…ƒï¼Œåœ¨ç¬¬ j+1 å±‚æœ‰ $s_{j+1}$ ä¸ªå•å…ƒï¼Œé‚£ä¹ˆ $\Theta^{(j)}$ åˆ™æ§åˆ¶ç€ç¬¬ j å±‚åˆ°ç¬¬ j+1 å±‚çš„æ˜ å°„çŸ©é˜µï¼ŒçŸ©é˜µçš„ç»´åº¦æ˜¯ï¼š $s_{j+1} * (s_j + 1)$ ã€‚(ä¾‹å¦‚ï¼š j=1 , $s_j=1$ï¼Œ $s_{j+1}$=1 ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬ä¸€å±‚åªæœ‰ä¸€ä¸ªå•å…ƒï¼Œç¬¬äºŒå±‚ä¹Ÿåªæœ‰ä¸€ä¸ªå•å…ƒï¼Œé‚£ä¹ˆ $\Theta^{(1)}$ çŸ©é˜µç»´åº¦å°±æ˜¯ 1 * 2 ,å› ä¸ºè¦ç®—ä¸Šåç½®å•å…ƒ)</p><p>å› ä¸ºæˆ‘ä»¬é€šå¸¸æœ‰ $a_0^{(j)}=1$ ï¼Œæ‰€ä»¥ï¼š</p>{% raw %}$$\begin{align*}a^{(j)}&amp;=g(z^{(j)})\\z^{(j+1)}&amp;=\Theta^{(j)}a^{(j)}\\h_\Theta(x)&amp;=a^{(j+1)}=g(z^{(j+1)})\\\end{align*}$${% endraw %}<p>ç”±è¿™ä¸ªå…³ç³»å…¶å®å¯ä»¥çœ‹å‡ºï¼Œç¥ç»ç½‘ç»œè·Ÿä¹‹å‰æ‰€å­¦çš„é€»è¾‘å›å½’æ ¹æœ¬åŒºåˆ«åœ¨äºï¼Œå®ƒæ˜¯å°†ä¸Šä¸€å±‚çš„è¾“å‡ºå½“åšä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œè¿™ä¸ªä»è¾“å…¥å±‚åˆ°éšè—å±‚å†åˆ°è¾“å‡ºå±‚ä¸€æ¬¡è®¡ç®—æ¿€åŠ±çš„è¿‡ç¨‹å«åš <strong>forward propagationï¼ˆå‰å‘ä¼ æ’­ï¼‰</strong>ã€‚</p><hr><h2 id="ä¸‰-Applications"><a href="#ä¸‰-Applications" class="headerlink" title="ä¸‰. Applications"></a>ä¸‰. Applications</h2><h3 id="1-é€»è¾‘è¿ç®—"><a href="#1-é€»è¾‘è¿ç®—" class="headerlink" title="1. é€»è¾‘è¿ç®—"></a>1. é€»è¾‘è¿ç®—</h3><p>åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œ é€»è¾‘ä¸è¿ç®—</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_4.png" alt></p><p>åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œ é€»è¾‘éè¿ç®—</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_3.png" alt></p><p>ä½†æ˜¯å•ä¸€ä¸€å±‚æ— æ³•å®Œæˆå¼‚æˆ–è¿ç®—ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_4.png" alt></p><p>å¼‚æˆ–åœ¨å‡ ä½•ä¸Šçš„é—®é¢˜å…¶å®æ˜¯å°†çº¢å‰å’Œè“åœˆåˆ†å¼€ï¼Œä½†æ˜¯æˆ‘ä»¬çš„è¾“å‡ºå‡½æ•°æ˜¯ï¼š $h_\Theta(x)=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2)$ ,è¿™æ˜¯çº¿æ€§çš„ï¼Œé‚£ä¹ˆåœ¨å›¾ä¸Šæ— è®ºæ€ä¹ˆç”»ä¸€æ¡ç›´çº¿ï¼Œä¹Ÿæ²¡æœ‰åŠæ³•å°†ä¸¤ä¸ªä¸åŒçš„è®­ç»ƒé›†åˆ†å¼€ã€‚æ—¢ç„¶ä¸€æ¡ç›´çº¿ä¸è¡Œï¼Œé‚£ä¹ˆç¥ç»ç½‘ç»œå¢åŠ ä¸€å±‚ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_5.png" alt></p><p>å¦‚ä¸Šå›¾ï¼Œå°†ç¬¬äºŒå±‚ç¬¬ä¸€ä¸ªå…ƒç´  $a_1^{(2)}$ ä½œä¸ºä¸è¿ç®—çš„ç»“æœï¼Œç¬¬äºŒä¸ªå…ƒç´  $a_2^{(2)}$ ä½œä¸ºæˆ–éè¿ç®—çš„ç»“æœï¼Œ $a_1^{(2)}$ å’Œ $a_2^{(2)}$ å†ä½œä¸ºè¾“å…¥ï¼Œè¿›è¡Œæˆ–è¿ç®—ï¼Œä½œä¸ºç¬¬ä¸‰å±‚è¾“å‡ºçš„ç»“æœï¼Œæœ€åå¾—åˆ°çš„ç»“æœä¸è¾“å…¥çš„å…³ç³»æ­£æ˜¯å¼‚æˆ–è¿ç®—çš„å…³ç³»ã€‚</p><h3 id="2-æœ¬è´¨"><a href="#2-æœ¬è´¨" class="headerlink" title="2. æœ¬è´¨"></a>2. æœ¬è´¨</h3><p><img src="https://img.halfrost.com/Blog/ArticleImage/71_1_5.png" alt></p><p>ç¥ç»ç½‘ç»œæ­£æ˜¯è¿™æ ·è§£å†³æ¯”è¾ƒå¤æ‚çš„å‡½æ•°ï¼Œå½“å±‚æ•°å¾ˆå¤šçš„æ—¶å€™ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªç›¸å¯¹ç®€å•çš„è¾“å…¥é‡ï¼Œé€šè¿‡åŠ ä»¥æƒé‡å’Œä¸åŒçš„è¿ç®—é€åˆ°ç¬¬äºŒå±‚ï¼Œè€Œç¬¬ä¸‰å±‚åœ¨ç¬¬äºŒå±‚ä½œä¸ºè¾“å…¥çš„åŸºç¡€ä¸Šå†æ¥è¿›è¡Œä¸€äº›æ›´å¤æ‚çš„è¿ç®—ï¼Œä¸€å±‚ä¸€å±‚ä¸‹å»è§£å†³é—®é¢˜ã€‚</p><hr><h2 id="å››-Neural-Networks-Representation-æµ‹è¯•"><a href="#å››-Neural-Networks-Representation-æµ‹è¯•" class="headerlink" title="å››. Neural Networks: Representation æµ‹è¯•"></a>å››. Neural Networks: Representation æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. Suppose you have a multi-class classification problem with three classes, trained with a 3 layer network. Let a(3)1=(hÎ˜(x))1 be the activation of the first output unit, and similarly a(3)2=(hÎ˜(x))2 and a(3)3=(hÎ˜(x))3. Then for any input x, it must be the case that a(3)1+a(3)2+a(3)3=1.</p><p>B. The activation values of the hidden units in a neural network, with the sigmoid activation function applied at every layer, are always in the range (0, 1).</p><p>C. A two layer (one input layer, one output layer; no hidden layer) neural network can represent the XOR function.</p><p>D. Any logical function over binary-valued (0 or 1) inputs x1 and x2 can be (approximately) represented using some neural network.</p><p>è§£ç­”ï¼š Bã€D</p><p>B.Så‹å‡½æ•°ä½œä¸ºåˆ¤æ–­å‡½æ•°è¿ç”¨åˆ°æ¯ä¸€å±‚ï¼Œå…¶èŒƒå›´æ˜¯[0,1]ï¼Œæ­£ç¡®ã€‚<br>D.ä»»ä½•äºŒè¿›åˆ¶è¾“å…¥çš„é€»è¾‘è¿ç®—éƒ½å¯ä»¥ç¥ç»ç½‘ç»œè§£å†³ï¼Œæ­£ç¡®ã€‚<br>C.å¼‚æˆ–ä¸å¯ä»¥ç”¨ä¸€å±‚ç¥ç»ç½‘ç»œè§£å†³ã€‚<br>A.ä¸ä¸€å®šï¼Œå†³ç­–å‡½æ•°ä¸æ˜¯Så‹å‡½æ•°çš„è¯æœ€åç»“æœç›¸åŠ å°±ä¸æ˜¯1äº†ã€‚   </p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Representation.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.2_Regularization</title>
      <link href="/2020/02/03/3-2-regularization/"/>
      <url>/2020/02/03/3-2-regularization/</url>
      
        <content type="html"><![CDATA[<p><img src="https://upload-images.jianshu.io/upload_images/1194012-756b3fa02ecf03db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt></p><h1 id="3-2-Regularization"><a href="#3-2-Regularization" class="headerlink" title="3.2_Regularization"></a>3.2_Regularization</h1><h2 id="ä¸€-Solving-the-Problem-of-Overfitting"><a href="#ä¸€-Solving-the-Problem-of-Overfitting" class="headerlink" title="ä¸€. Solving the Problem of Overfitting"></a>ä¸€. Solving the Problem of Overfitting</h2><p>è€ƒè™‘ä» $x \in \mathbb{R}$ é¢„æµ‹ y çš„é—®é¢˜ã€‚ä¸‹é¢æœ€å·¦è¾¹çš„å›¾æ˜¾ç¤ºäº†å°† $y =\theta_{0}+\theta_{1}x$ æ‹Ÿåˆåˆ°æ•°æ®é›†çš„ç»“æœã€‚æˆ‘ä»¬çœ‹åˆ°è¿™äº›æ•°æ®å¹¶ä¸æ˜¯ç›´çº¿çš„ï¼Œæ‰€ä»¥è¿™ä¸ªæ•°æ®å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_2.png" alt></p><p>ç›¸åï¼Œå¦‚æœæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç‰¹å¾ x2ï¼Œå¹¶ä¸”æ‹Ÿåˆ $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}$ï¼Œé‚£ä¹ˆæˆ‘ä»¬è·å¾—çš„æ•°æ®ç¨å¾®æ›´é€‚åˆ,å¦‚ä¸Šå›¾ã€‚</p><p>ä½†æ˜¯å¹¶ä¸æ˜¯æ·»åŠ çš„å¤šé¡¹å¼è¶Šå¤šè¶Šå¥½ã€‚ä½†æ˜¯ï¼Œæ·»åŠ å¤ªå¤šç‰¹å¾ä¹Ÿæ˜¯ä¸€ä¸ªå±é™©ï¼šæœ€å³è¾¹çš„æ•°å­—æ˜¯æ‹Ÿåˆäº”é˜¶å¤šé¡¹å¼ $y =\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}+\theta_{4}x^{4}+\theta_{5}x^{5} $ çš„ç»“æœã€‚æˆ‘ä»¬çœ‹åˆ°å³ä½¿æ‹Ÿåˆæ›²çº¿å®Œç¾åœ°ä¼ é€’äº†æ•°æ®ï¼Œæˆ‘ä»¬ä¹Ÿä¸ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é¢„æµ‹ï¼Œä¸Šå›¾æœ€å³è¾¹çš„å›¾å°±æ˜¯è¿‡åº¦æ‹Ÿåˆçš„ä¾‹å­ã€‚</p><p>ä¸Šå›¾æœ€å³è¾¹çš„å›¾ä¹Ÿç§°æœ‰<strong>é«˜æ–¹å·®</strong>ã€‚å¦‚æœæˆ‘ä»¬æ‹Ÿåˆä¸€ä¸ªé«˜é˜¶å¤šé¡¹å¼ï¼Œæœ‰è¿‡åº¦çš„ç‰¹å¾ï¼Œå¹¶ä¸”è¿™ä¸ªå‡è®¾å‡½æ•°èƒ½æ‹Ÿåˆå‡ ä¹æ‰€æœ‰çš„æ•°æ®ï¼Œè¿™å°±é¢ä¸´å¯èƒ½çš„å‡½æ•°å¤ªè¿‡äºåºå¤§ï¼Œå˜é‡å¤ªå¤šçš„é—®é¢˜ã€‚æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®å»çº¦æŸå®ƒï¼Œæ¥è·å¾—ä¸€ä¸ªå¥½çš„å‡è®¾å‡½æ•°ï¼Œè¿™å°±æ˜¯è¿‡åº¦æ‹Ÿåˆã€‚</p><p>æ¬ æ‹Ÿåˆæˆ–é«˜åå€šæ˜¯å½“æˆ‘ä»¬çš„å‡è®¾å‡½æ•°hçš„å½¢å¼å¾ˆéš¾ä¸æ•°æ®çš„è¶‹åŠ¿ä½œå›¾æ—¶ã€‚å®ƒé€šå¸¸æ˜¯ç”±ä¸€ä¸ªåŠŸèƒ½å¤ªç®€å•æˆ–åŠŸèƒ½å¤ªå°‘é€ æˆçš„ã€‚å¦ä¸€æ–¹é¢ï¼Œè¿‡åº¦æ‹Ÿåˆæˆ–é«˜åº¦æ–¹å·®æ˜¯ç”±é€‚åˆç°æœ‰æ•°æ®çš„å‡è®¾å‡½æ•°å¼•èµ·çš„ï¼Œä½†ä¸èƒ½å¾ˆå¥½åœ°é¢„æµ‹æ–°æ•°æ®ã€‚å®ƒé€šå¸¸æ˜¯ç”±ä¸€ä¸ªå¤æ‚çš„å‡½æ•°é€ æˆçš„ï¼Œå®ƒä¼šäº§ç”Ÿå¤§é‡ä¸æ•°æ®æ— å…³çš„ä¸å¿…è¦çš„æ›²çº¿å’Œè§’åº¦ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_3.png" alt></p><p>è¿™ä¸ªæœ¯è¯­é€‚ç”¨äºçº¿æ€§å’Œé€»è¾‘å›å½’ã€‚è§£å†³è¿‡åº¦é…åˆé—®é¢˜æœ‰ä¸¤ä¸ªä¸»è¦é€‰é¡¹ï¼š</p><h3 id="1-å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š"><a href="#1-å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š" class="headerlink" title="1. å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š"></a>1. å‡å°‘ç‰¹å¾çš„æ•°é‡ï¼š</h3><ul><li>æ‰‹åŠ¨é€‰æ‹©è¦ä¿ç•™çš„ç‰¹å¾ï¼Œå“ªäº›å˜é‡æ›´ä¸ºé‡è¦ï¼Œå“ªäº›å˜é‡åº”è¯¥ä¿ç•™ï¼Œå“ªäº›åº”è¯¥èˆå¼ƒã€‚ </li><li>ä½¿ç”¨æ¨¡å‹é€‰æ‹©ç®—æ³•ï¼ˆç¨ååœ¨è¯¾ç¨‹ä¸­å­¦ä¹ ï¼‰ï¼Œç®—æ³•ä¼šè‡ªåŠ¨é€‰æ‹©å“ªäº›ç‰¹å¾å˜é‡ä¿ç•™ï¼Œå“ªäº›èˆå¼ƒã€‚</li></ul><p>ç¼ºç‚¹æ˜¯èˆå¼ƒäº†ä¸€äº›ç‰¹å¾ä»¥åï¼Œä¹Ÿå°±èˆå¼ƒäº†ä¸€äº›é—®é¢˜çš„å…³é”®ä¿¡æ¯ã€‚</p><h3 id="2-æ­£åˆ™åŒ–"><a href="#2-æ­£åˆ™åŒ–" class="headerlink" title="2. æ­£åˆ™åŒ–"></a>2. æ­£åˆ™åŒ–</h3><ul><li>ä¿ç•™æ‰€æœ‰çš„ç‰¹å¾ï¼Œä½†å‡å°‘å‚æ•° $\theta_{j}$ çš„å¤§å°æˆ–è€…å‡å°‘é‡çº§ã€‚ </li><li>å½“æœ‰å¾ˆå¤šä¸ªç‰¹å¾çš„æ—¶å€™ï¼Œå¹¶ä¸”æ¯ä¸ªç‰¹å¾éƒ½ä¼šå¯¹æœ€ç»ˆé¢„æµ‹å€¼äº§ç”Ÿå½±å“ï¼Œæ­£åˆ™åŒ–å¯ä»¥ä¿è¯è¿ä½œè‰¯å¥½ã€‚</li></ul><p>æ­£åˆ™åŒ–ç›®çš„æ˜¯å°½é‡å»ç®€åŒ–è¿™ä¸ªå‡è®¾æ¨¡å‹ã€‚å› ä¸ºè¿™äº›å‚æ•°éƒ½æ¥è¿‘0çš„æ—¶å€™ï¼Œè¶Šç®€å•çš„æ¨¡å‹ä¹Ÿè¢«è¯æ˜è¶Šä¸å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_4.png" alt></p><p>å‡å°‘ä¸€äº›æ•°é‡çº§çš„ç‰¹å¾ï¼ŒåŠ ä¸€äº›â€œæƒ©ç½šâ€é¡¹(ä¸ºäº†ä½¿ä»£ä»·å‡½æ•°æœ€å°ï¼Œä¹˜ä»¥ 1000 å°±æ˜¯æƒ©ç½š)ã€‚</p><p>ä»£ä»·å‡½æ•°ï¼š</p>$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{2m} \left [ \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 + \lambda \sum_{i = 1}^{m} \theta_{j}^{2} \right ]$$<p>$\lambda \sum_{i = 1}^{m} \theta_{j}^{2}$ æ˜¯æ­£åˆ™åŒ–é¡¹ï¼Œå®ƒç¼©å°æ¯ä¸ªå‚æ•°çš„å€¼ã€‚ $\lambda$ æ˜¯æ­£åˆ™åŒ–å‚æ•°ï¼Œ$\lambda$ æ§åˆ¶ä¸¤ä¸ªä¸åŒç›®æ ‡ä¹‹é—´çš„å–èˆï¼Œå³æ›´å¥½çš„å»æ‹Ÿåˆè®­ç»ƒé›†çš„ç›®æ ‡ å’Œ å°†å‚æ•°æ§åˆ¶çš„æ›´å°çš„ç›®æ ‡ï¼Œä»è€Œä¿æŒå‡è®¾æ¨¡å‹çš„ç›¸å¯¹ç®€å•ï¼Œé¿å…å‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚</p><p>ä½†æ˜¯å¦‚æœé€‰æ‹©çš„ $\lambda $ å¤ªå¤§ï¼Œå¯èƒ½ä¼šè¿‡å¤šåœ°æ¶ˆé™¤ç‰¹å¾ï¼Œå¯¼è‡´ $\theta$ éƒ½çº¦ç­‰äº 0 äº†ï¼Œæœ€ç»ˆé¢„æµ‹å‡½æ•°å˜æˆäº†æ°´å¹³ç›´çº¿äº†ã€‚è¿™å°±å˜æˆäº†æ¬ æ‹Ÿåˆçš„ä¾‹å­äº†(åè§æ€§å¤ªå¼ºï¼Œåå·®è¿‡é«˜)ã€‚</p><hr><h2 id="äºŒ-Regularized-Linear-Regression-çº¿æ€§å›å½’æ­£åˆ™åŒ–"><a href="#äºŒ-Regularized-Linear-Regression-çº¿æ€§å›å½’æ­£åˆ™åŒ–" class="headerlink" title="äºŒ. Regularized Linear Regression çº¿æ€§å›å½’æ­£åˆ™åŒ–"></a>äºŒ. Regularized Linear Regression çº¿æ€§å›å½’æ­£åˆ™åŒ–</h2><h3 id="1-Gradient-Descent-çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"><a href="#1-Gradient-Descent-çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–" class="headerlink" title="1. Gradient Descent çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"></a>1. Gradient Descent çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–</h3><p>$$\theta_{0} := \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)}$$</p>$$\theta_{j} := \theta_{j} - \alpha \left [ \left ( \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}\right ) + \frac{\lambda}{m}\theta_{j} \right ]  \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$<p>å°†ä¸Šé¢çš„å¼å­åŒ–ç®€å¾—ï¼š</p>$$\theta_{j} := \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}   \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix}$$<p>åœ¨ä¸Šé¢çš„å¼å­ä¸­ $(1-\alpha \frac{\lambda}{m}) &lt; 1$ æ’å°äº 1ï¼Œçº¦ç­‰äº 1(0.999) ã€‚äºæ˜¯æ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹å°±æ˜¯æ¯æ¬¡æ›´æ–°éƒ½æŠŠå‚æ•°ä¹˜ä»¥ 0.999ï¼Œç¼©å°ä¸€ç‚¹ç‚¹ï¼Œç„¶åå†å‘æœ€å°ç‚¹çš„æ–¹å‘ç§»åŠ¨ä¸€ä¸‹ã€‚</p><h3 id="2-Normal-Equation-çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–"><a href="#2-Normal-Equation-çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–" class="headerlink" title="2. Normal Equation çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–"></a>2. Normal Equation çº¿æ€§å›å½’æ­£è§„æ–¹ç¨‹æ­£åˆ™åŒ–</h3><p>ä¹‹å‰æ¨å¯¼è¿‡çš„æ­£è§„æ–¹ç¨‹ç»“è®ºï¼š</p><p>$$\Theta = (X^{T}X)^{-1}X^{T}Y$$</p><p>æ­£åˆ™åŒ–ä»¥åï¼Œä¸Šè¿°å¼å­å˜æˆäº†ï¼š</p>$$\Theta = \left( X^{T}X +\lambda \begin{bmatrix}0 &amp;  &amp;  &amp;  &amp; \\  &amp; 1 &amp;  &amp;  &amp; \\  &amp;  &amp; 1 &amp;  &amp; \\  &amp;  &amp;  &amp; \ddots  &amp; \\  &amp;  &amp;  &amp;  &amp; 1\end{bmatrix} \right) ^{-1}X^{T}Y$$<p>åœ¨ä¹‹å‰çš„è®¨è®ºä¸­ï¼Œæœ‰ä¸€ä¸ª<strong>å‰ææ¡ä»¶æ˜¯ $X^{T}X$ æ˜¯éå¥‡å¼‚(éé€€åŒ–)çŸ©é˜µï¼Œ å³ $ \left | X^{T}X \right | \neq 0 $</strong></p><p>åœ¨ä¸Šè¿°æ­£åˆ™åŒ–çš„å¼å­é‡Œé¢ï¼Œåªè¦ $\lambda &gt; 0$ï¼Œå°±ä¸å­˜åœ¨ä¸å¯é€†çš„é—®é¢˜äº†ã€‚å› ä¸º $\left( X^{T}X +\lambda \begin{bmatrix}0 &amp;  &amp;  &amp;  &amp; \\  &amp; 1 &amp;  &amp;  &amp; \\  &amp;  &amp; 1 &amp;  &amp; \\  &amp;  &amp;  &amp; \ddots  &amp; \\  &amp;  &amp;  &amp;  &amp; 1\end{bmatrix} \right)$ è¿™ä¸€é¡¹ä¸€å®šæ˜¯å¯é€†çš„ï¼Œå› ä¸ºå®ƒä¸€å®šä¸æ˜¯å¥‡å¼‚çŸ©é˜µã€‚æ‰€ä»¥<strong>æ­£åˆ™åŒ–è¿˜èƒ½è§£å†³ä¸å¯é€†çš„æƒ…å†µ</strong>ã€‚</p><hr><h2 id="ä¸‰-Regularized-Logistic-Regression-é€»è¾‘å›å½’æ­£åˆ™åŒ–"><a href="#ä¸‰-Regularized-Logistic-Regression-é€»è¾‘å›å½’æ­£åˆ™åŒ–" class="headerlink" title="ä¸‰. Regularized Logistic Regression é€»è¾‘å›å½’æ­£åˆ™åŒ–"></a>ä¸‰. Regularized Logistic Regression é€»è¾‘å›å½’æ­£åˆ™åŒ–</h2><p><img src="https://img.halfrost.com/Blog/ArticleImage/70_5.png" alt></p><p>ä¹‹å‰è®¨è®ºè¿‡çš„ä»£ä»·å‡½æ•°æ˜¯ï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] \\\left( h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} \right ) \end{align*}$$<p>æ­£åˆ™åŒ–ä»¥åï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] +\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_{j}^{2}  \\\end{align*}$$<h3 id="1-Gradient-Descent-é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"><a href="#1-Gradient-Descent-é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–" class="headerlink" title="1. Gradient Descent é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–"></a>1. Gradient Descent é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™æ­£åˆ™åŒ–</h3><p>å¼å­ç­‰åŒäºçº¿æ€§å›å½’æ­£åˆ™åŒ–</p>$$\begin{align*}\theta_{0} &amp;:= \theta_{0} - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{0}^{(i)} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;j = 1 \\\theta_{j} &amp;:= \theta_{j}(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}   \;\;\;\;\;\;\;\;j \in \begin{Bmatrix} 1,2,3,4, \cdots n\end{Bmatrix} \\\end{align*}$$<p>è™½ç„¶å¼å­å’Œçº¿æ€§å›å½’çš„ä¸€æ¨¡ä¸€æ ·ï¼Œä¸è¿‡è¿™é‡Œçš„ $h_{\theta}(x)$ ä»£è¡¨çš„æ„ä¹‰ä¸åŒï¼Œé€»è¾‘å›å½’ä¸­ï¼š</p><p>$$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}}$$</p><hr><h2 id="å››-Regularization-æµ‹è¯•"><a href="#å››-Regularization-æµ‹è¯•" class="headerlink" title="å››. Regularization æµ‹è¯•"></a>å››. Regularization æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>You are training a classification model with logistic regression. Which of the following statements are true? Check all that apply.</p><p>A. Introducing regularization to the model always results in equal or better performance on the training set.</p><p>B. Introducing regularization to the model always results in equal or better performance on examples not in the training set.</p><p>C. Adding many new features to the model makes it more likely to overfit the training set.</p><p>D. Adding a new feature to the model always results in equal or better performance on examples not in the training set.</p><p>è§£ç­”ï¼š D  </p><p>Aã€B æ­£åˆ™åŒ–çš„å¼•å…¥æ˜¯è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œè€Œè¿‡æ‹Ÿåˆæ­£æ˜¯è¿‡åº¦æ‹Ÿåˆæ•°æ®ä½†æ— æ³•æ³›åŒ–åˆ°æ–°çš„æ•°æ®æ ·æœ¬ä¸­ã€‚<br>D å¢åŠ ä¸€äº›ç‰¹å¾é‡å¯èƒ½å¯¼è‡´æ‹Ÿåˆåœ¨è®­ç»ƒé›†åŸæœ¬æ²¡æœ‰è¢«æ‹Ÿåˆåˆ°çš„æ•°æ®ï¼Œæ­£ç¡®ï¼Œè¿™å°±æ˜¯è¿‡æ‹Ÿåˆã€‚</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you ran logistic regression twice, once with Î»=0, and once with Î»=1. One of the times, you got</p><p>parameters $\theta = \begin{bmatrix}26.29\\ 65.41\end{bmatrix}$, and the other time you got $\theta = \begin{bmatrix}2.75\\ 1.32\end{bmatrix}$. However, you forgot which value of Î» corresponds to which value of Î¸. Which one do you think corresponds to Î»=1?</p><p>A. $\theta = \begin{bmatrix}26.29\\ 65.41\end{bmatrix}$   </p><p>B. $\theta = \begin{bmatrix}2.75\\ 1.32\end{bmatrix}$</p><p>è§£ç­”ï¼š B</p><p>$\lambda = 1$è¡¨ç¤ºæ­£åˆ™åŒ–ä»¥åã€‚æ­£åˆ™åŒ–å…¶å®è®©æˆ‘ä»¬çš„ $\theta_j$å˜å°ï¼Œæ‰€ä»¥é€‰Bã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Which of the following statements about regularization are true? Check all that apply.</p><p>A. Using too large a value of Î» can cause your hypothesis to overfit the data; this can be avoided by reducing Î».</p><p>B. Consider a classification problem. Adding regularization may cause your classifier to incorrectly classify some training examples (which it had correctly classified when not using regularization, i.e. when Î»=0).</p><p>C. Because logistic regression outputs values 0â‰¤hÎ¸(x)â‰¤1, its range of output values can only be â€œshrunkâ€ slightly by regularization anyway, so regularization is generally not helpful for it.</p><p>D. Using a very large value of Î» cannot hurt the performance of your hypothesis; the only reason we do not set Î» to be too large is to avoid numerical problems.</p><p>è§£ç­”ï¼š B</p><p>C æ­£åˆ™åŒ–å¯¹é€»è¾‘å›å½’æ²¡ç”¨ï¼Œé”™è¯¯ã€‚<br>Aã€D   $\lambda$è¿‡å¤§ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Regularization.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.1_Logistic_Regression</title>
      <link href="/2020/02/03/3-1-logistic-regression/"/>
      <url>/2020/02/03/3-1-logistic-regression/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img.halfrost.com/Blog/ArticleImage/69_6.png" alt></p><h1 id="3-1-Logistic-Regression"><a href="#3-1-Logistic-Regression" class="headerlink" title="3.1_Logistic_Regression"></a>3.1_Logistic_Regression</h1><h2 id="ä¸€-Classification-and-Representation"><a href="#ä¸€-Classification-and-Representation" class="headerlink" title="ä¸€. Classification and Representation"></a>ä¸€. Classification and Representation</h2><p>è¦å°è¯•åˆ†ç±»ï¼Œä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨çº¿æ€§å›å½’ï¼Œå¹¶å°†æ‰€æœ‰å¤§äº0.5çš„é¢„æµ‹å€¼æ˜ å°„ä¸º1ï¼Œå°†å°äº0.5çš„æ‰€æœ‰é¢„æµ‹å€¼æ˜ å°„ä¸º0.ä½†æ˜¯ï¼Œæ­¤æ–¹æ³•æ•ˆæœä¸ä½³ï¼Œå› ä¸ºåˆ†ç±»å®é™…ä¸Šä¸æ˜¯çº¿æ€§å‡½æ•°ã€‚ åˆ†ç±»é—®é¢˜å°±åƒå›å½’é—®é¢˜ä¸€æ ·ï¼Œé™¤äº†æˆ‘ä»¬ç°åœ¨æƒ³è¦é¢„æµ‹çš„å€¼åªæœ‰å°‘æ•°ç¦»æ•£å€¼ã€‚</p><p><strong>çº¿æ€§å›å½’ç”¨æ¥è§£å†³åˆ†ç±»é—®é¢˜ï¼Œé€šå¸¸ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„</strong>ã€‚</p><p>æˆ‘ä»¬è§£å†³åˆ†ç±»é—®é¢˜ï¼Œå¿½ç•¥yæ˜¯ç¦»æ•£å€¼ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬çš„æ—§çº¿æ€§å›å½’ç®—æ³•æ¥å°è¯•é¢„æµ‹ç»™å®šçš„xã€‚ä½†æ˜¯ï¼Œæ„å»ºè¿™ç§æ–¹æ³•æ€§èƒ½å¾ˆå·®çš„ç¤ºä¾‹å¾ˆå®¹æ˜“ã€‚ç›´è§‚åœ°è¯´ï¼Œå½“çŸ¥é“$y\in \begin{Bmatrix}<br>0,1<br>\end{Bmatrix}$æ—¶ï¼Œ$h_{\theta}(x)$ å–å¤§äº1æˆ–å°äº0çš„å€¼ä¹Ÿæ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ä»¬æ”¹å˜æˆ‘ä»¬çš„å‡è®¾ $h_{\theta}(x)$ çš„å½¢å¼ä»¥æ»¡è¶³ $0\leqslant h_{\theta}(x)\leqslant 1$ã€‚è¿™æ˜¯é€šè¿‡å°† $\theta^{T}x$ æ’å…¥ Logistic å‡½æ•°æ¥å®Œæˆçš„ï¼š</p><p>$$g(x) = \frac{1}{1+e^{-x}}$$</p><p>ä¸Šå¼ç§°ä¸º Sigmoid Function æˆ–è€… Logistic Function</p><p>ä»¤ $h_{\theta}(x) = g(\theta^{T}x)$,$z = \theta^{T}x$,åˆ™:</p><p>$$g(x) = \frac{1}{1+e^{-\theta^{T}x}}$$</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/69_8.png" alt></p><p>è¿™é‡Œæ˜¾ç¤ºçš„å‡½æ•°$g(x)$å°†ä»»ä½•å®æ•°æ˜ å°„åˆ°ï¼ˆ0,1ï¼‰åŒºé—´ï¼Œä½¿å¾—å®ƒå¯ç”¨äºå°†ä»»æ„å€¼å‡½æ•°è½¬æ¢ä¸ºæ›´é€‚åˆåˆ†ç±»çš„å‡½æ•°ã€‚</p><p><strong>å†³ç­–è¾¹ç•Œä¸æ˜¯è®­ç»ƒé›†çš„å±æ€§ï¼Œè€Œæ˜¯å‡è®¾æœ¬èº«åŠå…¶å‚æ•°çš„å±æ€§</strong>ã€‚</p><hr><h2 id="äºŒ-Logistic-Regression-Model"><a href="#äºŒ-Logistic-Regression-Model" class="headerlink" title="äºŒ. Logistic Regression Model"></a>äºŒ. Logistic Regression Model</h2><h3 id="1-Cost-Function"><a href="#1-Cost-Function" class="headerlink" title="1. Cost Function"></a>1. Cost Function</h3><p>ä¹‹å‰å®šä¹‰çš„ä»£ä»·å‡½æ•°ï¼š</p><p>$$ \rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$</p><p>å¦‚æœå°† $$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} $$ ä»£å…¥åˆ°ä¸Šé¢çš„å¼å­ä¸­ï¼Œ$\rm{CostFunction}$ çš„å‡½æ•°å›¾åƒä¼šæ˜¯ä¸€ä¸ªéå‡¸å‡½æ•°ï¼Œä¼šæœ‰å¾ˆå¤šä¸ªå±€éƒ¨æå€¼ç‚¹ã€‚</p><p>äºæ˜¯æˆ‘ä»¬é‡æ–°å¯»æ‰¾ä¸€ä¸ªæ–°çš„ä»£ä»·å‡½æ•°ï¼š</p><p>$$\rm{CostFunction} = \rm{F}({\theta}) = \frac{1}{m}\sum_{i = 1}^{m} \rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)})$$</p>$$\rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)}) = \left\{\begin{matrix}-log(h_{\theta}(x)) &amp;if \; y = 1 \\ -log(1-h_{\theta}(x)) &amp; if\; y = 0\end{matrix}\right.$$<p>éœ€è¦è¯´æ˜çš„ä¸€ç‚¹æ˜¯ï¼Œåœ¨æˆ‘ä»¬çš„è®­ç»ƒé›†ä¸­ï¼Œç”šè‡³ä¸åœ¨è®­ç»ƒé›†ä¸­çš„æ ·æœ¬ï¼Œy çš„å€¼æ€»æ˜¯ç­‰äº 0 æˆ–è€… 1 ã€‚</p><h3 id="2-Simplified-Cost-Function-and-Gradient-Descent"><a href="#2-Simplified-Cost-Function-and-Gradient-Descent" class="headerlink" title="2. Simplified Cost Function and Gradient Descent"></a>2. Simplified Cost Function and Gradient Descent</h3><p>äºæ˜¯è¿›ä¸€æ­¥æˆ‘ä»¬æŠŠä»£ä»·å‡½æ•°å†™æˆä¸€ä¸ªå¼å­ï¼š</p><p>$$\rm{Cost}(h_{\theta}(x),y) = - ylog(h_{\theta}(x)) - (1-y)log(1-h_{\theta}(x))$$</p><p>æ‰€ä»¥ä»£ä»·å‡½æ•°æœ€ç»ˆè¡¨ç¤ºä¸ºï¼š</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta}) &amp;= \frac{1}{m}\sum_{i = 1}^{m} \rm{Cost}(h_{\theta}(x^{(i)}),y^{(i)})\\&amp;= -\frac{1}{m}\left [ \sum_{i=1}^{m} y^{(i)}logh_{\theta}(x^{(i)}) + (1-y^{(i)})log(1-h_{\theta}(x^{(i)})) \right ] \\\left( h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}} \right ) \end{align*}$$<p>å‘é‡åŒ–å½¢å¼ï¼š</p>$$\begin{align*}h &amp;= g(X\theta)\\ \rm{CostFunction} = \rm{F}({\theta}) &amp;= \frac{1}{m} \left ( -\overrightarrow{y}^{T}log(h) - (1-\overrightarrow{y})^{T}log(1-h) \right ) \\ \end{align*}$$<p>ä¸ºäº†æŠŠå¼å­å†™æˆä¸Šé¢è¿™æ ·å­æ˜¯æ¥è‡ªäºç»Ÿè®¡å­¦çš„æå¤§ä¼¼ç„¶ä¼°è®¡æ³•å¾—æ¥çš„ï¼Œå®ƒæ˜¯ç»Ÿè®¡å­¦é‡Œä¸ºä¸åŒçš„æ¨¡å‹å¿«é€Ÿå¯»æ‰¾å‚æ•°çš„æ–¹æ³•ã€‚å®ƒçš„æ€§è´¨ä¹‹ä¸€æ˜¯å®ƒæ˜¯å‡¸å‡½æ•°ã€‚</p><p>åˆ©ç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•ï¼Œå¾—åˆ°ä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼š</p><p>$$ \theta_{j} := \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$$</p><p>çŸ¢é‡åŒ–ï¼Œå³ï¼š</p><p>$$ \theta := \theta - \alpha \frac{1}{m} X^{T}(g(X\Theta)-\vec{y})$$</p><p><strong>è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯</strong>ï¼Œ</p><p><strong>çº¿æ€§å›å½’ä¸­ï¼Œ$h_{\theta}(x) = \theta^{T}x $</strong>,</p><p><strong>è€Œ Logistic å›å½’ä¸­ï¼Œ$h_{\theta}(x) = \frac{1}{1+e^{-\theta^{T}x}}$</strong> ã€‚</p><p>æœ€åï¼Œç‰¹å¾ç¼©æ”¾çš„æ–¹æ³•åŒæ ·é€‚ç”¨äº Logistic å›å½’ï¼Œè®©å…¶æ¢¯åº¦ä¸‹é™æ”¶æ•›æ›´å¿«ã€‚</p><hr><h3 id="3-æ±‚å¯¼è¿‡ç¨‹"><a href="#3-æ±‚å¯¼è¿‡ç¨‹" class="headerlink" title="3. æ±‚å¯¼è¿‡ç¨‹"></a>3. æ±‚å¯¼è¿‡ç¨‹</h3><p>é€»è¾‘å‡½æ•°</p><p>æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹å¦‚ä½•å¯¹é€»è¾‘å‡½æ•°ï¼ˆSigmoidå‡½æ•°ï¼‰æ±‚å¯¼ï¼š</p>$$\begin{align*}\sigma(x)'&amp;=\left(\frac{1}{1+e^{-x}}\right)'=\frac{-(1+e^{-x})'}{(1+e^{-x})^2}=\frac{-1'-(e^{-x})'}{(1+e^{-x})^2}=\frac{0-(-x)'(e^{-x})}{(1+e^{-x})^2}=\frac{-(-1)(e^{-x})}{(1+e^{-x})^2}=\frac{e^{-x}}{(1+e^{-x})^2} \newline &amp;=\left(\frac{1}{1+e^{-x}}\right)\left(\frac{e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{+1-1 + e^{-x}}{1+e^{-x}}\right)=\sigma(x)\left(\frac{1 + e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}\right)\\&amp;=\sigma(x)(1 - \sigma(x))\\\end{align*}$$<p>ä»£ä»·å‡½æ•°</p><p>åˆ©ç”¨ä¸Šé¢çš„ç»“æœï¼Œå€ŸåŠ©å¤åˆå‡½æ•°æ±‚å¯¼å…¬å¼ç­‰ï¼Œå¯å¾—ï¼š</p>$$\begin{align*}\frac{\partial}{\partial \theta_j} J(\theta) &amp;= \frac{\partial}{\partial \theta_j} \frac{-1}{m}\sum_{i=1}^m \left [ y^{(i)} log (h_\theta(x^{(i)})) + (1-y^{(i)}) log (1 - h_\theta(x^{(i)})) \right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} \frac{\partial}{\partial \theta_j} log (h_\theta(x^{(i)}))   + (1-y^{(i)}) \frac{\partial}{\partial \theta_j} log (1 - h_\theta(x^{(i)}))\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} h_\theta(x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - h_\theta(x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \frac{\partial}{\partial \theta_j} \sigma(\theta^T x^{(i)})}{h_\theta(x^{(i)})}   + \frac{(1-y^{(i)})\frac{\partial}{\partial \theta_j} (1 - \sigma(\theta^T x^{(i)}))}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   + \frac{- (1-y^{(i)}) \sigma(\theta^T x^{(i)}) (1 - \sigma(\theta^T x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     \frac{y^{(i)} h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{h_\theta(x^{(i)})}   - \frac{(1-y^{(i)}) h_\theta(x^{(i)}) (1 - h_\theta(x^{(i)})) \frac{\partial}{\partial \theta_j} \theta^T x^{(i)}}{1 - h_\theta(x^{(i)})}\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) x^{(i)}_j - (1-y^{(i)}) h_\theta(x^{(i)}) x^{(i)}_j\right ] \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} (1 - h_\theta(x^{(i)})) - (1-y^{(i)}) h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [     y^{(i)} - y^{(i)} h_\theta(x^{(i)}) - h_\theta(x^{(i)}) + y^{(i)} h_\theta(x^{(i)}) \right ] x^{(i)}_j \newline&amp;= - \frac{1}{m}\sum_{i=1}^m \left [ y^{(i)} - h_\theta(x^{(i)}) \right ] x^{(i)}_j  \newline&amp;= \frac{1}{m}\sum_{i=1}^m \left [ h_\theta(x^{(i)}) - y^{(i)} \right ] x^{(i)}_j\end{align*}$$<p>å‘é‡åŒ–å½¢å¼ï¼š</p><p>$$\nabla J(\theta) = \frac{1}{m} \cdot  X^T \cdot \left(g\left(X\cdot\theta\right) - \vec{y}\right)$$</p><hr><h3 id="4-Advanced-Optimization"><a href="#4-Advanced-Optimization" class="headerlink" title="4. Advanced Optimization"></a>4. Advanced Optimization</h3><p>é™¤å»æ¢¯åº¦ä¸‹é™æ³•ï¼Œè¿˜æœ‰å…¶ä»–çš„ä¼˜åŒ–æ–¹æ³•ï¼Œ</p><p>conjugate gradient å…±è½­æ¢¯åº¦æ³•ï¼Œ<br>BFGSï¼Œ<br>L_BFGSï¼Œ  </p><p>ä¸Šè¿°3ç§ç®—æ³•åœ¨é«˜ç­‰æ•°å€¼è®¡ç®—ä¸­ã€‚å®ƒä»¬ç›¸æ¯”æ¢¯åº¦ä¸‹é™ï¼Œæœ‰ä»¥ä¸‹ä¸€äº›ä¼˜ç‚¹ï¼š</p><ol><li>ä¸éœ€è¦æ‰‹åŠ¨é€‰æ‹©å­¦ä¹ ç‡ $\alpha$ ã€‚å¯ä»¥ç†è§£ä¸ºå®ƒä»¬æœ‰ä¸€ä¸ªæ™ºèƒ½çš„å†…å¾ªç¯(çº¿æœç´¢ç®—æ³•)ï¼Œå®ƒä¼šè‡ªåŠ¨å°è¯•ä¸åŒçš„å­¦ä¹ é€Ÿç‡ $\alpha$ï¼Œå¹¶è‡ªåŠ¨é€‰æ‹©ä¸€ä¸ªæœ€å¥½çš„å­¦ä¹ é€Ÿç‡ $\alpha$ ã€‚ç”šè‡³è¿˜å¯ä»¥ä¸ºæ¯æ¬¡è¿­ä»£é€‰æ‹©ä¸åŒçš„å­¦ä¹ é€Ÿç‡ï¼Œé‚£ä¹ˆå°±ä¸éœ€è¦è‡ªå·±é€‰æ‹©äº†ã€‚</li><li>æ”¶æ•›é€Ÿåº¦è¿œè¿œå¿«äºæ¢¯åº¦ä¸‹é™ã€‚</li></ol><p>ç¼ºç‚¹å°±æ˜¯ç›¸æ¯”æ¢¯åº¦ä¸‹é™è€Œè¨€ï¼Œæ›´åŠ å¤æ‚ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><pre class=" language-c"><code class="language-c">function <span class="token punctuation">[</span>jVal<span class="token punctuation">,</span> gradient<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">costFunction</span><span class="token punctuation">(</span>theta<span class="token punctuation">)</span>jVal <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">^</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token operator">^</span><span class="token number">2</span><span class="token punctuation">;</span>gradient <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">gradient</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">gradient</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token function">theta</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>è°ƒç”¨é«˜çº§å‡½æ•° fminunc:</p><pre class=" language-c"><code class="language-c">options <span class="token operator">=</span> <span class="token function">optimset</span><span class="token punctuation">(</span><span class="token string">'GrabObj'</span><span class="token punctuation">,</span><span class="token string">'on'</span><span class="token punctuation">,</span><span class="token string">'MaxIter'</span><span class="token punctuation">,</span><span class="token string">'100'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>initialTheta <span class="token operator">=</span> <span class="token function">zeros</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">[</span>optTheta<span class="token punctuation">,</span> functionVal<span class="token punctuation">,</span> exitFlag<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span>@costFunction<span class="token punctuation">,</span> initialTheta<span class="token punctuation">,</span> options<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>æœ€ç»ˆç»“æœ:</p><pre class=" language-c"><code class="language-c">optTheta <span class="token operator">=</span>     <span class="token number">5.0000</span>    <span class="token number">5.0000</span>functionVal <span class="token operator">=</span> <span class="token number">1.5777e-030</span>exitFlag <span class="token operator">=</span> <span class="token number">1</span></code></pre><p>optTheta è¡¨ç¤ºçš„æ˜¯æœ€ç»ˆæ±‚å¾—çš„ç»“æœï¼ŒfunctionVal è¡¨ç¤ºçš„æ˜¯ä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼Œè¿™é‡Œæ˜¯ 0ï¼Œæ˜¯æˆ‘ä»¬æœŸæœ›çš„ã€‚exitFlag è¡¨ç¤ºçš„æ˜¯æœ€ç»ˆæ˜¯å¦æ”¶æ•›ï¼Œ1è¡¨ç¤ºæ”¶æ•›ã€‚</p><p>è¿™é‡Œçš„ fminunc æ˜¯è¯•å›¾æ‰¾åˆ°ä¸€ä¸ªå¤šå˜é‡å‡½æ•°çš„æœ€å°å€¼ï¼Œä»ä¸€ä¸ªä¼°è®¡çš„åˆè¯•å€¼å¼€å§‹ï¼Œè¿™é€šå¸¸è¢«è®¤ä¸ºæ˜¯æ— çº¦æŸéçº¿æ€§ä¼˜åŒ–é—®é¢˜ã€‚</p><p>å¦å¤–ä¸€äº›ä¾‹å­ï¼š</p><pre class=" language-c"><code class="language-c">x <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>fun<span class="token punctuation">,</span>x0<span class="token punctuation">)</span>                                   <span class="token operator">%</span>è¯•å›¾ä»x0é™„è¿‘å¼€å§‹æ‰¾åˆ°å‡½æ•°çš„å±€éƒ¨æœ€å°å€¼ï¼Œx0å¯ä»¥æ˜¯æ ‡é‡ï¼Œå‘é‡æˆ–çŸ©é˜µx <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>fun<span class="token punctuation">,</span>x0<span class="token punctuation">,</span>options<span class="token punctuation">)</span>                           <span class="token operator">%</span>æ ¹æ®ç»“æ„ä½“optionsä¸­çš„è®¾ç½®æ¥æ‰¾åˆ°æœ€å°å€¼ï¼Œå¯ç”¨optimsetæ¥è®¾ç½®optionsx <span class="token operator">=</span><span class="token function">fminunc</span><span class="token punctuation">(</span>problem<span class="token punctuation">)</span>                                  <span class="token operator">%</span>ä¸ºproblemæ‰¾åˆ°æœ€å°å€¼<span class="token punctuation">,</span>è€Œproblemæ˜¯åœ¨Input Argumentsä¸­å®šä¹‰çš„ç»“æ„ä½“<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                               <span class="token operator">%</span>è¿”å›ç›®æ ‡å‡½æ•°funåœ¨è§£xå¤„çš„å‡½æ•°å€¼<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                      <span class="token operator">%</span>è¿”å›ä¸€ä¸ªæè¿°é€€å‡ºæ¡ä»¶çš„å€¼exitflag<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>               <span class="token operator">%</span>è¿”å›ä¸€ä¸ªå«outputçš„ç»“æ„ä½“ï¼Œå®ƒåŒ…å«ç€ä¼˜åŒ–çš„ä¿¡æ¯<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">,</span>grad<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>          <span class="token operator">%</span>è¿”å›å‡½æ•°åœ¨è§£xå¤„çš„æ¢¯åº¦çš„å€¼ï¼Œå­˜å‚¨åœ¨gradä¸­<span class="token punctuation">[</span>x<span class="token punctuation">,</span>fval<span class="token punctuation">,</span>exitflag<span class="token punctuation">,</span>output<span class="token punctuation">,</span>grad<span class="token punctuation">,</span>hessian<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">fminunc</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>  <span class="token operator">%</span>è¿”å›å‡½æ•°åœ¨è§£xå¤„çš„HessiançŸ©é˜µçš„å€¼ï¼Œå­˜å‚¨åœ¨hessianä¸­</code></pre><hr><h2 id="ä¸‰-Multiclass-Classification"><a href="#ä¸‰-Multiclass-Classification" class="headerlink" title="ä¸‰. Multiclass Classification"></a>ä¸‰. Multiclass Classification</h2><p>è¿™ä¸€ç« èŠ‚æˆ‘ä»¬æ¥è®¨è®ºä¸€ä¸‹å¦‚ä½•åˆ©ç”¨é€»è¾‘å›å½’æ¥è§£å†³å¤šç±»åˆ«åˆ†ç±»é—®é¢˜ã€‚ä»‹ç»ä¸€ä¸ªä¸€å¯¹å¤šçš„åˆ†ç±»ç®—æ³•ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/69_7.png" alt></p><p>ç°åœ¨ï¼Œå½“æˆ‘ä»¬æœ‰ä¸¤ä¸ªä»¥ä¸Šçš„ç±»åˆ«æ—¶ï¼Œæˆ‘ä»¬å°†å¤„ç†æ•°æ®çš„åˆ†ç±»ã€‚æˆ‘ä»¬å°†æ‰©å±•æˆ‘ä»¬çš„å®šä¹‰ï¼Œä½¿å¾—y = {0,1 â€¦ n}ï¼Œè€Œä¸æ˜¯y = {0,1}ã€‚ ç”±äºy = {0,1 â€¦ n}ï¼Œæˆ‘ä»¬å°†é—®é¢˜åˆ†æˆn + 1ï¼ˆ+1ï¼Œå› ä¸ºç´¢å¼•ä»0å¼€å§‹ï¼‰äºŒå…ƒåˆ†ç±»é—®é¢˜;åœ¨æ¯ä¸€ä¸ªä¸­ï¼Œæˆ‘ä»¬éƒ½é¢„æµ‹â€™yâ€™æ˜¯æˆ‘ä»¬å…¶ä¸­ä¸€ä¸ªç±»çš„æˆå‘˜çš„æ¦‚ç‡ã€‚</p><p>æœ€ç»ˆåœ¨ n + 1 ä¸ªåˆ†ç±»å™¨ä¸­åˆ†åˆ«è¾“å…¥ x ï¼Œç„¶åå–è¿™ n + 1 ä¸ªåˆ†ç±»å™¨æ¦‚ç‡çš„æœ€å¤§å€¼,å³æ˜¯å¯¹åº” $y=i$ çš„æ¦‚ç‡å€¼ã€‚</p><hr><h2 id="å››-Logistic-Regression-æµ‹è¯•"><a href="#å››-Logistic-Regression-æµ‹è¯•" class="headerlink" title="å››. Logistic Regression æµ‹è¯•"></a>å››. Logistic Regression æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose that you have trained a logistic regression classifier, and it outputs on a new example x a prediction hÎ¸(x) = 0.7. This means (check all that apply):</p><p>A. Our estimate for P(y=1|x;Î¸) is 0.7.<br>B. Our estimate for P(y=0|x;Î¸) is 0.3.<br>C. Our estimate for P(y=1|x;Î¸) is 0.3.<br>D. Our estimate for P(y=0|x;Î¸) is 0.7.  </p><p>è§£ç­”ï¼š Aã€B  </p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>Suppose you have the following training set, and fit a logistic regression classifier hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2).</p><p>Which of the following are true? Check all that apply.</p><p>A. Adding polynomial features (e.g., instead using hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2+Î¸3x21+Î¸4x1x2+Î¸5x22) ) could increase how well we can fit the training data.  </p><p>B. At the optimal value of Î¸ (e.g., found by fminunc), we will have J(Î¸)â‰¥0.  </p><p>C. Adding polynomial features (e.g., instead using hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2+Î¸3x21+Î¸4x1x2+Î¸5x22) ) would increase J(Î¸) because we are now summing over more terms.  </p><p>D. If we train gradient descent for enough iterations, for some examples x(i) in the training set it is possible to obtain hÎ¸(x(i))&gt;1.  </p><p>è§£ç­”ï¼š Aã€B</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>For logistic regression, the gradient is given by âˆ‚âˆ‚Î¸jJ(Î¸)=1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i)j. Which of these is a correct gradient descent update for logistic regression with a learning rate of Î±? Check all that apply.</p><p>A. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i) (simultaneously update for all j).  </p><p>B. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(hÎ¸(x(i))âˆ’y(i))x(i)j (simultaneously update for all j).  </p><p>C. Î¸j:=Î¸jâˆ’Î±1mâˆ‘mi=1(11+eâˆ’Î¸Tx(i)âˆ’y(i))x(i)j (simultaneously update for all j).  </p><p>D. Î¸:=Î¸âˆ’Î±1mâˆ‘mi=1(Î¸Txâˆ’y(i))x(i).  </p><p>è§£ç­”ï¼š Aã€D</p><p>çº¿æ€§å›å½’ä¸é€»è¾‘å›å½’çš„åŒºåˆ«</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Which of the following statements are true? Check all that apply.</p><p>A. The cost function J(Î¸) for logistic regression trained with mâ‰¥1 examples is always greater than or equal to zero.  </p><p>B. Linear regression always works well for classification if you classify by using a threshold on the prediction made by linear regression.  </p><p>C. The one-vs-all technique allows you to use logistic regression for problems in which each y(i) comes from a fixed, discrete set of values.   </p><p>D. For logistic regression, sometimes gradient descent will converge to a local minimum (and fail to find the global minimum). This is the reason we prefer more advanced optimization algorithms such as fminunc (conjugate gradient/BFGS/L-BFGS/etc).  </p><p>è§£ç­”ï¼š Aã€C</p><p>Dç”±äºä½¿ç”¨ä»£ä»·å‡½æ•°ä¸ºçº¿æ€§å›å½’ä»£ä»·å‡½æ•°ï¼Œä¼šæœ‰å¾ˆå¤šå±€éƒ¨æœ€ä¼˜å€¼</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Suppose you train a logistic classifier hÎ¸(x)=g(Î¸0+Î¸1x1+Î¸2x2). Suppose Î¸0=6,Î¸1=0,Î¸2=âˆ’1. Which of the following figures represents the decision boundary found by your classifier?</p><p>è§£ç­”ï¼š C</p><p>6-x2&gt;=0 å³X2&lt;6æ—¶ä¸º1</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Logistic_Regression.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.2_Computing_Parameters_Analytically</title>
      <link href="/2020/01/27/2-2-computing-parameters-analytically/"/>
      <url>/2020/01/27/2-2-computing-parameters-analytically/</url>
      
        <content type="html"><![CDATA[<h1 id="2-2-Computing-Parameters-Analytically"><a href="#2-2-Computing-Parameters-Analytically" class="headerlink" title="2.2_Computing_Parameters_Analytically"></a>2.2_Computing_Parameters_Analytically</h1><h2 id="ä¸€-Normal-Equation"><a href="#ä¸€-Normal-Equation" class="headerlink" title="ä¸€. Normal Equation"></a>ä¸€. Normal Equation</h2><h3 id="1-æ­£è§„æ–¹ç¨‹"><a href="#1-æ­£è§„æ–¹ç¨‹" class="headerlink" title="1. æ­£è§„æ–¹ç¨‹"></a>1. æ­£è§„æ–¹ç¨‹</h3><p>æ­£è§„æ–¹ç¨‹æ³•ç›¸å¯¹æ¢¯åº¦ä¸‹é™æ³•ï¼Œå®ƒå¯ä»¥ä¸€æ­¥æ‰¾åˆ°æœ€å°å€¼ã€‚è€Œä¸”å®ƒä¹Ÿä¸éœ€è¦è¿›è¡Œç‰¹å¾å€¼çš„ç¼©æ”¾ã€‚</p><p>æ ·æœ¬é›†æ˜¯ $ m * n $ çš„çŸ©é˜µï¼Œæ¯è¡Œæ ·æœ¬è¡¨ç¤ºä¸º $ \vec{x^{(i)}} $ ,ç¬¬ i è¡Œç¬¬ n åˆ—åˆ†åˆ«è¡¨ç¤ºä¸º $ x^{(i)}_{0} , x^{(i)}_{1} , x^{(i)}_{2} , x^{(i)}_{3} \cdots x^{(i)}_{n} $, m è¡Œå‘é‡åˆ†åˆ«è¡¨ç¤ºä¸º $ \vec{x^{(1)}} , \vec{x^{(2)}} , \vec{x^{(3)}} , \cdots \vec{x^{(m)}} $</p><p>ä»¤ </p>$$ \vec{x^{(i)}} = \begin{bmatrix} x^{(i)}_{0}\\ x^{(i)}_{1}\\ \vdots \\ x^{(i)}_{n}\\ \end{bmatrix} $$<p>$ \vec{x^{(i)}} $ æ˜¯è¿™æ ·ä¸€ä¸ª $(n+1)*1$ ç»´å‘é‡ã€‚æ¯è¡Œéƒ½å¯¹åº”ç€ i è¡Œ 0-n ä¸ªå˜é‡ã€‚</p><p>å†æ„é€ å‡ ä¸ªçŸ©é˜µï¼š</p>$$ X = \begin{bmatrix} (\vec{x^{(1)}})^{T}\\  \vdots \\  (\vec{x^{(m)}})^{T} \end{bmatrix} \;\;\;\;\Theta = \begin{bmatrix} \theta_{0}\\ \theta_{1}\\ \vdots \\ \theta_{n}\\ \end{bmatrix} \;\;\;\;Y = \begin{bmatrix} y^{(1)}\\ y^{(2)}\\ \vdots \\ y^{(m)}\\ \end{bmatrix} $$<p>X æ˜¯ä¸€ä¸ª $ m * (n+1)$ çš„çŸ©é˜µï¼Œ$ \Theta $ æ˜¯ä¸€ä¸ª $ (n+1) * 1$ çš„å‘é‡ï¼ŒY æ˜¯ä¸€ä¸ª $ m * 1$çš„çŸ©é˜µã€‚</p><p>å¯¹æ¯”ä¹‹å‰ä»£ä»·å‡½æ•°ä¸­ï¼Œ$$ \rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$</p>  $$\begin{align*}X \cdot \Theta - Y = \begin{bmatrix}(\vec{x^{(1)}})^{T}\\ \vdots \\ (\vec{x^{(m)}})^{T}\end{bmatrix} \cdot \begin{bmatrix} \theta_{0}\\ \theta_{1}\\ \vdots \\ \theta_{n}\\ \end{bmatrix} - \begin{bmatrix} y^{(1)}\\ y^{(2)}\\ \vdots \\ y^{(m)}\\ \end{bmatrix} = \begin{bmatrix} h_{\theta}(x^{(1)})-y^{(1)}\\ h_{\theta}(x^{(2)})-y^{(2)}\\ \vdots \\ h_{\theta}(x^{(m)})-y^{(m)}\\ \end{bmatrix}\end{align*}$$<p>ä»£å…¥åˆ°ä¹‹å‰ä»£ä»·å‡½æ•°ä¸­ï¼Œ</p>$$\begin{align*}\rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) &amp;= \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\&amp; = \frac{1}{2m} (X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y)\\\end{align*}$$<hr><h3 id="2-çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹"><a href="#2-çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹" class="headerlink" title="2. çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹"></a>2. çŸ©é˜µçš„å¾®åˆ†å’ŒçŸ©é˜µçš„è¿¹</h3><p>æ¥ä¸‹æ¥åœ¨è¿›è¡Œæ¨å¯¼ä¹‹å‰ï¼Œéœ€è¦å¼•å…¥çŸ©é˜µè¿¹çš„æ¦‚å¿µï¼Œå› ä¸ºè¿¹æ˜¯æ±‚è§£ä¸€é˜¶çŸ©é˜µå¾®åˆ†çš„å·¥å…·ã€‚</p><p>çŸ©é˜µè¿¹çš„å®šä¹‰æ˜¯ </p><p>$$ \rm{tr} A =  \sum_{i=1}^{n}A_{ii}$$ </p><p>ç®€å•çš„è¯´å°±æ˜¯å·¦ä¸Šè§’åˆ°å³ä¸‹è§’å¯¹è§’çº¿ä¸Šå…ƒç´ çš„å’Œã€‚</p><p>æ¥ä¸‹æ¥æœ‰å‡ ä¸ªæ€§è´¨åœ¨ä¸‹é¢æ¨å¯¼è¿‡ç¨‹ä¸­éœ€è¦ç”¨åˆ°ï¼š</p><ol><li><p>$ \rm{tr};a = a $ ï¼Œ a æ˜¯æ ‡é‡ ( $ a \in \mathbb{R} $)  </p></li><li><p>$ \rm{tr};AB = \rm{tr};BA $ æ›´è¿‘ä¸€æ­¥ $ \rm{tr};ABC = \rm{tr};CAB = \rm{tr};BCA $<br>è¯æ˜ï¼šå‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µï¼Œ B æ˜¯ $m * n$ çŸ©é˜µï¼Œåˆ™æœ‰<br>$$ \rm{tr};AB = \sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji} = \sum_{j=1}^{n} \sum_{i=1}^{m}B_{ji}A_{ij}= \rm{tr};BA $$<br>åŒç†ï¼š$$ \rm{tr};ABC = \rm{tr};(AB)C = \rm{tr};C(AB) = \rm{tr};CAB$$<br>$$ \rm{tr};ABC = \rm{tr};A(BC) = \rm{tr};(BC)A = \rm{tr};BCA$$<br>è¿èµ·æ¥ï¼Œå³ $$ \rm{tr};ABC = \rm{tr};CAB = \rm{tr};BCA $$</p></li><li><p>$ \triangledown_{A}\rm{tr};AB = \triangledown_{A}\rm{tr};BA = B^{T}$<br>è¯æ˜ï¼šæŒ‰ç…§çŸ©é˜µæ¢¯åº¦çš„å®šä¹‰ï¼š</p>   $$\triangledown_{X}f(X) = \begin{bmatrix}   \frac{\partial f(X) }{\partial x_{11}} &amp; \cdots &amp; \frac{\partial f(X) }{\partial x_{1n}}\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial f(X) }{\partial x_{m1}} &amp; \cdots &amp; \frac{\partial f(X) }{\partial x_{mn}}   \end{bmatrix} = \frac{\partial f(X) }{\partial X}$$   <p>å‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µï¼Œ B æ˜¯ $m * n$ çŸ©é˜µï¼Œåˆ™æœ‰</p>   $$\begin{align*}\triangledown_{A}\rm{tr}\;AB &amp;= \triangledown_{A} \sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}  = \frac{\partial}{\partial A}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})\\ &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}(\sum_{i=1}^{n}\sum_{j=1}^{m}A_{ij}B_{ji})   \end{bmatrix} \\ &amp; = \begin{bmatrix}   B_{11} &amp; \cdots &amp; B_{m1} \\    \vdots &amp; \ddots  &amp; \vdots \\    B_{1n} &amp; \cdots &amp; B_{mn}   \end{bmatrix} = B^{T}\\ \end{align*}$$   </li></ol>      $$\begin{align*}\triangledown_{A}\rm{tr}\;BA &amp;= \triangledown_{A} \sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}  = \frac{\partial}{\partial A}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})\\ &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji}) &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}(\sum_{i=1}^{m}\sum_{j=1}^{n}B_{ij}A_{ji})   \end{bmatrix} \\ &amp; = \begin{bmatrix}   B_{11} &amp; \cdots &amp; B_{m1} \\    \vdots &amp; \ddots  &amp; \vdots \\    B_{1n} &amp; \cdots &amp; B_{mn}   \end{bmatrix} = B^{T}\\ \end{align*}$$   <p>   æ‰€ä»¥æœ‰ $ \triangledown_{A}\rm{tr};AB = \triangledown_{A}\rm{tr};BA = B^{T}$</p><ol start="4"><li><p>$\triangledown_{A^{T}}a = (\triangledown_{A}a)^{T};;;; (a \in \mathbb{R})$<br>è¯æ˜ï¼šå‡è®¾ A æ˜¯ $n * m$ çŸ©é˜µ</p>   $$\begin{align*}\triangledown_{A^{T}}a &amp; = \begin{bmatrix}   \frac{\partial}{\partial A_{11}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{1n}}a\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{m1}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{mn}}a   \end{bmatrix}  = (\begin{bmatrix}   \frac{\partial}{\partial A_{11}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{1m}}a\\    \vdots &amp; \ddots  &amp; \vdots \\    \frac{\partial}{\partial A_{n1}}a &amp; \cdots &amp; \frac{\partial}{\partial A_{nm}}a   \end{bmatrix})^{T} \\ &amp; = (\triangledown_{A}a)^{T}\\ \end{align*}$$   </li><li><p>$\mathrm{d}(\rm{tr};A) = \rm{tr}(\mathrm{d}A)$<br>è¯æ˜ï¼š<br>$$\mathrm{d}(\rm{tr};A) = \mathrm{d}(\sum_{i=1}^{n}a_{ii}) = \sum_{i=1}^{n}\mathrm{d}a_{ii} = \rm{tr}(\mathrm{d}A)$$<br>çŸ©é˜µçš„è¿¹çš„å¾®åˆ†ç­‰äºçŸ©é˜µçš„å¾®åˆ†çš„è¿¹ã€‚</p></li><li><p>$\triangledown_{A}\rm{tr};ABA^{T}C = CAB + C^{T}AB^{T}$<br>è¯æ˜ï¼š<br>æ ¹æ®å®æ ‡é‡å‡½æ•°æ¢¯åº¦çš„ä¹˜æ³•æ³•åˆ™ï¼š<br>è‹¥ f(A)ã€g(A)ã€h(A) åˆ†åˆ«æ˜¯çŸ©é˜µ A çš„å®æ ‡é‡å‡½æ•°ï¼Œåˆ™æœ‰   $$\begin{align*}\frac{\partial f(A)g(A)}{\partial A} &amp;= g(A)\frac{\partial f(A)}{\partial A} + f(A)\frac{\partial g(A)}{\partial A}\\ \frac{\partial f(A)g(A)h(A)}{\partial A} &amp;= g(A)h(A)\frac{\partial f(A)}{\partial A} + f(A)h(A)\frac{\partial g(A)}{\partial A}+ f(A)g(A)\frac{\partial h(A)}{\partial A}\\ \end{align*}$$<br>ä»¤ $f(A) = AB,g(A) = A^{T}C$ï¼Œç”±æ€§è´¨5ï¼ŒçŸ©é˜µçš„è¿¹çš„å¾®åˆ†ç­‰äºçŸ©é˜µçš„å¾®åˆ†çš„è¿¹ï¼Œé‚£ä¹ˆåˆ™æœ‰ï¼š</p>   $$\begin{align*} \triangledown_{A}\rm{tr}\;ABA^{T}C &amp; = \rm{tr}(\triangledown_{A}ABA^{T}C) = \rm{tr}(\triangledown_{A}f(A)g(A)) = \rm{tr}\triangledown_{A_{1}}(A_{1}BA^{T}C) + \rm{tr}\triangledown_{A_{2}}(ABA_{2}^{T}C)  \\ &amp; = (BA^{T}C)^{T} + \rm{tr}\triangledown_{A_{2}}(ABA_{2}^{T}C) = C^{T}AB^{T} + \triangledown_{A_{2}}\rm{tr}(ABA_{2}^{T}C)\\ &amp; = C^{T}AB^{T} + \triangledown_{A_{2}}\rm{tr}(A_{2}^{T}CAB) = C^{T}AB^{T} + (\triangledown_{{A_{2}}^{T}}\;\rm{tr}\;A_{2}^{T}CAB)^{T} \\ &amp; = C^{T}AB^{T} + ((CAB)^{T})^{T}  \\ &amp; = C^{T}AB^{T} + CAB  \\ \end{align*}$$   </li></ol><hr><h3 id="3-æ¨å¯¼"><a href="#3-æ¨å¯¼" class="headerlink" title="3. æ¨å¯¼"></a>3. æ¨å¯¼</h3><p>å›åˆ°ä¹‹å‰çš„ä»£ä»·å‡½æ•°ä¸­ï¼š<br>$$<br>\rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m} (X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y)<br>$$<br>æ±‚å¯¼ï¼š</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{2m} \triangledown_{\theta}(X \cdot \Theta - Y)^{T}(X \cdot \Theta - Y) = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}-Y^{T})(X\Theta-Y)\\&amp; = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}X\Theta-Y^{T}X\Theta-\Theta^{T}X^{T}Y+Y^{T}Y) \\ \end{align*}$$<p>ä¸Šå¼ä¸­ï¼Œå¯¹ $\Theta $çŸ©é˜µæ±‚å¯¼ï¼Œ$ Y^{T}Y $ ä¸ $\Theta $ æ— å…³ï¼Œæ‰€ä»¥è¿™ä¸€é¡¹ä¸º 0 ã€‚ $Y^{T}X\Theta$ æ˜¯æ ‡é‡ï¼Œç”±æ€§è´¨4å¯ä»¥çŸ¥é“ï¼Œ$Y^{T}X\Theta = (Y^{T}X\Theta)^{T} = \Theta^{T}X^{T}Y$ï¼Œå› ä¸º $\Theta^{T}X^{T}X\Theta , Y^{T}X\Theta $éƒ½æ˜¯æ ‡é‡ï¼Œæ‰€ä»¥å®ƒä»¬çš„ä¹Ÿç­‰äºå®ƒä»¬çš„è¿¹ï¼Œï¼ˆå¤„ç†çŸ©é˜µå¾®åˆ†çš„é—®é¢˜å¸¸å¸¸å¼•å…¥çŸ©é˜µçš„è¿¹ï¼‰ï¼Œäºæ˜¯æœ‰</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{2m}\triangledown_{\theta}(\Theta^{T}X^{T}X\Theta-2Y^{T}X\Theta) \\ &amp; = \frac{1}{2m}\triangledown_{\theta}\rm{tr}\;(\Theta^{T}X^{T}X\Theta-2Y^{T}X\Theta) \\ &amp; = \frac{1}{2m}\triangledown_{\theta}\rm{tr}\;(\Theta\Theta^{T}X^{T}X-2Y^{T}X\Theta) \\ &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -\triangledown_{\theta}\rm{tr}\;Y^{T}X\Theta) \\ &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -(Y^{T}X)^{T}) = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -X^{T}Y)\\ \end{align*}$$<p>ä¸Šé¢ç¬¬ä¸‰æ­¥ç”¨çš„æ€§è´¨2çŸ©é˜µè¿¹çš„äº¤æ¢å¾‹ï¼Œç¬¬äº”æ­¥ç”¨çš„æ€§è´¨3ã€‚</p><p>ä¸ºäº†èƒ½è¿›ä¸€æ­¥åŒ–ç®€çŸ©é˜µçš„å¾®åˆ†ï¼Œæˆ‘ä»¬åœ¨çŸ©é˜µçš„è¿¹ä¸Šé¢ä¹˜ä»¥ä¸€ä¸ªå•ä½çŸ©é˜µï¼Œä¸å½±å“ç»“æœã€‚äºæ˜¯ï¼š</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp; = \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta\Theta^{T}X^{T}X -X^{T}Y) \\ &amp;= \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta I \Theta^{T}X^{T}X -X^{T}Y) \end{align*}$$<p>åˆ©ç”¨æ€§è´¨6 å±•å¼€ä¸Šé¢çš„å¼å­ï¼Œä»¤ $ A = \Theta , B = I , C = X^{T}X $ã€‚</p>$$\begin{align*}\triangledown_{\theta}\rm{F}(\theta) &amp;= \frac{1}{m}(\frac{1}{2}\triangledown_{\theta}\rm{tr}\;\Theta I \Theta^{T}X^{T}X -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta I + (X^{T}X)^{T}\Theta I^{T}) -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta I + (X^{T}X)^{T}\Theta I^{T}) -X^{T}Y) \\ &amp; = \frac{1}{m}(\frac{1}{2}(X^{T}X\Theta + X^{T}X\Theta) -X^{T}Y)  = \frac{1}{m}(X^{T}X\Theta -X^{T}Y) \\ \end{align*}$$<p>ä»¤ $\triangledown_{\theta}\rm{F}(\theta) = 0$ï¼Œå³ $X^{T}X\Theta -X^{T}Y = 0$, äºæ˜¯ $ X^{T}X\Theta = X^{T}Y $ ï¼Œè¿™é‡Œå‡è®¾ $ X^{T}X$ è¿™ä¸ªçŸ©é˜µæ˜¯å¯é€†çš„ï¼Œç­‰å·ä¸¤è¾¹åŒæ—¶å·¦ä¹˜$ X^{T}X$çš„é€†çŸ©é˜µï¼Œå¾—åˆ° $\Theta = (X^{T}X)^{-1}X^{T}Y$</p><p>æœ€ç»ˆç»“æœä¹Ÿå°±æ¨å¯¼å‡ºæ¥äº†ï¼Œ$$\Theta = (X^{T}X)^{-1}X^{T}Y$$</p><p>ä½†æ˜¯è¿™é‡Œæœ‰ä¸€ä¸ª<strong>å‰ææ¡ä»¶æ˜¯ $X^{T}X$ æ˜¯éå¥‡å¼‚(éé€€åŒ–)çŸ©é˜µï¼Œ å³ $ \left | X^{T}X \right | \neq 0 $</strong></p><hr><h3 id="4-æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š"><a href="#4-æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š" class="headerlink" title="4. æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š"></a>4. æ¢¯åº¦ä¸‹é™å’Œæ­£è§„æ–¹ç¨‹æ³•æ¯”è¾ƒï¼š</h3><p>ä¼˜ç‚¹ï¼š<br>æ¢¯åº¦ä¸‹é™åœ¨è¶…å¤§æ•°æ®é›†é¢å‰ä¹Ÿèƒ½è¿è¡Œçš„å¾ˆè‰¯å¥½ã€‚<br>æ­£è§„æ–¹ç¨‹åœ¨è¶…å¤§æ•°æ®é›†åˆé¢å‰æ€§èƒ½ä¼šå˜å¾—å¾ˆå·®ï¼Œå› ä¸ºéœ€è¦è®¡ç®— $(x^{T}x)^{-1}$,æ—¶é—´å¤æ‚åº¦åœ¨ $O(n^{3})$ è¿™ä¸ªçº§åˆ«ã€‚  </p><p>ç¼ºç‚¹ï¼š<br>æ¢¯åº¦ä¸‹é™éœ€è¦åˆç†çš„é€‰æ‹©å­¦ä¹ é€Ÿç‡ $\alpha$ , éœ€è¦å¾ˆå¤šæ¬¡è¿­ä»£çš„æ“ä½œå»é€‰æ‹©åˆç†çš„ $\alpha$ï¼Œå¯»æ‰¾æœ€å°å€¼çš„æ—¶å€™ä¹Ÿéœ€è¦è¿­ä»£å¾ˆå¤šæ¬¡æ‰èƒ½æ”¶æ•›ã€‚<br>æ­£è§„æ–¹ç¨‹çš„ä¼˜åŠ¿ç›¸æ¯”è€Œè¨€ï¼Œä¸éœ€è¦é€‰æ‹©å­¦ä¹ é€Ÿç‡ $\alpha$ï¼Œä¹Ÿä¸éœ€è¦å¤šæ¬¡çš„è¿­ä»£æˆ–è€…ç”»å›¾æ£€æµ‹æ˜¯å¦æ”¶æ•›ã€‚</p><hr><h2 id="äºŒ-Normal-Equation-Noninvertibility"><a href="#äºŒ-Normal-Equation-Noninvertibility" class="headerlink" title="äºŒ. Normal Equation Noninvertibility"></a>äºŒ. Normal Equation Noninvertibility</h2><p>ä¸Šä¸€ç« è°ˆåˆ°äº†å¦‚ä½•åˆ©ç”¨æ­£è§„æ–¹ç¨‹æ³•æ±‚è§£ $\Theta $,ä½†æ˜¯åœ¨çº¿æ€§ä»£æ•°ä¸­å­˜åœ¨è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœæ˜¯å¥‡å¼‚(é€€åŒ–)çŸ©é˜µï¼Œæ˜¯ä¸å­˜åœ¨é€†çŸ©é˜µçš„ã€‚ä¹Ÿå°±æ˜¯è¯´ç”¨ä¸Šé¢æ­£è§„æ–¹ç¨‹çš„å…¬å¼æ˜¯ä¸ä¸€å®šèƒ½æ±‚è§£å‡ºæ­£ç¡®ç»“æœçš„ã€‚</p><p>åœ¨ Octave è½¯ä»¶ä¸­ï¼Œå­˜åœ¨2ä¸ªæ±‚è§£é€†çŸ©é˜µçš„å‡½æ•°ï¼Œä¸€ä¸ªæ˜¯ pinv å’Œ invã€‚pinv (pseudo-inverse)æ±‚è§£çš„æ˜¯<strong>ä¼ªé€†çŸ©é˜µ</strong>ï¼Œinv æ±‚è§£çš„æ˜¯é€†çŸ©é˜µï¼Œæ‰€ä»¥ç”¨ pinv æ±‚è§£é—®é¢˜ï¼Œå°±ç®—æ˜¯ $ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µï¼Œä¹Ÿä¸€æ ·å¯ä»¥å¾—åˆ°æœ€åçš„ç»“æœã€‚</p><p>å¯¼è‡´$ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µæœ‰2ç§æƒ…å†µï¼š</p><ol><li>å¤šä½™çš„ç‰¹å¾ã€‚ç‰¹å¾ä¹‹é—´å‘ˆå€æ•°å…³ç³»ï¼Œçº¿æ€§ä¾èµ–ã€‚</li><li>è¿‡å¤šçš„ç‰¹å¾ã€‚å½“ $ m \leqslant n $ çš„æ—¶å€™ï¼Œä¼šå¯¼è‡´è¿‡å¤šçš„ç‰¹å¾ã€‚è§£å†³åŠæ³•æ˜¯åˆ é™¤ä¸€äº›ç‰¹å¾ï¼Œæˆ–è€…è¿›è¡Œæ­£åˆ™åŒ–ã€‚</li></ol><p>æ‰€ä»¥è§£å†³$ X^{T}X $ ä¸å­˜åœ¨é€†çŸ©é˜µçš„åŠæ³•ä¹Ÿå°±æ˜¯å¯¹åº”ä¸Šé¢2ç§æƒ…å†µï¼š</p><ol><li>åˆ æ‰å¤šä½™çš„ç‰¹å¾ï¼Œçº¿æ€§ç›¸å…³çš„ï¼Œå€æ•°å…³ç³»çš„ã€‚ç›´åˆ°æ²¡æœ‰å¤šä½™çš„ç‰¹å¾</li><li>å†åˆ é™¤ä¸€äº›ä¸å½±å“ç»“æœçš„ç‰¹å¾ï¼Œæˆ–è€…è¿›è¡Œæ­£åˆ™åŒ–ã€‚</li></ol><hr><h2 id="ä¸‰-Linear-Regression-with-Multiple-Variables-æµ‹è¯•"><a href="#ä¸‰-Linear-Regression-with-Multiple-Variables-æµ‹è¯•" class="headerlink" title="ä¸‰. Linear Regression with Multiple Variables æµ‹è¯•"></a>ä¸‰. Linear Regression with Multiple Variables æµ‹è¯•</h2><h3 id="1-Question-1"><a href="#1-Question-1" class="headerlink" title="1. Question 1"></a>1. Question 1</h3><p>Suppose m=4 students have taken some class, and the class had a midterm exam and a final exam. You have collected a dataset of their scores on the two exams, which is as follows:</p><p>midterm exam    (midterm exam)2    final exam<br>89    7921    96<br>72    5184    74<br>94    8836    87<br>69    4761    78<br>Youâ€™d like to use polynomial regression to predict a studentâ€™s final exam score from their midterm exam score. Concretely, suppose you want to fit a model of the form hÎ¸(x)=Î¸0+Î¸1x1+Î¸2x2, where x1 is the midterm score and x2 is (midterm score)2. Further, you plan to use both feature scaling (dividing by the â€œmax-minâ€, or range, of a feature) and mean normalization.</p><p>What is the normalized feature x(2)2? (Hint: midterm = 72, final = 74 is training example 2.) Please round off your answer to two decimal places and enter in the text box below.</p><p>è§£ç­”ï¼š<br>æ ‡å‡†åŒ– $$x = \frac{x_{2}^{2}-\frac{(7921+5184+8836+4761)}{4}}{\max - \min } = \frac{5184 - 6675.5}{8836-4761} = -0.37$$</p><h3 id="2-Question-2"><a href="#2-Question-2" class="headerlink" title="2. Question 2"></a>2. Question 2</h3><p>You run gradient descent for 15 iterations</p><p>with Î±=0.3 and compute J(Î¸) after each</p><p>iteration. You find that the value of J(Î¸) increases over</p><p>time. Based on this, which of the following conclusions seems</p><p>most plausible?</p><p>A. Rather than use the current value of Î±, itâ€™d be more promising to try a smaller value of Î± (say Î±=0.1).</p><p>B. Î±=0.3 is an effective choice of learning rate.</p><p>C. Rather than use the current value of Î±, itâ€™d be more promising to try a larger value of Î± (say Î±=1.0).</p><p>è§£ç­”ï¼š  A </p><p>ä¸‹é™å¤ªå¿«æ‰€ä»¥aä¸‹é™é€Ÿç‡è¿‡å¤§ï¼Œaè¶Šå¤§ä¸‹é™è¶Šå¿«ï¼Œaå°ä¸‹é™æ…¢ï¼Œåœ¨æœ¬é¢˜ä¸­ï¼Œä»£ä»·å‡½æ•°å¿«é€Ÿæ”¶æ•›åˆ°æœ€å°å€¼ï¼Œä»£è¡¨æ­¤æ—¶aæœ€åˆé€‚ã€‚</p><h3 id="3-Question-3"><a href="#3-Question-3" class="headerlink" title="3. Question 3"></a>3. Question 3</h3><p>Suppose you have m=28 training examples with n=4 features (excluding the additional all-ones feature for the intercept term, which you should add). The normal equation is Î¸=(XTX)âˆ’1XTy. For the given values of m and n, what are the dimensions of Î¸, X, and y in this equation?</p><p>A. X is 28Ã—4, y is 28Ã—1, Î¸ is 4Ã—4</p><p>B. X is 28Ã—5, y is 28Ã—5, Î¸ is 5Ã—5</p><p>C. X is 28Ã—5, y is 28Ã—1, Î¸ is 5Ã—1</p><p>D. X is 28Ã—4, y is 28Ã—1, Î¸ is4Ã—1</p><p>è§£ç­”ï¼š  C </p><p>è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé¢˜ç›®ä¸­è¯´äº†é¢å¤–æ·»åŠ ä¸€åˆ—å…¨éƒ¨ä¸º1çš„ï¼Œæ‰€ä»¥åˆ—æ•°æ˜¯5 ã€‚</p><h3 id="4-Question-4"><a href="#4-Question-4" class="headerlink" title="4. Question 4"></a>4. Question 4</h3><p>Suppose you have a dataset with m=50 examples and n=15 features for each example. You want to use multivariate linear regression to fit the parameters Î¸ to our data. Should you prefer gradient descent or the normal equation?</p><p>A. Gradient descent, since it will always converge to the optimal Î¸.</p><p>B. Gradient descent, since (XTX)âˆ’1 will be very slow to compute in the normal equation.</p><p>C. The normal equation, since it provides an efficient way to directly find the solution.</p><p>D. The normal equation, since gradient descent might be unable to find the optimal Î¸.</p><p>è§£ç­”ï¼š  C </p><p>æ•°æ®é‡å°‘ï¼Œé€‰æ‹©æ­£è§„æ–¹ç¨‹æ³•æ›´åŠ é«˜æ•ˆ</p><h3 id="5-Question-5"><a href="#5-Question-5" class="headerlink" title="5. Question 5"></a>5. Question 5</h3><p>Which of the following are reasons for using feature scaling?</p><p>A. It prevents the matrix XTX (used in the normal equation) from being non-invertable (singular/degenerate).</p><p>B. It is necessary to prevent the normal equation from getting stuck in local optima.</p><p>C. It speeds up gradient descent by making it require fewer iterations to get to a good solution.</p><p>D. It speeds up gradient descent by making each iteration of gradient descent less expensive to compute.</p><p>è§£ç­”ï¼š  C </p><p>normal equation ä¸éœ€è¦ Feature Scalingï¼Œæ’é™¤ABï¼Œ ç‰¹å¾ç¼©æ”¾å‡å°‘è¿­ä»£æ•°é‡ï¼ŒåŠ å¿«æ¢¯åº¦ä¸‹é™ï¼Œç„¶è€Œä¸èƒ½é˜²æ­¢æ¢¯åº¦ä¸‹é™é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Computing_Parameters_Analytically.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.1_Multivariate_Linear_Regression</title>
      <link href="/2020/01/27/2-1-multivariate-linear-regression/"/>
      <url>/2020/01/27/2-1-multivariate-linear-regression/</url>
      
        <content type="html"><![CDATA[<h1 id="Multivariate-Linear-Regression"><a href="#Multivariate-Linear-Regression" class="headerlink" title="Multivariate Linear Regression"></a>Multivariate Linear Regression</h1><h2 id="ä¸€-Multiple-Features"><a href="#ä¸€-Multiple-Features" class="headerlink" title="ä¸€. Multiple Features"></a>ä¸€. Multiple Features</h2><p>å…·æœ‰å¤šä¸ªå˜é‡çš„çº¿æ€§å›å½’ä¹Ÿè¢«ç§°ä¸ºâ€œå¤šå…ƒçº¿æ€§å›å½’â€ã€‚</p><p>$x_{j}^{(i)}$: è®­ç»ƒé›†ç¬¬ i ä¸ªå‘é‡ä¸­çš„ç¬¬ j ä¸ªå…ƒç´ (ç¬¬ i è¡Œç¬¬ j åˆ—)<br>$x^{(i)}$: è®­ç»ƒé›†ç¬¬ i ä¸ªå‘é‡(ç¬¬ i è¡Œ)<br>$ m $: æ€»å…± m è¡Œ<br>$ n $: æ€»å…± n åˆ—  </p><p>é€‚åº”è¿™äº›å¤šç‰¹å¾çš„å‡è®¾å‡½æ•°çš„å¤šå˜é‡å½¢å¼å¦‚ä¸‹ï¼š</p><p>$$ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{3} + \cdots + \theta_{n}x_{n} $$</p><p>ä½¿ç”¨çŸ©é˜µä¹˜æ³•çš„å®šä¹‰ï¼Œæˆ‘ä»¬çš„å¤šå˜é‡å‡è®¾å‡½æ•°å¯ä»¥ç®€æ´åœ°è¡¨ç¤ºä¸ºï¼š</p><p>$$ h_{\theta}(x) = \begin{bmatrix}<br>\theta_{0} &amp; \theta_{1} &amp; \cdots  &amp; \theta_{n}<br>\end{bmatrix} \begin{bmatrix}<br>x_{0}\<br>x_{1}\<br> \vdots \<br>x_{n}<br>\end{bmatrix} = \theta^{T}x$$</p><p>å…¶ä¸­ $ x_{0}^{(i)} = 1 (i\in 1,\cdots,m)$</p><hr><h2 id="äºŒ-Gradient-Descent-for-Multiple-Variables"><a href="#äºŒ-Gradient-Descent-for-Multiple-Variables" class="headerlink" title="äºŒ. Gradient Descent for Multiple Variables"></a>äºŒ. Gradient Descent for Multiple Variables</h2><p>å¤šä¸ªå˜é‡çš„æ¢¯åº¦ä¸‹é™ï¼ŒåŒæ—¶æ›´æ–° n ä¸ªå˜é‡ã€‚</p><p>$$ \theta_{j} := \theta_{j} - \alpha \frac{1}{m} \sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$$</p><p>å…¶ä¸­ $ j \in [0,n]$</p><hr><h2 id="ä¸‰-Gradient-Descent-in-Practice-I-Feature-Scaling"><a href="#ä¸‰-Gradient-Descent-in-Practice-I-Feature-Scaling" class="headerlink" title="ä¸‰. Gradient Descent in Practice I - Feature Scaling"></a>ä¸‰. Gradient Descent in Practice I - Feature Scaling</h2><p>ç‰¹å¾ç¼©æ”¾åŒ…æ‹¬å°†è¾“å…¥å€¼é™¤ä»¥è¾“å…¥å˜é‡çš„èŒƒå›´ï¼ˆå³æœ€å¤§å€¼å‡å»æœ€å°å€¼ï¼‰ï¼Œå¯¼è‡´æ–°çš„èŒƒå›´ä»…ä¸º1ã€‚</p><p>å‡å€¼å½’ä¸€åŒ–åŒ…æ‹¬ä»è¾“å…¥å˜é‡çš„å€¼ä¸­å‡å»è¾“å…¥å˜é‡çš„å¹³å‡å€¼ï¼Œä»è€Œå¯¼è‡´è¾“å…¥å˜é‡çš„æ–°å¹³å‡å€¼ä¸ºé›¶ã€‚</p><h3 id="1-Feature-Scaling"><a href="#1-Feature-Scaling" class="headerlink" title="1. Feature Scaling"></a>1. Feature Scaling</h3><p>ç‰¹å¾ç¼©æ”¾è®©ç‰¹å¾å€¼å–å€¼èŒƒå›´éƒ½æ¯”è¾ƒä¸€è‡´ï¼Œè¿™æ ·åœ¨æ‰§è¡Œæ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼Œâ€œä¸‹å±±çš„è·¯çº¿â€ä¼šæ›´åŠ ç®€å•ï¼Œæ›´å¿«çš„æ”¶æ•›ã€‚é€šå¸¸è¿›è¡Œç‰¹å¾ç¼©æ”¾éƒ½ä¼šæŠŠç‰¹å¾å€¼ç¼©å°½é‡ç¼©æ”¾åˆ° [-1,1] ä¹‹é—´<strong>æˆ–è€…è¿™ä¸ªåŒºé—´é™„è¿‘</strong>ã€‚</p><p>å³ $ x_{i} = \frac{x_{i}}{s_{i}}$</p><h3 id="2-Mean-normalization"><a href="#2-Mean-normalization" class="headerlink" title="2. Mean normalization"></a>2. Mean normalization</h3><p>$ x_{i} = \frac{x_{i} - \mu_{i}}{s_{i}}$</p><p>å…¶ä¸­ï¼Œ$\mu_{i}$ æ˜¯ç‰¹å¾å€¼çš„æ‰€æœ‰å€¼çš„å¹³å‡å€¼ï¼Œ$s_{i}$ æ˜¯å€¼çš„èŒƒå›´ï¼ˆæœ€å¤§ - æœ€å°ï¼‰ï¼Œæˆ–è€… $s_{i}$ æ˜¯æ ‡å‡†åå·®</p><p>å½“ç„¶ $x_{0} = 1$ å°±ä¸éœ€è¦ç»è¿‡ä¸Šè¿°çš„å¤„ç†äº†ï¼Œå› ä¸ºå®ƒæ°¸è¿œç­‰äº1ï¼Œä¸èƒ½æœ‰å‡å€¼ç­‰äº0çš„æƒ…å†µã€‚</p><hr><h2 id="å››-Gradient-Descent-in-Practice-II-Learning-Rate"><a href="#å››-Gradient-Descent-in-Practice-II-Learning-Rate" class="headerlink" title="å››. Gradient Descent in Practice II - Learning Rate"></a>å››. Gradient Descent in Practice II - Learning Rate</h2><p>å¦‚æœå­¦ä¹ ç‡ $\alpha $ å¤ªå°çš„è¯ï¼Œå°±ä¼šå¯¼è‡´æ”¶æ•›é€Ÿåº¦è¿‡æ…¢çš„é—®é¢˜ã€‚<br>å¦‚æœå­¦ä¹ ç‡ $\alpha $ å¤ªå¤§çš„è¯ï¼Œä»£ä»·å‡½æ•°å¯èƒ½ä¸ä¼šåœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½ä¸‹é™ï¼Œç”šè‡³å¯èƒ½ä¸æ”¶æ•›ï¼Œåœ¨æŸç§æƒ…å†µä¸‹ï¼Œå­¦ä¹ ç‡ $\alpha $ è¿‡å¤§ï¼Œä¹Ÿæœ‰å¯èƒ½å‡ºç°æ”¶æ•›ç¼“æ…¢ã€‚</p><p>å¯ä»¥é€šè¿‡ç»˜åˆ¶ä»£ä»·å‡½æ•°éšè¿­ä»£æ­¥æ•°å˜åŒ–çš„æ›²çº¿å»è°ƒè¯•è¿™ä¸ªé—®é¢˜ã€‚</p><p>$\alpha $ çš„å–å€¼å¯ä»¥ä» 0.001ï¼Œ0.003ï¼Œ0.01ï¼Œ0.03ï¼Œ0.1ï¼Œ0.3ï¼Œ1 è¿™å‡ ä¸ªå€¼å»å°è¯•ï¼Œé€‰ä¸€ä¸ªæœ€ä¼˜çš„ã€‚</p><hr><h2 id="äº”-Features-and-Polynomial-Regression"><a href="#äº”-Features-and-Polynomial-Regression" class="headerlink" title="äº”. Features and Polynomial Regression"></a>äº”. Features and Polynomial Regression</h2><p>å¯ä»¥é€šè¿‡æ”¹é€ ç‰¹å¾å€¼ï¼Œä¾‹å¦‚åˆå¹¶2ä¸ªç‰¹å¾ï¼Œç”¨ $ x_{3}$ æ¥è¡¨ç¤º $ x_{1} * x_{2} $</p><p>åœ¨å¤šé¡¹å¼å›å½’ä¸­ï¼Œé’ˆå¯¹ $ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{1}^{2} + \theta_{3}x_{1}^{3} $ ï¼Œæˆ‘ä»¬å¯ä»¥ä»¤ $ x_{2} = x_{1}^{2} , x_{3} = x_{1}^{3} $ é™ä½æ¬¡æ•°ã€‚</p><p>è¿˜å¯ä»¥è€ƒè™‘ç”¨æ ¹å·çš„å¼å­ï¼Œä¾‹å¦‚é€‰ç”¨  $ h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}\sqrt{x} $</p><p>é€šè¿‡ä¸Šè¿°è½¬æ¢ä»¥åï¼Œéœ€è¦è®°å¾—ç”¨<strong>ç‰¹å¾å€¼ç¼©æ”¾ï¼Œå‡å€¼å½’ä¸€åŒ–ï¼Œè°ƒæ•´å­¦ä¹ é€Ÿç‡çš„æ–¹å¼è°ƒæ•´ä¸€ä¸‹</strong>ã€‚</p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p><a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Multivariate_Linear_Regression.ipynb" target="_blank" rel="noopener">Source</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.2_Linear_Regression_With_One_Variable(Gradient_Descent)</title>
      <link href="/2020/01/26/1-2-linear-regression-with-one-variable/"/>
      <url>/2020/01/26/1-2-linear-regression-with-one-variable/</url>
      
        <content type="html"><![CDATA[<h1 id="Linear-Regression-With-One-Variable-Gradient-Descent"><a href="#Linear-Regression-With-One-Variable-Gradient-Descent" class="headerlink" title="Linear Regression With One Variable(Gradient Descent)"></a>Linear Regression With One Variable(Gradient Descent)</h1><h2 id="ä¸€-Model-Representation"><a href="#ä¸€-Model-Representation" class="headerlink" title="ä¸€. Model Representation"></a>ä¸€. Model Representation</h2><p>åœ¨ç»™å®šè®­ç»ƒé›†çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ å‡½æ•°hï¼šXâ†’Yï¼Œä½¿å¾—hï¼ˆxï¼‰æ˜¯yçš„ç›¸åº”å€¼çš„â€œå¥½â€é¢„æµ‹å™¨ã€‚ç”±äºå†å²åŸå› ï¼Œè¿™ä¸ªå‡½æ•°hè¢«ç§°ä¸ºå‡è®¾ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_0_1.png" alt></p><p>é€šè¿‡è¾“å…¥ä½æˆ¿é¢ç§¯ xï¼Œé€šè¿‡å­¦ä¹ å¥½çš„å‡½æ•°ï¼Œè¾“å‡ºæˆ¿å­çš„ä¼°ä»·ã€‚</p><h2 id="äºŒ-Cost-Function"><a href="#äºŒ-Cost-Function" class="headerlink" title="äºŒ. Cost Function"></a>äºŒ. Cost Function</h2><p>ä»£ä»·å‡½æ•°æ˜¯çº¿æ€§å›å½’ä¸­çš„ä¸€ä¸ªåº”ç”¨ï¼Œåœ¨çº¿æ€§å›å½’ä¸­ï¼Œè¦è§£å†³çš„ä¸€ä¸ªé—®é¢˜å°±æ˜¯æœ€å°åŒ–é—®é¢˜ã€‚</p><p>å‡è®¾åœ¨ä¸€å…ƒçº¿æ€§å›å½’ä¸­ï¼Œåœ¨ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€æ¡ç›´çº¿èƒ½å’Œè¯¥è®­ç»ƒé›†ä¸­çš„ç‚¹æœ€æ¥è¿‘ã€‚å‡è®¾ç›´çº¿æ–¹ç¨‹ä¸º </p><p>$$h_{\theta}(x) = \theta_{0} + \theta_{1}x$$</p><p>å¦‚ä½•é€‰æ‹© $\theta_{0}$ã€$\theta_{1}$ï¼Œä½¿å¾— $h_{\theta}(x)$ æ›´æ¥è¿‘äºè®­ç»ƒé›† (x,y) ï¼Ÿ</p><p>ä¸Šè¿°é—®é¢˜å¯ä»¥è½¬æ¢ä¸ºæ±‚ $$ \rm{CostFunction} = \rm{F}({\theta_{0}},{\theta_{1}}) = \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2 $$  æ±‚æœ€å°å€¼$$\min_{{\theta_{0}} {\theta_{1}}} \rm{F}({\theta_{0},{\theta_{1}})} $$</p><h2 id="ä¸‰-Gradient-Descent-æ¢¯åº¦ä¸‹é™"><a href="#ä¸‰-Gradient-Descent-æ¢¯åº¦ä¸‹é™" class="headerlink" title="ä¸‰. Gradient Descent æ¢¯åº¦ä¸‹é™"></a>ä¸‰. Gradient Descent æ¢¯åº¦ä¸‹é™</h2><p>æ¢¯åº¦ä¸‹é™çš„ä¸»è¦æ€æƒ³ï¼š</p><ol><li><p>åˆå§‹åŒ–<br>$$<br>{\theta_{0}}å’Œ {\theta_{1}} , {\theta_{0}} = 0 , {\theta_{1}}=0<br>$$</p></li><li><p>ä¸æ–­çš„æ”¹å˜ ${\theta_{0}}$ å’Œ ${\theta_{1}}$ å€¼ï¼Œä¸æ–­å‡å°‘ $F({\theta_{0}},{\theta_{1}})$ ç›´è‡³è¾¾åˆ°æœ€å°å€¼ï¼ˆæˆ–è€…å±€éƒ¨æœ€å°ï¼‰ã€‚</p></li></ol><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_1_0.png" alt></p><p>æƒ³è±¡æˆä¸‹å±±ï¼Œå¦‚ä½•ä¸‹å±±çš„é€Ÿåº¦æœ€å¿«ï¼Ÿè¿™é‡Œæ¶‰åŠåˆ°äº†ä¸‹å±±çš„é€Ÿåº¦ï¼Œå³æ­¥é•¿ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_2_.png" alt></p><p>æœ‰è¶£çš„æ˜¯æ¢æ—è¾¹ä¸€ä¸ªç‚¹ï¼Œä¸‹å±±ï¼Œæ‰¾åˆ°çš„æœ€ä¼˜è§£å¯èƒ½å°±æ˜¯å¦ä¸€ä¸ªäº†ã€‚è¿™ä¹Ÿæ˜¯æ¢¯åº¦ä¸‹é™çš„ä¸€ä¸ªç‰¹ç‚¹ã€‚å®ƒä¼šæ‰¾åˆ°æ‰€æœ‰çš„å±€éƒ¨æœ€ä¼˜è§£å‡ºæ¥ã€‚</p><p>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œä¸æ–­æ›´æ–°ï¼š</p>\begin{align*}\rm{temp}0 &amp;:= {\theta_{0}} - \alpha * \frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) \\\rm{temp}1 &amp;:= {\theta_{1}} - \alpha * \frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) \\{\theta_{0}} &amp;:= \rm{temp}0 \\{\theta_{1}} &amp;:= \rm{temp}1 \\\end{align*}<p>ç›´åˆ°æ”¶æ•›ã€‚æ³¨æ„ ${\theta_{0}}$ å’Œ ${\theta_{1}}$ å€¼è¦<strong>åŒæ—¶æ›´æ–°</strong>ï¼Œ<strong>åˆ‡è®°ä¸è¦æ±‚ä¸€æ¬¡å¯¼æ›´æ–°ä¸€æ¬¡ï¼</strong></p><p>$\alpha$ è¢«ç§°ä½œä¸ºå­¦ä¹ é€Ÿç‡ã€‚</p><p><img src="https://img.halfrost.com/Blog/ArticleImage/68_3.gif" alt></p><p>å¦‚æœ $\alpha$ è¢«è®¾ç½®çš„å¾ˆå°ï¼Œéœ€è¦å¾ˆå¤šæ¬¡å¾ªç¯æ‰èƒ½åˆ°åº•æœ€ä½ç‚¹ã€‚<br>å¦‚æœ $\alpha$ è¢«è®¾ç½®çš„å¾ˆå¤§ï¼Œæ¥æ¥å›å›å¯èƒ½å°±ä¼šç¦»æœ€ä½ç‚¹è¶Šæ¥è¶Šè¿œï¼Œ<strong>ä¼šå¯¼è‡´æ— æ³•æ”¶æ•›ï¼Œç”šè‡³å‘æ•£</strong>ã€‚</p><p>å½“å¿«è¦åˆ°æœ€ä½ç‚¹çš„æ—¶å€™ï¼Œæ¢¯åº¦ä¸‹é™ä¼šè¶Šæ¥è¶Šæ…¢ï¼Œå› ä¸º $ \frac{\partial }{\partial {\theta}}$ è¶Šæ¥è¶Šå°ã€‚</p><h2 id="å…³äº-æ¢¯åº¦-å’Œ-åå¯¼æ•°-çš„å…³ç³»"><a href="#å…³äº-æ¢¯åº¦-å’Œ-åå¯¼æ•°-çš„å…³ç³»" class="headerlink" title="å…³äº æ¢¯åº¦ å’Œ åå¯¼æ•° çš„å…³ç³»"></a>å…³äº æ¢¯åº¦ å’Œ åå¯¼æ•° çš„å…³ç³»</h2><p>åœ¨ä¸Šé¢æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬ä¸€ç›´ç”¨çš„æ˜¯åå¯¼æ•°è¿›è¡Œè®¨è®ºçš„ï¼Œå¯èƒ½ä¼šæœ‰äººæœ‰ç–‘é—®ï¼Œåå¯¼æ•°å’Œæ¢¯åº¦æœ‰å•¥å…³ç³»ï¼Ÿ</p><h3 id="1-å¯¼æ•°"><a href="#1-å¯¼æ•°" class="headerlink" title="1. å¯¼æ•°"></a>1. å¯¼æ•°</h3><p>å¦‚æœæ˜¯ä¸€å…ƒçš„ï¼Œé‚£ä¹ˆåå¯¼æ•°å°±é™çº§æˆäº†æ±‚å¯¼æ•°</p>$$ f^{'}(x_{0}) = \lim_{\Delta x\rightarrow 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta x\rightarrow 0} \frac{f(x_{0} + \Delta x) - f(x_{0})}{\Delta x} $$<p>å¯¼æ•°çš„å‡ ä½•æ„ä¹‰æ˜¯åˆ‡çº¿åœ¨è¯¥ç‚¹çš„æ–œç‡ï¼Œç‰©ç†æ„ä¹‰æ˜¯å‡½æ•°åœ¨è¿™ä¸€ç‚¹çš„ (ç¬æ—¶) å˜åŒ–ç‡ã€‚</p><h3 id="2-åå¯¼æ•°"><a href="#2-åå¯¼æ•°" class="headerlink" title="2. åå¯¼æ•°"></a>2. åå¯¼æ•°</h3><p>åœ¨æ¥çœ‹çœ‹åå¯¼æ•°çš„å®šä¹‰ï¼š</p>$$\begin{align*}f_{x}(x_{0},y_{0}) &amp; = \lim_{\Delta x \rightarrow 0} \frac{f(x_{0} + \Delta x , y_{0}) - f(x_{0},y_{0})}{\Delta x} \\ f_{y}(x_{0},y_{0}) &amp; = \lim_{\Delta y \rightarrow 0} \frac{f(x_{0} , y_{0} + \Delta y) - f(x_{0},y_{0})}{\Delta y} \\\end{align*}$$<p><img src="https://img.halfrost.com/Blog/ArticleImage/68_4.png" alt></p><p>åå¯¼æ•°çš„å‡ ä½•æ„ä¹‰ä¹Ÿæ˜¯åˆ‡çº¿çš„æ–œç‡ï¼Œä¸è¿‡ç”±äºåœ¨æ›²é¢ä¸Šï¼Œåœ¨ä¸€ä¸ªç‚¹ä¸Šä¸è¯¥æ›²é¢æ›²çº¿ç›¸åˆ‡çš„æ˜¯ä¸€ä¸ªé¢ï¼Œå°±æ„å‘³ç€åˆ‡çº¿æœ‰æ— æ•°æ¡ã€‚è¿™é‡Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯2æ¡åˆ‡çº¿ï¼Œä¸€ä¸ªæ¡æ˜¯å‚ç›´äº y è½´ï¼ˆå¹³è¡Œäº xOz å¹³é¢ï¼‰çš„åˆ‡çº¿ï¼Œå¦å¤–ä¸€æ¡æ˜¯å‚ç›´äº x è½´ï¼ˆå¹³è¡Œäº yOz å¹³é¢ï¼‰çš„åˆ‡çº¿ã€‚è¿™ä¸¤æ¡åˆ‡çº¿å¯¹åº”çš„æ–œç‡å°±æ˜¯å¯¹ X æ±‚åå¯¼å’Œå¯¹ Y æ±‚åå¯¼ã€‚</p><p>ä¸€ä¸ªå¤šå˜é‡å‡½æ•°çš„åå¯¼æ•°æ˜¯å®ƒå…³äºå…¶ä¸­ä¸€ä¸ªå˜é‡çš„å¯¼æ•°ï¼Œè€Œä¿æŒå…¶ä»–å˜é‡æ’å®šï¼ˆç›¸å¯¹äºå…¨å¯¼æ•°ï¼Œåœ¨å…¶ä¸­æ‰€æœ‰å˜é‡éƒ½å…è®¸å˜åŒ–ï¼‰ã€‚</p><p>åå¯¼æ•°çš„ç‰©ç†æ„ä¹‰è¡¨ç¤ºå‡½æ•°æ²¿ç€åæ ‡è½´æ­£æ–¹å‘ä¸Šçš„å˜åŒ–ç‡ã€‚</p><h3 id="3-æ–¹å‘å¯¼æ•°"><a href="#3-æ–¹å‘å¯¼æ•°" class="headerlink" title="3. æ–¹å‘å¯¼æ•°"></a>3. æ–¹å‘å¯¼æ•°</h3><p>åœ¨è¯´æ¢¯åº¦ä¹‹å‰ï¼Œä¸åº”è¯¥æ¼æ‰æ–¹å‘å¯¼æ•°ã€‚åå¯¼æ•°æ˜¯æ±‚çš„åœ¨ç‰¹å®šçš„2ä¸ªæ–¹å‘ä¸Šçš„å¯¼æ•°ï¼Œä½†æ˜¯ä»»æ„ä¸€ä¸ªæ–¹å‘ä¸Šä¹Ÿæ˜¯å­˜åœ¨å¯¼æ•°çš„ã€‚è¿™é‡Œå°±å¼•å…¥äº†æ–¹å‘å¯¼æ•°çš„æ¦‚å¿µã€‚</p><blockquote><p>è®¾å‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ çš„æŸç©ºé—´ä¸´åŸŸ $ U \subset R^{2}$ å†…æœ‰å®šä¹‰ï¼Œ L ä¸ºä»ç‚¹ $p_{0}$ å‡ºå‘çš„å°„çº¿ï¼Œ$p(x_{0},y_{0})$ ä¸º L ä¸Šä¸”åœ¨ U å†…çš„ä»»ä¸€ç‚¹ï¼Œä»¥ $t = \sqrt{(\Delta x)^{2} +(\Delta y)^{2} }$ è¡¨ç¤º $p$ ä¸ $p_{0}$ ä¹‹é—´çš„è·ç¦»ï¼Œè‹¥æé™ ï¼š</p></blockquote><blockquote>$$ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} = \lim_{t \rightarrow 0^{+}} \frac{f(x_{0} + tcos \alpha , y_{0}  +   tcos \beta) - f(x_{0},y_{0})}{t}$$<p>å­˜åœ¨ï¼Œåˆ™ç§°æ­¤æé™ä¸ºå‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}$ æ²¿æ–¹å‘ L çš„æ–¹å‘å¯¼æ•°ï¼Œè®°ä½œ $ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}$ ã€‚</p></blockquote><p>æ–¹å‘å¯¼æ•°æ˜¯åå¯¼æ•°çš„æ¦‚å¿µçš„æ¨å¹¿, åå¯¼æ•°ç ”ç©¶çš„æ˜¯æŒ‡å®šæ–¹å‘ (åæ ‡è½´æ–¹å‘) çš„å˜åŒ–ç‡ï¼Œåˆ°äº†æ–¹å‘å¯¼æ•°ï¼ŒæŒ‡å®šçš„æ–¹å‘å¯ä»¥æ˜¯ä»»æ„æ–¹å‘äº†ã€‚</p><blockquote><p>å¦‚æœå‡½æ•° u = u(x,y) åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ å¯å¾®åˆ†ï¼Œé‚£ä¹ˆå‡½æ•°åœ¨è¯¥ç‚¹æ²¿ä»»ä¸€æ–¹å‘ L çš„æ–¹å‘å¯¼æ•°å­˜åœ¨ï¼Œä¸”æœ‰</p></blockquote><blockquote>$$ \left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} = f_{x}(x_{0},y_{0})cos \alpha + f_{y}(x_{0},y_{0})cos \beta$$</blockquote><blockquote><p>å…¶ä¸­ï¼Œ $cos \alpha  $ ï¼Œ$cos \beta$ æ˜¯æ–¹å‘ L çš„æ–¹å‘ä½™å¼¦ã€‚</p></blockquote><p>ä¸€ä¸ªæ ‡é‡åœºåœ¨æŸç‚¹æ²¿ç€æŸä¸ªå‘é‡æ–¹å‘ä¸Šçš„æ–¹å‘å¯¼æ•°ï¼Œæç»˜äº†è¯¥ç‚¹é™„è¿‘æ ‡é‡åœºæ²¿ç€è¯¥å‘é‡æ–¹å‘å˜åŠ¨æ—¶çš„ç¬æ—¶å˜åŒ–ç‡ã€‚è¿™ä¸ªå‘é‡æ–¹å‘å¯ä»¥æ˜¯ä»»ä¸€æ–¹å‘ã€‚</p><p>æ–¹å‘å¯¼æ•°çš„ç‰©ç†æ„ä¹‰è¡¨ç¤ºå‡½æ•°åœ¨æŸç‚¹æ²¿ç€æŸä¸€ç‰¹å®šæ–¹å‘ä¸Šçš„å˜åŒ–ç‡ã€‚</p><h3 id="4-æ¢¯åº¦"><a href="#4-æ¢¯åº¦" class="headerlink" title="4. æ¢¯åº¦"></a>4. æ¢¯åº¦</h3><p>æœ€åæ¥è®²è®²æ¢¯åº¦ï¼Œæ¢¯åº¦çš„å®šä¹‰ï¼š</p><blockquote><p>åœ¨äºŒå…ƒå‡½æ•°çš„æƒ…å½¢ï¼Œè®¾å‡½æ•° $f(x,y)$ åœ¨å¹³é¢åŒºåŸŸ D å†…å…·æœ‰ä¸€é˜¶è¿ç»­åå¯¼æ•°ï¼Œåˆ™å¯¹äºæ¯ä¸€ç‚¹ $P_{0}(x_{0},y_{0}) \in D $,éƒ½å¯å®šå‡ºä¸€ä¸ªå‘é‡ï¼š</p></blockquote><blockquote>$$ f_{x}(x_{0},y_{0}) \vec{i} + f_{y}(x_{0},y_{0}) \vec{j} $$</blockquote><blockquote><p>è¿™ä¸ªå‘é‡ç§°ä¸ºå‡½æ•° $f(x,y)$ åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ çš„æ¢¯åº¦ï¼Œè®°ä½œ $ \textbf{grad}\;\;f(x_{0},y_{0}) $ æˆ– $ \triangledown f(x_{0},y_{0}) $ , å³</p></blockquote><blockquote>$$ \textbf{grad}\;\;f(x_{0},y_{0}) = \triangledown f(x_{0},y_{0}) = f_{x}(x_{0},y_{0}) \vec{i} + f_{y}(x_{0},y_{0}) \vec{j} $$</blockquote><blockquote><p>å…¶ä¸­ $ \triangledown = \frac{\partial }{\partial x} \vec{i} + \frac{\partial }{\partial y} \vec{j} $ ç§°ä¸º (äºŒç»´çš„) å‘é‡å¾®åˆ†ç®—å­ æˆ–è€… Nabla ç®—å­ï¼Œ $ \triangledown f = \frac{\partial f}{\partial x} \;\; \vec{i} + \frac{\partial f }{\partial y} \;\; \vec{j} $</p></blockquote><p>å¦‚æœå‡½æ•° $f(x,y)$ åœ¨ç‚¹ $p_{0}(x_{0},y_{0})$ å¯å¾®åˆ†ï¼Œ $\vec{e_{j}} = (cos \alpha,cos \beta)$ æ˜¯ä¸æ–¹å‘ L åŒå‘çš„å•ä½å‘é‡ï¼Œåˆ™ï¼š</p>$$\begin{align*}\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})} &amp;= f_{x}(x_{0},y_{0})cos \alpha + f_{y}(x_{0},y_{0})cos \beta \\&amp;= \textbf{grad}\;\;f(x_{0},y_{0}) \cdot \vec{e_{j}} = \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right | cos \theta \\\end{align*}$$<p>å…¶ä¸­ $ \theta $ ä¸º $ \textbf{grad};;f(x_{0},y_{0}) $ ä¸ $ \vec{e_{j}} $ çš„å¤¹è§’ã€‚</p><ol><li>å½“ $\theta = 0 $ çš„æ—¶å€™ï¼Œ$\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}  = \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right |$</li></ol><p>å³ <strong>å‡½æ•° $f(x,y)$ åœ¨ä¸€ç‚¹çš„æ¢¯åº¦ $ \textbf{grad};;f $ æ˜¯è¿™æ ·çš„ä¸€ä¸ªå‘é‡ï¼Œå®ƒçš„æ–¹å‘æ˜¯å‡½æ•°åœ¨è¿™ç‚¹çš„æ–¹å‘å¯¼æ•°å–å¾—æœ€å¤§å€¼çš„æ–¹å‘ï¼Œå®ƒçš„æ¨¡å°±ç­‰äºæ–¹å‘å¯¼æ•°çš„æœ€å¤§å€¼</strong> ã€‚</p><ol start="2"><li>å½“ $\theta = \pi $ çš„æ—¶å€™ï¼Œ$\left.\begin{matrix}\frac{\partial f}{\partial l}\end{matrix}\right|_{(x_{0},y_{0})}  = - \left | \textbf{grad}\;\;f(x_{0},y_{0}) \right |$</li></ol><p>å³ $ \vec{e_{j}} $ ä¸ æ¢¯åº¦ æ–¹å‘ç›¸åçš„æ—¶å€™ï¼Œå‡½æ•°å‡å°‘æœ€å¿«ï¼Œåœ¨è¿™ä¸ªæ–¹å‘çš„æ–¹å‘å¯¼æ•°è¾¾åˆ°æœ€å°å€¼ã€‚</p><p><strong>æ‰€ä»¥æ¢¯åº¦ä¸‹é™å°±æ˜¯åŸºäºè¿™ä¸ªåŸç†</strong>ã€‚</p><p>å‡½æ•°åœ¨æŸä¸€ç‚¹å¤„çš„æ–¹å‘å¯¼æ•°åœ¨å…¶æ¢¯åº¦æ–¹å‘ä¸Šè¾¾åˆ°æœ€å¤§å€¼ï¼Œæ­¤æœ€å¤§å€¼å³æ¢¯åº¦çš„æ¨¡æ•°ã€‚</p><p>è¿™å°±æ˜¯è¯´ï¼Œæ²¿æ¢¯åº¦æ–¹å‘ï¼Œå‡½æ•°å€¼å¢åŠ æœ€å¿«ã€‚åŒæ ·å¯çŸ¥ï¼Œæ–¹å‘å¯¼æ•°çš„æœ€å°å€¼åœ¨æ¢¯åº¦çš„ç›¸åæ–¹å‘å–å¾—ï¼Œæ­¤æœ€å°å€¼ä¸ºæœ€å¤§å€¼çš„ç›¸åæ•°ï¼Œä»è€Œæ²¿æ¢¯åº¦ç›¸åæ–¹å‘å‡½æ•°å€¼çš„å‡å°‘æœ€å¿«ã€‚</p><table><thead><tr><th>æ¦‚å¿µ</th><th>ç‰©ç†æ„ä¹‰</th></tr></thead><tbody><tr><td>å¯¼æ•°   $ f^{â€˜}(x)  $</td><td>å‡½æ•°åœ¨è¯¥ç‚¹çš„ç¬æ—¶å˜åŒ–ç‡</td></tr><tr><td>åå¯¼æ•° $ \frac{\partial f(x,y) }{\partial x}  $</td><td>å‡½æ•°åœ¨åæ ‡è½´æ–¹å‘ä¸Šçš„å˜åŒ–ç‡</td></tr><tr><td>æ–¹å‘å¯¼æ•°</td><td>å‡½æ•°åœ¨æŸç‚¹æ²¿æŸä¸ªç‰¹å®šæ–¹å‘çš„å˜åŒ–ç‡</td></tr><tr><td>æ¢¯åº¦  $ \textbf{grad};;f(x,y)  $</td><td>å‡½æ•°åœ¨è¯¥ç‚¹æ²¿æ‰€æœ‰æ–¹å‘å˜åŒ–ç‡æœ€å¤§çš„é‚£ä¸ªæ–¹å‘</td></tr></tbody></table><h2 id="å››-Linear-Regression-çº¿æ€§å›å½’"><a href="#å››-Linear-Regression-çº¿æ€§å›å½’" class="headerlink" title="å››. Linear Regression çº¿æ€§å›å½’"></a>å››. Linear Regression çº¿æ€§å›å½’</h2><p>æ¢¯åº¦ä¸‹é™æ˜¯å¾ˆå¸¸ç”¨çš„ç®—æ³•ï¼Œå®ƒä¸ä»…è¢«ç”¨åœ¨çº¿æ€§å›å½’ï¼Œè¿˜ç”¨åœ¨çº¿æ€§å›å½’æ¨¡å‹ã€å¹³æ–¹è¯¯å·®ä»£ä»·å‡½æ•°ä¸­ã€‚</p>\begin{align*}\frac{\partial }{\partial {\theta_{j}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp; = \frac{\partial }{\partial {\theta_{j}}} \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\\end{align*}<p>ä»¤ $ z = (h_{\theta}(x^{(i)})-y^{(i)})^2$ , $ u = h_{\theta}(x^{(i)})-y^{(i)}$ , åˆ™ $ z = u^2 $ã€‚ è€ƒè™‘åˆ° $f(z)$  å’Œ $f(u)$ éƒ½æ˜¯è¿ç»­çš„ï¼Œåˆ™æœ‰ï¼š</p>\begin{align*}\frac{\partial }{\partial {\theta_{j}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp; = \frac{\partial }{\partial {\theta_{j}}} \frac{1}{2m}\sum_{i = 1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})^2\\&amp; = \frac{1}{2m}\sum_{i = 1}^{m} \frac{\partial z }{\partial u} \frac{\partial u }{\partial {\theta_{j}}} = \frac{1}{2m} * 2 \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{j}}}\\&amp; = \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{j}}} \\\end{align*}<p>++++++++++++</p><p>å°† u å±•å¼€ $ u = \theta_{0} + {\theta_{1}}x^{(i)}-y^{(i)}$ , ä»¤ j = 0,åˆ™æœ‰</p>\begin{align*}\frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp;= \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{0}}} \\&amp;= \frac{1}{m} \sum_{i = 1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)}) = \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) \\\end{align*}<p>ä»¤ j = 1,åˆ™æœ‰</p>\begin{align*}\frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) &amp;=  \frac{1}{m} \sum_{i = 1}^{m} u \frac{\partial u }{\partial {\theta_{1}}}\\&amp;= \frac{1}{m} \sum_{i = 1}^{m}(\theta_{0} + \theta_{1}x^{(i)} - y^{(i)}) * x^{(i)} = \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\\end{align*}<p>æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼š</p> \begin{align*}\rm{temp}0 &amp;:= {\theta_{0}} - \alpha * \frac{\partial }{\partial {\theta_{0}}}\rm{F}({\theta_{0}},{\theta_{1}}) = {\theta_{0}} - \alpha * \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})  \\\rm{temp}1 &amp;:= {\theta_{1}} - \alpha * \frac{\partial }{\partial {\theta_{1}}}\rm{F}({\theta_{0}},{\theta_{1}}) = {\theta_{1}} - \alpha * \frac{1}{m} \sum_{i = 1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)}) * x^{(i)} \\{\theta_{0}} &amp;:= \rm{temp}0  \\{\theta_{1}} &amp;:= \rm{temp}1  \\\end{align*}<p>å½“ç„¶é™¤äº†ç”¨æ¢¯åº¦ä¸‹é™çš„è¿­ä»£ç®—æ³•ï¼Œè¿˜æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥ç®—å‡ºä»£ä»·å‡½æ•°çš„æœ€å°å€¼ï¼Œæ¯”å¦‚çº¿æ€§ä»£æ•°é‡Œé¢çš„ æ­£è§„æ–¹ç¨‹ç»„æ³•ã€‚ä½†æ˜¯ä¸¤è€…ç›¸æ¯”è¾ƒè€Œè¨€ï¼Œæ¢¯åº¦ä¸‹é™é€‚åˆæ›´å¤§çš„æ•°æ®é›†ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ä¸æ–­æ›´æ–°ä»¥åï¼Œçº¿æ€§å›å½’ä»¥åçš„æ›²çº¿å’ŒåŸå§‹æ•°æ®é›†ä¼šè¶Šæ¥è¶Šæ‹Ÿåˆã€‚</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npx_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.91</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.23</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.923</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.941</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.543</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.744</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.674</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">5.33</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.31</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.68</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.99</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.54</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.89</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.86</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.63</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.6453</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.75</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.345</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.5754</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.35654</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.43646</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.6443</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.64534</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.7457</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.6464</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.74643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.42</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.1243</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.088</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.342</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.22</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.44</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.33</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.91</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">4.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.23</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.923</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.941</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.02</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">6.34</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.543</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.546</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">8.744</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.674</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">5.33</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.31</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.78</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.01</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.68</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    <span class="token punctuation">[</span><span class="token number">9.99</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3.54</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6.89</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">10.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inlineplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token string">'bo'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'real'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_data<span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'estimated'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>&lt;matplotlib.legend.Legend at 0x7fa6805ab128&gt;</code></pre><p><img src="/2020/01/26/1-2-linear-regression-with-one-variable/output_7_1.png" alt="output"></p><hr><blockquote><p>GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p><p>Follow: <a href="https://github.com/halfrost" target="_blank" rel="noopener">halfrost Â· GitHub</a></p><p>Source: <a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb" target="_blank" rel="noopener">https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Gradient_descent.ipynb</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.1_What_is_Machine_Learning</title>
      <link href="/2020/01/19/1-1-what-is-machine-learning/"/>
      <url>/2020/01/19/1-1-what-is-machine-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="What-is-Machine-Learning"><a href="#What-is-Machine-Learning" class="headerlink" title="What is Machine Learning"></a>What is Machine Learning</h1><p><img src="/2020/01/19/1-1-what-is-machine-learning/machine-learning.png" alt="Machine_Learning"></p><h2 id="ä¸€ã€-Definition"><a href="#ä¸€ã€-Definition" class="headerlink" title="ä¸€ã€ Definition"></a>ä¸€ã€ Definition</h2><p>å®šä¹‰ï¼š</p><p>1997å¹´ï¼Œ<code>Tom Mitchell</code> ç»™å‡ºæœºå™¨å­¦ä¹ çš„å®šä¹‰ï¼š</p><pre><code>ç¨‹åºåˆ©ç”¨ç»éªŒEæ”¹å–„äº†åœ¨ä»»åŠ¡Tä¸­çš„æ€§èƒ½Pï¼Œå°±å¯ä»¥è¯´ï¼šå…³äºä»»åŠ¡Tå’Œæµ‹é‡æ€§èƒ½Pï¼Œè¯¥ç¨‹åºå¯¹ç»éªŒEè¿›è¡Œäº†å­¦ä¹ ã€‚</code></pre><h2 id="äºŒã€-Classify"><a href="#äºŒã€-Classify" class="headerlink" title="äºŒã€ Classify"></a>äºŒã€ Classify</h2><p>åˆ†ç±»ï¼š</p><ul><li>æœ‰ç›‘ç£å­¦ä¹ <code>supervised learning</code> :å·²çŸ¥çš„Data Setä¸­æ˜ç¡®äº†è¾“å…¥/è¾“å‡ºï¼Œä¸”è¾“å…¥å’Œè¾“å‡ºå­˜åœ¨å…³ç³»ã€‚ <ul><li><code>Supervised Learning</code>å¯ä»¥åˆ†ä¸ºï¼šåˆ†ç±»(Classification)å’Œå›å½’(Regression)é—®é¢˜ã€‚</li><li><ol><li>Classificationï¼š é¢„æµ‹ç¦»æ•£çš„ç»“æœã€‚å°†è¾“å…¥æ˜ å°„åˆ°ç¦»æ•£çš„ç±»åˆ«ä¸­ã€‚</li></ol></li><li><ol start="2"><li>Regressionï¼š é¢„æµ‹è¿ç»­è¾“å‡ºä¸­çš„ç»“æœã€‚ ä»è¾“å…¥æ˜ å°„åˆ°æŸä¸ªè¿ç»­çš„å‡½æ•°çš„è¾“å‡ºä¸­ã€‚</li></ol></li></ul></li></ul><blockquote><p>æ— ç›‘ç£å­¦ä¹ ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¾ˆå°‘æˆ–æ ¹æœ¬ä¸çŸ¥é“æˆ‘ä»¬çš„ç»“æœåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚<strong>æˆ‘ä»¬å¯ä»¥ä»æ•°æ®ä¸­å¾—å‡ºç»“æ„</strong>ï¼Œæˆ‘ä»¬ä¸ä¸€å®šçŸ¥é“å˜é‡çš„å½±å“ã€‚ æˆ‘ä»¬å¯ä»¥é€šè¿‡åŸºäºæ•°æ®ä¸­å˜é‡ä¹‹é—´çš„å…³ç³»å¯¹æ•°æ®è¿›è¡Œèšç±»æ¥æ¨å¯¼å‡ºè¿™ç§ç»“æ„ã€‚ åœ¨æ— ç›‘ç£å­¦ä¹ çš„æƒ…å†µä¸‹ï¼Œ<strong>æ²¡æœ‰åŸºäºé¢„æµ‹ç»“æœçš„åé¦ˆ</strong>ã€‚æ— ç›‘ç£å­¦ä¹ å¯ä»¥åˆ†ä¸ºâ€œèšç±»â€å’Œâ€œéèšç±»â€ã€‚</p></blockquote><ul><li>æ— ç›‘ç£å­¦ä¹ <code>unsupervised learning</code> : æ²¡æœ‰é¢„çŸ¥çš„labelï¼Œä»å˜é‡çš„ç»“æ„ä¸­å¯»æ‰¾å…³ç³»ï¼Œè€Œæ²¡æœ‰åŸºäºé¢„æµ‹ç»“æœçš„åé¦ˆã€‚<ul><li><code>Unspervised Learning</code>å¯ä»¥åˆ†ä¸º<code>èšç±»</code>ï¼Œ å’Œ <code>éèšç±»</code>ã€‚</li><li><ol><li>èšç±»ï¼š å¯ä»¥ç†è§£ä¸ºå¯¹æ•°æ®è‡ªåŠ¨åˆ†ç»„æˆä¸åŒå˜é‡çš„ç›¸ä¼¼æˆ–è€…ç›¸å…³çš„ç°‡ã€‚</li></ol></li><li><ol start="2"><li>éèšç±»ï¼š æ¯”å¦‚â€œé¸¡å°¾é…’ä¼šç®—æ³•â€â€“&gt;ä»æ··ä¹±çš„ç¯å¢ƒä¸­è¯†åˆ«å’ŒæŸ¥æ‰¾ç»“æœã€‚</li></ol></li></ul></li></ul><blockquote><p>å‚è€ƒï¼š GitHub Repoï¼š<a href="https://github.com/halfrost/Halfrost-Field" target="_blank" rel="noopener">Halfrost-Field</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> å´æ©è¾¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19å¹´å²æœ«</title>
      <link href="/2019/12/31/19-nian-sui-mo/"/>
      <url>/2019/12/31/19-nian-sui-mo/</url>
      
        <content type="html"><![CDATA[<h1 id="æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–"><a href="#æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–" class="headerlink" title="æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–"></a>æŒ¥åˆ«2019ï¼Œè¿æ¥å˜åŒ–</h1><p>2020æ˜¯ä¸ªå¾ˆæœ‰æ„æ€çš„å¹´ä»½ï¼ŒABABçš„å½¢å¼æœ—æœ—ä¸Šå£ï¼Œå¦‚æœè¦è¿™æ ·ä¸¥æ ¼çš„ç®—çš„è¯ï¼Œä¸Šä¸€ä¸ªè¿™æ ·çš„å¹´ä»½æ˜¯1919å¹´ï¼Œç›¸éš”101å¹´äº†å·²ç»ï¼Œä¸‹ä¸€æ¬¡è¦åˆ°2121ï¼Œåˆæ˜¯101å¹´ä»¥åï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬ä¸€ç”Ÿä¸­ï¼Œåªä¼šç»å†è¿™æ ·ä¸€æ¬¡çš„ABABå¹´ä»½ï¼Œå®åœ¨æ˜¯å€¼å¾—ç”¨åŠ›å»è®°å¿†å’Œæ„Ÿå—ã€‚</p><h2 id="2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ"><a href="#2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ" class="headerlink" title="2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ"></a>2019ï¼Œæˆ‘å¾—åˆ°äº†ä»€ä¹ˆï¼Ÿ</h2><blockquote><p>Sometimes it lasts in love, sometimes it hurt instead.</p></blockquote><p>ä¸€ä¸ªå¹¶ä¸æ“…é•¿çš„æŠ€èƒ½ï¼Œä¸€æ®µè¯´ä¸æ¸…é“ä¸æ˜çš„å…³ç³»ï¼Œä¸€ä¸ªä¸å¥½ä¸åçš„å·¥ä½œæœºä¼šã€‚è¿˜æœ‰ä¸€ä¸ªä¸çŸ¥é“æ˜¯åœ¨æˆé•¿è¿˜æ˜¯åœ¨å˜è€çš„è‡ªå·±ã€‚</p><h3 id="æŠ€èƒ½"><a href="#æŠ€èƒ½" class="headerlink" title="æŠ€èƒ½"></a>æŠ€èƒ½</h3><blockquote><p>å…³äºé¡¹ç›®</p></blockquote><p>åœ¨å¤æ—¦çš„ä¸€å¹´åŠï¼Œè¯´æ˜¯å­¦ä¹ NLPï¼Œå…¶å®åˆ°äº†æœ€åä¹Ÿåªæ˜¯ä¸€ç›´åœ¨çš®æ¯›çš„å±‚é¢æ™ƒæ‚ ï¼Œæ€»æ˜¯æ— æ³•æ·±å…¥ã€‚</p><p>å…¶å®è‡ªå·±ä¹Ÿæ¸…æ¥šè‡ªå·±çš„åŸå› åœ¨å“ªè¾¹ï¼Œå¾ˆéš¾ä¸“æ³¨ä¸€ä¸ªæ–¹å‘ï¼Œå„ç§éƒ½åœ¨å¥½å¥‡ï¼Œç»“æœå°±æ˜¯çœ‹ä¸¤ç¯‡è®ºæ–‡å°±ç®—äº†ï¼Œå…¶å®è¿‡ä¸¤å¤©ä¹Ÿå°±å¿˜äº†ã€‚NLPæˆ–è€…è¯´æ˜¯æ·±åº¦å­¦ä¹ ï¼Œæ–¹å‘åƒå¥‡ç™¾æ€ªï¼Œå…¶å®å‰æœŸæ‰¾å‡†ä¸€ä¸ªæœ‰å·¥ä¸šåº”ç”¨å‰æ™¯çš„æ–¹å‘ï¼Œæ¯”å¦‚å¯¹è¯ç³»ç»Ÿï¼Œæ‘˜è¦ï¼Œè¿™ç§ï¼Œæ²¿ç€ä¸€ç¯‡ç»¼è¿°ç‹¬ç«‹å¼€å±•ç ”ç©¶ï¼Œä»£ç å’Œè®ºæ–‡åŒæ—¶å¼€å§‹ï¼Œå†çœ‹äº›ç›¸å…³çš„æ¯”èµ›å¼€æºçš„ä»£ç ï¼Œåº”è¯¥åŠå¹´å°±èƒ½å…¥é—¨ã€‚è¿™ä¸ªäº‹æƒ…åªèƒ½è¯´æ˜è‡ªå·±æµ®èºï¼Œæµ®èºæ˜¯ç§‘ç ”çš„å¤§å¿Œï¼Œæ‰€ä»¥æˆ‘ä¸é€‚åˆè¯»åšäº†ï¼Œè‡³å°‘ç›®å‰çœ‹æ¥æ˜¯è¿™æ ·çš„ã€‚</p><p>å•Šæˆ‘çœŸæ˜¯ä¸ªæ†¨æ†¨ã€‚</p><p>æœ€æ°”çš„æ˜¯æœ€åTensorflowå’ŒPyTorchå±…ç„¶ä¸€ä¸ªéƒ½ä¸ç†Ÿâ€¦æˆ‘è¿™æ¸£æ¸£å·¥ç¨‹èƒ½åŠ›æ€»æ˜¯ä¼šç»™æˆ‘å·¨å¤§çš„æ‰“å‡»â€¦</p><blockquote><p>å…³äºå®éªŒå®¤</p></blockquote><p>2018å¹´5æœˆä»½å¼€å§‹åœ¨ç‹è€å¸ˆçš„EDAå®éªŒå®¤å‘†äº†ä¸€ä¸ªå¤šæœˆï¼Œè®¤è¯†äº†å¸ˆå…„åˆ˜æ·‡ï¼Œå’Œé’Ÿç¨‹åŒå­¦ä¸€èµ·æC++ç¼–è¯‘å™¨ï¼Œç»“æœæˆ‘æ€»æ˜¯éš¾ä»¥å…¥é—¨ï¼Œé‚£æ—¶å€™æˆ‘å¤§æ¦‚è¿æ€ä¹ˆæŸ¥èµ„æ–™éƒ½ä¸ä¼šã€‚è€Œä¸”è«åå…¶å¦™çš„å«‰å¦’é’Ÿç¨‹ï¼Œè¶Šæ¥è¶Šéš¾å—ï¼Œæ‰€ä»¥æœ€åè¿˜æ˜¯ç¦»å¼€äº†ã€‚</p><p>å½“æ—¶çš„å¥‘æœºæ˜¯å¬åˆ˜æ¶›è®²ç®—æ³•ä¼šæ›´æœ‰â€é’±é€”â€œï¼Œå°±å¿ƒåŠ¨æ¥äº†IBICASï¼Œå½“æ—¶å®éªŒå®¤è¿˜å«åšBCRCï¼Œäº‹å®è¯æ˜ï¼Œä¸ç®¡å“ªä¸€ä¸ªæ–¹å‘ï¼Œåªè¦å­¦å¾—å¥½å°±ç‰›é€¼ï¼ŒåŒä¸ºITåŸºæœ¬ä¸å­˜åœ¨å“ªä¸ªæ–¹å‘æ˜æ˜¾æ›´æœ‰â€˜â€™é’±é€”â€œï¼ŒæŠ„è¿‘è·¯çš„æ–¹å¼æ˜¯ä¸å¯å–çš„â€¦æœ€åæˆ‘çš„offerä¸å¦‚ä¸€ç›´åšICçš„åŒå­¦ï¼Œå¾ˆå¤§çš„æ•™è®­ï¼Œä»”ç»†æƒ³åšä»€ä¹ˆäº‹æƒ…éƒ½æ˜¯è¿™ä¸ªé“ç†å§â€¦<strong>è¦æ€€ç€åšåˆ°æœ€å¥½çš„å¿ƒæ€å»åšäº‹æƒ…</strong></p><p>æœ€æœ‰æ„æ€çš„æ˜¯æœ€åçš„offerå±…ç„¶è¿˜æ˜¯C++å¼€å‘ï¼Œæœç„¶æ˜¯æœ‰ä¸€ç§å¾ªç¯ã€‚</p><blockquote><p>å…³äºè¯¾ç¨‹</p></blockquote><p>å¤æ—¦å·¥ç¡•çš„è¯¾ç¨‹æœ¬æ¥è®¾ç½®çš„å°±å¾ˆå¤šï¼Œå„ç§è¯¾ç¨‹å„ç§å­¦åˆ†ï¼Œè®©äººå¤´å¤§â€¦</p><p>ç ”ä¸€çš„æ—¶å€™æˆ‘æ€»æ˜¯å¿ƒå¤§ï¼Œæƒ³ç€å°½å¿«ä¿®å®Œå­¦åˆ†å»å®ä¹ ï¼Œæ‰€ä»¥ç¬¬ä¸€å­¦æœŸé€‰è¯¾12é—¨ï¼ŒçœŸçš„ä½œæ­»ï¼Œè€Œä¸”ç´¯æ˜¯æ¬¡è¦ï¼Œå› ä¸ºåªæ˜¯ä¸ºäº†æ—¶é—´ä¸å†²çªé€‰äº†å¾ˆå¤šä¸ä¼šç”¨åˆ°çš„è¯¾ç¨‹ï¼Œæ¯”å¦‚MEMSï¼Œè´¼æ°”çš„ä¸€é—¨ï¼Œæœ€åç»©ç‚¹ä¹Ÿç›¸åº”çš„å¾ˆä½ã€‚</p><p>æ¯•ç«Ÿä¸æ˜¯è®¡ç®—æœºä¸“ä¸šï¼Œå¤§éƒ¨åˆ†çš„è¯¾ç¨‹éƒ½æ˜¯é›†æˆç”µè·¯ï¼Œå®é™…ä¸Šå¯¹æˆ‘çš„é¡¹ç›®å’Œå°†æ¥çš„å®ä¹ å·¥ä½œå¸®åŠ©éƒ½ä¸å¤§ï¼Œç°åœ¨å›å¿†ï¼Œè¿˜æ˜¯è§‰å¾—æ˜¯åœ¨æ··å­¦åˆ†ã€‚</p><p>ä¸è¿‡å®åœ¨æ˜¯å¯¹ICå…´è¶£ä¸å¤§ï¼Œé‚£æˆ‘å–œæ¬¢ä»€ä¹ˆå‘¢ï¼Ÿå¤§æ¦‚å°±æ˜¯æ–°é²œçš„èƒ½ç†è§£èƒ½çœ‹åˆ°çš„ç‚«é…·ä¸€ç‚¹çš„ä¸œè¥¿ã€‚è¿™æ ·æƒ³æƒ³æˆ‘æ¢äº†è½¯å¼€ï¼Œæ¢äº†ç®—æ³•ï¼Œä¹Ÿä¸èƒ½è¯´æ˜¯å®Œå…¨çœ‹åœ¨â€é’±é€”â€œçš„è¯±æƒ‘ä¸Šé¢â€¦hhh</p><h3 id="å…³ç³»"><a href="#å…³ç³»" class="headerlink" title="å…³ç³»"></a>å…³ç³»</h3><p>2019å¹´æ˜¯æˆ‘é¢ä¸´å„ç§å…³ç³»æœ€å¤šä¸€å¹´ï¼Œå½“ç„¶ä¸»è¦æ˜¯ç”·å¥³ç”Ÿçš„å…³ç³»å‘ç”Ÿäº†å·¨å¤§çš„å˜åŒ–ã€‚å¯¹äºè¿™äº›ï¼Œå½“æˆ‘èº«å¤„å…¶ä¸­çš„æ—¶å€™ï¼Œå†…å¿ƒå¿å¿‘ä¹Ÿæ¿€åŠ¨æœŸå¾…ï¼Œå¯æ˜¯åˆ°äº†ä»Šå¤©å½»åº•è„±ç¦»è¿™äº›ï¼Œç•™ä¸‹çš„åªæœ‰ç©ºè™šå’Œæ»¡åœ°çš„é¸¡æ¯›â€¦</p><blockquote><p>Chen Jiawen</p></blockquote><p>é™ˆè®¤è¯†åœ¨ä¸€å‘¨cpä¸Šï¼Œ2018.06ï¼Œåœ¨æˆ‘åˆšåˆšæ¥ä¸Šæµ·ï¼Œä¸€åˆ‡éƒ½æ˜¯å¾ˆå¥½å¥‡å¾ˆæ–°é²œï¼Œæˆ‘ä»¬ä»ç½‘ç»œä¸Šè®¤è¯†å’Œå¼€å§‹ï¼Œåˆ°2020.01.01ï¼Œä¹Ÿä»ç½‘ç»œä¸Šç»“æŸï¼Œä¸­é—´åˆ†åˆ†åˆåˆä¹‹ä¹…ï¼Œå®Œå…¨å†™ä¸€æœ¬è®©äººé¸¡çš®æ‰è½çš„çŸ«æƒ…å°è¯´ã€‚</p><p>2018.06å¥¹åŒæ„ä¸€èµ· â€”&gt; 2018.06å¥¹ç«‹åˆ»æ‚„æ‚„å›å®¶å‡†è€ƒç ”ï¼Œå¹¶æ²¡èƒ½è§é¢ â€”&gt; å¥¹åœ¨å®¶å­¦ä¹ ï¼Œä¸¤ä¸ªå¯‚å¯çš„äººæ€»æ˜¯äº’ç›¸é™ªä¼´ â€”&gt; å› ä¸ºçªç„¶èƒ–äº†å¾ˆå¤šæˆ–è€…å…¶ä»–ä¸€äº›çç¢çš„å°äº‹ï¼Œæˆ‘å¯¹å¥¹ç”Ÿæ°”è¿‡å¾ˆå¤šæ¬¡ â€”&gt; 2018.12è€ƒç ”ç»“æŸï¼Œæˆ‘æå‡ºåˆ†æ‰‹ â€”&gt; 2019.02æˆç»©å‡ºæ¥ï¼Œè½æ¦œï¼Œå¥¹æŒ½å›ï¼Œæˆ‘ä»¬åˆåœ¨ä¸€èµ· â€”&gt; å®šä¸‹å†é™ªä¸€å¹´ â€”&gt; ä¸­é—´å„ç§çŸ›ç›¾ï¼Œçº ç¼ ï¼Œåˆ†æ‰‹ä¸æ–­ â€”&gt; 2019.10æˆ‘å¯¹æ–‡åéœ²äº†ä¸€äº›å¿ƒäº‹ï¼Œå’Œé™ˆä¸å†æƒ³ç€æŒ½å› â€”&gt; 2019.11å½»åº•ç»“æŸ â€”&gt; 2019.12.31å› ä¸ºæ±ªï¼Œå¥¹æƒ³æŒ½å› â€”&gt; 2020.01.01,ç»ˆäºè½®åˆ°å¥¹ä¸»åŠ¨ææ‹œæ‹œï¼Œå¥½è¿ã€‚</p><p><strong><em>å…ƒæ—¦å¿«ä¹ï¼ŒCJWï¼ç¥ 2020å¹´ï¼Œå¿ƒæƒ³äº‹æˆ~</em></strong></p><p>å…¶å®æˆ‘å¯¹åˆ«äººçš„è¦æ±‚ï¼Œåœ¨è¿™ä¹‹åå†ä¹Ÿä¸ä¼šæœ‰äº†ï¼Œæ˜ç™½äº†ä¸€ä»¶äº‹æƒ…ï¼šå–œæ¬¢å°±æ˜¯å–œæ¬¢ï¼Œä¸å–œæ¬¢å°±æ˜¯ä¸å–œæ¬¢ï¼Œå–œæ¬¢çš„æ²¾æ»¡æ³¥åœŸä¹Ÿä¸ä¼šæŒ‘å‰”ã€‚</p><blockquote><p>Wang Lu</p></blockquote><p>æŠ±æ­‰ï¼Œ2019.11-2019.12ï¼Œä¸€ä¸ªå¤šæœˆï¼Œæ²¡èƒ½åˆ°æœ€åï¼Œæˆ‘çœŸçš„è ¢ã€‚</p><p>å”¯ä¸€æœ‹å‹åœˆå®˜å®£å®¶äººä¹ŸçŸ¥é“çš„ä¸€ä½ï¼Œç»“æœè¶Šæ¥è¶Šç´¯ï¼Œæˆ‘æƒ³è¦çš„æ„Ÿæƒ…ä¸æ˜¯è¿™ç§è¢«æ¯”è¾ƒè¡¡é‡ä¹‹åè§‰å¾—å¯¹æ–¹ä¸é”™å°±okçš„ï¼Œè¿™æ®µå…³ç³»é‡Œé¢ï¼Œæˆ‘æ˜¯æƒ³æŠ¤ä½ çˆ±ä½ çš„ï¼Œä¸€ä¸ªæ¯”æˆ‘å¹´é¾„å°çš„å¥³å­©å­æ¯”æˆ‘è¦æˆç†Ÿã€‚è¿›è¡Œä¸‹å»çœŸçš„å¤ªç´¯äº†ï¼Œèº«å¿ƒä¿±ç–²ï¼Œæ‰¿è®¤è‡ªå·±å¹¶ä¸æ˜¯ä¹‹å‰æƒ³çš„é‚£æ ·å¯¹å¥³ç”Ÿæ— è¦æ±‚ã€‚å–œæ¬¢è¿™ç§å°äº‹ï¼Œæ²¡æœ‰è§¦ç¢°åˆ°é‚£æ ¹å¼¦ï¼Œå°±æ³¨å®šæ²¡æœ‰å¯èƒ½å‘ç”Ÿäº†å§ã€‚</p><p>è™½ç„¶æˆ‘æ˜¯è¦è¯´æŠ±æ­‰çš„ä¸€æ–¹ï¼Œä½†æ˜¯å®é™…ä¸Šä½ ä¹Ÿå¹¶ä¸å–œæ¬¢æˆ‘çš„å§ã€‚</p><p><strong><em>å„è‡ªå®‰å¥½å•¦ï¼Œæœ¬å‘½å¹´å¼€å¿ƒå¹¸ç¦</em></strong></p><blockquote><p>Wen YZ</p></blockquote><p>æ— </p><p>æˆ‘ç†è§£ä½ äº†ã€‚</p><p>ä¸Šæµ·å¯¹æˆ‘çš„æ„ä¹‰å‡ ä¹æ¶ˆå¤±æ®†å°½äº†ï¼Œè°¢è°¢ä½ æ²¡ç”¨åŠ›æ‹’ç»ï¼Œåªæ˜¯è¿™æ ·ä¾æ—§ä¸ä¼šè§‰å¾—æ˜¯å¾ˆå¥½çš„æ–¹å¼ã€‚æˆ‘çŒœæˆ‘ä¼šåœ¨ç¦»å¼€ä¸Šæµ·ä¹‹å‰å†è§ä½ æœ€åä¸€æ¬¡å•¦ï¼Œä¸ä¼šæ‰“æ‰°ä½ å¾ˆä¹…çš„ã€‚YZåŒå­¦çœŸçœŸæ˜¯å¤©ä½¿ã€‚</p><blockquote><p>å®¶äºº</p></blockquote><p>æˆ‘å§æœ€æœ€é‡è¦ï¼Œå§å§å¿ƒçœ¼å¤ªå°‘äº†ï¼Œå¯¹å§å§å‘äº†ä¸€æ¬¡ç«ï¼Œæ„Ÿåˆ°å¾ˆéš¾å—ã€‚æƒ³ä¸€ç›´é™ªå§å§å“ˆå“ˆå“ˆå“ˆ</p><p>å¥¶å¥¶å’Œçˆ¸çˆ¸ï¼Œè¦å¤šå…³å¿ƒå®¶äººå•Šï¼Œè‡ªå·±æ—©å°±ä¸æ˜¯å°å­©äº†ã€‚</p><blockquote><p>ä¼™ä¼´</p></blockquote><p>ä¸ç®—å¤šï¼Œè¿˜ç®—å¥½ã€‚ä¹‹åä¼šåŠªåŠ›äº¤æœ‹å‹çš„ï¼Œè®©å¤§å®¶çœ‹åˆ°æˆ‘çš„â™¥ä¹Ÿä¸æ˜¯ä¸€ç›´å¾ˆæ¯ç‡¥ã€‚ä»¥å‰çš„ç°åœ¨çš„å„ä½å°ä¼™ä¼´ï¼Œæˆ‘ä»¬éƒ½è¦åŠªåŠ›ç©è€ï¼ŒåŠªåŠ›å­¦ä¹ å·¥ä½œï¼ŒåŠ æ²¹ã€‚</p><h3 id="å·¥ä½œ"><a href="#å·¥ä½œ" class="headerlink" title="å·¥ä½œ"></a>å·¥ä½œ</h3><blockquote><p>å®ä¹ </p></blockquote><p>ä»2019.04-2019.06ï¼Œå¤§æ¦‚é¢äº†4ï¼Œ5å®¶çš„ç®—æ³•ï¼Œéƒ½æ˜¯å¤§å‚ï¼Œè¢«å„ç§è¹‚èºï¼Œæˆ‘æ€‚äº†ï¼Œä¹‹åæš‘å‡å°±æ²¡å†ç»§ç»­äº†ã€‚è¿™æ˜¯æˆ‘æ‰¾å·¥ä½œä»¥æ¥æœ€å¤§çš„é”™ã€‚</p><p>æ€»ç»“å¤±è¯¯ï¼š</p><ul><li>ä¸åº”è¯¥ä¸Šæ¥å…ˆé¢å¤§å‚ï¼›</li><li>ä¸åº”è¯¥ä¸è®¤çœŸåˆ·é¢˜ï¼›</li><li>ä¸åº”è¯¥è‡ªæƒ­å½¢ç§½ï¼›</li></ul><p>æœ€ç»ˆ2019.09åœ¨ç™¾å§“ç½‘å®ä¹ äº†4å‘¨å·¦å³ï¼Œä¸€è¾¹å¿™ç€ç§‹æ‹›ä¸€è¾¹å®ä¹ ï¼ŒçœŸçš„å¿ƒéƒ½è¦æ“ç¢äº†ã€‚</p><p>è°¢è°¢å„ä½ã€‚æ‰€å¹¸æœ€ç»ˆçš„ç»“æœæ˜¯æˆ‘èƒ½æ¥å—çš„ã€‚</p><p>å› ä¸ºè¿™æ ·çš„æ¶ˆæå®³æ€•çš„å¿ƒç†ï¼Œç›´æ¥å¯¼è‡´è‡ªå·±é”™è¿‡æå‰æ‰¹ï¼Œæ­£å¼æ‰¹çš„ç¬”è¯•éƒ½æ²¡æœ‰é€šè¿‡ä¸€å®¶ï¼ŒçœŸçš„å¤ªèœäº†ã€‚è¿˜æ˜¯è¦åŠªåŠ›å¤šå­¦ä¹ å¤šåˆ·é¢˜ï¼ŒæŒæ¡åˆ°çš„ç¼–ç¨‹æŠ€èƒ½æ˜¯è‡ªå·±çš„ï¼Œä¼šæ˜¯æ°¸è¿œéƒ½æœ‰ç”¨çš„ã€‚</p><blockquote><p>Offer</p></blockquote><p>æœ€åæ‹¿åˆ°çš„offerå±…ç„¶æ˜¯æ—©æ—©å°±é¢çš„ç¬¬ä¸€å®¶ï¼ŒZTEï¼Œè¿™æ ·æƒ³æƒ³ï¼ŒçœŸçš„è®¤çœŸé¢è¯•çš„åªæœ‰ZTEå’Œåä¸ºä¸¤å®¶ï¼Œåä¸ºçš„ä¾ç„¶ä¸æ˜¯å¾ˆåŒ¹é…ï¼Œè¢«åˆ·æ‰äº†ã€‚ZTEçš„è¯´æ˜¯C++è½¯å¼€ï¼Œä½†æ˜¯åé€šä¿¡ç³»ç»Ÿåè®®ï¼Œä¾ç„¶ä¸èƒ½è¯´æ˜¯ç†æƒ³ã€‚è€Œä¸”è–ªæ°´æ¯”è¾ƒåŒå­¦å·®è·ä¹Ÿæœ‰ä¸€äº›ã€‚</p><p>è°å«æˆ‘æ˜¯èœé¸¡å‘¢..å“­â€¦</p><p>å…ˆæ‹¿åˆ°ä¸Šæµ·çš„æˆ·å£ï¼Œ2020.07å…¥èŒï¼Œ2021.04æˆ‘ä¸€å®šä¼šè¿›å…¥å¤´æ¡æˆ–è€…PDDå…¶ä¸­ä¹‹ä¸€çš„ï¼ŒFLAGç«‹åœ¨è¿™äº†ã€‚</p><h2 id="2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ"><a href="#2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ" class="headerlink" title="2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ"></a>2020ï¼Œæˆ‘æƒ³è¦ä»€ä¹ˆï¼Ÿ</h2><p>2020å¹´é¼ å¹´ï¼Œæˆ‘åˆšåˆšç»“æŸäº†è‡ªå·±çš„æœ¬å‘½å¹´ï¼Œåœ¨å®éªŒå®¤åšæ¯•è®¾ï¼Œæœ‰å‡ ä¸ªèŠå¾—æ¥çš„æœ‹å‹ï¼Œé©¬ä¸Šä¼šé¢ä¸´æ¯•ä¸šå’Œå·¥ä½œï¼Œå¸¦ç€è‡ªå·±å¹¶ä¸å¨´ç†Ÿçš„æŠ€èƒ½ï¼Œä¸€åˆ‡å¥½åƒæ²¡é‚£ä¹ˆå¥½ï¼Œä¹Ÿæ²¡é‚£ä¹ˆç³Ÿã€‚å…ƒæ—¦è¿™å¤©ï¼Œæˆ‘æƒ³è®¸å¾ˆå¤šçš„å¿ƒæ„¿ï¼Œå¸Œæœ›èƒ½åœ¨è¿™ä¸€å¹´å¾—åˆ°å›åº”ã€‚</p><p>å°å­©å­éƒ½ä¼šè´ªå¿ƒçš„ã€‚æˆ‘æƒ³è¦å¾ˆå¥½çš„æŠ€èƒ½ï¼Œå¾ˆå¤šçš„é’±ï¼Œå¾ˆå¤šçš„æœ‹å‹ï¼Œå¾ˆå……å®çš„æ—¶é—´ã€‚</p><p>æŠ€èƒ½æ–¹é¢ï¼š</p><ol><li>C++ï¼ˆå·¥ä½œå¿…é¡»ï¼‰</li><li>NLPï¼ŒPythonï¼ŒPyTorchï¼ˆæ¯•è®¾ä»¥åŠä¸ªäººå‘å±•ï¼‰</li><li>è‹±è¯­</li></ol><p>ç”Ÿæ´»æ–¹é¢ï¼š</p><ol><li>Kindleï¼ˆæƒ³æ¡èµ·é˜…è¯»çš„ä¹ æƒ¯ï¼‰</li><li>æ˜¾ç¤ºå™¨ï¼Œæ¡Œæ¤…ï¼ˆå’Œæˆ‘çš„Surfaceé…åˆåº”è¯¥ç®—ä¸ªä¸é”™çš„ç”Ÿäº§ç¯å¢ƒï¼‰</li><li>ç¾½æ¯›çƒæ‹ï¼Œçƒé‹</li></ol><p>å¦å¤–è¿˜æœ‰ï¼Œå¸Œæœ›é¡ºåˆ©æ¯•ä¸šï¼Œå¸Œæœ›å·¥ä½œåä¹Ÿèƒ½æœ‰ç”Ÿæ´»ï¼Œå¸Œæœ›æœ‹å‹ä¸€ç›´éƒ½èƒ½æ¯«æ— èŠ¥è’‚ï¼Œå¸Œæœ›æˆ‘å–œæ¬¢çš„äººä¹Ÿæ°å¥½çœ‹åˆ°äº†æˆ‘ã€‚</p><p>FLAG:</p><ol><li>æ–°å»ºä¸€ä¸ªGithubè´¦å·ï¼ŒæŠŠç°åœ¨çš„ä¸œè¥¿æ…¢æ…¢è‡ªå·±å†™ä¸€éï¼›</li><li>æ¯å¤©commitï¼Œå°‘ä¸€ä¸ªcommitå°±å‡é¤ä¸€é¡¿ï¼›</li><li>27wâ€”&gt;35wï¼Œè¦ç›¸ä¿¡è‡ªå·±åŠªåŠ›æé«˜å°±å¯ä»¥è¾¾åˆ°ã€‚</li></ol><p>æ€»ä¹‹ï¼Œ2020å¹´ï¼Œå„ä½ä¸€èµ·å˜å¾—æ›´å¥½å§~ æµå¹´ç¬‘æ·ï¼Œæœªæ¥å¯æœŸï¼</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æ—¥è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¹´ç»ˆæ€»ç»“ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_PyTorchåŸºç¡€ä½¿ç”¨</title>
      <link href="/2019/11/07/01-pytorch-ji-chu-shi-yong/"/>
      <url>/2019/11/07/01-pytorch-ji-chu-shi-yong/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>__version__</code></pre><pre><code>'1.3.0'</code></pre><a id="more"></a><h1 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h1><blockquote><p>Tensorçš„ä½¿ç”¨ï¼š</p></blockquote><ul><li><ol><li>æ„å»º</li></ol></li><li><ol start="2"><li>Tensorçš„åŸºæœ¬è¿ç®—</li></ol></li><li><ol start="3"><li>Tensorä¸Numpyè½¬æ¢</li></ol></li><li><ol start="4"><li>å…±äº«å†…å­˜çš„æƒ…å†µ</li></ol></li><li><ol start="5"><li>è‡ªåŠ¨å¾®åˆ†</li></ol></li></ul><h2 id="1-æ„å»ºTensor"><a href="#1-æ„å»ºTensor" class="headerlink" title="1. æ„å»ºTensor"></a>1. æ„å»ºTensor</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æ„å»º5Ã—3çŸ©é˜µï¼Œåˆ†é…ç©ºé—´ï¼Œä¸åˆå§‹åŒ–</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ä½¿ç”¨ç‰¹å®šæ•°æ®åˆå§‹åŒ–Tensor</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ä½¿ç”¨[0, 1]å‡åŒ€åˆ†å¸ƒéšæœºåˆå§‹åŒ–</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æŸ¥çœ‹Tensorå½¢çŠ¶çš„ä¸¤ç§æ–¹æ³•</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre><code>3</code></pre><h2 id="2-Tensorçš„åŸºæœ¬è¿ç®—"><a href="#2-Tensorçš„åŸºæœ¬è¿ç®—" class="headerlink" title="2. Tensorçš„åŸºæœ¬è¿ç®—"></a>2. Tensorçš„åŸºæœ¬è¿ç®—</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># åŠ æ³•</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬ä¸€ç§æ–¹å¼</span>z <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token comment" spellcheck="true"># ç¬¬äºŒç§æ–¹å¼</span>torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> out<span class="token operator">=</span>z<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬ä¸‰ç§æ–¹å¼</span>z <span class="token operator">=</span> y<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ç¬¬å››ç§æ–¹å¼ï¼Œä¿®æ”¹yå€¼</span>y<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>x<span class="token punctuation">)</span></code></pre><pre><code>tensor([[1.4718, 0.5690, 1.1329],        [0.3453, 0.8727, 0.7226],        [1.2681, 0.8222, 1.8243],        [1.3840, 0.8803, 1.4788],        [1.5312, 1.0661, 0.9357]])</code></pre><h2 id="3-Tensorä¸Numpyè½¬æ¢"><a href="#3-Tensorä¸Numpyè½¬æ¢" class="headerlink" title="3. Tensorä¸Numpyè½¬æ¢"></a>3. Tensorä¸Numpyè½¬æ¢</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Tensorçš„åˆ‡ç‰‡ä¸Numpyç›¸ä¼¼,é€‰å‡ºindex=1çš„åˆ—</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ–°å»ºå…¨ä¸º1çš„Tensor</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Tensor->Numpy</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Numpy -> Tensor</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np a <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''è¦æ³¨æ„è¿™é‡Œçš„aå’Œbå†…å­˜å…±äº«ï¼Œä¸€ä¸ªæ”¹å˜ï¼Œå¦ä¸€ä¸ªä¼šåŒæ—¶è·Ÿéšæ”¹å˜'''</span><span class="token comment" spellcheck="true"># è·å–æŸä¸ªå…ƒç´ å€¼</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ³¨æ„ï¼štorch.tensorä¸torch.Tensoræœ‰å·®åˆ«ï¼Œè€Œä¸”ï¼Œtorch.tensoræ˜¯å¯¹åŸå§‹tensorçš„æ‹·è´ï¼Œä¸å†å…±äº«åŒæ ·çš„å†…å­˜</span>z_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>z_<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span></code></pre><pre><code>tensor([5., 3.])tensor([5., 3.])tensor([6., 4.])tensor([5., 3.])/home/xwjia/anaconda3/envs/Torch/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).</code></pre><h2 id="4-å…±äº«å†…å­˜æƒ…å†µ"><a href="#4-å…±äº«å†…å­˜æƒ…å†µ" class="headerlink" title="4. å…±äº«å†…å­˜æƒ…å†µ"></a>4. å…±äº«å†…å­˜æƒ…å†µ</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># å½“éœ€è¦å…±äº«å†…å­˜æ—¶ï¼Œå¯ä»¥ï¼š</span>a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æˆ–è€…</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è½¬æ¢ä¸ºGPUæ”¯æŒçš„Tensor</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>a <span class="token operator">=</span> a<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>c <span class="token operator">=</span> a <span class="token operator">+</span> b</code></pre><h2 id="5-è‡ªåŠ¨å¾®åˆ†"><a href="#5-è‡ªåŠ¨å¾®åˆ†" class="headerlink" title="5. è‡ªåŠ¨å¾®åˆ†"></a>5. è‡ªåŠ¨å¾®åˆ†</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ä¸ºTensorè®¾å®šå¯ä»¥æ±‚å¯¼</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token comment" spellcheck="true"># ç¬¬äºŒæ¬¡æ±‚å¯¼ä¹‹å‰è¦å½’é›¶ï¼Œä¸ç„¶ä¼šç´¯åŠ </span>x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad</code></pre><pre><code>tensor([[1., 1.],        [1., 1.]])</code></pre><pre class=" language-python"><code class="language-python"></code></pre><h1 id="ç¥ç»ç½‘ç»œ"><a href="#ç¥ç»ç½‘ç»œ" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h1><p>å¯¼å…¥<code>torch.nn</code>ï¼Œå°è£…å¯ä»¥è‡ªåŠ¨æ±‚å¯¼ï¼Œåªéœ€è¦åœ¨è‡ªå®šä¹‰çš„ç±»ç»§æ‰¿äº<code>nn.Module</code>,ç±»ä¸­éœ€è¦å®ç°<code>__init__</code>å’Œ<code>forward</code>æ–¹æ³•ï¼›</p><p>å…¶ä¸­ï¼š</p><ul><li><ol><li><code>__init__</code>ä¸­å­˜æ”¾ç½‘ç»œä¸­å¯ä»¥å­¦ä¹ çš„å‚æ•°ï¼›</li></ol></li><li><ol start="2"><li><code>super(Net, self).__init__()</code>ç­‰ä»·äºçˆ¶ç±»<code>nn.Module.__init__(self)</code></li></ol></li><li><ol start="3"><li>ç½‘ç»œä¸­ä¸å­¦ä¹ çš„å‚æ•°ï¼Œæ¯”å¦‚æœ€å¤§æ± åŒ–æˆ–è€…ReLUï¼Œå¯ä»¥æ”¾åœ¨<code>forward</code>æ–¹æ³•ä¸­</li></ol></li></ul><h2 id="1-è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ"><a href="#1-è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ" class="headerlink" title="1. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ"></a>1. è‡ªå®šä¹‰ç¥ç»ç½‘ç»œ</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F <span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#reshape, '-1'è¡¨ç¤ºè‡ªé€‚åº”</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ‰“å°ç½‘ç»œå¯å­¦ä¹ çš„å‚æ•°</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">)</span>params <span class="token operator">=</span> list<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> parameters <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&lt;generator object Module.parameters at 0x7fb59472e7d0&gt;&lt;bound method Module.named_parameters of Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&gt;10conv1.weight : torch.Size([6, 1, 5, 5])conv1.bias : torch.Size([6])conv2.weight : torch.Size([16, 6, 5, 5])conv2.bias : torch.Size([16])fc1.weight : torch.Size([120, 400])fc1.bias : torch.Size([120])fc2.weight : torch.Size([84, 120])fc2.bias : torch.Size([84])fc3.weight : torch.Size([10, 84])fc3.bias : torch.Size([10])</code></pre><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>out<span class="token comment" spellcheck="true"># æ‰€æœ‰å‚æ•°æ¸…é›¶</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch-nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨-input-unsqueeze-0-å°†batch-sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚-nn-Conv2d-è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚"><a href="#éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch-nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨-input-unsqueeze-0-å°†batch-sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚-nn-Conv2d-è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚" class="headerlink" title="éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch.nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨ input.unsqueeze(0)å°†batch_sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚ nn.Conv2d è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚"></a>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œtorch.nnåªæ”¯æŒmini-batchesï¼Œä¸æ”¯æŒä¸€æ¬¡åªè¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œå³ä¸€æ¬¡å¿…é¡»æ˜¯ä¸€ä¸ªbatchã€‚ä½†å¦‚æœåªæƒ³è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œåˆ™ç”¨ <code>input.unsqueeze(0)</code>å°†batch_sizeè®¾ä¸ºï¼‘ã€‚ä¾‹å¦‚ <code>nn.Conv2d</code> è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„ï¼Œå½¢å¦‚</h3><p>$$<br>nSamples \times nChannels \times Height \times Width<br>$$</p><h3 id="å¯å°†nSampleè®¾ä¸º1ï¼Œå³"><a href="#å¯å°†nSampleè®¾ä¸º1ï¼Œå³" class="headerlink" title="å¯å°†nSampleè®¾ä¸º1ï¼Œå³"></a>å¯å°†nSampleè®¾ä¸º1ï¼Œå³</h3><p>$$<br>1 \times nChannels \times Height \times Width<br>$$</p><h2 id="2-æŸå¤±å‡½æ•°"><a href="#2-æŸå¤±å‡½æ•°" class="headerlink" title="2. æŸå¤±å‡½æ•°"></a>2. æŸå¤±å‡½æ•°</h2><ul><li><ol><li><code>nn.MSELoss</code>è®¡ç®—å‡æ–¹è¯¯å·®ï¼›</li></ol></li><li><ol start="2"><li><code>nn.CrossEntropyLoss</code>è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼›</li></ol></li></ul><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><pre><code>tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])tensor(28.4120, grad_fn=&lt;MseLossBackward&gt;)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è¿è¡Œ.backward,å¯ä»¥è§‚å¯Ÿè°ƒç”¨åå‘ä¼ æ’­ä¹‹å‰å’Œä¹‹åçš„grad</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># æŠŠnetä¸­çš„æ‰€æœ‰å¯å­¦ä¹ å‚æ•°çš„æ¢¯åº¦æ¸…é›¶</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"åå‘ä¼ æ’­ä¹‹å‰ conv1.bias çš„æ¢¯åº¦"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"åå‘ä¼ æ’­ä¹‹å...."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><pre><code>åå‘ä¼ æ’­ä¹‹å‰ conv1.bias çš„æ¢¯åº¦tensor([0., 0., 0., 0., 0., 0.])åå‘ä¼ æ’­ä¹‹å....tensor([ 0.0700, -0.0912,  0.0596,  0.0453,  0.0661,  0.0147])</code></pre><h2 id="3-ä¼˜åŒ–å™¨"><a href="#3-ä¼˜åŒ–å™¨" class="headerlink" title="3. ä¼˜åŒ–å™¨"></a>3. ä¼˜åŒ–å™¨</h2><p>åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ä¹‹åï¼Œè¿˜éœ€è¦è¦ä¼˜åŒ–æ–¹æ³•æ›´æ–°ç½‘ç»œçš„æƒé‡å’Œå‚æ•°ï¼Œæ¯”å¦‚<code>SGD</code>:</p><p><code>weight = weight - learning_rate * gradient</code></p><p>æ‰‹åŠ¨å®ç°å¦‚ä¸‹ï¼š</p><pre class=" language-python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># inplace å‡æ³•</span></code></pre><p><code>torch.optim</code>ä¸­å®ç°äº†æ·±åº¦å­¦ä¹ ä¸­ç»å¤§å¤šæ•°çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚RMSPropã€Adamã€SGDç­‰ï¼Œæ›´ä¾¿äºä½¿ç”¨ï¼Œå› æ­¤å¤§å¤šæ•°æ—¶å€™å¹¶ä¸éœ€è¦æ‰‹åŠ¨å†™ä¸Šè¿°ä»£ç ã€‚</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment" spellcheck="true"># æ–°å»ºä¼˜åŒ–å™¨ï¼Œ æŒ‡å®šéœ€è¦è°ƒæ•´çš„å‚æ•°å’Œå­¦ä¹ ç‡</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è®­ç»ƒæ—¶ï¼Œæ¢¯åº¦å…ˆæ¸…é›¶ï¼š</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># è®¡ç®—loss</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># åå‘ä¼ æ’­</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># æ›´æ–°å‚æ•°</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="4-æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"><a href="#4-æ•°æ®åŠ è½½å’Œé¢„å¤„ç†" class="headerlink" title="4. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"></a>4. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†</h2><p><code>torchvision</code>å®ç°äº†å¸¸ç”¨çš„å›¾åƒæ•°æ®åŠ è½½åŠŸèƒ½ï¼Œä¾‹å¦‚Imagenetã€CIFAR10ã€MNISTç­‰ï¼Œä»¥åŠå¸¸ç”¨çš„æ•°æ®è½¬æ¢æ“ä½œï¼Œè¿™æå¤§åœ°æ–¹ä¾¿äº†æ•°æ®åŠ è½½ï¼Œå¹¶ä¸”ä»£ç å…·æœ‰å¯é‡ç”¨æ€§ã€‚</p><h3 id="å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»"><a href="#å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»" class="headerlink" title="å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»"></a>å°è¯•ç‰›åˆ€ï¼šCIFAR-10åˆ†ç±»</h3><p>ä¸‹é¢æˆ‘ä»¬æ¥å°è¯•å®ç°å¯¹CIFAR-10æ•°æ®é›†çš„åˆ†ç±»ï¼Œæ­¥éª¤å¦‚ä¸‹: </p><ol><li>ä½¿ç”¨torchvisionåŠ è½½å¹¶é¢„å¤„ç†CIFAR-10æ•°æ®é›†</li><li>å®šä¹‰ç½‘ç»œ</li><li>å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</li><li>è®­ç»ƒç½‘ç»œå¹¶æ›´æ–°ç½‘ç»œå‚æ•°</li><li>æµ‹è¯•ç½‘ç»œ</li></ol><h4 id="CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†"><a href="#CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†" class="headerlink" title="CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†"></a>CIFAR-10æ•°æ®åŠ è½½åŠé¢„å¤„ç†</h4><p>CIFAR-10<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">^3</a>æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„å½©è‰²å›¾ç‰‡æ•°æ®é›†ï¼Œå®ƒæœ‰10ä¸ªç±»åˆ«: â€˜airplaneâ€™, â€˜automobileâ€™, â€˜birdâ€™, â€˜catâ€™, â€˜deerâ€™, â€˜dogâ€™, â€˜frogâ€™, â€˜horseâ€™, â€˜shipâ€™, â€˜truckâ€™ã€‚æ¯å¼ å›¾ç‰‡éƒ½æ˜¯$3\times32\times32$ï¼Œä¹Ÿå³3-é€šé“å½©è‰²å›¾ç‰‡ï¼Œåˆ†è¾¨ç‡ä¸º$32\times32$ã€‚</p><h2 id="5-å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ "><a href="#5-å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ " class="headerlink" title="5. å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ "></a>5. å®Œæ•´CIFAR-10åˆ†ç±»ç»ƒä¹ </h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchvision  <span class="token keyword">as</span> tv <span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToPILImageshow <span class="token operator">=</span> ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># å¯ä»¥æŠŠTensorè½¬æˆImageï¼Œæ–¹ä¾¿å¯è§†åŒ–</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#å½’ä¸€åŒ–</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®­ç»ƒé›†</span>trainset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span></code></pre><pre><code>0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/xwjia/tmp/data/cifar-10-python.tar.gz 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 169443328/170498071 [00:20&lt;00:00, 11268338.34it/s]Extracting /home/xwjia/tmp/data/cifar-10-python.tar.gz to /home/xwjia/tmp/data/</code></pre><pre class=" language-python"><code class="language-python">trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    trainset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æµ‹è¯•é›†</span>testset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    testset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span></code></pre><pre><code>Files already downloaded and verified</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># æŸ¥çœ‹æŸä¸ªæ ·æœ¬</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token operator">=</span> trainset<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>ship</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_29_1.png" alt="png"></p><p>Dataloaderæ˜¯ä¸€ä¸ªå¯è¿­ä»£çš„å¯¹è±¡ï¼Œå®ƒå°†datasetè¿”å›çš„æ¯ä¸€æ¡æ•°æ®æ‹¼æ¥æˆä¸€ä¸ªbatchï¼Œå¹¶æä¾›å¤šçº¿ç¨‹åŠ é€Ÿä¼˜åŒ–å’Œæ•°æ®æ‰“ä¹±ç­‰æ“ä½œã€‚å½“ç¨‹åºå¯¹datasetçš„æ‰€æœ‰æ•°æ®éå†å®Œä¸€éä¹‹åï¼Œç›¸åº”çš„å¯¹Dataloaderä¹Ÿå®Œæˆäº†ä¸€æ¬¡è¿­ä»£ã€‚</p><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#è¿”å›ä¸‹ä¸€ä¸ªbatchï¼Œ4å¼ å›¾ç‰‡å’Œæ ‡ç­¾</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%11s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span><span class="token punctuation">(</span>images<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>truck         cat       plane       truck</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_31_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è‡ªå®šä¹‰ç½‘ç»œç»“æ„</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc1   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc2   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®­ç»ƒç½‘ç»œ</span>torch<span class="token punctuation">.</span>set_num_threads<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># è¾“å…¥æ•°æ®</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment" spellcheck="true"># æ¢¯åº¦æ¸…é›¶</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># forward + backward</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># æ›´æ–°å‚æ•°</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># æ‰“å°logä¿¡æ¯</span>        <span class="token comment" spellcheck="true"># lossæ˜¯ä¸€ä¸ªscalarï¼Œ éœ€è¦ä½¿ç”¨loss.item()è·å–æ•°å€¼ï¼Œ ä¸èƒ½ä½¿ç”¨loss[0]</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true"># æ¯2000ä¸ªbatchæ‰“å°ä¸€ä¸‹è®­ç»ƒçŠ¶æ€</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span><span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> running_loss<span class="token operator">/</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></code></pre><pre><code>[1,  2000] loss: 2.163[1,  4000] loss: 1.823[1,  6000] loss: 1.656[1,  8000] loss: 1.586[1, 10000] loss: 1.495[1, 12000] loss: 1.467[2,  2000] loss: 1.405[2,  4000] loss: 1.376[2,  6000] loss: 1.343[2,  8000] loss: 1.322[2, 10000] loss: 1.320[2, 12000] loss: 1.311Finished Training</code></pre><h3 id="æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ"><a href="#æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ" class="headerlink" title="æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ"></a>æ¥ä¸‹æ¥çœ‹æµ‹è¯•é›†ï¼Œæµ‹è¯•è®­ç»ƒçš„ç»“æœ</h3><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'å®é™…çš„label: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%08s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token operator">/</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># è®¡ç®—å›¾ç‰‡åœ¨æ¯ä¸ªç±»åˆ«ä¸Šçš„åˆ†æ•°</span>outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># å¾—åˆ†æœ€é«˜çš„é‚£ä¸ªç±»</span>_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'é¢„æµ‹ç»“æœï¼š '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>é¢„æµ‹ç»“æœï¼š    cat  ship  ship plane</code></pre><pre class=" language-python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>   <span class="token comment" spellcheck="true"># é¢„æµ‹æ­£ç¡®çš„å›¾ç‰‡æ•°</span>total <span class="token operator">=</span> <span class="token number">0</span>     <span class="token comment" spellcheck="true"># æ€»å…±çš„å›¾ç‰‡æ•°</span><span class="token comment" spellcheck="true"># ç”±äºæµ‹è¯•æ—¶ä¸éœ€è¦æ±‚å¯¼ï¼Œ æ‰€ä»¥å¯ä»¥æš‚æ—¶å…³é—­autogradï¼Œ æé«˜é€Ÿåº¦ï¼Œ èŠ‚çº¦å†…å­˜</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"10000å¼ æµ‹è¯•é›†ä¸­çš„å‡†ç¡®ç‡æ˜¯ï¼š %d %%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token operator">/</span>total<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>10000å¼ æµ‹è¯•é›†ä¸­çš„å‡†ç¡®ç‡æ˜¯ï¼š 54 %</code></pre><h2 id="åœ¨GPUä¸Šè®­ç»ƒ"><a href="#åœ¨GPUä¸Šè®­ç»ƒ" class="headerlink" title="åœ¨GPUä¸Šè®­ç»ƒ"></a>åœ¨GPUä¸Šè®­ç»ƒ</h2><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><p>å¯¹PyTorchçš„åŸºç¡€ä»‹ç»è‡³æ­¤ç»“æŸã€‚æ€»ç»“ä¸€ä¸‹ï¼Œæœ¬èŠ‚ä¸»è¦åŒ…å«ä»¥ä¸‹å†…å®¹ã€‚</p><ol><li>Tensor: ç±»ä¼¼Numpyæ•°ç»„çš„æ•°æ®ç»“æ„ï¼Œä¸Numpyæ¥å£ç±»ä¼¼ï¼Œå¯æ–¹ä¾¿åœ°äº’ç›¸è½¬æ¢ã€‚</li><li>autograd/: ä¸ºtensoræä¾›è‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½ã€‚</li><li>nn: ä¸“é—¨ä¸ºç¥ç»ç½‘ç»œè®¾è®¡çš„æ¥å£ï¼Œæä¾›äº†å¾ˆå¤šæœ‰ç”¨çš„åŠŸèƒ½(ç¥ç»ç½‘ç»œå±‚ï¼ŒæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨ç­‰)ã€‚</li><li>ç¥ç»ç½‘ç»œè®­ç»ƒ: ä»¥CIFAR-10åˆ†ç±»ä¸ºä¾‹æ¼”ç¤ºäº†ç¥ç»ç½‘ç»œçš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€ç½‘ç»œæ­å»ºã€è®­ç»ƒåŠæµ‹è¯•ã€‚</li></ol><p>ä»ä¸‹ä¸€ç« å¼€å§‹ï¼Œæœ¬ä¹¦å°†æ·±å…¥ç³»ç»Ÿåœ°è®²è§£PyTorchçš„å„éƒ¨åˆ†çŸ¥è¯†ã€‚</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> æ·±åº¦å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorchæ¡†æ¶å…¥é—¨ä¸å®æˆ˜ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/10/20/hello-world/"/>
      <url>/2019/10/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
