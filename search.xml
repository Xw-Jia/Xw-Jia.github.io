<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>19年岁末</title>
      <link href="/2019/12/31/19-nian-sui-mo/"/>
      <url>/2019/12/31/19-nian-sui-mo/</url>
      
        <content type="html"><![CDATA[<h1 id="挥别2019，迎接变化"><a href="#挥别2019，迎接变化" class="headerlink" title="挥别2019，迎接变化"></a>挥别2019，迎接变化</h1><p>2020是个很有意思的年份，ABAB的形式朗朗上口，如果要这样严格的算的话，上一个这样的年份是1919年，相隔101年了已经，下一次要到2121，又是101年以后，也就是说，我们一生中，只会经历这样一次的ABAB年份，实在是值得用力去记忆和感受。</p><h2 id="2019，我得到了什么？"><a href="#2019，我得到了什么？" class="headerlink" title="2019，我得到了什么？"></a>2019，我得到了什么？</h2><blockquote><p>Sometimes it lasts in love, sometimes it hurt instead.</p></blockquote><p>一个并不擅长的技能，一段说不清道不明的关系，一个不好不坏的工作机会。还有一个不知道是在成长还是在变老的自己。</p><h3 id="技能"><a href="#技能" class="headerlink" title="技能"></a>技能</h3><blockquote><p>关于项目</p></blockquote><p>在复旦的一年半，说是学习NLP，其实到了最后也只是一直在皮毛的层面晃悠，总是无法深入。</p><p>其实自己也清楚自己的原因在哪边，很难专注一个方向，各种都在好奇，结果就是看两篇论文就算了，其实过两天也就忘了。NLP或者说是深度学习，方向千奇百怪，其实前期找准一个有工业应用前景的方向，比如对话系统，摘要，这种，沿着一篇综述独立开展研究，代码和论文同时开始，再看些相关的比赛开源的代码，应该半年就能入门。这个事情只能说明自己浮躁，浮躁是科研的大忌，所以我不适合读博了，至少目前看来是这样的。</p><p>啊我真是个憨憨。</p><p>最气的是最后Tensorflow和PyTorch居然一个都不熟…我这渣渣工程能力总是会给我巨大的打击…</p><blockquote><p>关于实验室</p></blockquote><p>2018年5月份开始在王老师的EDA实验室呆了一个多月，认识了师兄刘淇，和钟程同学一起搞C++编译器，结果我总是难以入门，那时候我大概连怎么查资料都不会。而且莫名其妙的嫉妒钟程，越来越难受，所以最后还是离开了。</p><p>当时的契机是听刘涛讲算法会更有”钱途“，就心动来了IBICAS，当时实验室还叫做BCRC，事实证明，不管哪一个方向，只要学得好就牛逼，同为IT基本不存在哪个方向明显更有‘’钱途“，抄近路的方式是不可取的…最后我的offer不如一直做IC的同学，很大的教训，仔细想做什么事情都是这个道理吧…<strong>要怀着做到最好的心思去做事情</strong></p><p>最有意思的是最后的offer居然还是C++开发，果然是有一种循环。</p><blockquote><p>关于课程</p></blockquote><p>复旦工硕的课程本来设置的就很多，各种课程各种学分，让人头大…</p><p>研一的时候我总是心大，想着尽快修完学分去实习，所以第一学期选课12门，真的作死，而且累是次要，因为只是为了时间不冲突选了很多不会用到的课程，比如MEMS，贼气的一门，最后绩点也相应的很低。</p><p>毕竟不是计算机专业，大部分的课程都是集成电路，实际上对我的项目和将来的实习工作帮助都不大，现在回忆，还是觉得是在混学分。</p><p>不过实在是对IC兴趣不大，那我喜欢什么呢？大概就是新鲜的能理解能看到的炫酷一点的东西。这样想想我换了软开，换了算法，也不能说是完全看在”钱途“的诱惑上面…hhh</p><h3 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h3><p>2019年是我面临各种关系最多一年，当然主要是男女生的关系发生了巨大的变化。对于这些，当我身处其中的时候，内心忐忑也激动期待，可是到了今天彻底脱离这些，留下的只有空虚和满地的鸡毛…</p><blockquote><p>Chen Jiawen</p></blockquote><p>陈认识在一周cp上，2018.06，在我刚刚来上海，一切都是很好奇很新鲜，我们从网络上认识和开始，到2020.01.01，也从网络上结束，中间分分合合之久，完全写一本让人鸡皮掉落的矫情小说。</p><p>2018.06她同意一起 —&gt; 2018.06她立刻悄悄回家准考研，并没能见面 —&gt; 她在家学习，两个寂寞的人总是互相陪伴 —&gt; 因为突然胖了很多或者其他一些琐碎的小事，我对她生气过很多次 —&gt; 2018.12考研结束，我提出分手 —&gt; 2019.02成绩出来，落榜，她挽回，我们又在一起 —&gt; 定下再陪一年 —&gt; 中间各种矛盾，纠缠，分手不断 —&gt; 2019.10我对文吐露了一些心事，和陈不再想着挽回 —&gt; 2019.11彻底结束 —&gt; 2019.12.31因为汪，她想挽回 —&gt; 2020.01.01,终于轮到她主动提拜拜，好运。</p><p><strong><em>元旦快乐，CJW！祝 2020年，心想事成~</em></strong></p><p>其实我对别人的要求，在这之后再也不会有了，明白了一件事情：喜欢就是喜欢，不喜欢就是不喜欢，喜欢的沾满泥土也不会挑剔。</p><blockquote><p>Wang Lu</p></blockquote><p>抱歉，2019.11-2019.12，一个多月，没能到最后，我真的蠢。</p><p>唯一朋友圈官宣家人也知道的一位，结果越来越累，我想要的感情不是这种被比较衡量之后觉得对方不错就ok的，这段关系里面，我是想护你爱你的，一个比我年龄小的女孩子比我要成熟。进行下去真的太累了，身心俱疲，承认自己并不是之前想的那样对女生无要求。喜欢这种小事，没有触碰到那根弦，就注定没有可能发生了吧。</p><p>虽然我是要说抱歉的一方，但是实际上你也并不喜欢我的吧。</p><p><strong><em>各自安好啦，本命年开心幸福</em></strong></p><blockquote><p>Wen YZ</p></blockquote><p>无</p><p>我理解你了。</p><p>上海对我的意义几乎消失殆尽了，谢谢你没用力拒绝，只是这样依旧不会觉得是很好的方式。我猜我会在离开上海之前再见你最后一次啦，不会打扰你很久的。YZ同学真真是天使。</p><blockquote><p>家人</p></blockquote><p>我姐最最重要，姐姐心眼太少了，对姐姐发了一次火，感到很难受。想一直陪姐姐哈哈哈哈</p><p>奶奶和爸爸，要多关心家人啊，自己早就不是小孩了。</p><blockquote><p>伙伴</p></blockquote><p>不算多，还算好。之后会努力交朋友的，让大家看到我的♥也不是一直很枯燥。以前的现在的各位小伙伴，我们都要努力玩耍，努力学习工作，加油。</p><h3 id="工作"><a href="#工作" class="headerlink" title="工作"></a>工作</h3><blockquote><p>实习</p></blockquote><p>从2019.04-2019.06，大概面了4，5家的算法，都是大厂，被各种蹂躏，我怂了，之后暑假就没再继续了。这是我找工作以来最大的错。</p><p>总结失误：</p><ul><li>不应该上来先面大厂；</li><li>不应该不认真刷题；</li><li>不应该自惭形秽；</li></ul><p>最终2019.09在百姓网实习了4周左右，一边忙着秋招一边实习，真的心都要操碎了。</p><p>谢谢各位。所幸最终的结果是我能接受的。</p><p>因为这样的消极害怕的心理，直接导致自己错过提前批，正式批的笔试都没有通过一家，真的太菜了。还是要努力多学习多刷题，掌握到的编程技能是自己的，会是永远都有用的。</p><blockquote><p>Offer</p></blockquote><p>最后拿到的offer居然是早早就面的第一家，ZTE，这样想想，真的认真面试的只有ZTE和华为两家，华为的依然不是很匹配，被刷掉了。ZTE的说是C++软开，但是偏通信系统协议，依然不能说是理想。而且薪水比较同学差距也有一些。</p><p>谁叫我是菜鸡呢..哭…</p><p>先拿到上海的户口，2020.07入职，2021.04我一定会进入头条或者PDD其中之一的，FLAG立在这了。</p><h2 id="2020，我想要什么？"><a href="#2020，我想要什么？" class="headerlink" title="2020，我想要什么？"></a>2020，我想要什么？</h2><p>2020年鼠年，我刚刚结束了自己的本命年，在实验室做毕设，有几个聊得来的朋友，马上会面临毕业和工作，带着自己并不娴熟的技能，一切好像没那么好，也没那么糟。元旦这天，我想许很多的心愿，希望能在这一年得到回应。</p><p>小孩子都会贪心的。我想要很好的技能，很多的钱，很多的朋友，很充实的时间。</p><p>技能方面：</p><ol><li>C++（工作必须）</li><li>NLP，Python，PyTorch（毕设以及个人发展）</li><li>英语</li></ol><p>生活方面：</p><ol><li>Kindle（想捡起阅读的习惯）</li><li>显示器，桌椅（和我的Surface配合应该算个不错的生产环境）</li><li>羽毛球拍，球鞋</li></ol><p>另外还有，希望顺利毕业，希望工作后也能有生活，希望朋友一直都能毫无芥蒂，希望我喜欢的人也恰好看到了我。</p><p>FLAG:</p><ol><li>新建一个Github账号，把现在的东西慢慢自己写一遍；</li><li>每天commit，少一个commit就减餐一顿；</li><li>27w—&gt;35w，要相信自己努力提高就可以达到。</li></ol><p>总之，2020年，各位一起变得更好吧~ 流年笑掷，未来可期！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 年终总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01_PyTorch基础使用</title>
      <link href="/2019/11/07/01-pytorch-ji-chu-shi-yong/"/>
      <url>/2019/11/07/01-pytorch-ji-chu-shi-yong/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>__version__</code></pre><pre><code>'1.3.0'</code></pre><a id="more"></a><h1 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h1><blockquote><p>Tensor的使用：</p></blockquote><ul><li><ol><li>构建</li></ol></li><li><ol start="2"><li>Tensor的基本运算</li></ol></li><li><ol start="3"><li>Tensor与Numpy转换</li></ol></li><li><ol start="4"><li>共享内存的情况</li></ol></li><li><ol start="5"><li>自动微分</li></ol></li></ul><h2 id="1-构建Tensor"><a href="#1-构建Tensor" class="headerlink" title="1. 构建Tensor"></a>1. 构建Tensor</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 构建5×3矩阵，分配空间，不初始化</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 使用特定数据初始化Tensor</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 使用[0, 1]均匀分布随机初始化</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 查看Tensor形状的两种方法</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre><code>3</code></pre><h2 id="2-Tensor的基本运算"><a href="#2-Tensor的基本运算" class="headerlink" title="2. Tensor的基本运算"></a>2. Tensor的基本运算</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加法</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 第一种方式</span>z <span class="token operator">=</span> x <span class="token operator">+</span> y<span class="token comment" spellcheck="true"># 第二种方式</span>torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> out<span class="token operator">=</span>z<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 第三种方式</span>z <span class="token operator">=</span> y<span class="token punctuation">.</span>add<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 第四种方式，修改y值</span>y<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>x<span class="token punctuation">)</span></code></pre><pre><code>tensor([[1.4718, 0.5690, 1.1329],        [0.3453, 0.8727, 0.7226],        [1.2681, 0.8222, 1.8243],        [1.3840, 0.8803, 1.4788],        [1.5312, 1.0661, 0.9357]])</code></pre><h2 id="3-Tensor与Numpy转换"><a href="#3-Tensor与Numpy转换" class="headerlink" title="3. Tensor与Numpy转换"></a>3. Tensor与Numpy转换</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Tensor的切片与Numpy相似,选出index=1的列</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 新建全为1的Tensor</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Tensor->Numpy</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Numpy -> Tensor</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np a <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token triple-quoted-string string">'''要注意这里的a和b内存共享，一个改变，另一个会同时跟随改变'''</span><span class="token comment" spellcheck="true"># 获取某个元素值</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 注意：torch.tensor与torch.Tensor有差别，而且，torch.tensor是对原始tensor的拷贝，不再共享同样的内存</span>z_ <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>z_<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span></code></pre><pre><code>tensor([5., 3.])tensor([5., 3.])tensor([6., 4.])tensor([5., 3.])/home/xwjia/anaconda3/envs/Torch/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).</code></pre><h2 id="4-共享内存情况"><a href="#4-共享内存情况" class="headerlink" title="4. 共享内存情况"></a>4. 共享内存情况</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 当需要共享内存时，可以：</span>a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 或者</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 转换为GPU支持的Tensor</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>a <span class="token operator">=</span> a<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>c <span class="token operator">=</span> a <span class="token operator">+</span> b</code></pre><h2 id="5-自动微分"><a href="#5-自动微分" class="headerlink" title="5. 自动微分"></a>5. 自动微分</h2><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 为Tensor设定可以求导</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token comment" spellcheck="true"># 第二次求导之前要归零，不然会累加</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad</code></pre><pre><code>tensor([[1., 1.],        [1., 1.]])</code></pre><pre class=" language-python"><code class="language-python"></code></pre><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>导入<code>torch.nn</code>，封装可以自动求导，只需要在自定义的类继承于<code>nn.Module</code>,类中需要实现<code>__init__</code>和<code>forward</code>方法；</p><p>其中：</p><ul><li><ol><li><code>__init__</code>中存放网络中可以学习的参数；</li></ol></li><li><ol start="2"><li><code>super(Net, self).__init__()</code>等价于父类<code>nn.Module.__init__(self)</code></li></ol></li><li><ol start="3"><li>网络中不学习的参数，比如最大池化或者ReLU，可以放在<code>forward</code>方法中</li></ol></li></ul><h2 id="1-自定义神经网络"><a href="#1-自定义神经网络" class="headerlink" title="1. 自定义神经网络"></a>1. 自定义神经网络</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F <span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#reshape, '-1'表示自适应</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 打印网络可学习的参数</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">)</span>params <span class="token operator">=</span> list<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> parameters <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> parameters<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&lt;generator object Module.parameters at 0x7fb59472e7d0&gt;&lt;bound method Module.named_parameters of Net(  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))&gt;10conv1.weight : torch.Size([6, 1, 5, 5])conv1.bias : torch.Size([6])conv2.weight : torch.Size([16, 6, 5, 5])conv2.bias : torch.Size([16])fc1.weight : torch.Size([120, 400])fc1.bias : torch.Size([120])fc2.weight : torch.Size([84, 120])fc2.bias : torch.Size([84])fc3.weight : torch.Size([10, 84])fc3.bias : torch.Size([10])</code></pre><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>input<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>out <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>out<span class="token comment" spellcheck="true"># 所有参数清零</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="需要注意的是，torch-nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用-input-unsqueeze-0-将batch-size设为１。例如-nn-Conv2d-输入必须是4维的，形如"><a href="#需要注意的是，torch-nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用-input-unsqueeze-0-将batch-size设为１。例如-nn-Conv2d-输入必须是4维的，形如" class="headerlink" title="需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 input.unsqueeze(0)将batch_size设为１。例如 nn.Conv2d 输入必须是4维的，形如"></a>需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 <code>input.unsqueeze(0)</code>将batch_size设为１。例如 <code>nn.Conv2d</code> 输入必须是4维的，形如</h3><p>$$<br>nSamples \times nChannels \times Height \times Width<br>$$</p><h3 id="可将nSample设为1，即"><a href="#可将nSample设为1，即" class="headerlink" title="可将nSample设为1，即"></a>可将nSample设为1，即</h3><p>$$<br>1 \times nChannels \times Height \times Width<br>$$</p><h2 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2. 损失函数"></a>2. 损失函数</h2><ul><li><ol><li><code>nn.MSELoss</code>计算均方误差；</li></ol></li><li><ol start="2"><li><code>nn.CrossEntropyLoss</code>计算交叉熵损失；</li></ol></li></ul><pre class=" language-python"><code class="language-python">input <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span></code></pre><pre><code>tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])tensor(28.4120, grad_fn=&lt;MseLossBackward&gt;)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 运行.backward,可以观察调用反向传播之前和之后的grad</span>net<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 把net中的所有可学习参数的梯度清零</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"反向传播之前 conv1.bias 的梯度"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"反向传播之后...."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>conv1<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>grad<span class="token punctuation">)</span></code></pre><pre><code>反向传播之前 conv1.bias 的梯度tensor([0., 0., 0., 0., 0., 0.])反向传播之后....tensor([ 0.0700, -0.0912,  0.0596,  0.0453,  0.0661,  0.0147])</code></pre><h2 id="3-优化器"><a href="#3-优化器" class="headerlink" title="3. 优化器"></a>3. 优化器</h2><p>反向传播计算梯度之后，还需要要优化方法更新网络的权重和参数，比如<code>SGD</code>:</p><p><code>weight = weight - learning_rate * gradient</code></p><p>手动实现如下：</p><pre class=" language-python"><code class="language-python">learning_rate <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> f <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    f<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sub_<span class="token punctuation">(</span>f<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token operator">*</span> learning_rate<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># inplace 减法</span></code></pre><p><code>torch.optim</code>中实现了深度学习中绝大多数的优化方法，例如RMSProp、Adam、SGD等，更便于使用，因此大多数时候并不需要手动写上述代码。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment" spellcheck="true"># 新建优化器， 指定需要调整的参数和学习率</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 训练时，梯度先清零：</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 计算loss</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>input<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 反向传播</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 更新参数</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><h2 id="4-数据加载和预处理"><a href="#4-数据加载和预处理" class="headerlink" title="4. 数据加载和预处理"></a>4. 数据加载和预处理</h2><p><code>torchvision</code>实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。</p><h3 id="小试牛刀：CIFAR-10分类"><a href="#小试牛刀：CIFAR-10分类" class="headerlink" title="小试牛刀：CIFAR-10分类"></a>小试牛刀：CIFAR-10分类</h3><p>下面我们来尝试实现对CIFAR-10数据集的分类，步骤如下: </p><ol><li>使用torchvision加载并预处理CIFAR-10数据集</li><li>定义网络</li><li>定义损失函数和优化器</li><li>训练网络并更新网络参数</li><li>测试网络</li></ol><h4 id="CIFAR-10数据加载及预处理"><a href="#CIFAR-10数据加载及预处理" class="headerlink" title="CIFAR-10数据加载及预处理"></a>CIFAR-10数据加载及预处理</h4><p>CIFAR-10<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener">^3</a>是一个常用的彩色图片数据集，它有10个类别: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。每张图片都是$3\times32\times32$，也即3-通道彩色图片，分辨率为$32\times32$。</p><h2 id="5-完整CIFAR-10分类练习"><a href="#5-完整CIFAR-10分类练习" class="headerlink" title="5. 完整CIFAR-10分类练习"></a>5. 完整CIFAR-10分类练习</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchvision  <span class="token keyword">as</span> tv <span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToPILImageshow <span class="token operator">=</span> ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 可以把Tensor转成Image，方便可视化</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#归一化</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练集</span>trainset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span></code></pre><pre><code>0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/xwjia/tmp/data/cifar-10-python.tar.gz 99%|█████████▉| 169443328/170498071 [00:20&lt;00:00, 11268338.34it/s]Extracting /home/xwjia/tmp/data/cifar-10-python.tar.gz to /home/xwjia/tmp/data/</code></pre><pre class=" language-python"><code class="language-python">trainloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    trainset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 测试集</span>testset <span class="token operator">=</span> tv<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'/home/xwjia/tmp/data/'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>testloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    testset<span class="token punctuation">,</span>    batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'plane'</span><span class="token punctuation">,</span> <span class="token string">'car'</span><span class="token punctuation">,</span> <span class="token string">'bird'</span><span class="token punctuation">,</span> <span class="token string">'cat'</span><span class="token punctuation">,</span>           <span class="token string">'deer'</span><span class="token punctuation">,</span> <span class="token string">'dog'</span><span class="token punctuation">,</span> <span class="token string">'frog'</span><span class="token punctuation">,</span> <span class="token string">'horse'</span><span class="token punctuation">,</span> <span class="token string">'ship'</span><span class="token punctuation">,</span> <span class="token string">'truck'</span><span class="token punctuation">)</span></code></pre><pre><code>Files already downloaded and verified</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 查看某个样本</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token operator">=</span> trainset<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>classes<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>ship</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_29_1.png" alt="png"></p><p>Dataloader是一个可迭代的对象，它将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。</p><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#返回下一个batch，4张图片和标签</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%11s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span><span class="token punctuation">(</span>images<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>truck         cat       plane       truck</code></pre><p><img src="/2019/11/07/01-pytorch-ji-chu-shi-yong/output_31_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 自定义网络结构</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc1   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>fc2   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3   <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>         x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                <span class="token keyword">return</span> xnet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span></code></pre><pre><code>Net(  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  (fc1): Linear(in_features=400, out_features=120, bias=True)  (fc2): Linear(in_features=120, out_features=84, bias=True)  (fc3): Linear(in_features=84, out_features=10, bias=True))</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义损失函数和优化器</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> optimcriterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练网络</span>torch<span class="token punctuation">.</span>set_num_threads<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 输入数据</span>        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        <span class="token comment" spellcheck="true"># 梯度清零</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># forward + backward</span>        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 更新参数</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 打印log信息</span>        <span class="token comment" spellcheck="true"># loss是一个scalar， 需要使用loss.item()获取数值， 不能使用loss[0]</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">1999</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true"># 每2000个batch打印一下训练状态</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span><span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> running_loss<span class="token operator">/</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            running_loss <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span></code></pre><pre><code>[1,  2000] loss: 2.163[1,  4000] loss: 1.823[1,  6000] loss: 1.656[1,  8000] loss: 1.586[1, 10000] loss: 1.495[1, 12000] loss: 1.467[2,  2000] loss: 1.405[2,  4000] loss: 1.376[2,  6000] loss: 1.343[2,  8000] loss: 1.322[2, 10000] loss: 1.320[2, 12000] loss: 1.311Finished Training</code></pre><h3 id="接下来看测试集，测试训练的结果"><a href="#接下来看测试集，测试训练的结果" class="headerlink" title="接下来看测试集，测试训练的结果"></a>接下来看测试集，测试训练的结果</h3><pre class=" language-python"><code class="language-python">dataiter <span class="token operator">=</span> iter<span class="token punctuation">(</span>testloader<span class="token punctuation">)</span>images<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataiter<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'实际的label: '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%08s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>show<span class="token punctuation">(</span>tv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>images<span class="token operator">/</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 计算图片在每个类别上的分数</span>outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 得分最高的那个类</span>_<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果： '</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'%5s'</span><span class="token operator">%</span>classes<span class="token punctuation">[</span>predicted<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>预测结果：    cat  ship  ship plane</code></pre><pre class=" language-python"><code class="language-python">correct <span class="token operator">=</span> <span class="token number">0</span>   <span class="token comment" spellcheck="true"># 预测正确的图片数</span>total <span class="token operator">=</span> <span class="token number">0</span>     <span class="token comment" spellcheck="true"># 总共的图片数</span><span class="token comment" spellcheck="true"># 由于测试时不需要求导， 所以可以暂时关闭autograd， 提高速度， 节约内存</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> testloader<span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"10000张测试集中的准确率是： %d %%"</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token operator">/</span>total<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>10000张测试集中的准确率是： 54 %</code></pre><h2 id="在GPU上训练"><a href="#在GPU上训练" class="headerlink" title="在GPU上训练"></a>在GPU上训练</h2><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>images <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>output <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> labels<span class="token punctuation">)</span></code></pre><p>对PyTorch的基础介绍至此结束。总结一下，本节主要包含以下内容。</p><ol><li>Tensor: 类似Numpy数组的数据结构，与Numpy接口类似，可方便地互相转换。</li><li>autograd/: 为tensor提供自动求导功能。</li><li>nn: 专门为神经网络设计的接口，提供了很多有用的功能(神经网络层，损失函数，优化器等)。</li><li>神经网络训练: 以CIFAR-10分类为例演示了神经网络的训练流程，包括数据加载、网络搭建、训练及测试。</li></ol><p>从下一章开始，本书将深入系统地讲解PyTorch的各部分知识。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch框架入门与实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/10/20/hello-world/"/>
      <url>/2019/10/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
